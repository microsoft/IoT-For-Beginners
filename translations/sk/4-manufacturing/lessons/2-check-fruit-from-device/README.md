<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "557f4ee96b752e0651d2e6e74aa6bd14",
  "translation_date": "2025-08-28T08:38:22+00:00",
  "source_file": "4-manufacturing/lessons/2-check-fruit-from-device/README.md",
  "language_code": "sk"
}
-->
# Skontrolujte kvalitu ovocia pomocou IoT zariadenia

![Prehƒæad tejto lekcie vo forme sketchnote](../../../../../translated_images/lesson-16.215daf18b00631fbdfd64c6fc2dc6044dff5d544288825d8076f9fb83d964c23.sk.jpg)

> Sketchnote od [Nitya Narasimhan](https://github.com/nitya). Kliknite na obr√°zok pre jeho zv√§ƒç≈°en√∫ verziu.

## Kv√≠z pred predn√°≈°kou

[Kv√≠z pred predn√°≈°kou](https://black-meadow-040d15503.1.azurestaticapps.net/quiz/31)

## √övod

V predch√°dzaj√∫cej lekcii ste sa nauƒçili o klasifik√°toroch obr√°zkov a o tom, ako ich tr√©nova≈• na rozpozn√°vanie dobr√©ho a zl√©ho ovocia. Aby ste mohli tento klasifik√°tor obr√°zkov pou≈æi≈• v IoT aplik√°cii, potrebujete by≈• schopn√≠ zachyti≈• obr√°zok pomocou nejakej kamery a odosla≈• tento obr√°zok do cloudu na klasifik√°ciu.

V tejto lekcii sa nauƒç√≠te o kamerov√Ωch senzoroch a o tom, ako ich pou≈æ√≠va≈• s IoT zariaden√≠m na zachytenie obr√°zku. Tie≈æ sa nauƒç√≠te, ako zavola≈• klasifik√°tor obr√°zkov z v√°≈°ho IoT zariadenia.

V tejto lekcii sa budeme venova≈•:

* [Kamerov√Ωm senzorom](../../../../../4-manufacturing/lessons/2-check-fruit-from-device)
* [Zachyteniu obr√°zku pomocou IoT zariadenia](../../../../../4-manufacturing/lessons/2-check-fruit-from-device)
* [Publikovaniu v√°≈°ho klasifik√°tora obr√°zkov](../../../../../4-manufacturing/lessons/2-check-fruit-from-device)
* [Klasifik√°cii obr√°zkov z v√°≈°ho IoT zariadenia](../../../../../4-manufacturing/lessons/2-check-fruit-from-device)
* [Zlep≈°eniu modelu](../../../../../4-manufacturing/lessons/2-check-fruit-from-device)

## Kamerov√© senzory

Kamerov√© senzory, ako u≈æ n√°zov napoved√°, s√∫ kamery, ktor√© m√¥≈æete pripoji≈• k v√°≈°mu IoT zariadeniu. M√¥≈æu zachyt√°va≈• statick√© obr√°zky alebo streamova≈• video. Niektor√© vracaj√∫ surov√© obrazov√© d√°ta, in√© komprimuj√∫ obrazov√© d√°ta do s√∫borov ako JPEG alebo PNG. Kamery, ktor√© pracuj√∫ s IoT zariadeniami, s√∫ zvyƒçajne oveƒæa men≈°ie a maj√∫ ni≈æ≈°ie rozl√≠≈°enie, ne≈æ na ak√© ste zvyknut√≠, ale m√¥≈æete z√≠ska≈• aj kamery s vysok√Ωm rozl√≠≈°en√≠m, ktor√© sa vyrovnaj√∫ ≈°piƒçkov√Ωm telef√≥nom. K dispoz√≠cii s√∫ r√¥zne vymeniteƒæn√© objekt√≠vy, viacn√°sobn√© kamerov√© zostavy, infraƒçerven√© termokamery alebo UV kamery.

![Svetlo zo sc√©ny prech√°dza cez objekt√≠v a zaostruje sa na CMOS senzor](../../../../../translated_images/cmos-sensor.75f9cd74decb137149a4c9ea825251a4549497d67c0ae2776159e6102bb53aa9.sk.png)

V√§ƒç≈°ina kamerov√Ωch senzorov pou≈æ√≠va obrazov√© senzory, kde ka≈æd√Ω pixel je fotodi√≥da. Objekt√≠v zaostruje obraz na obrazov√Ω senzor a tis√≠ce alebo mili√≥ny fotodi√≥d deteguj√∫ svetlo dopadaj√∫ce na ka≈æd√∫ z nich a zaznamen√°vaj√∫ to ako obrazov√© d√°ta.

> üíÅ Objekt√≠vy prevracaj√∫ obrazy, kamerov√Ω senzor ich potom otoƒç√≠ sp√§≈• do spr√°vnej polohy. To ist√© sa deje vo va≈°ich oƒçiach ‚Äì to, ƒço vid√≠te, je detegovan√© hore nohami na zadnej strane v√°≈°ho oka a v√°≈° mozog to oprav√≠.

> üéì Obrazov√Ω senzor je zn√°my ako senzor s akt√≠vnym pixelom (APS) a najpopul√°rnej≈°√≠m typom APS je senzor na b√°ze komplement√°rneho kovovo-oxidov√©ho polovodiƒça, alebo CMOS. Mo≈æno ste u≈æ poƒçuli pojem CMOS senzor pou≈æ√≠van√Ω pre kamerov√© senzory.

Kamerov√© senzory s√∫ digit√°lne senzory, ktor√© posielaj√∫ obrazov√© d√°ta ako digit√°lne d√°ta, zvyƒçajne s pomocou kni≈ænice, ktor√° poskytuje komunik√°ciu. Kamery sa prip√°jaj√∫ pomocou protokolov ako SPI, aby mohli posiela≈• veƒæk√© mno≈æstvo d√°t ‚Äì obr√°zky s√∫ podstatne v√§ƒç≈°ie ako jednotliv√© ƒç√≠sla zo senzora, ako je napr√≠klad teplotn√Ω senzor.

‚úÖ Ak√© s√∫ obmedzenia t√Ωkaj√∫ce sa veƒækosti obr√°zkov pri IoT zariadeniach? Zamyslite sa nad obmedzeniami, najm√§ na hardv√©ri mikrokontrol√©rov.

## Zachytenie obr√°zku pomocou IoT zariadenia

Svoje IoT zariadenie m√¥≈æete pou≈æi≈• na zachytenie obr√°zku, ktor√Ω bude klasifikovan√Ω.

### √öloha ‚Äì zachytenie obr√°zku pomocou IoT zariadenia

Prejdite si pr√≠slu≈°n√Ω n√°vod na zachytenie obr√°zku pomocou v√°≈°ho IoT zariadenia:

* [Arduino - Wio Terminal](wio-terminal-camera.md)
* [Jednodoskov√Ω poƒç√≠taƒç - Raspberry Pi](pi-camera.md)
* [Jednodoskov√Ω poƒç√≠taƒç - Virtu√°lne zariadenie](virtual-device-camera.md)

## Publikovanie v√°≈°ho klasifik√°tora obr√°zkov

V predch√°dzaj√∫cej lekcii ste tr√©novali svoj klasifik√°tor obr√°zkov. Predt√Ωm, ne≈æ ho budete m√¥c≈• pou≈æi≈• z v√°≈°ho IoT zariadenia, mus√≠te model publikova≈•.

### Iter√°cie modelu

Keƒè sa v√°≈° model tr√©noval v predch√°dzaj√∫cej lekcii, mohli ste si v≈°imn√∫≈•, ≈æe na karte **V√Ωkon** sa na strane zobrazuj√∫ iter√°cie. Keƒè ste model prv√Ωkr√°t tr√©novali, videli ste *Iter√°ciu 1* poƒças tr√©ningu. Keƒè ste model zlep≈°ili pomocou predikƒçn√Ωch obr√°zkov, videli ste *Iter√°ciu 2* poƒças tr√©ningu.

Ka≈æd√Ωkr√°t, keƒè model tr√©nujete, z√≠skate nov√∫ iter√°ciu. Toto je sp√¥sob, ako sledova≈• r√¥zne verzie v√°≈°ho modelu tr√©novan√© na r√¥znych d√°tov√Ωch sad√°ch. Keƒè vykon√°te **R√Ωchly test**, je tam rozbaƒæovacia ponuka, ktor√∫ m√¥≈æete pou≈æi≈• na v√Ωber iter√°cie, aby ste mohli porovna≈• v√Ωsledky medzi viacer√Ωmi iter√°ciami.

Keƒè ste spokojn√≠ s iter√°ciou, m√¥≈æete ju publikova≈•, aby bola dostupn√° na pou≈æitie z extern√Ωch aplik√°ci√≠. T√Ωmto sp√¥sobom m√¥≈æete ma≈• publikovan√∫ verziu, ktor√∫ pou≈æ√≠vaj√∫ va≈°e zariadenia, a z√°rove≈à pracova≈• na novej verzii cez viacero iter√°ci√≠, a potom ju publikova≈•, keƒè budete s ≈àou spokojn√≠.

### √öloha ‚Äì publikovanie iter√°cie

Iter√°cie sa publikuj√∫ z port√°lu Custom Vision.

1. Otvorte port√°l Custom Vision na [CustomVision.ai](https://customvision.ai) a prihl√°ste sa, ak ho e≈°te nem√°te otvoren√Ω. Potom otvorte svoj projekt `fruit-quality-detector`.

1. Vyberte kartu **V√Ωkon** z mo≈ænost√≠ v hornej ƒçasti.

1. Vyberte najnov≈°iu iter√°ciu zo zoznamu *Iter√°cie* na strane.

1. Kliknite na tlaƒçidlo **Publikova≈•** pre dan√∫ iter√°ciu.

    ![Tlaƒçidlo publikova≈•](../../../../../translated_images/custom-vision-publish-button.b7174e1977b0c33b8b72d4e5b1326c779e0af196f3849d09985ee2d7d5493a39.sk.png)

1. V dial√≥govom okne *Publikova≈• model* nastavte *Predikƒçn√Ω zdroj* na zdroj `fruit-quality-detector-prediction`, ktor√Ω ste vytvorili v predch√°dzaj√∫cej lekcii. Nechajte n√°zov ako `Iteration2` a kliknite na tlaƒçidlo **Publikova≈•**.

1. Po publikovan√≠ kliknite na tlaƒçidlo **Predikƒçn√° URL adresa**. Toto zobraz√≠ podrobnosti o predikƒçnom API, ktor√© budete potrebova≈• na volanie modelu z v√°≈°ho IoT zariadenia. Spodn√° ƒças≈• je oznaƒçen√° *Ak m√°te s√∫bor s obr√°zkom*, a toto s√∫ detaily, ktor√© potrebujete. Skop√≠rujte URL adresu, ktor√° bude vyzera≈• nejako takto:

    ```output
    https://<location>.api.cognitive.microsoft.com/customvision/v3.0/Prediction/<id>/classify/iterations/Iteration2/image
    ```

    Kde `<location>` bude lokalita, ktor√∫ ste pou≈æili pri vytv√°ran√≠ v√°≈°ho zdroja Custom Vision, a `<id>` bude dlh√© ID zlo≈æen√© z p√≠smen a ƒç√≠sel.

    Tie≈æ si skop√≠rujte hodnotu *Prediction-Key*. Toto je bezpeƒçnostn√Ω kƒæ√∫ƒç, ktor√Ω mus√≠te odosla≈• pri volan√≠ modelu. Len aplik√°cie, ktor√© odosielaj√∫ tento kƒæ√∫ƒç, m√¥≈æu model pou≈æ√≠va≈•, v≈°etky ostatn√© aplik√°cie bud√∫ odmietnut√©.

    ![Dial√≥gov√© okno predikƒçn√©ho API zobrazuj√∫ce URL a kƒæ√∫ƒç](../../../../../translated_images/custom-vision-prediction-key-endpoint.30c569ffd0338864f319911f052d5e9b8c5066cb0800a26dd6f7ff5713130ad8.sk.png)

‚úÖ Keƒè sa publikuje nov√° iter√°cia, bude ma≈• in√Ω n√°zov. Ako si mysl√≠te, ≈æe by ste zmenili iter√°ciu, ktor√∫ pou≈æ√≠va IoT zariadenie?

## Klasifik√°cia obr√°zkov z v√°≈°ho IoT zariadenia

Teraz m√¥≈æete pou≈æi≈• tieto pripojovacie √∫daje na volanie klasifik√°tora obr√°zkov z v√°≈°ho IoT zariadenia.

### √öloha ‚Äì klasifik√°cia obr√°zkov z v√°≈°ho IoT zariadenia

Prejdite si pr√≠slu≈°n√Ω n√°vod na klasifik√°ciu obr√°zkov pomocou v√°≈°ho IoT zariadenia:

* [Arduino - Wio Terminal](wio-terminal-classify-image.md)
* [Jednodoskov√Ω poƒç√≠taƒç - Raspberry Pi/Virtu√°lne IoT zariadenie](single-board-computer-classify-image.md)

## Zlep≈°enie modelu

M√¥≈æe sa sta≈•, ≈æe v√Ωsledky, ktor√© z√≠skate pri pou≈æit√≠ kamery pripojenej k v√°≈°mu IoT zariadeniu, nebud√∫ zodpoveda≈• tomu, ƒço by ste oƒçak√°vali. Predikcie nie s√∫ v≈ædy tak√© presn√© ako pri pou≈æit√≠ obr√°zkov nahran√Ωch z v√°≈°ho poƒç√≠taƒça. Je to preto, ≈æe model bol tr√©novan√Ω na in√Ωch d√°tach, ne≈æ ak√© sa pou≈æ√≠vaj√∫ na predikcie.

Aby ste dosiahli ƒço najlep≈°ie v√Ωsledky pre klasifik√°tor obr√°zkov, chcete model tr√©nova≈• s obr√°zkami, ktor√© s√∫ ƒço najpodobnej≈°ie obr√°zkom pou≈æit√Ωm na predikcie. Ak ste napr√≠klad pou≈æili kameru telef√≥nu na zachytenie obr√°zkov na tr√©ning, kvalita obr√°zkov, ostros≈• a farby bud√∫ odli≈°n√© od kamery pripojenej k IoT zariadeniu.

![2 obr√°zky ban√°nov, jeden s n√≠zkym rozl√≠≈°en√≠m a zl√Ωm osvetlen√≠m z IoT zariadenia, druh√Ω s vysok√Ωm rozl√≠≈°en√≠m a dobr√Ωm osvetlen√≠m z telef√≥nu](../../../../../translated_images/banana-picture-compare.174df164dc326a42cf7fb051a7497e6113c620e91552d92ca914220305d47d9a.sk.png)

Na obr√°zku vy≈°≈°ie bol obr√°zok ban√°nu naƒæavo zachyten√Ω pomocou kamery Raspberry Pi, zatiaƒæ ƒço obr√°zok napravo bol zachyten√Ω toho ist√©ho ban√°nu na tom istom mieste pomocou iPhonu. Je viditeƒæn√Ω rozdiel v kvalite ‚Äì obr√°zok z iPhonu je ostrej≈°√≠, s jasnej≈°√≠mi farbami a v√§ƒç≈°√≠m kontrastom.

‚úÖ ƒåo in√© by mohlo sp√¥sobi≈•, ≈æe obr√°zky zachyten√© va≈°√≠m IoT zariaden√≠m bud√∫ ma≈• nespr√°vne predikcie? Zamyslite sa nad prostred√≠m, v ktorom by mohlo by≈• IoT zariadenie pou≈æit√©, a ak√© faktory m√¥≈æu ovplyvni≈• zachyten√Ω obr√°zok.

Na zlep≈°enie modelu ho m√¥≈æete pretr√©nova≈• pomocou obr√°zkov zachyten√Ωch z IoT zariadenia.

### √öloha ‚Äì zlep≈°enie modelu

1. Klasifikujte viacero obr√°zkov zrel√©ho a nezrel√©ho ovocia pomocou v√°≈°ho IoT zariadenia.

1. Na port√°li Custom Vision pretr√©nujte model pomocou obr√°zkov na karte *Predikcie*.

    > ‚ö†Ô∏è Ak potrebujete, m√¥≈æete sa odvola≈• na [pokyny na pretr√©novanie v√°≈°ho klasifik√°tora v lekcii 1](../1-train-fruit-detector/README.md#retrain-your-image-classifier).

1. Ak va≈°e obr√°zky vyzeraj√∫ veƒæmi odli≈°ne od p√¥vodn√Ωch pou≈æit√Ωch na tr√©ning, m√¥≈æete v≈°etky p√¥vodn√© obr√°zky vymaza≈• tak, ≈æe ich vyberiete na karte *Tr√©ningov√© obr√°zky* a kliknete na tlaƒçidlo **Vymaza≈•**. Na v√Ωber obr√°zku presu≈àte kurzor nad obr√°zok a objav√≠ sa za≈°krt√°vacie pol√≠ƒçko, ktor√© m√¥≈æete vybra≈• alebo zru≈°i≈•.

1. Vytr√©nujte nov√∫ iter√°ciu modelu a publikujte ju podƒæa vy≈°≈°ie uveden√Ωch krokov.

1. Aktualizujte URL adresu koncov√©ho bodu vo va≈°om k√≥de a znova spustite aplik√°ciu.

1. Opakujte tieto kroky, k√Ωm nebudete spokojn√≠ s v√Ωsledkami predikci√≠.

---

## üöÄ V√Ωzva

Ako veƒæmi ovplyv≈àuje rozl√≠≈°enie obr√°zkov alebo osvetlenie predikciu?

Sk√∫ste zmeni≈• rozl√≠≈°enie obr√°zkov vo va≈°om k√≥de zariadenia a zistite, ƒçi to ovplyvn√≠ kvalitu obr√°zkov. Tie≈æ sk√∫ste zmeni≈• osvetlenie.

Ak by ste mali vytvori≈• produkƒçn√© zariadenie na predaj farm√°m alebo tov√°r≈àam, ako by ste zabezpeƒçili, ≈æe bude v≈ædy poskytova≈• konzistentn√© v√Ωsledky?

## Kv√≠z po predn√°≈°ke

[Kv√≠z po predn√°≈°ke](https://black-meadow-040d15503.1.azurestaticapps.net/quiz/32)

## Prehƒæad a samo≈°t√∫dium

Svoj model Custom Vision ste tr√©novali pomocou port√°lu. To z√°vis√≠ od dostupnosti obr√°zkov ‚Äì a v re√°lnom svete nemus√≠te by≈• schopn√≠ z√≠ska≈• tr√©ningov√© d√°ta, ktor√© zodpovedaj√∫ tomu, ƒço zachyt√°va kamera na va≈°om zariaden√≠. Tento probl√©m m√¥≈æete ob√≠s≈• t√Ωm, ≈æe budete tr√©nova≈• priamo z v√°≈°ho zariadenia pomocou tr√©ningov√©ho API, aby ste model tr√©novali pomocou obr√°zkov zachyten√Ωch z v√°≈°ho IoT zariadenia.

* Preƒç√≠tajte si o tr√©ningovom API v [r√Ωchlom ≈°tarte pou≈æ√≠vania Custom Vision SDK](https://docs.microsoft.com/azure/cognitive-services/custom-vision-service/quickstarts/image-classification?WT.mc_id=academic-17441-jabenn&tabs=visual-studio&pivots=programming-language-python)

## Zadanie

[Reagujte na v√Ωsledky klasifik√°cie](assignment.md)

---

**Upozornenie**:  
Tento dokument bol prelo≈æen√Ω pomocou slu≈æby na automatick√Ω preklad [Co-op Translator](https://github.com/Azure/co-op-translator). Hoci sa sna≈æ√≠me o presnos≈•, upozor≈àujeme, ≈æe automatick√© preklady m√¥≈æu obsahova≈• chyby alebo nepresnosti. P√¥vodn√Ω dokument v jeho p√¥vodnom jazyku by mal by≈• pova≈æovan√Ω za autoritat√≠vny zdroj. Pre kritick√© inform√°cie sa odpor√∫ƒça profesion√°lny ƒæudsk√Ω preklad. Nezodpoved√°me za ≈æiadne nedorozumenia alebo nespr√°vne interpret√°cie vypl√Ωvaj√∫ce z pou≈æitia tohto prekladu.