<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "606f3af1c78e3741e48ce77c31cea626",
  "translation_date": "2025-08-28T09:02:51+00:00",
  "source_file": "6-consumer/lessons/3-spoken-feedback/pi-text-to-speech.md",
  "language_code": "sk"
}
-->
# Text na re캜 - Raspberry Pi

V tejto 캜asti lekcie nap칤코ete k칩d na konverziu textu na re캜 pomocou slu쬭y re캜i.

## Konverzia textu na re캜 pomocou slu쬭y re캜i

Text m칪쬰 by콘 odoslan칳 do slu쬭y re캜i pomocou REST API, aby sa z칤skala re캜 vo forme zvukov칠ho s칰boru, ktor칳 je mo쬹칠 prehra콘 na va코om IoT zariaden칤. Pri po쬴adavke na re캜 je potrebn칠 zada콘 hlas, ktor칳 sa m치 pou쬴콘, preto쬰 re캜 m칪쬰 by콘 generovan치 pomocou r칪znych hlasov.

Ka쬯칳 jazyk podporuje r칪zne hlasy a m칪쬰te vykona콘 REST po쬴adavku na slu쬭u re캜i, aby ste z칤skali zoznam podporovan칳ch hlasov pre ka쬯칳 jazyk.

### 칔loha - z칤skanie hlasu

1. Otvorte projekt `smart-timer` vo VS Code.

1. Pridajte nasleduj칰ci k칩d nad funkciu `say`, aby ste po쬴adali o zoznam hlasov pre jazyk:

    ```python
    def get_voice():
        url = f'https://{location}.tts.speech.microsoft.com/cognitiveservices/voices/list'
    
        headers = {
            'Authorization': 'Bearer ' + get_access_token()
        }
    
        response = requests.get(url, headers=headers)
        voices_json = json.loads(response.text)
    
        first_voice = next(x for x in voices_json if x['Locale'].lower() == language.lower() and x['VoiceType'] == 'Neural')
        return first_voice['ShortName']
    
    voice = get_voice()
    print(f'Using voice {voice}')
    ```

    Tento k칩d definuje funkciu nazvan칰 `get_voice`, ktor치 pou쮂셨a slu쬭u re캜i na z칤skanie zoznamu hlasov. N치sledne n치jde prv칳 hlas, ktor칳 zodpoved치 pou쮂셨an칠mu jazyku.

    T치to funkcia je potom volan치 na ulo쬰nie prv칠ho hlasu a n치zov hlasu je vytla캜en칳 do konzoly. Tento hlas m칪쬰 by콘 po쬬dovan칳 raz a jeho hodnota pou쬴t치 pri ka쬯om volan칤 na konverziu textu na re캜.

    > 游누 Kompletn칳 zoznam podporovan칳ch hlasov m칪쬰te z칤ska콘 z [dokument치cie o podpore jazykov a hlasov na Microsoft Docs](https://docs.microsoft.com/azure/cognitive-services/speech-service/language-support?WT.mc_id=academic-17441-jabenn#text-to-speech). Ak chcete pou쬴콘 konkr칠tny hlas, m칪쬰te t칰to funkciu odstr치ni콘 a pevne zada콘 hlas pod쬬 n치zvu hlasu z tejto dokument치cie. Napr칤klad:
    >
    > ```python
    > voice = 'hi-IN-SwaraNeural'
    > ```

### 칔loha - konverzia textu na re캜

1. Pod t칳mto definujte kon코tantu pre form치t zvuku, ktor칳 sa m치 z칤ska콘 zo slu쬭y re캜i. Pri po쬴adavke na zvuk m칪쬰te pou쬴콘 r칪zne form치ty.

    ```python
    playback_format = 'riff-48khz-16bit-mono-pcm'
    ```

    Form치t, ktor칳 m칪쬰te pou쬴콘, z치vis칤 od v치코ho hardv칠ru. Ak dostanete chyby `Invalid sample rate` pri prehr치van칤 zvuku, zme켿te to na in칰 hodnotu. Zoznam podporovan칳ch hodn칪t n치jdete v [dokument치cii REST API pre text na re캜 na Microsoft Docs](https://docs.microsoft.com/azure/cognitive-services/speech-service/rest-text-to-speech?WT.mc_id=academic-17441-jabenn#audio-outputs). Budete musie콘 pou쬴콘 zvuk vo form치te `riff` a hodnoty, ktor칠 m칪쬰te vysk칰코a콘, s칰 `riff-16khz-16bit-mono-pcm`, `riff-24khz-16bit-mono-pcm` a `riff-48khz-16bit-mono-pcm`.

1. Pod t칳mto deklarujte funkciu nazvan칰 `get_speech`, ktor치 bude konvertova콘 text na re캜 pomocou REST API slu쬭y re캜i:

    ```python
    def get_speech(text):
    ```

1. Vo funkcii `get_speech` definujte URL na volanie a hlavi캜ky na odoslanie:

    ```python
        url = f'https://{location}.tts.speech.microsoft.com/cognitiveservices/v1'
    
        headers = {
            'Authorization': 'Bearer ' + get_access_token(),
            'Content-Type': 'application/ssml+xml',
            'X-Microsoft-OutputFormat': playback_format
        }
    ```

    Toto nastav칤 hlavi캜ky na pou쬴tie generovan칠ho pr칤stupov칠ho tokenu, nastav칤 obsah na SSML a definuje potrebn칳 form치t zvuku.

1. Pod t칳mto definujte SSML na odoslanie do REST API:

    ```python
    ssml =  f'<speak version=\'1.0\' xml:lang=\'{language}\'>'
    ssml += f'<voice xml:lang=\'{language}\' name=\'{voice}\'>'
    ssml += text
    ssml += '</voice>'
    ssml += '</speak>'
    ```

    Tento SSML nastav칤 jazyk a hlas, ktor칳 sa m치 pou쬴콘, spolu s textom na konverziu.

1. Nakoniec pridajte k칩d do tejto funkcie na vykonanie REST po쬴adavky a vr치tenie bin치rnych zvukov칳ch d치t:

    ```python
    response = requests.post(url, headers=headers, data=ssml.encode('utf-8'))
    return io.BytesIO(response.content)
    ```

### 칔loha - prehr치vanie zvuku

1. Pod funkciou `get_speech` definujte nov칰 funkciu na prehr치vanie zvuku vr치ten칠ho z REST API volania:

    ```python
    def play_speech(speech):
    ```

1. Parameter `speech` odovzdan칳 do tejto funkcie bude bin치rny zvukov칳 칰daj vr치ten칳 z REST API. Pou쬴te nasleduj칰ci k칩d na otvorenie tohto ako wave s칰boru a jeho odovzdanie do PyAudio na prehr치vanie zvuku:

    ```python
    def play_speech(speech):
        with wave.open(speech, 'rb') as wave_file:
            stream = audio.open(format=audio.get_format_from_width(wave_file.getsampwidth()),
                                channels=wave_file.getnchannels(),
                                rate=wave_file.getframerate(),
                                output_device_index=speaker_card_number,
                                output=True)

            data = wave_file.readframes(4096)

            while len(data) > 0:
                stream.write(data)
                data = wave_file.readframes(4096)

            stream.stop_stream()
            stream.close()
    ```

    Tento k칩d pou쮂셨a PyAudio stream, rovnako ako pri zachyt치van칤 zvuku. Rozdiel je v tom, 쬰 stream je nastaven칳 ako v칳stupn칳 stream a 칰daje s칰 캜칤tan칠 zo zvukov칳ch d치t a pos칰van칠 do streamu.

    Namiesto pevn칠ho nastavenia detailov streamu, ako je vzorkovacia frekvencia, s칰 tieto 칰daje 캜칤tan칠 zo zvukov칳ch d치t.

1. Nahra캞te obsah funkcie `say` nasleduj칰cim:

    ```python
    speech = get_speech(text)
    play_speech(speech)
    ```

    Tento k칩d konvertuje text na re캜 ako bin치rne zvukov칠 칰daje a prehr치va zvuk.

1. Spustite aplik치ciu a uistite sa, 쬰 funk캜n치 aplik치cia tie be쮂. Nastavte nieko쬶o 캜asova캜ov a budete po캜u콘 hovoren칰 odpove캞, ktor치 ozn치mi, 쬰 v치코 캜asova캜 bol nastaven칳, a potom 캞al코iu hovoren칰 odpove캞, ke캞 캜asova캜 skon캜칤.

    Ak dostanete chyby `Invalid sample rate`, zme켿te `playback_format` pod쬬 vy코코ie uveden칠ho popisu.

> 游누 Tento k칩d n치jdete v prie캜inku [code-spoken-response/pi](../../../../../6-consumer/lessons/3-spoken-feedback/code-spoken-response/pi).

游 V치코 program 캜asova캜a bol 칰spe코n칳!

---

**Upozornenie**:  
Tento dokument bol prelo쬰n칳 pomocou slu쬭y na automatick칳 preklad [Co-op Translator](https://github.com/Azure/co-op-translator). Aj ke캞 sa sna쮂셠e o presnos콘, upozor켿ujeme, 쬰 automatick칠 preklady m칪쬿 obsahova콘 chyby alebo nepresnosti. P칪vodn칳 dokument v jeho p칪vodnom jazyku by mal by콘 pova쬺van칳 za autoritat칤vny zdroj. Pre d칪le쬴t칠 inform치cie sa odpor칰캜a profesion치lny 쬿dsk칳 preklad. Nezodpoved치me za ak칠ko쭀ek nedorozumenia alebo nespr치vne interpret치cie vypl칳vaj칰ce z pou쬴tia tohto prekladu.