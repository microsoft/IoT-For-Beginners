<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "a202fa5889790a3777bfc33dd9f4b459",
  "translation_date": "2025-08-28T08:59:25+00:00",
  "source_file": "6-consumer/lessons/3-spoken-feedback/wio-terminal-text-to-speech.md",
  "language_code": "sk"
}
-->
# Text na re캜 - Wio Terminal

V tejto 캜asti lekcie prevediete text na re캜, aby ste poskytli hovoren칰 sp칛tn칰 v칛zbu.

## Text na re캜

SDK pre slu쬭y re캜i, ktor칠 ste pou쬴li v predch치dzaj칰cej lekcii na prevod re캜i na text, m칪쬰te pou쬴콘 aj na prevod textu sp칛콘 na re캜.

## Z칤skanie zoznamu hlasov

Pri po쬴adavke na re캜 mus칤te zada콘 hlas, ktor칳 sa m치 pou쬴콘, preto쬰 re캜 m칪쬰 by콘 generovan치 pomocou r칪znych hlasov. Ka쬯칳 jazyk podporuje r칪zne hlasy a zoznam podporovan칳ch hlasov pre ka쬯칳 jazyk m칪쬰te z칤ska콘 zo slu쬭y re캜i SDK. Tu sa prejavuj칰 obmedzenia mikrokontrol칠rov - volanie na z칤skanie zoznamu hlasov podporovan칳ch slu쬭ami text na re캜 je JSON dokument s ve쬶os콘ou viac ako 77 KB, 캜o je pr칤li코 ve쬶칠 na spracovanie Wio Terminalom. V 캜ase p칤sania tento zoznam obsahuje 215 hlasov, pri캜om ka쬯칳 je definovan칳 JSON dokumentom, ako je tento:

```json
{
    "Name": "Microsoft Server Speech Text to Speech Voice (en-US, AriaNeural)",
    "DisplayName": "Aria",
    "LocalName": "Aria",
    "ShortName": "en-US-AriaNeural",
    "Gender": "Female",
    "Locale": "en-US",
    "StyleList": [
        "chat",
        "customerservice",
        "narration-professional",
        "newscast-casual",
        "newscast-formal",
        "cheerful",
        "empathetic"
    ],
    "SampleRateHertz": "24000",
    "VoiceType": "Neural",
    "Status": "GA"
}
```

Tento JSON je pre hlas **Aria**, ktor칳 m치 viacero 코t칳lov hlasu. Na prevod textu na re캜 sta캜칤 kr치tky n치zov, `en-US-AriaNeural`.

Namiesto s콘ahovania a dek칩dovania cel칠ho tohto zoznamu na va코om mikrokontrol칠ri budete musie콘 nap칤sa콘 캞al코칤 serverless k칩d na z칤skanie zoznamu hlasov pre jazyk, ktor칳 pou쮂셨ate, a zavola콘 ho z v치코ho Wio Terminalu. V치코 k칩d potom m칪쬰 vybra콘 vhodn칳 hlas zo zoznamu, napr칤klad prv칳, ktor칳 n치jde.

### 칔loha - vytvorte serverless funkciu na z칤skanie zoznamu hlasov

1. Otvorte svoj projekt `smart-timer-trigger` vo VS Code a otvorte termin치l, pri캜om sa uistite, 쬰 virtu치lne prostredie je aktivovan칠. Ak nie, ukon캜ite a znova vytvorte termin치l.

1. Otvorte s칰bor `local.settings.json` a pridajte nastavenia pre k쮂줷 API slu쬭y re캜i a umiestnenie:

    ```json
    "SPEECH_KEY": "<key>",
    "SPEECH_LOCATION": "<location>"
    ```

    Nahra캞te `<key>` k쮂줷꼂m API pre v치코 zdroj slu쬭y re캜i. Nahra캞te `<location>` umiestnen칤m, ktor칠 ste pou쬴li pri vytv치ran칤 zdroja slu쬭y re캜i.

1. Pridajte nov칳 HTTP trigger do tejto aplik치cie s n치zvom `get-voices` pomocou nasleduj칰ceho pr칤kazu z termin치lu VS Code v kore켿ovom prie캜inku projektu aplik치cie funkci칤:

    ```sh
    func new --name get-voices --template "HTTP trigger"
    ```

    T칳m sa vytvor칤 HTTP trigger s n치zvom `get-voices`.

1. Nahra캞te obsah s칰boru `__init__.py` v prie캜inku `get-voices` nasleduj칰cim:

    ```python
    import json
    import os
    import requests
    
    import azure.functions as func
    
    def main(req: func.HttpRequest) -> func.HttpResponse:
        location = os.environ['SPEECH_LOCATION']
        speech_key = os.environ['SPEECH_KEY']
    
        req_body = req.get_json()
        language = req_body['language']
    
        url = f'https://{location}.tts.speech.microsoft.com/cognitiveservices/voices/list'
    
        headers = {
            'Ocp-Apim-Subscription-Key': speech_key
        }
    
        response = requests.get(url, headers=headers)
        voices_json = json.loads(response.text)
    
        voices = filter(lambda x: x['Locale'].lower() == language.lower(), voices_json)
        voices = map(lambda x: x['ShortName'], voices)
    
        return func.HttpResponse(json.dumps(list(voices)), status_code=200)
    ```

    Tento k칩d vykon치 HTTP po쬴adavku na endpoint na z칤skanie hlasov. Tento zoznam hlasov je ve쬶칳 blok JSON s hlasmi pre v코etky jazyky, tak쬰 hlasy pre jazyk odoslan칳 v tele po쬴adavky s칰 filtrovan칠, potom sa extrahuje kr치tky n치zov a vr치ti sa ako JSON zoznam. Kr치tky n치zov je hodnota potrebn치 na prevod textu na re캜, tak쬰 sa vr치ti iba t치to hodnota.

    > 游누 Filter m칪쬰te pod쬬 potreby zmeni콘, aby ste vybrali iba hlasy, ktor칠 chcete.

    T칳m sa ve쬶os콘 칰dajov zn칤쬴 z 77 KB (v 캜ase p칤sania) na ove쬬 men코칤 JSON dokument. Napr칤klad pre americk칠 hlasy je to 408 bajtov.

1. Spustite svoju funk캜n칰 aplik치ciu lok치lne. Potom ju m칪쬰te zavola콘 pomocou n치stroja ako curl rovnak칳m sp칪sobom, ako ste testovali HTTP trigger `text-to-timer`. Uistite sa, 쬰 odosielate svoj jazyk ako JSON telo:

    ```json
    {
        "language":"<language>"
    }
    ```

    Nahra캞te `<language>` svoj칤m jazykom, napr칤klad `en-GB` alebo `zh-CN`.

> 游누 Tento k칩d n치jdete v prie캜inku [code-spoken-response/functions](../../../../../6-consumer/lessons/3-spoken-feedback/code-spoken-response/functions).

### 칔loha - z칤skajte hlas z v치코ho Wio Terminalu

1. Otvorte projekt `smart-timer` vo VS Code, ak e코te nie je otvoren칳.

1. Otvorte hlavi캜kov칳 s칰bor `config.h` a pridajte URL pre va코u funk캜n칰 aplik치ciu:

    ```cpp
    const char *GET_VOICES_FUNCTION_URL = "<URL>";
    ```

    Nahra캞te `<URL>` URL adresou pre HTTP trigger `get-voices` vo va코ej funk캜nej aplik치cii. T치to bude rovnak치 ako hodnota pre `TEXT_TO_TIMER_FUNCTION_URL`, okrem n치zvu funkcie `get-voices` namiesto `text-to-timer`.

1. Vytvorte nov칳 s칰bor v prie캜inku `src` s n치zvom `text_to_speech.h`. Tento s칰bor sa pou쬴je na definovanie triedy na prevod textu na re캜.

1. Pridajte nasleduj칰ce direkt칤vy `include` na za캜iatok nov칠ho s칰boru `text_to_speech.h`:

    ```cpp
    #pragma once

    #include <Arduino.h>
    #include <ArduinoJson.h>
    #include <HTTPClient.h>
    #include <Seeed_FS.h>
    #include <SD/Seeed_SD.h>
    #include <WiFiClient.h>
    #include <WiFiClientSecure.h>
    
    #include "config.h"
    #include "speech_to_text.h"
    ```

1. Pod t칳mto deklarujte triedu `TextToSpeech` spolu s in코tanciou, ktor치 sa m칪쬰 pou쬴콘 v zvy코ku aplik치cie:

    ```cpp
    class TextToSpeech
    {
    public:
    private:
    };
    
    TextToSpeech textToSpeech;
    ```

1. Na volanie va코ej funk캜nej aplik치cie mus칤te deklarova콘 WiFi klienta. Pridajte nasleduj칰ce do sekcie `private` triedy:

    ```cpp
    WiFiClient _client;
    ```

1. V sekcii `private` pridajte pole pre vybran칳 hlas:

    ```cpp
    String _voice;
    ```

1. Do sekcie `public` pridajte funkciu `init`, ktor치 z칤ska prv칳 hlas:

    ```cpp
    void init()
    {
    }
    ```

1. Na z칤skanie hlasov je potrebn칠 odosla콘 JSON dokument do funk캜nej aplik치cie s jazykom. Pridajte nasleduj칰ci k칩d do funkcie `init` na vytvorenie tohto JSON dokumentu:

    ```cpp
    DynamicJsonDocument doc(1024);
    doc["language"] = LANGUAGE;

    String body;
    serializeJson(doc, body);
    ```

1. N치sledne vytvorte `HTTPClient` a pou쬴te ho na volanie funk캜nej aplik치cie na z칤skanie hlasov, odoslan칤m JSON dokumentu:

    ```cpp
    HTTPClient httpClient;
    httpClient.begin(_client, GET_VOICES_FUNCTION_URL);

    int httpResponseCode = httpClient.POST(body);
    ```

1. Pod t칳mto pridajte k칩d na kontrolu k칩du odpovede a ak je 200 (칰spech), extrahujte zoznam hlasov a z칤skajte prv칳 zo zoznamu:

    ```cpp
    if (httpResponseCode == 200)
    {
        String result = httpClient.getString();
        Serial.println(result);

        DynamicJsonDocument doc(1024);
        deserializeJson(doc, result.c_str());

        JsonArray obj = doc.as<JsonArray>();
        _voice = obj[0].as<String>();

        Serial.print("Using voice ");
        Serial.println(_voice);
    }
    else
    {
        Serial.print("Failed to get voices - error ");
        Serial.println(httpResponseCode);
    }
    ```

1. Po tomto ukon캜ite pripojenie HTTP klienta:

    ```cpp
    httpClient.end();
    ```

1. Otvorte s칰bor `main.cpp` a pridajte nasleduj칰cu direkt칤vu `include` na za캜iatok, aby ste zahrnuli tento nov칳 hlavi캜kov칳 s칰bor:

    ```cpp
    #include "text_to_speech.h"
    ```

1. Vo funkcii `setup`, pod volan칤m `speechToText.init();`, pridajte nasleduj칰ce na inicializ치ciu triedy `TextToSpeech`:

    ```cpp
    textToSpeech.init();
    ```

1. Skontrolujte k칩d, nahrajte ho do v치코ho Wio Terminalu a otestujte ho cez s칠riov칳 monitor. Uistite sa, 쬰 va코a funk캜n치 aplik치cia be쮂.

    Uvid칤te zoznam dostupn칳ch hlasov vr치ten칳ch z funk캜nej aplik치cie spolu s vybran칳m hlasom.

    ```output
    --- Available filters and text transformations: colorize, debug, default, direct, hexlify, log2file, nocontrol, printable, send_on_enter, time
    --- More details at http://bit.ly/pio-monitor-filters
    --- Miniterm on /dev/cu.usbmodem1101  9600,8,N,1 ---
    --- Quit: Ctrl+C | Menu: Ctrl+T | Help: Ctrl+T followed by Ctrl+H ---
    Connecting to WiFi..
    Connected!
    Got access token.
    ["en-US-JennyNeural", "en-US-JennyMultilingualNeural", "en-US-GuyNeural", "en-US-AriaNeural", "en-US-AmberNeural", "en-US-AnaNeural", "en-US-AshleyNeural", "en-US-BrandonNeural", "en-US-ChristopherNeural", "en-US-CoraNeural", "en-US-ElizabethNeural", "en-US-EricNeural", "en-US-JacobNeural", "en-US-MichelleNeural", "en-US-MonicaNeural", "en-US-AriaRUS", "en-US-BenjaminRUS", "en-US-GuyRUS", "en-US-ZiraRUS"]
    Using voice en-US-JennyNeural
    Ready.
    ```

## Prevod textu na re캜

Ke캞 m치te hlas, ktor칳 chcete pou쬴콘, m칪쬰te ho pou쬴콘 na prevod textu na re캜. Rovnak칠 obmedzenia pam칛te pre hlasy platia aj pri prevode re캜i na text, tak쬰 re캜 budete musie콘 ulo쬴콘 na SD kartu, aby sa mohla prehra콘 cez ReSpeaker.

> 游누 V predch치dzaj칰cich lekci치ch tohto projektu ste pou쮂셨ali flash pam칛콘 na ukladanie re캜i zachytenej z mikrof칩nu. T치to lekcia pou쮂셨a SD kartu, preto쬰 je jednoduch코ie prehr치va콘 zvuk z nej pomocou kni쬹칤c Seeed audio.

Existuje aj 캞al코ie obmedzenie, ktor칠 treba zv치쬴콘, a to dostupn칠 zvukov칠 d치ta zo slu쬭y re캜i a form치ty, ktor칠 Wio Terminal podporuje. Na rozdiel od plnohodnotn칳ch po캜칤ta캜ov m칪쬿 by콘 zvukov칠 kni쬹ice pre mikrokontrol칠ry ve쬸i obmedzen칠 v podporovan칳ch zvukov칳ch form치toch. Napr칤klad kni쬹ica Seeed Arduino Audio, ktor치 dok치쬰 prehr치va콘 zvuk cez ReSpeaker, podporuje iba zvuk so vzorkovacou frekvenciou 44,1 kHz. Slu쬭y Azure re캜i m칪쬿 poskytova콘 zvuk v nieko쬶칳ch form치toch, ale 쬴adny z nich nepou쮂셨a t칰to vzorkovaciu frekvenciu, poskytuj칰 iba 8 kHz, 16 kHz, 24 kHz a 48 kHz. To znamen치, 쬰 zvuk mus칤 by콘 pre-vzorkovan칳 na 44,1 kHz, 캜o by vy쬬dovalo viac zdrojov, ne m치 Wio Terminal, najm칛 pam칛te.

Ke캞 je potrebn칠 manipulova콘 s 칰dajmi, ako s칰 tieto, je 캜asto lep코ie pou쬴콘 serverless k칩d, najm칛 ak s칰 칰daje z칤skavan칠 prostredn칤ctvom webov칠ho volania. Wio Terminal m칪쬰 zavola콘 serverless funkciu, odovzda콘 text na prevod a serverless funkcia m칪쬰 zavola콘 slu쬭u re캜i na prevod textu na re캜, ako aj pre-vzorkova콘 zvuk na po쬬dovan칰 vzorkovaciu frekvenciu. Potom m칪쬰 vr치ti콘 zvuk vo form치te, ktor칳 Wio Terminal potrebuje, aby sa mohol ulo쬴콘 na SD kartu a prehra콘 cez ReSpeaker.

### 칔loha - vytvorte serverless funkciu na prevod textu na re캜

1. Otvorte svoj projekt `smart-timer-trigger` vo VS Code a otvorte termin치l, pri캜om sa uistite, 쬰 virtu치lne prostredie je aktivovan칠. Ak nie, ukon캜ite a znova vytvorte termin치l.

1. Pridajte nov칳 HTTP trigger do tejto aplik치cie s n치zvom `text-to-speech` pomocou nasleduj칰ceho pr칤kazu z termin치lu VS Code v kore켿ovom prie캜inku projektu aplik치cie funkci칤:

    ```sh
    func new --name text-to-speech --template "HTTP trigger"
    ```

    T칳m sa vytvor칤 HTTP trigger s n치zvom `text-to-speech`.

1. Bal칤k Pip [librosa](https://librosa.org) obsahuje funkcie na pre-vzorkovanie zvuku, tak쬰 ho pridajte do s칰boru `requirements.txt`:

    ```sh
    librosa
    ```

    Po pridan칤 nain코talujte bal칤ky Pip pomocou nasleduj칰ceho pr칤kazu z termin치lu VS Code:

    ```sh
    pip install -r requirements.txt
    ```

    > 丘멆잺 Ak pou쮂셨ate Linux, vr치tane Raspberry Pi OS, mo쬹o budete musie콘 nain코talova콘 `libsndfile` pomocou nasleduj칰ceho pr칤kazu:
    >
    > ```sh
    > sudo apt update
    > sudo apt install libsndfile1-dev
    > ```

1. Na prevod textu na re캜 nem칪쬰te pou쬴콘 priamo k쮂줷 API slu쬭y re캜i, namiesto toho mus칤te po쬴ada콘 o pr칤stupov칳 token, pri캜om na autentifik치ciu po쬴adavky na pr칤stupov칳 token pou쬴jete k쮂줷 API. Otvorte s칰bor `__init__.py` z prie캜inka `text-to-speech` a nahra캞te v코etok k칩d v 켿om nasleduj칰cim:

    ```python
    import io
    import os
    import requests
    
    import librosa
    import soundfile as sf
    import azure.functions as func
    
    location = os.environ['SPEECH_LOCATION']
    speech_key = os.environ['SPEECH_KEY']
    
    def get_access_token():
        headers = {
            'Ocp-Apim-Subscription-Key': speech_key
        }
    
        token_endpoint = f'https://{location}.api.cognitive.microsoft.com/sts/v1.0/issuetoken'
        response = requests.post(token_endpoint, headers=headers)
        return str(response.text)
    ```

    T칳m sa definuj칰 kon코tanty pre umiestnenie a k쮂줷 slu쬭y re캜i, ktor칠 sa na캜칤taj칰 z nastaven칤. Potom sa definuje funkcia `get_access_token`, ktor치 z칤ska pr칤stupov칳 token pre slu쬭u re캜i.

1. Pod tento k칩d pridajte nasleduj칰ce:

    ```python
    playback_format = 'riff-48khz-16bit-mono-pcm'

    def main(req: func.HttpRequest) -> func.HttpResponse:
        req_body = req.get_json()
        language = req_body['language']
        voice = req_body['voice']
        text = req_body['text']
    
        url = f'https://{location}.tts.speech.microsoft.com/cognitiveservices/v1'
    
        headers = {
            'Authorization': 'Bearer ' + get_access_token(),
            'Content-Type': 'application/ssml+xml',
            'X-Microsoft-OutputFormat': playback_format
        }
    
        ssml =  f'<speak version=\'1.0\' xml:lang=\'{language}\'>'
        ssml += f'<voice xml:lang=\'{language}\' name=\'{voice}\'>'
        ssml += text
        ssml += '</voice>'
        ssml += '</speak>'
    
        response = requests.post(url, headers=headers, data=ssml.encode('utf-8'))
    
        raw_audio, sample_rate = librosa.load(io.BytesIO(response.content), sr=48000)
        resampled = librosa.resample(raw_audio, sample_rate, 44100)
        
        output_buffer = io.BytesIO()
        sf.write(output_buffer, resampled, 44100, 'PCM_16', format='wav')
        output_buffer.seek(0)
    
        return func.HttpResponse(output_buffer.read(), status_code=200)
    ```

    T칳m sa definuje HTTP trigger, ktor칳 prev치dza text na re캜. Extrahuje text na prevod, jazyk a hlas z JSON tela odoslan칠ho v po쬴adavke, vytvor칤 SSML na po쬴adavku re캜i a potom zavol치 pr칤slu코n칠 REST API, pri캜om autentifikuje pomocou pr칤stupov칠ho tokenu. Toto volanie REST API vr치ti zvuk k칩dovan칳 ako 16-bitov칳, 48 kHz mono WAV s칰bor, definovan칳 hodnotou `playback_format`, ktor치 sa odosiela do volania REST API.

    Tento zvuk sa potom pre-vzorkuje pomocou `librosa` z vzorkovacej frekvencie 48 kHz na vzorkovaciu frekvenciu 44,1 kHz, potom sa tento zvuk ulo쮂 do bin치rneho bufferu, ktor칳 sa n치sledne vr치ti.

1. Spustite svoju funk캜n칰 aplik치ciu lok치lne alebo ju nasadte do cloudu. Potom ju m칪쬰te zavola콘 pomocou n치stroja ako curl rovnak칳m sp칪sobom, ako ste testovali HTTP trigger `text-to-timer`. Uistite sa, 쬰 odosielate jazyk, hlas a text ako JSON telo:

    ```json
    {
        "language": "<language>",
        "voice": "<voice>",
        "text": "<text>"
    }
    ```

    Nahra캞te `<language>` svoj칤m jazykom, napr칤klad `en-GB` alebo `zh-CN`. Nahra캞te `<voice>` hlasom, ktor칳 chcete pou쬴콘. Nahra캞te `<text>` textom, ktor칳 chcete previes콘 na re캜. V칳stup m칪쬰te ulo쬴콘 do s칰boru a prehra콘 ho pomocou ak칠hoko쭀ek prehr치va캜a, ktor칳 dok치쬰 prehr치va콘 WAV s칰bory.

    Napr칤klad na prevod "Hello" na re캜 pomocou americkej angli캜tiny s hlasom Jenny Neural, s funk캜nou aplik치ciou be쬴acou lok치lne, m칪쬰te pou쬴콘 nasleduj칰ci pr칤kaz curl:

    ```sh
    curl -X GET 'http://localhost:7071/api/text-to-speech' \
         -H 'Content-Type: application/json' \
         -o hello.wav \
         -d '{
           "language":"en-US",
           "voice": "en-US-JennyNeural",
           "text": "Hello"
         }'
    ```

    T칳m sa ulo쮂 zvuk do `hello.wav` v aktu치lnom adres치ri.

> 游누 Tento k칩d n치jdete v prie캜inku [code-spoken-response/functions](../../../../../6-consumer/lessons/3-spoken-feedback/code-spoken-response/functions).

### 칔loha - z칤skajte re캜 z v치코ho Wio Terminalu

1. Otvorte projekt `smart-timer` vo VS Code, ak e코te nie je otvoren칳.

1. Otvorte hlavi캜kov칳 s칰bor `config.h` a pridajte URL pre va코u funk캜n칰 aplik치ciu:

    ```cpp
    const char *TEXT_TO_SPEECH_FUNCTION_URL = "<URL>";
    ```

    Nahra캞te `<URL>` URL adresou pre HTTP trigger `text-to-speech` vo va코ej funk캜nej aplik치cii. T치to bude rovnak치 ako hodnota pre `TEXT_TO_TIMER_FUNCTION_URL`, okrem n치zvu funkcie `text-to-speech` namiesto `text-to-timer`.

1. Otvorte hlavi캜kov칳 s칰bor `text_to_speech.h` a pridajte nasleduj칰cu met칩du do sekcie `public` triedy `TextToSpeech`:

    ```cpp
    void convertTextToSpeech(String text)
    {
    }
    ```

1. Do met칩dy `convertTextToSpeech` pridajte nasleduj칰ci k칩d na vytvorenie JSON na odoslanie do funk캜nej aplik치cie:

    ```cpp
    DynamicJsonDocument doc(1024);
    doc["language"] = LANGUAGE;
    doc["voice"] = _voice;
    doc["text"] = text;

    String body;
    serializeJson(doc, body);
    ```

    Tento k칩d zapisuje jazyk, hlas a text do JSON dokumentu a potom ho serializuje na re콘azec.

1. Pod t칳mto pridajte nasleduj칰ci k칩d na volanie funk캜nej aplik치cie:

    ```cpp
    HTTPClient httpClient;
    httpClient.begin(_client, TEXT_TO_SPEECH_FUNCTION_URL);

    int httpResponseCode = httpClient.POST(body);
    ```

    Tento k칩d vytvor칤 `HTTPClient` a potom vykon치 POST po쬴adavku pomocou JSON dokumentu na HTTP trigger `text-to-speech`.

1. Ak volanie funguje, surov칠 bin치rne d치ta vr치ten칠 z volania funk캜nej aplik치cie m칪쬿 by콘 streamovan칠 do s칰boru na SD karte. Pridajte nasleduj칰ci k칩d na vykonanie tohto:

    ```cpp
    if (httpResponseCode == 200)
    {            
        File wav_file = SD.open("SPEECH.WAV", FILE_WRITE);
        httpClient.writeToStream(&wav_file);
        wav_file.close();
    }
    else
    {
        Serial.print("Failed to get speech - error ");
        Serial.println(httpResponseCode);
    }
    ```

    Tento k칩d skontroluje odpove캞 a ak je 200 (칰spech), bin치rne d치ta sa streamuj칰 do s칰boru v kore켿ovom adres치ri SD karty s n치zvom `SPEECH.WAV`.

1. Na konci tejto met칩dy ukon캜ite HTTP pripojenie:

    ```cpp
    httpClient.end();
    ```

1. Text, ktor칳 sa m치 prehovori콘, teraz m칪쬰te previes콘 na zvuk. V s칰bore `main.cpp` pridajte nasleduj칰ci riadok na koniec funkcie `say`, aby ste previedli text na re캜:
```cpp
    textToSpeech.convertTextToSpeech(text);
    ```

### 칔loha - prehr치vanie zvuku z v치코ho Wio Terminalu

**캛oskoro dostupn칠**

## Nasadenie va코ej funk캜nej aplik치cie do cloudu

D칪vodom, pre캜o sp칰코콘a콘 funk캜n칰 aplik치ciu lok치lne, je to, 쬰 bal칤k `librosa` pre Pip na Linuxe m치 z치vislos콘 na kni쬹ici, ktor치 nie je predvolene nain코talovan치, a bude ju potrebn칠 nain코talova콘 predt칳m, ne bude funk캜n치 aplik치cia schopn치 be쬬콘. Funk캜n칠 aplik치cie s칰 bezserverov칠 - neexistuj칰 servery, ktor칠 by ste mohli spravova콘 sami, tak쬰 nie je mo쬹칠 t칰to kni쬹icu nain코talova콘 vopred.

Rie코en칤m je namiesto toho nasadi콘 va코u funk캜n칰 aplik치ciu pomocou Docker kontajnera. Tento kontajner je nasaden칳 cloudom v쬯y, ke캞 je potrebn칠 spusti콘 nov칰 in코tanciu va코ej funk캜nej aplik치cie (napr칤klad ke캞 dopyt presiahne dostupn칠 zdroje alebo ak aplik치cia nebola nejak칳 캜as pou쮂셨an치 a bola ukon캜en치).

Pokyny na nastavenie funk캜nej aplik치cie a nasadenie cez Docker n치jdete v [dokument치cii na Microsoft Docs o vytvoren칤 funkcie na Linuxe pomocou vlastn칠ho kontajnera](https://docs.microsoft.com/azure/azure-functions/functions-create-function-linux-custom-image?WT.mc_id=academic-17441-jabenn&tabs=bash%2Cazurecli&pivots=programming-language-python).

Ke캞 je aplik치cia nasaden치, m칪쬰te prenies콘 k칩d pre Wio Terminal na pr칤stup k tejto funkcii:

1. Pridajte certifik치t Azure Functions do `config.h`:

    ```cpp
    const char *FUNCTIONS_CERTIFICATE =
        "-----BEGIN CERTIFICATE-----\r\n"
        "MIIFWjCCBEKgAwIBAgIQDxSWXyAgaZlP1ceseIlB4jANBgkqhkiG9w0BAQsFADBa\r\n"
        "MQswCQYDVQQGEwJJRTESMBAGA1UEChMJQmFsdGltb3JlMRMwEQYDVQQLEwpDeWJl\r\n"
        "clRydXN0MSIwIAYDVQQDExlCYWx0aW1vcmUgQ3liZXJUcnVzdCBSb290MB4XDTIw\r\n"
        "MDcyMTIzMDAwMFoXDTI0MTAwODA3MDAwMFowTzELMAkGA1UEBhMCVVMxHjAcBgNV\r\n"
        "BAoTFU1pY3Jvc29mdCBDb3Jwb3JhdGlvbjEgMB4GA1UEAxMXTWljcm9zb2Z0IFJT\r\n"
        "QSBUTFMgQ0EgMDEwggIiMA0GCSqGSIb3DQEBAQUAA4ICDwAwggIKAoICAQCqYnfP\r\n"
        "mmOyBoTzkDb0mfMUUavqlQo7Rgb9EUEf/lsGWMk4bgj8T0RIzTqk970eouKVuL5R\r\n"
        "IMW/snBjXXgMQ8ApzWRJCZbar879BV8rKpHoAW4uGJssnNABf2n17j9TiFy6BWy+\r\n"
        "IhVnFILyLNK+W2M3zK9gheiWa2uACKhuvgCca5Vw/OQYErEdG7LBEzFnMzTmJcli\r\n"
        "W1iCdXby/vI/OxbfqkKD4zJtm45DJvC9Dh+hpzqvLMiK5uo/+aXSJY+SqhoIEpz+\r\n"
        "rErHw+uAlKuHFtEjSeeku8eR3+Z5ND9BSqc6JtLqb0bjOHPm5dSRrgt4nnil75bj\r\n"
        "c9j3lWXpBb9PXP9Sp/nPCK+nTQmZwHGjUnqlO9ebAVQD47ZisFonnDAmjrZNVqEX\r\n"
        "F3p7laEHrFMxttYuD81BdOzxAbL9Rb/8MeFGQjE2Qx65qgVfhH+RsYuuD9dUw/3w\r\n"
        "ZAhq05yO6nk07AM9c+AbNtRoEcdZcLCHfMDcbkXKNs5DJncCqXAN6LhXVERCw/us\r\n"
        "G2MmCMLSIx9/kwt8bwhUmitOXc6fpT7SmFvRAtvxg84wUkg4Y/Gx++0j0z6StSeN\r\n"
        "0EJz150jaHG6WV4HUqaWTb98Tm90IgXAU4AW2GBOlzFPiU5IY9jt+eXC2Q6yC/Zp\r\n"
        "TL1LAcnL3Qa/OgLrHN0wiw1KFGD51WRPQ0Sh7QIDAQABo4IBJTCCASEwHQYDVR0O\r\n"
        "BBYEFLV2DDARzseSQk1Mx1wsyKkM6AtkMB8GA1UdIwQYMBaAFOWdWTCCR1jMrPoI\r\n"
        "VDaGezq1BE3wMA4GA1UdDwEB/wQEAwIBhjAdBgNVHSUEFjAUBggrBgEFBQcDAQYI\r\n"
        "KwYBBQUHAwIwEgYDVR0TAQH/BAgwBgEB/wIBADA0BggrBgEFBQcBAQQoMCYwJAYI\r\n"
        "KwYBBQUHMAGGGGh0dHA6Ly9vY3NwLmRpZ2ljZXJ0LmNvbTA6BgNVHR8EMzAxMC+g\r\n"
        "LaArhilodHRwOi8vY3JsMy5kaWdpY2VydC5jb20vT21uaXJvb3QyMDI1LmNybDAq\r\n"
        "BgNVHSAEIzAhMAgGBmeBDAECATAIBgZngQwBAgIwCwYJKwYBBAGCNyoBMA0GCSqG\r\n"
        "SIb3DQEBCwUAA4IBAQCfK76SZ1vae4qt6P+dTQUO7bYNFUHR5hXcA2D59CJWnEj5\r\n"
        "na7aKzyowKvQupW4yMH9fGNxtsh6iJswRqOOfZYC4/giBO/gNsBvwr8uDW7t1nYo\r\n"
        "DYGHPpvnpxCM2mYfQFHq576/TmeYu1RZY29C4w8xYBlkAA8mDJfRhMCmehk7cN5F\r\n"
        "JtyWRj2cZj/hOoI45TYDBChXpOlLZKIYiG1giY16vhCRi6zmPzEwv+tk156N6cGS\r\n"
        "Vm44jTQ/rs1sa0JSYjzUaYngoFdZC4OfxnIkQvUIA4TOFmPzNPEFdjcZsgbeEz4T\r\n"
        "cGHTBPK4R28F44qIMCtHRV55VMX53ev6P3hRddJb\r\n"
        "-----END CERTIFICATE-----\r\n";
    ```

1. Zme켿te v코etky zahrnutia `
<WiFiClient.h>` na `<WiFiClientSecure.h>`.

1. Zme켿te v코etky polia `WiFiClient` na `WiFiClientSecure`.

1. V ka쬯ej triede, ktor치 m치 pole `WiFiClientSecure`, pridajte kon코truktor a nastavte certifik치t v tomto kon코truktore:

    ```cpp
    _client.setCACert(FUNCTIONS_CERTIFICATE);
    ```

---

**Upozornenie**:  
Tento dokument bol prelo쬰n칳 pomocou slu쬭y AI prekladu [Co-op Translator](https://github.com/Azure/co-op-translator). Hoci sa sna쮂셠e o presnos콘, pros칤m, berte na vedomie, 쬰 automatizovan칠 preklady m칪쬿 obsahova콘 chyby alebo nepresnosti. P칪vodn칳 dokument v jeho rodnom jazyku by mal by콘 pova쬺van칳 za autoritat칤vny zdroj. Pre kritick칠 inform치cie sa odpor칰캜a profesion치lny 쬿dsk칳 preklad. Nie sme zodpovedn칤 za ak칠ko쭀ek nedorozumenia alebo nespr치vne interpret치cie vypl칳vaj칰ce z pou쬴tia tohto prekladu.