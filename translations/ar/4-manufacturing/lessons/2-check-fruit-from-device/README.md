<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "557f4ee96b752e0651d2e6e74aa6bd14",
  "translation_date": "2025-08-26T21:46:15+00:00",
  "source_file": "4-manufacturing/lessons/2-check-fruit-from-device/README.md",
  "language_code": "ar"
}
-->
# التحقق من جودة الفاكهة باستخدام جهاز إنترنت الأشياء

![رسم توضيحي لهذه الدرس](../../../../../translated_images/lesson-16.215daf18b00631fbdfd64c6fc2dc6044dff5d544288825d8076f9fb83d964c23.ar.jpg)

> رسم توضيحي بواسطة [نيتيا ناراسيمهان](https://github.com/nitya). اضغط على الصورة للحصول على نسخة أكبر.

## اختبار ما قبل المحاضرة

[اختبار ما قبل المحاضرة](https://black-meadow-040d15503.1.azurestaticapps.net/quiz/31)

## المقدمة

في الدرس السابق، تعلمت عن مصنفات الصور وكيفية تدريبها للكشف عن الفاكهة الجيدة والسيئة. لاستخدام هذا المصنف في تطبيق إنترنت الأشياء، تحتاج إلى القدرة على التقاط صورة باستخدام نوع من الكاميرات وإرسال هذه الصورة إلى السحابة لتصنيفها.

في هذا الدرس، ستتعلم عن مستشعرات الكاميرا وكيفية استخدامها مع جهاز إنترنت الأشياء لالتقاط صورة. ستتعلم أيضًا كيفية استدعاء مصنف الصور من جهاز إنترنت الأشياء الخاص بك.

في هذا الدرس سنتناول:

* [مستشعرات الكاميرا](../../../../../4-manufacturing/lessons/2-check-fruit-from-device)
* [التقاط صورة باستخدام جهاز إنترنت الأشياء](../../../../../4-manufacturing/lessons/2-check-fruit-from-device)
* [نشر مصنف الصور الخاص بك](../../../../../4-manufacturing/lessons/2-check-fruit-from-device)
* [تصنيف الصور من جهاز إنترنت الأشياء الخاص بك](../../../../../4-manufacturing/lessons/2-check-fruit-from-device)
* [تحسين النموذج](../../../../../4-manufacturing/lessons/2-check-fruit-from-device)

## مستشعرات الكاميرا

مستشعرات الكاميرا، كما يشير الاسم، هي كاميرات يمكنك توصيلها بجهاز إنترنت الأشياء الخاص بك. يمكنها التقاط صور ثابتة أو تسجيل فيديو متدفق. بعضها يعيد بيانات الصور الخام، والبعض الآخر يضغط البيانات إلى ملف صورة مثل JPEG أو PNG. عادةً ما تكون الكاميرات التي تعمل مع أجهزة إنترنت الأشياء أصغر وأقل دقة مما قد تكون معتادًا عليه، ولكن يمكنك الحصول على كاميرات عالية الدقة تنافس أفضل الهواتف. يمكنك الحصول على عدسات قابلة للتبديل، إعدادات كاميرا متعددة، كاميرات حرارية بالأشعة تحت الحمراء، أو كاميرات الأشعة فوق البنفسجية.

![الضوء من المشهد يمر عبر عدسة ويركز على مستشعر CMOS](../../../../../translated_images/cmos-sensor.75f9cd74decb137149a4c9ea825251a4549497d67c0ae2776159e6102bb53aa9.ar.png)

معظم مستشعرات الكاميرا تستخدم مستشعرات الصور حيث كل بكسل هو ديود ضوئي. تقوم العدسة بتركيز الصورة على مستشعر الصورة، وتقوم آلاف أو ملايين الديودات الضوئية بالكشف عن الضوء الساقط على كل منها وتسجيله كبيانات بكسل.

> 💁 العدسات تقلب الصور، ثم يقوم مستشعر الكاميرا بإعادة الصورة إلى وضعها الصحيح. هذا هو الحال أيضًا في عينيك - ما تراه يتم الكشف عنه مقلوبًا في الجزء الخلفي من عينك ويقوم دماغك بتصحيحه.

> 🎓 يُعرف مستشعر الصورة باسم مستشعر البكسل النشط (APS)، والنوع الأكثر شيوعًا من APS هو مستشعر أشباه الموصلات بأكسيد معدني مكمل، أو CMOS. ربما سمعت بمصطلح مستشعر CMOS المستخدم لمستشعرات الكاميرا.

مستشعرات الكاميرا هي مستشعرات رقمية، ترسل بيانات الصور كبيانات رقمية، عادةً بمساعدة مكتبة توفر الاتصال. تتصل الكاميرات باستخدام بروتوكولات مثل SPI للسماح لها بإرسال كميات كبيرة من البيانات - الصور أكبر بكثير من الأرقام الفردية من مستشعر مثل مستشعر درجة الحرارة.

✅ ما هي القيود المتعلقة بحجم الصور مع أجهزة إنترنت الأشياء؟ فكر في القيود خاصةً على أجهزة التحكم الدقيقة.

## التقاط صورة باستخدام جهاز إنترنت الأشياء

يمكنك استخدام جهاز إنترنت الأشياء الخاص بك لالتقاط صورة لتصنيفها.

### المهمة - التقاط صورة باستخدام جهاز إنترنت الأشياء

اتبع الدليل المناسب لالتقاط صورة باستخدام جهاز إنترنت الأشياء الخاص بك:

* [Arduino - Wio Terminal](wio-terminal-camera.md)
* [كمبيوتر أحادي اللوحة - Raspberry Pi](pi-camera.md)
* [كمبيوتر أحادي اللوحة - جهاز افتراضي](virtual-device-camera.md)

## نشر مصنف الصور الخاص بك

لقد قمت بتدريب مصنف الصور الخاص بك في الدرس السابق. قبل أن تتمكن من استخدامه من جهاز إنترنت الأشياء الخاص بك، تحتاج إلى نشر النموذج.

### تكرارات النموذج

عندما كان النموذج الخاص بك يتدرب في الدرس السابق، ربما لاحظت أن علامة التبويب **الأداء** تعرض التكرارات على الجانب. عندما قمت بتدريب النموذج لأول مرة، كنت سترى *التكرار 1* أثناء التدريب. عندما قمت بتحسين النموذج باستخدام صور التنبؤ، كنت سترى *التكرار 2* أثناء التدريب.

في كل مرة تقوم فيها بتدريب النموذج، تحصل على تكرار جديد. هذه طريقة لتتبع الإصدارات المختلفة من النموذج المدربة على مجموعات بيانات مختلفة. عندما تقوم بإجراء **اختبار سريع**، هناك قائمة منسدلة يمكنك استخدامها لتحديد التكرار، بحيث يمكنك مقارنة النتائج عبر تكرارات متعددة.

عندما تكون راضيًا عن تكرار معين، يمكنك نشره ليكون متاحًا للاستخدام من التطبيقات الخارجية. بهذه الطريقة يمكنك الحصول على إصدار منشور يستخدمه أجهزتك، ثم العمل على إصدار جديد عبر تكرارات متعددة، ثم نشره بمجرد أن تكون راضيًا عنه.

### المهمة - نشر تكرار

يتم نشر التكرارات من بوابة Custom Vision.

1. افتح بوابة Custom Vision على [CustomVision.ai](https://customvision.ai) وقم بتسجيل الدخول إذا لم تكن قد فتحتها بالفعل. ثم افتح مشروعك `fruit-quality-detector`.

1. اختر علامة التبويب **الأداء** من الخيارات في الأعلى.

1. اختر أحدث تكرار من قائمة *التكرارات* على الجانب.

1. اضغط على زر **النشر** للتكرار.

    ![زر النشر](../../../../../translated_images/custom-vision-publish-button.b7174e1977b0c33b8b72d4e5b1326c779e0af196f3849d09985ee2d7d5493a39.ar.png)

1. في مربع الحوار *نشر النموذج*، قم بتعيين *مورد التنبؤ* إلى المورد `fruit-quality-detector-prediction` الذي أنشأته في الدرس السابق. اترك الاسم كما هو `Iteration2`، واضغط على زر **النشر**.

1. بمجرد النشر، اضغط على زر **عنوان URL للتنبؤ**. سيعرض هذا تفاصيل واجهة برمجة التطبيقات للتنبؤ، وستحتاج إلى هذه التفاصيل لاستدعاء النموذج من جهاز إنترنت الأشياء الخاص بك. القسم السفلي يحمل عنوان *إذا كان لديك ملف صورة*، وهذه هي التفاصيل التي تريدها. خذ نسخة من عنوان URL الذي يظهر والذي سيكون شيئًا مثل:

    ```output
    https://<location>.api.cognitive.microsoft.com/customvision/v3.0/Prediction/<id>/classify/iterations/Iteration2/image
    ```

    حيث `<location>` سيكون الموقع الذي استخدمته عند إنشاء مورد الرؤية المخصص، و `<id>` سيكون معرفًا طويلًا مكونًا من أحرف وأرقام.

    أيضًا، خذ نسخة من قيمة *مفتاح التنبؤ*. هذا مفتاح آمن يجب تمريره عند استدعاء النموذج. فقط التطبيقات التي تمرر هذا المفتاح يُسمح لها باستخدام النموذج، وأي تطبيقات أخرى يتم رفضها.

    ![مربع الحوار الخاص بواجهة برمجة التطبيقات للتنبؤ يظهر عنوان URL والمفتاح](../../../../../translated_images/custom-vision-prediction-key-endpoint.30c569ffd0338864f319911f052d5e9b8c5066cb0800a26dd6f7ff5713130ad8.ar.png)

✅ عندما يتم نشر تكرار جديد، سيكون له اسم مختلف. كيف تعتقد أنه يمكنك تغيير التكرار الذي يستخدمه جهاز إنترنت الأشياء؟

## تصنيف الصور من جهاز إنترنت الأشياء الخاص بك

يمكنك الآن استخدام تفاصيل الاتصال هذه لاستدعاء مصنف الصور من جهاز إنترنت الأشياء الخاص بك.

### المهمة - تصنيف الصور من جهاز إنترنت الأشياء الخاص بك

اتبع الدليل المناسب لتصنيف الصور باستخدام جهاز إنترنت الأشياء الخاص بك:

* [Arduino - Wio Terminal](wio-terminal-classify-image.md)
* [كمبيوتر أحادي اللوحة - Raspberry Pi/جهاز إنترنت الأشياء الافتراضي](single-board-computer-classify-image.md)

## تحسين النموذج

قد تجد أن النتائج التي تحصل عليها عند استخدام الكاميرا المتصلة بجهاز إنترنت الأشياء الخاص بك لا تتطابق مع ما كنت تتوقعه. التنبؤات ليست دائمًا دقيقة مثل استخدام الصور التي تم تحميلها من جهاز الكمبيوتر الخاص بك. هذا لأن النموذج تم تدريبه على بيانات مختلفة عن تلك المستخدمة في التنبؤات.

للحصول على أفضل النتائج لمصنف الصور، تريد تدريب النموذج باستخدام صور مشابهة قدر الإمكان للصور المستخدمة في التنبؤات. إذا كنت قد استخدمت كاميرا هاتفك لالتقاط الصور للتدريب، على سبيل المثال، فإن جودة الصورة، الحدة، والألوان ستكون مختلفة عن كاميرا متصلة بجهاز إنترنت الأشياء.

![صورتان لموز، واحدة منخفضة الدقة مع إضاءة ضعيفة من جهاز إنترنت الأشياء، والأخرى عالية الدقة مع إضاءة جيدة من هاتف](../../../../../translated_images/banana-picture-compare.174df164dc326a42cf7fb051a7497e6113c620e91552d92ca914220305d47d9a.ar.png)

في الصورة أعلاه، الصورة على اليسار تم التقاطها باستخدام كاميرا Raspberry Pi، والصورة على اليمين تم التقاطها لنفس الموزة في نفس الموقع باستخدام iPhone. هناك فرق واضح في الجودة - صورة iPhone أكثر وضوحًا، بألوان أكثر إشراقًا وتباين أعلى.

✅ ما الذي قد يسبب أن تكون الصور التي يلتقطها جهاز إنترنت الأشياء الخاص بك تحتوي على تنبؤات غير صحيحة؟ فكر في البيئة التي قد يُستخدم فيها جهاز إنترنت الأشياء، ما العوامل التي يمكن أن تؤثر على الصورة التي يتم التقاطها؟

لتحسين النموذج، يمكنك إعادة تدريبه باستخدام الصور التي تم التقاطها من جهاز إنترنت الأشياء.

### المهمة - تحسين النموذج

1. صنف صورًا متعددة لكل من الفاكهة الناضجة وغير الناضجة باستخدام جهاز إنترنت الأشياء الخاص بك.

1. في بوابة Custom Vision، أعد تدريب النموذج باستخدام الصور في علامة التبويب *التنبؤات*.

    > ⚠️ يمكنك الرجوع إلى [التعليمات الخاصة بإعادة تدريب المصنف الخاص بك في الدرس الأول إذا لزم الأمر](../1-train-fruit-detector/README.md#retrain-your-image-classifier).

1. إذا كانت صورك تبدو مختلفة جدًا عن الصور الأصلية المستخدمة في التدريب، يمكنك حذف جميع الصور الأصلية عن طريق تحديدها في علامة التبويب *صور التدريب* والضغط على زر **الحذف**. لتحديد صورة، حرك المؤشر فوقها وسيظهر علامة اختيار، اضغط على تلك العلامة لتحديد أو إلغاء تحديد الصورة.

1. قم بتدريب تكرار جديد للنموذج ونشره باستخدام الخطوات أعلاه.

1. قم بتحديث عنوان URL في الكود الخاص بك، وأعد تشغيل التطبيق.

1. كرر هذه الخطوات حتى تكون راضيًا عن نتائج التنبؤات.

---

## 🚀 التحدي

ما مدى تأثير دقة الصورة أو الإضاءة على التنبؤ؟

حاول تغيير دقة الصور في كود جهازك وشاهد ما إذا كان ذلك يحدث فرقًا في جودة الصور. أيضًا، حاول تغيير الإضاءة.

إذا كنت ستقوم بإنشاء جهاز إنتاجي لبيعه للمزارع أو المصانع، كيف ستضمن أنه يعطي نتائج متسقة طوال الوقت؟

## اختبار ما بعد المحاضرة

[اختبار ما بعد المحاضرة](https://black-meadow-040d15503.1.azurestaticapps.net/quiz/32)

## المراجعة والدراسة الذاتية

لقد قمت بتدريب نموذج الرؤية المخصص الخاص بك باستخدام البوابة. يعتمد هذا على وجود صور متاحة - وفي العالم الحقيقي قد لا تتمكن من الحصول على بيانات تدريب تتطابق مع ما تلتقطه الكاميرا على جهازك. يمكنك تجاوز هذا عن طريق التدريب مباشرةً من جهازك باستخدام واجهة برمجة التطبيقات للتدريب، لتدريب نموذج باستخدام الصور التي تم التقاطها من جهاز إنترنت الأشياء الخاص بك.

* اقرأ عن واجهة برمجة التطبيقات للتدريب في [البدء السريع باستخدام SDK للرؤية المخصصة](https://docs.microsoft.com/azure/cognitive-services/custom-vision-service/quickstarts/image-classification?WT.mc_id=academic-17441-jabenn&tabs=visual-studio&pivots=programming-language-python)

## الواجب

[الرد على نتائج التصنيف](assignment.md)

---

**إخلاء المسؤولية**:  
تم ترجمة هذا المستند باستخدام خدمة الترجمة بالذكاء الاصطناعي [Co-op Translator](https://github.com/Azure/co-op-translator). بينما نسعى لتحقيق الدقة، يرجى العلم أن الترجمات الآلية قد تحتوي على أخطاء أو معلومات غير دقيقة. يجب اعتبار المستند الأصلي بلغته الأصلية المصدر الموثوق. للحصول على معلومات حاسمة، يُوصى بالاستعانة بترجمة بشرية احترافية. نحن غير مسؤولين عن أي سوء فهم أو تفسيرات خاطئة تنشأ عن استخدام هذه الترجمة.