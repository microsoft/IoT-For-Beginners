<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "557f4ee96b752e0651d2e6e74aa6bd14",
  "translation_date": "2025-08-25T20:57:01+00:00",
  "source_file": "4-manufacturing/lessons/2-check-fruit-from-device/README.md",
  "language_code": "fa"
}
-->
# بررسی کیفیت میوه با استفاده از دستگاه IoT

![نمای کلی درس به صورت اسکچ‌نوت](../../../../../translated_images/lesson-16.215daf18b00631fbdfd64c6fc2dc6044dff5d544288825d8076f9fb83d964c23.fa.jpg)

> اسکچ‌نوت توسط [نیتیا ناراسیمهان](https://github.com/nitya). برای مشاهده نسخه بزرگ‌تر روی تصویر کلیک کنید.

## آزمون پیش از درس

[آزمون پیش از درس](https://black-meadow-040d15503.1.azurestaticapps.net/quiz/31)

## مقدمه

در درس قبلی درباره دسته‌بندی‌کننده‌های تصویر یاد گرفتید و نحوه آموزش آن‌ها برای تشخیص میوه‌های خوب و بد را بررسی کردید. برای استفاده از این دسته‌بندی‌کننده تصویر در یک برنامه IoT، باید بتوانید با استفاده از نوعی دوربین، تصویر را ثبت کرده و آن را به فضای ابری ارسال کنید تا دسته‌بندی شود.

در این درس، درباره حسگرهای دوربین و نحوه استفاده از آن‌ها با دستگاه IoT برای ثبت تصویر یاد خواهید گرفت. همچنین نحوه فراخوانی دسته‌بندی‌کننده تصویر از دستگاه IoT را خواهید آموخت.

در این درس موارد زیر را پوشش خواهیم داد:

* [حسگرهای دوربین](../../../../../4-manufacturing/lessons/2-check-fruit-from-device)
* [ثبت تصویر با استفاده از دستگاه IoT](../../../../../4-manufacturing/lessons/2-check-fruit-from-device)
* [انتشار دسته‌بندی‌کننده تصویر](../../../../../4-manufacturing/lessons/2-check-fruit-from-device)
* [دسته‌بندی تصاویر از دستگاه IoT](../../../../../4-manufacturing/lessons/2-check-fruit-from-device)
* [بهبود مدل](../../../../../4-manufacturing/lessons/2-check-fruit-from-device)

## حسگرهای دوربین

حسگرهای دوربین، همان‌طور که از نامشان پیداست، دوربین‌هایی هستند که می‌توانید به دستگاه IoT خود متصل کنید. این دوربین‌ها می‌توانند تصاویر ثابت بگیرند یا ویدئوهای استریم ضبط کنند. برخی از آن‌ها داده‌های خام تصویر را ارائه می‌دهند، در حالی که برخی دیگر داده‌های تصویر را به فایل‌هایی مانند JPEG یا PNG فشرده می‌کنند. معمولاً دوربین‌هایی که با دستگاه‌های IoT کار می‌کنند، بسیار کوچک‌تر و با وضوح پایین‌تر از آنچه که ممکن است به آن عادت داشته باشید هستند، اما می‌توانید دوربین‌های با وضوح بالا تهیه کنید که با گوشی‌های پیشرفته رقابت می‌کنند. همچنین می‌توانید لنزهای قابل تعویض، تنظیمات چند دوربینه، دوربین‌های حرارتی مادون قرمز یا دوربین‌های UV تهیه کنید.

![نور از یک صحنه از لنز عبور کرده و روی حسگر CMOS متمرکز می‌شود](../../../../../translated_images/cmos-sensor.75f9cd74decb137149a4c9ea825251a4549497d67c0ae2776159e6102bb53aa9.fa.png)

بیشتر حسگرهای دوربین از حسگرهای تصویری استفاده می‌کنند که در آن هر پیکسل یک فوتودیود است. لنز تصویر را روی حسگر تصویر متمرکز می‌کند و هزاران یا میلیون‌ها فوتودیود نور را که به هر یک می‌تابد تشخیص داده و آن را به عنوان داده پیکسل ثبت می‌کنند.

> 💁 لنزها تصاویر را وارونه می‌کنند، سپس حسگر دوربین تصویر را به حالت صحیح برمی‌گرداند. این موضوع در چشم‌های شما نیز همین‌طور است - آنچه می‌بینید به صورت وارونه در پشت چشم شما تشخیص داده می‌شود و مغز شما آن را اصلاح می‌کند.

> 🎓 حسگر تصویر به عنوان حسگر پیکسل فعال (APS) شناخته می‌شود و محبوب‌ترین نوع APS، حسگر نیمه‌هادی اکسید فلزی مکمل یا CMOS است. ممکن است اصطلاح حسگر CMOS را برای حسگرهای دوربین شنیده باشید.

حسگرهای دوربین حسگرهای دیجیتال هستند که داده‌های تصویر را به صورت دیجیتال ارسال می‌کنند، معمولاً با کمک یک کتابخانه که ارتباط را فراهم می‌کند. دوربین‌ها با استفاده از پروتکل‌هایی مانند SPI متصل می‌شوند تا بتوانند مقادیر زیادی داده ارسال کنند - تصاویر به طور قابل توجهی بزرگ‌تر از اعداد منفرد از حسگرهایی مانند حسگر دما هستند.

✅ محدودیت‌های مربوط به اندازه تصویر در دستگاه‌های IoT چیست؟ به خصوص به محدودیت‌های سخت‌افزار میکروکنترلر فکر کنید.

## ثبت تصویر با استفاده از دستگاه IoT

می‌توانید از دستگاه IoT خود برای ثبت تصویر و دسته‌بندی آن استفاده کنید.

### وظیفه - ثبت تصویر با استفاده از دستگاه IoT

راهنمای مربوطه را دنبال کنید تا با استفاده از دستگاه IoT خود تصویر ثبت کنید:

* [Arduino - Wio Terminal](wio-terminal-camera.md)
* [کامپیوتر تک‌برد - Raspberry Pi](pi-camera.md)
* [کامپیوتر تک‌برد - دستگاه مجازی](virtual-device-camera.md)

## انتشار دسته‌بندی‌کننده تصویر

شما دسته‌بندی‌کننده تصویر خود را در درس قبلی آموزش دادید. قبل از اینکه بتوانید از آن در دستگاه IoT خود استفاده کنید، باید مدل را منتشر کنید.

### تکرارهای مدل

هنگامی که مدل شما در درس قبلی آموزش داده شد، ممکن است متوجه شده باشید که تب **Performance** تکرارها را در کنار نشان می‌دهد. وقتی برای اولین بار مدل را آموزش دادید، *Iteration 1* را در حال آموزش مشاهده کردید. وقتی مدل را با استفاده از تصاویر پیش‌بینی بهبود دادید، *Iteration 2* را در حال آموزش مشاهده کردید.

هر بار که مدل را آموزش می‌دهید، یک تکرار جدید دریافت می‌کنید. این یک روش برای پیگیری نسخه‌های مختلف مدل شما است که بر اساس مجموعه داده‌های مختلف آموزش داده شده‌اند. وقتی یک **Quick Test** انجام می‌دهید، یک منوی کشویی وجود دارد که می‌توانید از آن برای انتخاب تکرار استفاده کنید، بنابراین می‌توانید نتایج را در چندین تکرار مقایسه کنید.

وقتی از یک تکرار راضی هستید، می‌توانید آن را منتشر کنید تا از برنامه‌های خارجی قابل استفاده باشد. به این ترتیب می‌توانید یک نسخه منتشر شده داشته باشید که توسط دستگاه‌های شما استفاده می‌شود، سپس روی نسخه جدیدی در چندین تکرار کار کنید و پس از رضایت از آن، آن را منتشر کنید.

### وظیفه - انتشار یک تکرار

تکرارها از پورتال Custom Vision منتشر می‌شوند.

1. پورتال Custom Vision را در [CustomVision.ai](https://customvision.ai) باز کنید و وارد شوید اگر هنوز باز نکرده‌اید. سپس پروژه `fruit-quality-detector` خود را باز کنید.

1. تب **Performance** را از گزینه‌های بالا انتخاب کنید.

1. آخرین تکرار را از لیست *Iterations* در کنار انتخاب کنید.

1. دکمه **Publish** را برای تکرار انتخاب کنید.

    ![دکمه انتشار](../../../../../translated_images/custom-vision-publish-button.b7174e1977b0c33b8b72d4e5b1326c779e0af196f3849d09985ee2d7d5493a39.fa.png)

1. در دیالوگ *Publish Model*، منبع *Prediction resource* را به منبع `fruit-quality-detector-prediction` که در درس قبلی ایجاد کردید تنظیم کنید. نام را به صورت `Iteration2` بگذارید و دکمه **Publish** را انتخاب کنید.

1. پس از انتشار، دکمه **Prediction URL** را انتخاب کنید. این جزئیات API پیش‌بینی را نشان می‌دهد و شما به این جزئیات برای فراخوانی مدل از دستگاه IoT خود نیاز دارید. بخش پایین‌تر با عنوان *If you have an image file* برچسب‌گذاری شده است و این جزئیاتی است که می‌خواهید. URL نشان داده شده را کپی کنید که چیزی شبیه به:

    ```output
    https://<location>.api.cognitive.microsoft.com/customvision/v3.0/Prediction/<id>/classify/iterations/Iteration2/image
    ```

    خواهد بود، جایی که `<location>` مکان مورد استفاده شما هنگام ایجاد منبع Custom Vision و `<id>` یک شناسه طولانی متشکل از حروف و اعداد خواهد بود.

    همچنین مقدار *Prediction-Key* را کپی کنید. این یک کلید امن است که باید هنگام فراخوانی مدل ارسال شود. فقط برنامه‌هایی که این کلید را ارسال می‌کنند اجازه استفاده از مدل را دارند و سایر برنامه‌ها رد می‌شوند.

    ![دیالوگ API پیش‌بینی که URL و کلید را نشان می‌دهد](../../../../../translated_images/custom-vision-prediction-key-endpoint.30c569ffd0338864f319911f052d5e9b8c5066cb0800a26dd6f7ff5713130ad8.fa.png)

✅ وقتی یک تکرار جدید منتشر می‌شود، نام متفاوتی خواهد داشت. چگونه فکر می‌کنید می‌توانید تکرار مورد استفاده دستگاه IoT را تغییر دهید؟

## دسته‌بندی تصاویر از دستگاه IoT

اکنون می‌توانید از این جزئیات اتصال برای فراخوانی دسته‌بندی‌کننده تصویر از دستگاه IoT خود استفاده کنید.

### وظیفه - دسته‌بندی تصاویر از دستگاه IoT

راهنمای مربوطه را دنبال کنید تا با استفاده از دستگاه IoT خود تصاویر را دسته‌بندی کنید:

* [Arduino - Wio Terminal](wio-terminal-classify-image.md)
* [کامپیوتر تک‌برد - Raspberry Pi/دستگاه IoT مجازی](single-board-computer-classify-image.md)

## بهبود مدل

ممکن است متوجه شوید که نتایجی که هنگام استفاده از دوربین متصل به دستگاه IoT خود دریافت می‌کنید با آنچه انتظار دارید مطابقت ندارد. پیش‌بینی‌ها همیشه به اندازه استفاده از تصاویر آپلود شده از کامپیوتر شما دقیق نیستند. این به این دلیل است که مدل با داده‌های متفاوتی نسبت به آنچه برای پیش‌بینی استفاده می‌شود آموزش داده شده است.

برای دریافت بهترین نتایج از یک دسته‌بندی‌کننده تصویر، باید مدل را با تصاویری که تا حد ممکن مشابه تصاویر مورد استفاده برای پیش‌بینی هستند آموزش دهید. اگر از دوربین گوشی خود برای ثبت تصاویر برای آموزش استفاده کرده‌اید، به عنوان مثال، کیفیت تصویر، وضوح و رنگ با دوربین متصل به دستگاه IoT متفاوت خواهد بود.

![دو تصویر موز، یکی با وضوح پایین و نور ضعیف از دستگاه IoT و دیگری با وضوح بالا و نور خوب از گوشی](../../../../../translated_images/banana-picture-compare.174df164dc326a42cf7fb051a7497e6113c620e91552d92ca914220305d47d9a.fa.png)

در تصویر بالا، تصویر موز سمت چپ با استفاده از دوربین Raspberry Pi گرفته شده است، و تصویر سمت راست از همان موز در همان مکان با استفاده از آیفون گرفته شده است. تفاوت کیفیت قابل توجه است - تصویر آیفون واضح‌تر، با رنگ‌های روشن‌تر و کنتراست بیشتر است.

✅ چه عواملی ممکن است باعث شوند تصاویر ثبت شده توسط دستگاه IoT شما پیش‌بینی‌های نادرست داشته باشند؟ به محیطی که ممکن است دستگاه IoT در آن استفاده شود فکر کنید، چه عواملی می‌توانند بر تصویر ثبت شده تأثیر بگذارند؟

برای بهبود مدل، می‌توانید آن را با استفاده از تصاویر ثبت شده از دستگاه IoT دوباره آموزش دهید.

### وظیفه - بهبود مدل

1. تصاویر متعدد از میوه‌های رسیده و نارس را با استفاده از دستگاه IoT خود دسته‌بندی کنید.

1. در پورتال Custom Vision، مدل را با استفاده از تصاویر در تب *Predictions* دوباره آموزش دهید.

    > ⚠️ می‌توانید به [دستورالعمل‌های مربوط به آموزش مجدد دسته‌بندی‌کننده خود در درس 1 در صورت نیاز مراجعه کنید](../1-train-fruit-detector/README.md#retrain-your-image-classifier).

1. اگر تصاویر شما بسیار متفاوت از تصاویر اصلی مورد استفاده برای آموزش هستند، می‌توانید تمام تصاویر اصلی را با انتخاب آن‌ها در تب *Training Images* و انتخاب دکمه **Delete** حذف کنید. برای انتخاب یک تصویر، نشانگر خود را روی آن حرکت دهید و یک علامت تیک ظاهر می‌شود، آن علامت تیک را انتخاب کنید تا تصویر انتخاب یا لغو انتخاب شود.

1. یک تکرار جدید از مدل را آموزش دهید و آن را با استفاده از مراحل بالا منتشر کنید.

1. URL نقطه پایانی را در کد خود به‌روزرسانی کنید و برنامه را دوباره اجرا کنید.

1. این مراحل را تکرار کنید تا از نتایج پیش‌بینی‌ها راضی باشید.

---

## 🚀 چالش

چقدر وضوح تصویر یا نورپردازی بر پیش‌بینی تأثیر می‌گذارد؟

سعی کنید وضوح تصاویر را در کد دستگاه خود تغییر دهید و ببینید آیا تفاوتی در کیفیت تصاویر ایجاد می‌کند. همچنین نورپردازی را تغییر دهید.

اگر بخواهید یک دستگاه تولیدی برای فروش به مزارع یا کارخانه‌ها ایجاد کنید، چگونه اطمینان حاصل می‌کنید که همیشه نتایج یکسان و دقیق ارائه می‌دهد؟

## آزمون پس از درس

[آزمون پس از درس](https://black-meadow-040d15503.1.azurestaticapps.net/quiz/32)

## مرور و مطالعه شخصی

شما مدل Custom Vision خود را با استفاده از پورتال آموزش دادید. این وابسته به داشتن تصاویر موجود است - و در دنیای واقعی ممکن است نتوانید داده‌های آموزشی که با تصاویر ثبت شده توسط دوربین دستگاه شما مطابقت دارند را دریافت کنید. می‌توانید این مشکل را با آموزش مستقیم از دستگاه خود با استفاده از API آموزش حل کنید تا مدلی با استفاده از تصاویر ثبت شده از دستگاه IoT خود آموزش دهید.

* درباره API آموزش در [شروع سریع استفاده از SDK Custom Vision](https://docs.microsoft.com/azure/cognitive-services/custom-vision-service/quickstarts/image-classification?WT.mc_id=academic-17441-jabenn&tabs=visual-studio&pivots=programming-language-python) مطالعه کنید.

## تکلیف

[پاسخ به نتایج دسته‌بندی](assignment.md)

**سلب مسئولیت**:  
این سند با استفاده از سرویس ترجمه هوش مصنوعی [Co-op Translator](https://github.com/Azure/co-op-translator) ترجمه شده است. در حالی که ما تلاش می‌کنیم دقت را حفظ کنیم، لطفاً توجه داشته باشید که ترجمه‌های خودکار ممکن است شامل خطاها یا نادرستی‌ها باشند. سند اصلی به زبان اصلی آن باید به عنوان منبع معتبر در نظر گرفته شود. برای اطلاعات حساس، توصیه می‌شود از ترجمه انسانی حرفه‌ای استفاده کنید. ما هیچ مسئولیتی در قبال سوء تفاهم‌ها یا تفسیرهای نادرست ناشی از استفاده از این ترجمه نداریم.