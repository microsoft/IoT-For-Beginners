<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "557f4ee96b752e0651d2e6e74aa6bd14",
  "translation_date": "2025-08-26T06:31:48+00:00",
  "source_file": "4-manufacturing/lessons/2-check-fruit-from-device/README.md",
  "language_code": "pl"
}
-->
# SprawdÅº jakoÅ›Ä‡ owocÃ³w za pomocÄ… urzÄ…dzenia IoT

![Szkicowy przeglÄ…d tej lekcji](../../../../../translated_images/lesson-16.215daf18b00631fbdfd64c6fc2dc6044dff5d544288825d8076f9fb83d964c23.pl.jpg)

> Szkic autorstwa [Nitya Narasimhan](https://github.com/nitya). Kliknij obrazek, aby zobaczyÄ‡ wiÄ™kszÄ… wersjÄ™.

## Quiz przed wykÅ‚adem

[Quiz przed wykÅ‚adem](https://black-meadow-040d15503.1.azurestaticapps.net/quiz/31)

## Wprowadzenie

W poprzedniej lekcji nauczyÅ‚eÅ› siÄ™ o klasyfikatorach obrazÃ³w i o tym, jak je trenowaÄ‡, aby wykrywaÄ‡ dobre i zÅ‚e owoce. Aby uÅ¼yÄ‡ tego klasyfikatora obrazÃ³w w aplikacji IoT, musisz byÄ‡ w stanie uchwyciÄ‡ obraz za pomocÄ… jakiegoÅ› rodzaju kamery i przesÅ‚aÄ‡ ten obraz do chmury w celu klasyfikacji.

W tej lekcji dowiesz siÄ™ o czujnikach kamer i o tym, jak uÅ¼ywaÄ‡ ich z urzÄ…dzeniem IoT do uchwycenia obrazu. Nauczysz siÄ™ rÃ³wnieÅ¼, jak wywoÅ‚aÄ‡ klasyfikator obrazÃ³w z urzÄ…dzenia IoT.

W tej lekcji omÃ³wimy:

* [Czujniki kamer](../../../../../4-manufacturing/lessons/2-check-fruit-from-device)
* [Uchwycenie obrazu za pomocÄ… urzÄ…dzenia IoT](../../../../../4-manufacturing/lessons/2-check-fruit-from-device)
* [Publikacja klasyfikatora obrazÃ³w](../../../../../4-manufacturing/lessons/2-check-fruit-from-device)
* [Klasyfikacja obrazÃ³w z urzÄ…dzenia IoT](../../../../../4-manufacturing/lessons/2-check-fruit-from-device)
* [Udoskonalenie modelu](../../../../../4-manufacturing/lessons/2-check-fruit-from-device)

## Czujniki kamer

Czujniki kamer, jak sama nazwa wskazuje, to kamery, ktÃ³re moÅ¼na podÅ‚Ä…czyÄ‡ do urzÄ…dzenia IoT. MogÄ… robiÄ‡ zdjÄ™cia lub rejestrowaÄ‡ strumieniowe wideo. NiektÃ³re zwracajÄ… surowe dane obrazowe, inne kompresujÄ… dane obrazowe do pliku graficznego, takiego jak JPEG lub PNG. Zazwyczaj kamery wspÃ³Å‚pracujÄ…ce z urzÄ…dzeniami IoT sÄ… znacznie mniejsze i majÄ… niÅ¼szÄ… rozdzielczoÅ›Ä‡ niÅ¼ te, do ktÃ³rych moÅ¼esz byÄ‡ przyzwyczajony, ale moÅ¼na znaleÅºÄ‡ kamery o wysokiej rozdzielczoÅ›ci, ktÃ³re dorÃ³wnujÄ… najlepszym telefonom. DostÄ™pne sÄ… rÃ³Å¼ne wymienne obiektywy, zestawy wielokamerowe, kamery termiczne na podczerwieÅ„ czy kamery UV.

![ÅšwiatÅ‚o ze sceny przechodzi przez obiektyw i jest skupiane na czujniku CMOS](../../../../../translated_images/cmos-sensor.75f9cd74decb137149a4c9ea825251a4549497d67c0ae2776159e6102bb53aa9.pl.png)

WiÄ™kszoÅ›Ä‡ czujnikÃ³w kamer wykorzystuje czujniki obrazu, gdzie kaÅ¼dy piksel jest fotodiodÄ…. Obiektyw skupia obraz na czujniku obrazu, a tysiÄ…ce lub miliony fotodiod wykrywajÄ… Å›wiatÅ‚o padajÄ…ce na kaÅ¼dÄ… z nich i zapisujÄ… je jako dane pikselowe.

> ğŸ’ Obiektywy odwracajÄ… obrazy, a czujnik kamery nastÄ™pnie odwraca obraz z powrotem do wÅ‚aÅ›ciwej orientacji. To samo dzieje siÄ™ w twoich oczach - to, co widzisz, jest wykrywane do gÃ³ry nogami na tylnej czÄ™Å›ci oka, a twÃ³j mÃ³zg to koryguje.

> ğŸ“ Czujnik obrazu jest znany jako Aktywny Czujnik Pikseli (APS), a najpopularniejszym typem APS jest czujnik komplementarny metal-oksydowy pÃ³Å‚przewodnikowy, czyli CMOS. MoÅ¼esz znaÄ‡ termin czujnik CMOS uÅ¼ywany w odniesieniu do czujnikÃ³w kamer.

Czujniki kamer to czujniki cyfrowe, przesyÅ‚ajÄ…ce dane obrazowe jako dane cyfrowe, zazwyczaj z pomocÄ… biblioteki zapewniajÄ…cej komunikacjÄ™. Kamery Å‚Ä…czÄ… siÄ™ za pomocÄ… protokoÅ‚Ã³w takich jak SPI, aby umoÅ¼liwiÄ‡ przesyÅ‚anie duÅ¼ych iloÅ›ci danych - obrazy sÄ… znacznie wiÄ™ksze niÅ¼ pojedyncze liczby z czujnika, takiego jak czujnik temperatury.

âœ… Jakie sÄ… ograniczenia dotyczÄ…ce rozmiaru obrazu w urzÄ…dzeniach IoT? ZastanÃ³w siÄ™ nad ograniczeniami, szczegÃ³lnie w przypadku sprzÄ™tu mikroprocesorowego.

## Uchwycenie obrazu za pomocÄ… urzÄ…dzenia IoT

MoÅ¼esz uÅ¼yÄ‡ swojego urzÄ…dzenia IoT do uchwycenia obrazu, ktÃ³ry ma zostaÄ‡ sklasyfikowany.

### Zadanie - uchwycenie obrazu za pomocÄ… urzÄ…dzenia IoT

PrzejdÅº przez odpowiedni przewodnik, aby uchwyciÄ‡ obraz za pomocÄ… swojego urzÄ…dzenia IoT:

* [Arduino - Wio Terminal](wio-terminal-camera.md)
* [Komputer jednopÅ‚ytkowy - Raspberry Pi](pi-camera.md)
* [Komputer jednopÅ‚ytkowy - Wirtualne urzÄ…dzenie](virtual-device-camera.md)

## Publikacja klasyfikatora obrazÃ³w

W poprzedniej lekcji wytrenowaÅ‚eÅ› swÃ³j klasyfikator obrazÃ³w. Zanim bÄ™dziesz mÃ³gÅ‚ go uÅ¼ywaÄ‡ z urzÄ…dzenia IoT, musisz opublikowaÄ‡ model.

### Iteracje modelu

Podczas trenowania modelu w poprzedniej lekcji mogÅ‚eÅ› zauwaÅ¼yÄ‡, Å¼e zakÅ‚adka **Performance** pokazuje iteracje z boku. Kiedy po raz pierwszy trenowaÅ‚eÅ› model, widziaÅ‚eÅ› *Iteration 1* w trakcie trenowania. Kiedy ulepszyÅ‚eÅ› model za pomocÄ… obrazÃ³w predykcyjnych, widziaÅ‚eÅ› *Iteration 2* w trakcie trenowania.

Za kaÅ¼dym razem, gdy trenujesz model, powstaje nowa iteracja. Jest to sposÃ³b na Å›ledzenie rÃ³Å¼nych wersji modelu trenowanych na rÃ³Å¼nych zestawach danych. Podczas **Quick Test** dostÄ™pny jest rozwijany wybÃ³r, ktÃ³ry pozwala wybraÄ‡ iteracjÄ™, aby porÃ³wnaÄ‡ wyniki miÄ™dzy rÃ³Å¼nymi iteracjami.

Kiedy jesteÅ› zadowolony z iteracji, moÅ¼esz jÄ… opublikowaÄ‡, aby byÅ‚a dostÄ™pna do uÅ¼ycia w aplikacjach zewnÄ™trznych. DziÄ™ki temu moÅ¼esz mieÄ‡ opublikowanÄ… wersjÄ™ uÅ¼ywanÄ… przez urzÄ…dzenia, a nastÄ™pnie pracowaÄ‡ nad nowÄ… wersjÄ… przez wiele iteracji, a nastÄ™pnie opublikowaÄ‡ jÄ…, gdy bÄ™dziesz z niej zadowolony.

### Zadanie - publikacja iteracji

Iteracje sÄ… publikowane z portalu Custom Vision.

1. Uruchom portal Custom Vision na [CustomVision.ai](https://customvision.ai) i zaloguj siÄ™, jeÅ›li jeszcze tego nie zrobiÅ‚eÅ›. NastÄ™pnie otwÃ³rz swÃ³j projekt `fruit-quality-detector`.

1. Wybierz zakÅ‚adkÄ™ **Performance** z opcji u gÃ³ry.

1. Wybierz najnowszÄ… iteracjÄ™ z listy *Iterations* z boku.

1. Wybierz przycisk **Publish** dla iteracji.

    ![Przycisk publikacji](../../../../../translated_images/custom-vision-publish-button.b7174e1977b0c33b8b72d4e5b1326c779e0af196f3849d09985ee2d7d5493a39.pl.png)

1. W oknie dialogowym *Publish Model* ustaw *Prediction resource* na zasÃ³b `fruit-quality-detector-prediction`, ktÃ³ry utworzyÅ‚eÅ› w poprzedniej lekcji. Pozostaw nazwÄ™ jako `Iteration2` i wybierz przycisk **Publish**.

1. Po opublikowaniu wybierz przycisk **Prediction URL**. WyÅ›wietli to szczegÃ³Å‚y dotyczÄ…ce API predykcji, ktÃ³re bÄ™dÄ… potrzebne do wywoÅ‚ania modelu z urzÄ…dzenia IoT. Dolna sekcja jest oznaczona *If you have an image file* i to sÄ… szczegÃ³Å‚y, ktÃ³re ciÄ™ interesujÄ…. Skopiuj URL, ktÃ³ry bÄ™dzie wyglÄ…daÅ‚ mniej wiÄ™cej tak:

    ```output
    https://<location>.api.cognitive.microsoft.com/customvision/v3.0/Prediction/<id>/classify/iterations/Iteration2/image
    ```

    Gdzie `<location>` bÄ™dzie lokalizacjÄ… uÅ¼ywanÄ… podczas tworzenia zasobu Custom Vision, a `<id>` bÄ™dzie dÅ‚ugim identyfikatorem skÅ‚adajÄ…cym siÄ™ z liter i cyfr.

    Skopiuj rÃ³wnieÅ¼ wartoÅ›Ä‡ *Prediction-Key*. Jest to klucz zabezpieczajÄ…cy, ktÃ³ry musisz przekazaÄ‡ podczas wywoÅ‚ywania modelu. Tylko aplikacje, ktÃ³re przekazujÄ… ten klucz, mogÄ… korzystaÄ‡ z modelu, inne aplikacje sÄ… odrzucane.

    ![Okno dialogowe API predykcji pokazujÄ…ce URL i klucz](../../../../../translated_images/custom-vision-prediction-key-endpoint.30c569ffd0338864f319911f052d5e9b8c5066cb0800a26dd6f7ff5713130ad8.pl.png)

âœ… Kiedy nowa iteracja zostanie opublikowana, bÄ™dzie miaÅ‚a innÄ… nazwÄ™. Jak myÅ›lisz, jak moÅ¼na zmieniÄ‡ iteracjÄ™ uÅ¼ywanÄ… przez urzÄ…dzenie IoT?

## Klasyfikacja obrazÃ³w z urzÄ…dzenia IoT

Teraz moÅ¼esz uÅ¼yÄ‡ tych szczegÃ³Å‚Ã³w poÅ‚Ä…czenia, aby wywoÅ‚aÄ‡ klasyfikator obrazÃ³w z urzÄ…dzenia IoT.

### Zadanie - klasyfikacja obrazÃ³w z urzÄ…dzenia IoT

PrzejdÅº przez odpowiedni przewodnik, aby sklasyfikowaÄ‡ obrazy za pomocÄ… swojego urzÄ…dzenia IoT:

* [Arduino - Wio Terminal](wio-terminal-classify-image.md)
* [Komputer jednopÅ‚ytkowy - Raspberry Pi/Wirtualne urzÄ…dzenie IoT](single-board-computer-classify-image.md)

## Udoskonalenie modelu

MoÅ¼esz zauwaÅ¼yÄ‡, Å¼e wyniki uzyskane przy uÅ¼yciu kamery podÅ‚Ä…czonej do urzÄ…dzenia IoT nie odpowiadajÄ… twoim oczekiwaniom. Predykcje nie zawsze sÄ… tak dokÅ‚adne, jak w przypadku obrazÃ³w przesÅ‚anych z komputera. Dzieje siÄ™ tak, poniewaÅ¼ model byÅ‚ trenowany na innych danych niÅ¼ te uÅ¼ywane do predykcji.

Aby uzyskaÄ‡ najlepsze wyniki dla klasyfikatora obrazÃ³w, naleÅ¼y trenowaÄ‡ model za pomocÄ… obrazÃ³w, ktÃ³re sÄ… jak najbardziej podobne do obrazÃ³w uÅ¼ywanych do predykcji. Na przykÅ‚ad, jeÅ›li uÅ¼yÅ‚eÅ› kamery telefonu do uchwycenia obrazÃ³w do trenowania, jakoÅ›Ä‡ obrazu, ostroÅ›Ä‡ i kolor bÄ™dÄ… rÃ³Å¼ne od kamery podÅ‚Ä…czonej do urzÄ…dzenia IoT.

![2 zdjÄ™cia bananÃ³w, jedno o niskiej rozdzielczoÅ›ci i sÅ‚abym oÅ›wietleniu z urzÄ…dzenia IoT, drugie o wysokiej rozdzielczoÅ›ci i dobrym oÅ›wietleniu z telefonu](../../../../../translated_images/banana-picture-compare.174df164dc326a42cf7fb051a7497e6113c620e91552d92ca914220305d47d9a.pl.png)

Na powyÅ¼szym obrazku zdjÄ™cie banana po lewej zostaÅ‚o zrobione za pomocÄ… kamery Raspberry Pi, a zdjÄ™cie po prawej zostaÅ‚o zrobione tego samego banana w tym samym miejscu za pomocÄ… iPhone'a. WidaÄ‡ zauwaÅ¼alnÄ… rÃ³Å¼nicÄ™ w jakoÅ›ci - zdjÄ™cie z iPhone'a jest ostrzejsze, z jaÅ›niejszymi kolorami i wiÄ™kszym kontrastem.

âœ… Co jeszcze moÅ¼e powodowaÄ‡, Å¼e obrazy uchwycone przez twoje urzÄ…dzenie IoT majÄ… nieprawidÅ‚owe predykcje? ZastanÃ³w siÄ™ nad Å›rodowiskiem, w ktÃ³rym moÅ¼e byÄ‡ uÅ¼ywane urzÄ…dzenie IoT, jakie czynniki mogÄ… wpÅ‚ywaÄ‡ na uchwycony obraz?

Aby ulepszyÄ‡ model, moÅ¼esz go ponownie wytrenowaÄ‡, uÅ¼ywajÄ…c obrazÃ³w uchwyconych z urzÄ…dzenia IoT.

### Zadanie - udoskonalenie modelu

1. Sklasyfikuj wiele obrazÃ³w zarÃ³wno dojrzaÅ‚ych, jak i niedojrzaÅ‚ych owocÃ³w za pomocÄ… swojego urzÄ…dzenia IoT.

1. W portalu Custom Vision ponownie wytrenuj model, uÅ¼ywajÄ…c obrazÃ³w na zakÅ‚adce *Predictions*.

    > âš ï¸ MoÅ¼esz odwoÅ‚aÄ‡ siÄ™ do [instrukcji dotyczÄ…cych ponownego trenowania klasyfikatora w lekcji 1, jeÅ›li zajdzie taka potrzeba](../1-train-fruit-detector/README.md#retrain-your-image-classifier).

1. JeÅ›li twoje obrazy wyglÄ…dajÄ… bardzo inaczej niÅ¼ oryginalne uÅ¼yte do trenowania, moÅ¼esz usunÄ…Ä‡ wszystkie oryginalne obrazy, wybierajÄ…c je na zakÅ‚adce *Training Images* i klikajÄ…c przycisk **Delete**. Aby wybraÄ‡ obraz, najedÅº na niego kursorem, a pojawi siÄ™ znacznik wyboru, kliknij go, aby wybraÄ‡ lub odznaczyÄ‡ obraz.

1. Wytrenuj nowÄ… iteracjÄ™ modelu i opublikuj jÄ…, korzystajÄ…c z powyÅ¼szych krokÃ³w.

1. Zaktualizuj URL punktu koÅ„cowego w swoim kodzie i uruchom aplikacjÄ™ ponownie.

1. Powtarzaj te kroki, aÅ¼ bÄ™dziesz zadowolony z wynikÃ³w predykcji.

---

## ğŸš€ Wyzwanie

Jak bardzo rozdzielczoÅ›Ä‡ obrazu lub oÅ›wietlenie wpÅ‚ywa na predykcjÄ™?

SprÃ³buj zmieniÄ‡ rozdzielczoÅ›Ä‡ obrazÃ³w w kodzie swojego urzÄ…dzenia i zobacz, czy ma to wpÅ‚yw na jakoÅ›Ä‡ obrazÃ³w. SprÃ³buj rÃ³wnieÅ¼ zmieniÄ‡ oÅ›wietlenie.

JeÅ›li miaÅ‚byÅ› stworzyÄ‡ urzÄ…dzenie produkcyjne do sprzedaÅ¼y na farmach lub w fabrykach, jak zapewniÅ‚byÅ›, Å¼e zawsze daje ono spÃ³jne wyniki?

## Quiz po wykÅ‚adzie

[Quiz po wykÅ‚adzie](https://black-meadow-040d15503.1.azurestaticapps.net/quiz/32)

## PrzeglÄ…d i samodzielna nauka

WytrenowaÅ‚eÅ› swÃ³j model Custom Vision za pomocÄ… portalu. To wymaga posiadania dostÄ™pnych obrazÃ³w - a w rzeczywistoÅ›ci moÅ¼esz nie byÄ‡ w stanie uzyskaÄ‡ danych treningowych, ktÃ³re odpowiadajÄ… temu, co uchwyca kamera na twoim urzÄ…dzeniu. MoÅ¼esz obejÅ›Ä‡ ten problem, trenujÄ…c bezpoÅ›rednio z urzÄ…dzenia za pomocÄ… API treningowego, aby wytrenowaÄ‡ model za pomocÄ… obrazÃ³w uchwyconych z urzÄ…dzenia IoT.

* Przeczytaj o API treningowym w [szybkim starcie korzystania z Custom Vision SDK](https://docs.microsoft.com/azure/cognitive-services/custom-vision-service/quickstarts/image-classification?WT.mc_id=academic-17441-jabenn&tabs=visual-studio&pivots=programming-language-python)

## Zadanie

[Reakcja na wyniki klasyfikacji](assignment.md)

**ZastrzeÅ¼enie**:  
Ten dokument zostaÅ‚ przetÅ‚umaczony za pomocÄ… usÅ‚ugi tÅ‚umaczenia AI [Co-op Translator](https://github.com/Azure/co-op-translator). ChociaÅ¼ dokÅ‚adamy wszelkich staraÅ„, aby tÅ‚umaczenie byÅ‚o precyzyjne, prosimy pamiÄ™taÄ‡, Å¼e automatyczne tÅ‚umaczenia mogÄ… zawieraÄ‡ bÅ‚Ä™dy lub nieÅ›cisÅ‚oÅ›ci. Oryginalny dokument w jego rodzimym jÄ™zyku powinien byÄ‡ uznawany za wiarygodne ÅºrÃ³dÅ‚o. W przypadku informacji o kluczowym znaczeniu zaleca siÄ™ skorzystanie z profesjonalnego tÅ‚umaczenia przez czÅ‚owieka. Nie ponosimy odpowiedzialnoÅ›ci za jakiekolwiek nieporozumienia lub bÅ‚Ä™dne interpretacje wynikajÄ…ce z uÅ¼ycia tego tÅ‚umaczenia.