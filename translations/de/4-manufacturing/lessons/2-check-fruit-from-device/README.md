<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "557f4ee96b752e0651d2e6e74aa6bd14",
  "translation_date": "2025-08-25T20:56:33+00:00",
  "source_file": "4-manufacturing/lessons/2-check-fruit-from-device/README.md",
  "language_code": "de"
}
-->
# √úberpr√ºfung der Obstqualit√§t mit einem IoT-Ger√§t

![Eine Sketchnote-√úbersicht dieser Lektion](../../../../../translated_images/lesson-16.215daf18b00631fbdfd64c6fc2dc6044dff5d544288825d8076f9fb83d964c23.de.jpg)

> Sketchnote von [Nitya Narasimhan](https://github.com/nitya). Klicken Sie auf das Bild f√ºr eine gr√∂√üere Version.

## Quiz vor der Vorlesung

[Quiz vor der Vorlesung](https://black-meadow-040d15503.1.azurestaticapps.net/quiz/31)

## Einf√ºhrung

In der letzten Lektion haben Sie etwas √ºber Bildklassifikatoren gelernt und wie man sie trainiert, um gutes und schlechtes Obst zu erkennen. Um diesen Bildklassifikator in einer IoT-Anwendung zu verwenden, m√ºssen Sie in der Lage sein, ein Bild mit einer Kamera aufzunehmen und dieses Bild in die Cloud zu senden, um es zu klassifizieren.

In dieser Lektion lernen Sie Kamerasensoren kennen und wie Sie diese mit einem IoT-Ger√§t verwenden, um ein Bild aufzunehmen. Au√üerdem erfahren Sie, wie Sie den Bildklassifikator von Ihrem IoT-Ger√§t aus aufrufen k√∂nnen.

In dieser Lektion behandeln wir:

* [Kamerasensoren](../../../../../4-manufacturing/lessons/2-check-fruit-from-device)
* [Ein Bild mit einem IoT-Ger√§t aufnehmen](../../../../../4-manufacturing/lessons/2-check-fruit-from-device)
* [Ihren Bildklassifikator ver√∂ffentlichen](../../../../../4-manufacturing/lessons/2-check-fruit-from-device)
* [Bilder von Ihrem IoT-Ger√§t klassifizieren](../../../../../4-manufacturing/lessons/2-check-fruit-from-device)
* [Das Modell verbessern](../../../../../4-manufacturing/lessons/2-check-fruit-from-device)

## Kamerasensoren

Kamerasensoren sind, wie der Name schon sagt, Kameras, die Sie mit Ihrem IoT-Ger√§t verbinden k√∂nnen. Sie k√∂nnen Standbilder aufnehmen oder Streaming-Videos erfassen. Einige liefern Rohbilddaten, andere komprimieren die Bilddaten in eine Bilddatei wie JPEG oder PNG. Normalerweise sind die Kameras, die mit IoT-Ger√§ten funktionieren, viel kleiner und haben eine geringere Aufl√∂sung als die, die Sie vielleicht gewohnt sind. Es gibt jedoch auch hochaufl√∂sende Kameras, die mit den besten Smartphones konkurrieren k√∂nnen. Sie k√∂nnen verschiedene Wechselobjektive, Mehrkamerasysteme, Infrarot-W√§rmekameras oder UV-Kameras erhalten.

![Das Licht einer Szene passiert eine Linse und wird auf einen CMOS-Sensor fokussiert](../../../../../translated_images/cmos-sensor.75f9cd74decb137149a4c9ea825251a4549497d67c0ae2776159e6102bb53aa9.de.png)

Die meisten Kamerasensoren verwenden Bildsensoren, bei denen jedes Pixel eine Fotodiode ist. Eine Linse fokussiert das Bild auf den Bildsensor, und Tausende oder Millionen von Fotodioden erfassen das Licht, das auf jede einzelne f√§llt, und zeichnen dies als Pixeldaten auf.

> üíÅ Linsen drehen Bilder um, der Kamerasensor dreht das Bild dann wieder richtig herum. Das ist auch bei Ihren Augen der Fall ‚Äì das, was Sie sehen, wird auf der R√ºckseite Ihres Auges auf den Kopf gestellt erfasst, und Ihr Gehirn korrigiert es.

> üéì Der Bildsensor wird als Active-Pixel-Sensor (APS) bezeichnet, und der beliebteste Typ von APS ist ein Complementary Metal-Oxide Semiconductor-Sensor, oder CMOS. Sie haben m√∂glicherweise den Begriff CMOS-Sensor f√ºr Kamerasensoren geh√∂rt.

Kamerasensoren sind digitale Sensoren, die Bilddaten als digitale Daten senden, normalerweise mit Hilfe einer Bibliothek, die die Kommunikation bereitstellt. Kameras verwenden Protokolle wie SPI, um gro√üe Datenmengen zu senden ‚Äì Bilder sind erheblich gr√∂√üer als einzelne Zahlen von einem Sensor wie einem Temperatursensor.

‚úÖ Welche Einschr√§nkungen gibt es bei der Bildgr√∂√üe mit IoT-Ger√§ten? Denken Sie insbesondere an die Beschr√§nkungen bei Mikrocontroller-Hardware.

## Ein Bild mit einem IoT-Ger√§t aufnehmen

Sie k√∂nnen Ihr IoT-Ger√§t verwenden, um ein Bild aufzunehmen, das klassifiziert werden soll.

### Aufgabe ‚Äì ein Bild mit einem IoT-Ger√§t aufnehmen

Arbeiten Sie die entsprechende Anleitung durch, um ein Bild mit Ihrem IoT-Ger√§t aufzunehmen:

* [Arduino - Wio Terminal](wio-terminal-camera.md)
* [Einplatinencomputer - Raspberry Pi](pi-camera.md)
* [Einplatinencomputer - Virtuelles Ger√§t](virtual-device-camera.md)

## Ihren Bildklassifikator ver√∂ffentlichen

Sie haben Ihren Bildklassifikator in der letzten Lektion trainiert. Bevor Sie ihn von Ihrem IoT-Ger√§t aus verwenden k√∂nnen, m√ºssen Sie das Modell ver√∂ffentlichen.

### Modelliterationen

W√§hrend Ihr Modell in der letzten Lektion trainiert wurde, haben Sie m√∂glicherweise bemerkt, dass die Registerkarte **Leistung** Iterationen auf der Seite anzeigt. Als Sie das Modell zum ersten Mal trainiert haben, haben Sie *Iteration 1* im Training gesehen. Als Sie das Modell mit den Vorhersagebildern verbessert haben, haben Sie *Iteration 2* im Training gesehen.

Jedes Mal, wenn Sie das Modell trainieren, erhalten Sie eine neue Iteration. Dies ist eine M√∂glichkeit, die verschiedenen Versionen Ihres Modells zu verfolgen, die mit unterschiedlichen Datens√§tzen trainiert wurden. Wenn Sie einen **Schnelltest** durchf√ºhren, gibt es ein Dropdown-Men√º, mit dem Sie die Iteration ausw√§hlen k√∂nnen, sodass Sie die Ergebnisse √ºber mehrere Iterationen hinweg vergleichen k√∂nnen.

Wenn Sie mit einer Iteration zufrieden sind, k√∂nnen Sie sie ver√∂ffentlichen, um sie f√ºr externe Anwendungen verf√ºgbar zu machen. Auf diese Weise k√∂nnen Sie eine ver√∂ffentlichte Version haben, die von Ihren Ger√§ten verwendet wird, dann an einer neuen Version √ºber mehrere Iterationen arbeiten und diese ver√∂ffentlichen, sobald Sie damit zufrieden sind.

### Aufgabe ‚Äì eine Iteration ver√∂ffentlichen

Iterationen werden √ºber das Custom Vision-Portal ver√∂ffentlicht.

1. Starten Sie das Custom Vision-Portal unter [CustomVision.ai](https://customvision.ai) und melden Sie sich an, falls Sie es noch nicht ge√∂ffnet haben. √ñffnen Sie dann Ihr Projekt `fruit-quality-detector`.

1. W√§hlen Sie die Registerkarte **Leistung** aus den Optionen oben aus.

1. W√§hlen Sie die neueste Iteration aus der Liste *Iterationen* auf der Seite aus.

1. W√§hlen Sie die Schaltfl√§che **Ver√∂ffentlichen** f√ºr die Iteration aus.

    ![Die Schaltfl√§che Ver√∂ffentlichen](../../../../../translated_images/custom-vision-publish-button.b7174e1977b0c33b8b72d4e5b1326c779e0af196f3849d09985ee2d7d5493a39.de.png)

1. Legen Sie im Dialogfeld *Modell ver√∂ffentlichen* die *Vorhersageressource* auf die Ressource `fruit-quality-detector-prediction` fest, die Sie in der letzten Lektion erstellt haben. Lassen Sie den Namen als `Iteration2` und w√§hlen Sie die Schaltfl√§che **Ver√∂ffentlichen** aus.

1. Sobald die Iteration ver√∂ffentlicht ist, w√§hlen Sie die Schaltfl√§che **Vorhersage-URL** aus. Dies zeigt Details der Vorhersage-API, die Sie ben√∂tigen, um das Modell von Ihrem IoT-Ger√§t aus aufzurufen. Der untere Abschnitt ist mit *Wenn Sie eine Bilddatei haben* beschriftet, und dies sind die Details, die Sie ben√∂tigen. Kopieren Sie die angezeigte URL, die etwa so aussieht:

    ```output
    https://<location>.api.cognitive.microsoft.com/customvision/v3.0/Prediction/<id>/classify/iterations/Iteration2/image
    ```

    Dabei wird `<location>` der Standort sein, den Sie bei der Erstellung Ihrer Custom Vision-Ressource verwendet haben, und `<id>` wird eine lange ID aus Buchstaben und Zahlen sein.

    Kopieren Sie auch den Wert *Vorhersage-Schl√ºssel*. Dies ist ein sicherer Schl√ºssel, den Sie √ºbergeben m√ºssen, wenn Sie das Modell aufrufen. Nur Anwendungen, die diesen Schl√ºssel √ºbergeben, d√ºrfen das Modell verwenden, alle anderen Anwendungen werden abgelehnt.

    ![Das Dialogfeld Vorhersage-API zeigt die URL und den Schl√ºssel](../../../../../translated_images/custom-vision-prediction-key-endpoint.30c569ffd0338864f319911f052d5e9b8c5066cb0800a26dd6f7ff5713130ad8.de.png)

‚úÖ Wenn eine neue Iteration ver√∂ffentlicht wird, hat sie einen anderen Namen. Wie w√ºrden Sie die Iteration √§ndern, die ein IoT-Ger√§t verwendet?

## Bilder von Ihrem IoT-Ger√§t klassifizieren

Sie k√∂nnen diese Verbindungsdetails jetzt verwenden, um den Bildklassifikator von Ihrem IoT-Ger√§t aus aufzurufen.

### Aufgabe ‚Äì Bilder von Ihrem IoT-Ger√§t klassifizieren

Arbeiten Sie die entsprechende Anleitung durch, um Bilder mit Ihrem IoT-Ger√§t zu klassifizieren:

* [Arduino - Wio Terminal](wio-terminal-classify-image.md)
* [Einplatinencomputer - Raspberry Pi/Virtuelles IoT-Ger√§t](single-board-computer-classify-image.md)

## Das Modell verbessern

Es kann sein, dass die Ergebnisse, die Sie mit der Kamera Ihres IoT-Ger√§ts erhalten, nicht den Erwartungen entsprechen. Die Vorhersagen sind m√∂glicherweise nicht so genau wie bei Bildern, die von Ihrem Computer hochgeladen wurden. Dies liegt daran, dass das Modell mit anderen Daten trainiert wurde als denjenigen, die f√ºr Vorhersagen verwendet werden.

Um die besten Ergebnisse f√ºr einen Bildklassifikator zu erzielen, sollten Sie das Modell mit Bildern trainieren, die den f√ºr Vorhersagen verwendeten Bildern so √§hnlich wie m√∂glich sind. Wenn Sie beispielsweise Ihre Handykamera verwendet haben, um Bilder f√ºr das Training aufzunehmen, werden die Bildqualit√§t, Sch√§rfe und Farben anders sein als bei einer Kamera, die mit einem IoT-Ger√§t verbunden ist.

![2 Bananenbilder, eines mit niedriger Aufl√∂sung und schlechter Beleuchtung von einem IoT-Ger√§t, und eines mit hoher Aufl√∂sung und guter Beleuchtung von einem Telefon](../../../../../translated_images/banana-picture-compare.174df164dc326a42cf7fb051a7497e6113c620e91552d92ca914220305d47d9a.de.png)

Im obigen Bild wurde das Bananenbild links mit einer Raspberry Pi-Kamera aufgenommen, das rechts mit einem iPhone von derselben Banane am selben Ort. Es gibt einen deutlichen Unterschied in der Qualit√§t ‚Äì das iPhone-Bild ist sch√§rfer, mit helleren Farben und mehr Kontrast.

‚úÖ Was k√∂nnte sonst noch dazu f√ºhren, dass die von Ihrem IoT-Ger√§t aufgenommenen Bilder falsche Vorhersagen haben? Denken Sie an die Umgebung, in der ein IoT-Ger√§t verwendet werden k√∂nnte. Welche Faktoren k√∂nnen das aufgenommene Bild beeinflussen?

Um das Modell zu verbessern, k√∂nnen Sie es mit den Bildern, die vom IoT-Ger√§t aufgenommen wurden, erneut trainieren.

### Aufgabe ‚Äì das Modell verbessern

1. Klassifizieren Sie mehrere Bilder von reifen und unreifen Fr√ºchten mit Ihrem IoT-Ger√§t.

1. Trainieren Sie das Modell im Custom Vision-Portal erneut mit den Bildern auf der Registerkarte *Vorhersagen*.

    > ‚ö†Ô∏è Sie k√∂nnen [die Anweisungen zum erneuten Trainieren Ihres Klassifikators in Lektion 1 bei Bedarf](../1-train-fruit-detector/README.md#retrain-your-image-classifier) nachlesen.

1. Wenn Ihre Bilder sehr unterschiedlich zu den urspr√ºnglichen Bildern aussehen, die f√ºr das Training verwendet wurden, k√∂nnen Sie alle urspr√ºnglichen Bilder l√∂schen, indem Sie sie auf der Registerkarte *Trainingsbilder* ausw√§hlen und die Schaltfl√§che **L√∂schen** ausw√§hlen. Um ein Bild auszuw√§hlen, bewegen Sie den Cursor dar√ºber, und ein H√§kchen erscheint. W√§hlen Sie dieses H√§kchen aus, um das Bild auszuw√§hlen oder die Auswahl aufzuheben.

1. Trainieren Sie eine neue Iteration des Modells und ver√∂ffentlichen Sie es mit den oben genannten Schritten.

1. Aktualisieren Sie die Endpunkt-URL in Ihrem Code und f√ºhren Sie die App erneut aus.

1. Wiederholen Sie diese Schritte, bis Sie mit den Ergebnissen der Vorhersagen zufrieden sind.

---

## üöÄ Herausforderung

Wie stark beeinflussen die Bildaufl√∂sung oder Beleuchtung die Vorhersage?

Versuchen Sie, die Aufl√∂sung der Bilder in Ihrem Ger√§tecode zu √§ndern, und sehen Sie, ob dies einen Unterschied in der Qualit√§t der Bilder macht. Probieren Sie auch unterschiedliche Beleuchtung aus.

Wenn Sie ein Produktionsger√§t entwickeln w√ºrden, das an Bauernh√∂fe oder Fabriken verkauft wird, wie w√ºrden Sie sicherstellen, dass es immer konsistente Ergebnisse liefert?

## Quiz nach der Vorlesung

[Quiz nach der Vorlesung](https://black-meadow-040d15503.1.azurestaticapps.net/quiz/32)

## R√ºckblick & Selbststudium

Sie haben Ihr Custom Vision-Modell mit dem Portal trainiert. Dies setzt voraus, dass Bilder verf√ºgbar sind ‚Äì und in der realen Welt k√∂nnen Sie m√∂glicherweise keine Trainingsdaten erhalten, die mit den Bildern √ºbereinstimmen, die die Kamera Ihres Ger√§ts aufnimmt. Sie k√∂nnen dies umgehen, indem Sie direkt von Ihrem Ger√§t aus mit der Trainings-API trainieren, um ein Modell mit Bildern zu trainieren, die von Ihrem IoT-Ger√§t aufgenommen wurden.

* Lesen Sie mehr √ºber die Trainings-API im [Schnellstart zur Verwendung des Custom Vision SDK](https://docs.microsoft.com/azure/cognitive-services/custom-vision-service/quickstarts/image-classification?WT.mc_id=academic-17441-jabenn&tabs=visual-studio&pivots=programming-language-python)

## Aufgabe

[Auf Klassifikationsergebnisse reagieren](assignment.md)

**Haftungsausschluss**:  
Dieses Dokument wurde mithilfe des KI-√úbersetzungsdienstes [Co-op Translator](https://github.com/Azure/co-op-translator) √ºbersetzt. Obwohl wir uns um Genauigkeit bem√ºhen, beachten Sie bitte, dass automatisierte √úbersetzungen Fehler oder Ungenauigkeiten enthalten k√∂nnen. Das Originaldokument in seiner urspr√ºnglichen Sprache sollte als ma√ügebliche Quelle betrachtet werden. F√ºr kritische Informationen wird eine professionelle menschliche √úbersetzung empfohlen. Wir √ºbernehmen keine Haftung f√ºr Missverst√§ndnisse oder Fehlinterpretationen, die sich aus der Nutzung dieser √úbersetzung ergeben.