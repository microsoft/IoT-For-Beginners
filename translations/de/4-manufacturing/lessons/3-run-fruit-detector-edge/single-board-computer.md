<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "50151d9f9dce2801348a93880ef16d86",
  "translation_date": "2025-08-25T21:09:36+00:00",
  "source_file": "4-manufacturing/lessons/3-run-fruit-detector-edge/single-board-computer.md",
  "language_code": "de"
}
-->
# Klassifizieren eines Bildes mit einem IoT-Edge-basierten Bildklassifikator - Virtuelle IoT-Hardware und Raspberry Pi

In diesem Teil der Lektion verwenden Sie den Bildklassifikator, der auf dem IoT-Edge-Ger√§t l√§uft.

## Verwenden des IoT-Edge-Klassifikators

Das IoT-Ger√§t kann so umgeleitet werden, dass es den IoT-Edge-Bildklassifikator verwendet. Die URL f√ºr den Bildklassifikator lautet `http://<IP-Adresse oder Name>/image`, wobei `<IP-Adresse oder Name>` durch die IP-Adresse oder den Hostnamen des Computers ersetzt wird, auf dem IoT Edge l√§uft.

Die Python-Bibliothek f√ºr Custom Vision funktioniert nur mit cloud-gehosteten Modellen, nicht mit Modellen, die auf IoT Edge gehostet werden. Das bedeutet, dass Sie die REST-API verwenden m√ºssen, um den Klassifikator aufzurufen.

### Aufgabe - Verwenden des IoT-Edge-Klassifikators

1. √ñffnen Sie das Projekt `fruit-quality-detector` in VS Code, falls es noch nicht ge√∂ffnet ist. Wenn Sie ein virtuelles IoT-Ger√§t verwenden, stellen Sie sicher, dass die virtuelle Umgebung aktiviert ist.

1. √ñffnen Sie die Datei `app.py` und entfernen Sie die Import-Anweisungen von `azure.cognitiveservices.vision.customvision.prediction` und `msrest.authentication`.

1. F√ºgen Sie die folgende Import-Anweisung am Anfang der Datei hinzu:

    ```python
    import requests
    ```

1. L√∂schen Sie den gesamten Code nach dem Speichern des Bildes in einer Datei, beginnend mit `image_file.write(image.read())` bis zum Ende der Datei.

1. F√ºgen Sie den folgenden Code am Ende der Datei hinzu:

    ```python
    prediction_url = '<URL>'
    headers = {
        'Content-Type' : 'application/octet-stream'
    }
    image.seek(0)
    response = requests.post(prediction_url, headers=headers, data=image)
    results = response.json()
    
    for prediction in results['predictions']:
        print(f'{prediction["tagName"]}:\t{prediction["probability"] * 100:.2f}%')
    ```

    Ersetzen Sie `<URL>` durch die URL Ihres Klassifikators.

    Dieser Code f√ºhrt eine REST-POST-Anfrage an den Klassifikator aus und sendet das Bild als Body der Anfrage. Die Ergebnisse werden als JSON zur√ºckgegeben und dekodiert, um die Wahrscheinlichkeiten auszugeben.

1. F√ºhren Sie Ihren Code aus, w√§hrend Ihre Kamera auf ein St√ºck Obst gerichtet ist, ein geeignetes Bildset verwendet wird oder Obst auf Ihrer Webcam sichtbar ist, falls Sie virtuelle IoT-Hardware verwenden. Sie sehen die Ausgabe in der Konsole:

    ```output
    (.venv) ‚ûú  fruit-quality-detector python app.py
    ripe:   56.84%
    unripe: 43.16%
    ```

> üíÅ Sie finden diesen Code im Ordner [code-classify/pi](../../../../../4-manufacturing/lessons/3-run-fruit-detector-edge/code-classify/pi) oder [code-classify/virtual-iot-device](../../../../../4-manufacturing/lessons/3-run-fruit-detector-edge/code-classify/virtual-iot-device).

üòÄ Ihr Programm zur Klassifizierung der Obstqualit√§t war ein Erfolg!

**Haftungsausschluss**:  
Dieses Dokument wurde mit dem KI-√úbersetzungsdienst [Co-op Translator](https://github.com/Azure/co-op-translator) √ºbersetzt. Obwohl wir uns um Genauigkeit bem√ºhen, beachten Sie bitte, dass automatisierte √úbersetzungen Fehler oder Ungenauigkeiten enthalten k√∂nnen. Das Originaldokument in seiner urspr√ºnglichen Sprache sollte als ma√ügebliche Quelle betrachtet werden. F√ºr kritische Informationen wird eine professionelle menschliche √úbersetzung empfohlen. Wir √ºbernehmen keine Haftung f√ºr Missverst√§ndnisse oder Fehlinterpretationen, die sich aus der Nutzung dieser √úbersetzung ergeben.