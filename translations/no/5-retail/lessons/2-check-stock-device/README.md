<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "1c9e5fa8b7be726c75a97232b1e41c97",
  "translation_date": "2025-08-27T22:17:12+00:00",
  "source_file": "5-retail/lessons/2-check-stock-device/README.md",
  "language_code": "no"
}
-->
# Sjekk lagerbeholdning fra en IoT-enhet

![En sketchnote-oversikt over denne leksjonen](../../../../../translated_images/lesson-20.0211df9551a8abb300fc8fcf7dc2789468dea2eabe9202273ac077b0ba37f15e.no.jpg)

> Sketchnote av [Nitya Narasimhan](https://github.com/nitya). Klikk p√• bildet for en st√∏rre versjon.

## Quiz f√∏r leksjonen

[Quiz f√∏r leksjonen](https://black-meadow-040d15503.1.azurestaticapps.net/quiz/39)

## Introduksjon

I forrige leksjon l√¶rte du om de ulike bruksomr√•dene for objektdeteksjon i detaljhandel. Du l√¶rte ogs√• hvordan du trener en objektdetektor til √• identifisere lagerbeholdning. I denne leksjonen vil du l√¶re hvordan du bruker objektdetektoren fra din IoT-enhet for √• telle lagerbeholdning.

I denne leksjonen dekker vi:

* [Lagerbeholdningstelling](../../../../../5-retail/lessons/2-check-stock-device)
* [Kall objektdetektoren fra din IoT-enhet](../../../../../5-retail/lessons/2-check-stock-device)
* [Avgrensningsbokser](../../../../../5-retail/lessons/2-check-stock-device)
* [Tren modellen p√• nytt](../../../../../5-retail/lessons/2-check-stock-device)
* [Tell lagerbeholdning](../../../../../5-retail/lessons/2-check-stock-device)

> üóë Dette er den siste leksjonen i dette prosjektet, s√• etter at du har fullf√∏rt denne leksjonen og oppgaven, ikke glem √• rydde opp i skyressursene dine. Du vil trenge ressursene for √• fullf√∏re oppgaven, s√• s√∏rg for √• gj√∏re det f√∏rst.
>
> Se [veiledningen for √• rydde opp i prosjektet ditt](../../../clean-up.md) hvis du trenger instruksjoner for hvordan du gj√∏r dette.

## Lagerbeholdningstelling

Objektdetektorer kan brukes til lagerkontroll, enten for √• telle lagerbeholdning eller for √• sikre at lageret er der det skal v√¶re. IoT-enheter med kameraer kan plasseres rundt i butikken for √• overv√•ke lageret, med fokus p√• omr√•der der det er viktig √• ha varer p√• lager, som steder med f√•, men verdifulle varer.

For eksempel, hvis et kamera peker mot en hylle som kan holde 8 bokser med tomatpur√©, og en objektdetektor bare oppdager 7 bokser, mangler √©n og m√• fylles p√•.

![7 bokser med tomatpur√© p√• en hylle, 4 p√• √∏verste rad, 3 p√• nederste rad](../../../../../translated_images/stock-7-cans-tomato-paste.f86059cc573d7becaa89a0eafb9d2cd7e2fe37405a530fe565990e2333d0e4a1.no.png)

I bildet ovenfor har en objektdetektor oppdaget 7 bokser med tomatpur√© p√• en hylle som kan holde 8 bokser. Ikke bare kan IoT-enheten sende en melding om behovet for p√•fyll, men den kan ogs√• gi en indikasjon p√• hvor den manglende varen befinner seg, viktig informasjon hvis du bruker roboter til √• fylle p√• hyllene.

> üíÅ Avhengig av butikken og populariteten til varen, ville p√•fyll sannsynligvis ikke skje hvis bare √©n boks mangler. Du m√• bygge en algoritme som avgj√∏r n√•r p√•fyll skal skje basert p√• produktet, kundene og andre kriterier.

‚úÖ I hvilke andre situasjoner kan du kombinere objektdeteksjon og roboter?

Noen ganger kan feil varer havne p√• hyllene. Dette kan skyldes menneskelige feil under p√•fylling, eller kunder som ombestemmer seg og legger en vare tilbake p√• f√∏rste tilgjengelige plass. N√•r dette gjelder varer som ikke er lett bedervelige, som hermetikk, er det en irritasjon. Hvis det gjelder lett bedervelige varer som frosne eller kj√∏lte produkter, kan det bety at varen ikke lenger kan selges, da det kan v√¶re umulig √• vite hvor lenge varen har v√¶rt ute av fryseren.

Objektdeteksjon kan brukes til √• oppdage uventede varer, og varsle en person eller robot om √• returnere varen s√• snart den oppdages.

![En boks med babymais p√• tomatpur√©hylle](../../../../../translated_images/stock-rogue-corn.be1f3ada8c4578544641af66671c1711a4c02297f14cc7f503354dae0d30a954.no.png)

I bildet ovenfor har en boks med babymais blitt plassert p√• hyllen ved siden av tomatpur√©en. Objektdetektoren har oppdaget dette, slik at IoT-enheten kan varsle en person eller robot om √• returnere boksen til riktig plass.

## Kall objektdetektoren fra din IoT-enhet

Objektdetektoren du trente i forrige leksjon kan kalles fra din IoT-enhet.

### Oppgave - publiser en iterasjon av objektdetektoren din

Iterasjoner publiseres fra Custom Vision-portalen.

1. √Öpne Custom Vision-portalen p√• [CustomVision.ai](https://customvision.ai) og logg inn hvis du ikke allerede har den √•pen. Deretter √•pner du prosjektet ditt `stock-detector`.

1. Velg **Performance**-fanen fra alternativene √∏verst.

1. Velg den nyeste iterasjonen fra listen *Iterations* p√• siden.

1. Klikk p√• **Publish**-knappen for iterasjonen.

    ![Publiser-knappen](../../../../../translated_images/custom-vision-object-detector-publish-button.34ee379fc650ccb9856c3868d0003f413b9529f102fc73c37168c98d721cc293.no.png)

1. I dialogboksen *Publish Model*, sett *Prediction resource* til ressursen `stock-detector-prediction` som du opprettet i forrige leksjon. La navnet v√¶re `Iteration2`, og klikk p√• **Publish**-knappen.

1. N√•r den er publisert, klikker du p√• **Prediction URL**-knappen. Dette vil vise detaljer om prediksjons-API-en, og du vil trenge disse for √• kalle modellen fra din IoT-enhet. Den nederste delen er merket *If you have an image file*, og dette er detaljene du trenger. Ta en kopi av URL-en som vises, som vil v√¶re noe som:

    ```output
    https://<location>.api.cognitive.microsoft.com/customvision/v3.0/Prediction/<id>/detect/iterations/Iteration2/image
    ```

    Der `<location>` vil v√¶re stedet du brukte da du opprettet din Custom Vision-ressurs, og `<id>` vil v√¶re en lang ID best√•ende av bokstaver og tall.

    Ta ogs√• en kopi av verdien *Prediction-Key*. Dette er en sikker n√∏kkel som du m√• sende n√•r du kaller modellen. Bare applikasjoner som sender denne n√∏kkelen har lov til √• bruke modellen, alle andre applikasjoner blir avvist.

    ![Dialogboksen for prediksjons-API som viser URL og n√∏kkel](../../../../../translated_images/custom-vision-prediction-key-endpoint.30c569ffd0338864f319911f052d5e9b8c5066cb0800a26dd6f7ff5713130ad8.no.png)

‚úÖ N√•r en ny iterasjon publiseres, vil den ha et annet navn. Hvordan tror du du ville endret iterasjonen en IoT-enhet bruker?

### Oppgave - kall objektdetektoren fra din IoT-enhet

F√∏lg den relevante veiledningen nedenfor for √• bruke objektdetektoren fra din IoT-enhet:

* [Arduino - Wio Terminal](wio-terminal-object-detector.md)
* [Enkeltkortdatamaskin - Raspberry Pi/virtuell enhet](single-board-computer-object-detector.md)

## Avgrensningsbokser

N√•r du bruker objektdetektoren, f√•r du ikke bare tilbake de oppdagede objektene med deres tagger og sannsynligheter, men ogs√• avgrensningsboksene for objektene. Disse definerer hvor objektdetektoren oppdaget objektet med den gitte sannsynligheten.

> üíÅ En avgrensningsboks er en boks som definerer omr√•det som inneholder det oppdagede objektet, en boks som definerer grensen for objektet.

Resultatene av en prediksjon i **Predictions**-fanen i Custom Vision har avgrensningsboksene tegnet p√• bildet som ble sendt for prediksjon.

![4 bokser med tomatpur√© p√• en hylle med prediksjoner for de 4 oppdagelsene med 35.8%, 33.5%, 25.7% og 16.6%](../../../../../translated_images/custom-vision-stock-prediction.942266ab1bcca3410ecdf23643b9f5f570cfab2345235074e24c51f285777613.no.png)

I bildet ovenfor ble 4 bokser med tomatpur√© oppdaget. I resultatene er en r√∏d firkant lagt over hvert objekt som ble oppdaget i bildet, som indikerer avgrensningsboksen for bildet.

‚úÖ √Öpne prediksjonene i Custom Vision og sjekk avgrensningsboksene.

Avgrensningsbokser er definert med 4 verdier - topp, venstre, h√∏yde og bredde. Disse verdiene er p√• en skala fra 0-1, som representerer posisjonene som en prosentandel av st√∏rrelsen p√• bildet. Origo (posisjonen 0,0) er √∏verst til venstre p√• bildet, s√• toppverdien er avstanden fra toppen, og bunnen av avgrensningsboksen er toppen pluss h√∏yden.

![En avgrensningsboks rundt en boks med tomatpur√©](../../../../../translated_images/bounding-box.1420a7ea0d3d15f71e1ffb5cf4b2271d184fac051f990abc541975168d163684.no.png)

Bildet ovenfor er 600 piksler bredt og 800 piksler h√∏yt. Avgrensningsboksen starter 320 piksler ned, som gir en toppkoordinat p√• 0.4 (800 x 0.4 = 320). Fra venstre starter avgrensningsboksen 240 piksler inn, som gir en venstrekoordinat p√• 0.4 (600 x 0.4 = 240). H√∏yden p√• avgrensningsboksen er 240 piksler, som gir en h√∏ydeverdi p√• 0.3 (800 x 0.3 = 240). Bredden p√• avgrensningsboksen er 120 piksler, som gir en breddeverdi p√• 0.2 (600 x 0.2 = 120).

| Koordinat | Verdi |
| ---------- | ----: |
| Topp       | 0.4   |
| Venstre    | 0.4   |
| H√∏yde      | 0.3   |
| Bredde     | 0.2   |

Ved √• bruke prosentverdier fra 0-1 betyr det at uansett hvilken st√∏rrelse bildet skaleres til, starter avgrensningsboksen 0.4 av veien langs og ned, og er 0.3 av h√∏yden og 0.2 av bredden.

Du kan bruke avgrensningsbokser kombinert med sannsynligheter for √• evaluere hvor n√∏yaktig en oppdagelse er. For eksempel kan en objektdetektor oppdage flere objekter som overlapper, for eksempel oppdage √©n boks inne i en annen. Koden din kan se p√• avgrensningsboksene, forst√• at dette er umulig, og ignorere eventuelle objekter som har betydelig overlapping med andre objekter.

![To avgrensningsbokser som overlapper en boks med tomatpur√©](../../../../../translated_images/overlap-object-detection.d431e03cae75072a2760430eca7f2c5fdd43045bfd72dadcbf12711f7cd6c2ae.no.png)

I eksempelet ovenfor indikerer √©n avgrensningsboks en oppdaget boks med tomatpur√© med 78.3%. En annen avgrensningsboks er litt mindre og er inne i den f√∏rste boksen med en sannsynlighet p√• 64.3%. Koden din kan sjekke avgrensningsboksene, se at de overlapper fullstendig, og ignorere den lavere sannsynligheten, da det ikke er mulig at √©n boks er inne i en annen.

‚úÖ Kan du tenke deg en situasjon der det er gyldig √• oppdage ett objekt inne i et annet?

## Tren modellen p√• nytt

Som med bildekategorisering, kan du trene modellen din p√• nytt ved √• bruke data samlet inn av din IoT-enhet. √Ö bruke disse dataene fra virkeligheten vil sikre at modellen din fungerer godt n√•r den brukes fra din IoT-enhet.

I motsetning til bildekategorisering, kan du ikke bare tagge et bilde. I stedet m√• du gjennomg√• hver avgrensningsboks som modellen har oppdaget. Hvis boksen er rundt feil ting, m√• den slettes, og hvis den er p√• feil sted, m√• den justeres.

### Oppgave - tren modellen p√• nytt

1. S√∏rg for at du har samlet inn et utvalg bilder ved hjelp av din IoT-enhet.

1. Fra **Predictions**-fanen, velg et bilde. Du vil se r√∏de bokser som indikerer avgrensningsboksene for de oppdagede objektene.

1. G√• gjennom hver avgrensningsboks. Velg den f√∏rst, og du vil se en pop-up som viser taggen. Bruk h√•ndtakene p√• hj√∏rnene av avgrensningsboksen for √• justere st√∏rrelsen hvis n√∏dvendig. Hvis taggen er feil, fjern den med **X**-knappen og legg til riktig tag. Hvis avgrensningsboksen ikke inneholder et objekt, slett den med s√∏ppelb√∏tteknappen.

1. Lukk redigeringsverkt√∏yet n√•r du er ferdig, og bildet vil flytte seg fra **Predictions**-fanen til **Training Images**-fanen. Gjenta prosessen for alle prediksjonene.

1. Bruk **Train**-knappen for √• trene modellen din p√• nytt. N√•r den er trent, publiser iterasjonen og oppdater IoT-enheten din til √• bruke URL-en til den nye iterasjonen.

1. Re-deploy koden din og test IoT-enheten din.

## Tell lagerbeholdning

Ved √• kombinere antall oppdagede objekter og avgrensningsboksene kan du telle lagerbeholdningen p√• en hylle.

### Oppgave - tell lagerbeholdning

F√∏lg den relevante veiledningen nedenfor for √• telle lagerbeholdning ved hjelp av resultatene fra objektdetektoren fra din IoT-enhet:

* [Arduino - Wio Terminal](wio-terminal-count-stock.md)
* [Enkeltkortdatamaskin - Raspberry Pi/virtuell enhet](single-board-computer-count-stock.md)

---

## üöÄ Utfordring

Kan du oppdage feil lagerbeholdning? Tren modellen din p√• flere objekter, og oppdater appen din til √• varsle deg hvis feil lager oppdages.

Kanskje du kan ta dette et steg videre og oppdage lagerbeholdning side om side p√• samme hylle, og se om noe har blitt plassert p√• feil sted ved √• definere grenser for avgrensningsboksene.

## Quiz etter leksjonen

[Quiz etter leksjonen](https://black-meadow-040d15503.1.azurestaticapps.net/quiz/40)

## Gjennomgang og selvstudium

* L√¶r mer om hvordan du kan designe et ende-til-ende lagerdeteksjonssystem fra [Out of stock detection at the edge pattern guide p√• Microsoft Docs](https://docs.microsoft.com/hybrid/app-solutions/pattern-out-of-stock-at-edge?WT.mc_id=academic-17441-jabenn)
* L√¶r andre m√•ter √• bygge ende-til-ende l√∏sninger for detaljhandel ved √• kombinere en rekke IoT- og sky-tjenester ved √• se denne [Behind the scenes of a retail solution - Hands On! video p√• YouTube](https://www.youtube.com/watch?v=m3Pc300x2Mw).

## Oppgave

[Bruk objektdetektoren din p√• kanten](assignment.md)

---

**Ansvarsfraskrivelse**:  
Dette dokumentet er oversatt ved hjelp av AI-oversettelsestjenesten [Co-op Translator](https://github.com/Azure/co-op-translator). Selv om vi streber etter n√∏yaktighet, v√¶r oppmerksom p√• at automatiske oversettelser kan inneholde feil eller un√∏yaktigheter. Det originale dokumentet p√• sitt opprinnelige spr√•k b√∏r anses som den autoritative kilden. For kritisk informasjon anbefales profesjonell menneskelig oversettelse. Vi er ikke ansvarlige for misforst√•elser eller feiltolkninger som oppst√•r ved bruk av denne oversettelsen.