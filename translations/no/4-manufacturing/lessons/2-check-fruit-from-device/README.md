<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "557f4ee96b752e0651d2e6e74aa6bd14",
  "translation_date": "2025-08-27T20:41:06+00:00",
  "source_file": "4-manufacturing/lessons/2-check-fruit-from-device/README.md",
  "language_code": "no"
}
-->
# Sjekk fruktkvalitet med en IoT-enhet

![En sketchnote-oversikt over denne leksjonen](../../../../../translated_images/lesson-16.215daf18b00631fbdfd64c6fc2dc6044dff5d544288825d8076f9fb83d964c23.no.jpg)

> Sketchnote av [Nitya Narasimhan](https://github.com/nitya). Klikk p√• bildet for en st√∏rre versjon.

## Quiz f√∏r leksjonen

[Quiz f√∏r leksjonen](https://black-meadow-040d15503.1.azurestaticapps.net/quiz/31)

## Introduksjon

I forrige leksjon l√¶rte du om bildeklassifisering og hvordan du kan trene dem til √• oppdage god og d√•rlig frukt. For √• bruke denne bildeklassifiseringen i en IoT-applikasjon, m√• du kunne ta et bilde med et kamera og sende dette bildet til skyen for klassifisering.

I denne leksjonen vil du l√¶re om kamerasensorer og hvordan du bruker dem med en IoT-enhet for √• ta et bilde. Du vil ogs√• l√¶re hvordan du kan bruke bildeklassifiseringen fra din IoT-enhet.

I denne leksjonen dekker vi:

* [Kamerasensorer](../../../../../4-manufacturing/lessons/2-check-fruit-from-device)
* [Ta et bilde med en IoT-enhet](../../../../../4-manufacturing/lessons/2-check-fruit-from-device)
* [Publiser din bildeklassifisering](../../../../../4-manufacturing/lessons/2-check-fruit-from-device)
* [Klassifiser bilder fra din IoT-enhet](../../../../../4-manufacturing/lessons/2-check-fruit-from-device)
* [Forbedre modellen](../../../../../4-manufacturing/lessons/2-check-fruit-from-device)

## Kamerasensorer

Kamerasensorer, som navnet antyder, er kameraer som kan kobles til din IoT-enhet. De kan ta stillbilder eller fange str√∏mmet video. Noen gir r√• bildedata, mens andre komprimerer bildedata til en bildefil som JPEG eller PNG. Vanligvis er kameraene som fungerer med IoT-enheter mye mindre og har lavere oppl√∏sning enn det du kanskje er vant til, men du kan f√• kameraer med h√∏y oppl√∏sning som kan konkurrere med toppmoderne telefoner. Du kan ogs√• f√• ulike utskiftbare linser, oppsett med flere kameraer, infrar√∏de termiske kameraer eller UV-kameraer.

![Lyset fra en scene passerer gjennom en linse og fokuseres p√• en CMOS-sensor](../../../../../translated_images/cmos-sensor.75f9cd74decb137149a4c9ea825251a4549497d67c0ae2776159e6102bb53aa9.no.png)

De fleste kamerasensorer bruker bildesensorer der hver piksel er en fotodiode. En linse fokuserer bildet p√• bildesensoren, og tusenvis eller millioner av fotodioder registrerer lyset som faller p√• hver enkelt og lagrer det som pikseldata.

> üíÅ Linser inverterer bilder, og kamerasensoren snur deretter bildet tilbake til riktig vei. Det samme skjer i √∏ynene dine - det du ser registreres opp ned p√• baksiden av √∏yet, og hjernen din korrigerer det.

> üéì Bildesensoren kalles en Active-Pixel Sensor (APS), og den mest popul√¶re typen APS er en komplement√¶r metalloksid-halvleder-sensor, eller CMOS. Du har kanskje h√∏rt begrepet CMOS-sensor brukt for kamerasensorer.

Kamerasensorer er digitale sensorer som sender bildedata som digitale data, vanligvis med hjelp av et bibliotek som gir kommunikasjonen. Kameraer kobles til ved hjelp av protokoller som SPI for √• sende store mengder data - bilder er betydelig st√∏rre enn enkeltverdier fra en sensor som en temperatursensor.

‚úÖ Hva er begrensningene rundt bildest√∏rrelse med IoT-enheter? Tenk p√• begrensningene, spesielt p√• maskinvare for mikrokontrollere.

## Ta et bilde med en IoT-enhet

Du kan bruke din IoT-enhet til √• ta et bilde som skal klassifiseres.

### Oppgave - ta et bilde med en IoT-enhet

F√∏lg den relevante veiledningen for √• ta et bilde med din IoT-enhet:

* [Arduino - Wio Terminal](wio-terminal-camera.md)
* [Enkeltkortdatamaskin - Raspberry Pi](pi-camera.md)
* [Enkeltkortdatamaskin - Virtuell enhet](virtual-device-camera.md)

## Publiser din bildeklassifisering

Du trente din bildeklassifisering i forrige leksjon. F√∏r du kan bruke den fra din IoT-enhet, m√• du publisere modellen.

### Modelliterasjoner

N√•r modellen din ble trent i forrige leksjon, la du kanskje merke til at fanen **Performance** viser iterasjoner p√• siden. N√•r du f√∏rst trente modellen, ville du ha sett *Iteration 1* under trening. N√•r du forbedret modellen ved hjelp av prediksjonsbildene, ville du ha sett *Iteration 2* under trening.

Hver gang du trener modellen, f√•r du en ny iterasjon. Dette er en m√•te √• holde oversikt over de forskjellige versjonene av modellen din trent p√• forskjellige datasett. N√•r du gj√∏r en **Quick Test**, er det en rullegardinmeny du kan bruke til √• velge iterasjonen, slik at du kan sammenligne resultatene p√• tvers av flere iterasjoner.

N√•r du er forn√∏yd med en iterasjon, kan du publisere den for √• gj√∏re den tilgjengelig for bruk fra eksterne applikasjoner. P√• denne m√•ten kan du ha en publisert versjon som brukes av enhetene dine, deretter jobbe med en ny versjon over flere iterasjoner, og publisere den n√•r du er forn√∏yd med den.

### Oppgave - publiser en iterasjon

Iterasjoner publiseres fra Custom Vision-portalen.

1. √Öpne Custom Vision-portalen p√• [CustomVision.ai](https://customvision.ai) og logg inn hvis du ikke allerede har den √•pen. Deretter √•pner du prosjektet ditt `fruit-quality-detector`.

1. Velg fanen **Performance** fra alternativene √∏verst.

1. Velg den nyeste iterasjonen fra listen *Iterations* p√• siden.

1. Velg knappen **Publish** for iterasjonen.

    ![Publiseringsknappen](../../../../../translated_images/custom-vision-publish-button.b7174e1977b0c33b8b72d4e5b1326c779e0af196f3849d09985ee2d7d5493a39.no.png)

1. I dialogboksen *Publish Model*, sett *Prediction resource* til ressursen `fruit-quality-detector-prediction` som du opprettet i forrige leksjon. La navnet v√¶re `Iteration2`, og velg knappen **Publish**.

1. N√•r den er publisert, velg knappen **Prediction URL**. Dette vil vise detaljer om prediksjons-API-en, og du vil trenge disse for √• bruke modellen fra din IoT-enhet. Den nedre delen er merket *If you have an image file*, og dette er detaljene du trenger. Ta en kopi av URL-en som vises, som vil v√¶re noe som:

    ```output
    https://<location>.api.cognitive.microsoft.com/customvision/v3.0/Prediction/<id>/classify/iterations/Iteration2/image
    ```

    Der `<location>` vil v√¶re stedet du brukte da du opprettet din Custom Vision-ressurs, og `<id>` vil v√¶re en lang ID laget av bokstaver og tall.

    Ta ogs√• en kopi av verdien *Prediction-Key*. Dette er en sikker n√∏kkel som du m√• sende n√•r du bruker modellen. Bare applikasjoner som sender denne n√∏kkelen har lov til √• bruke modellen, alle andre applikasjoner blir avvist.

    ![Dialogboksen for prediksjons-API som viser URL og n√∏kkel](../../../../../translated_images/custom-vision-prediction-key-endpoint.30c569ffd0338864f319911f052d5e9b8c5066cb0800a26dd6f7ff5713130ad8.no.png)

‚úÖ N√•r en ny iterasjon publiseres, vil den ha et annet navn. Hvordan tror du at du ville endret iterasjonen en IoT-enhet bruker?

## Klassifiser bilder fra din IoT-enhet

Du kan n√• bruke disse tilkoblingsdetaljene til √• bruke bildeklassifiseringen fra din IoT-enhet.

### Oppgave - klassifiser bilder fra din IoT-enhet

F√∏lg den relevante veiledningen for √• klassifisere bilder ved hjelp av din IoT-enhet:

* [Arduino - Wio Terminal](wio-terminal-classify-image.md)
* [Enkeltkortdatamaskin - Raspberry Pi/Virtual IoT-enhet](single-board-computer-classify-image.md)

## Forbedre modellen

Du kan oppleve at resultatene du f√•r n√•r du bruker kameraet koblet til din IoT-enhet ikke samsvarer med det du forventer. Prediksjonene er ikke alltid like n√∏yaktige som n√•r du bruker bilder lastet opp fra datamaskinen din. Dette skyldes at modellen ble trent p√• forskjellige data enn det som brukes for prediksjoner.

For √• f√• de beste resultatene for en bildeklassifisering, vil du trene modellen med bilder som er s√• like som mulig de bildene som brukes for prediksjoner. Hvis du for eksempel brukte telefonkameraet ditt til √• ta bilder for trening, vil bildekvaliteten, skarpheten og fargen v√¶re annerledes enn et kamera koblet til en IoT-enhet.

![2 bilder av bananer, et lavoppl√∏selig med d√•rlig belysning fra en IoT-enhet, og et h√∏yoppl√∏selig med god belysning fra en telefon](../../../../../translated_images/banana-picture-compare.174df164dc326a42cf7fb051a7497e6113c620e91552d92ca914220305d47d9a.no.png)

I bildet ovenfor ble bananbildet til venstre tatt med et Raspberry Pi-kamera, mens det til h√∏yre ble tatt av den samme bananen p√• samme sted med en iPhone. Det er en merkbar forskjell i kvalitet - iPhone-bildet er skarpere, med lysere farger og mer kontrast.

‚úÖ Hva annet kan f√∏re til at bildene tatt av din IoT-enhet gir feil prediksjoner? Tenk p√• milj√∏et en IoT-enhet kan brukes i, hvilke faktorer kan p√•virke bildet som tas?

For √• forbedre modellen kan du trene den p√• nytt ved hjelp av bildene tatt fra IoT-enheten.

### Oppgave - forbedre modellen

1. Klassifiser flere bilder av b√•de moden og umoden frukt ved hjelp av din IoT-enhet.

1. I Custom Vision-portalen, tren modellen p√• nytt ved hjelp av bildene p√• fanen *Predictions*.

    > ‚ö†Ô∏è Du kan referere til [instruksjonene for √• trene klassifiseringen p√• nytt i leksjon 1 hvis n√∏dvendig](../1-train-fruit-detector/README.md#retrain-your-image-classifier).

1. Hvis bildene dine ser veldig forskjellige ut fra de opprinnelige som ble brukt til trening, kan du slette alle de opprinnelige bildene ved √• velge dem i fanen *Training Images* og velge knappen **Delete**. For √• velge et bilde, flytt mark√∏ren over det, og en hake vil vises. Velg den haken for √• velge eller fjerne valget av bildet.

1. Tren en ny iterasjon av modellen og publiser den ved hjelp av trinnene ovenfor.

1. Oppdater endepunkt-URL-en i koden din, og kj√∏r appen p√• nytt.

1. Gjenta disse trinnene til du er forn√∏yd med resultatene av prediksjonene.

---

## üöÄ Utfordring

Hvor mye p√•virker bildekvalitet eller belysning prediksjonen?

Pr√∏v √• endre oppl√∏sningen p√• bildene i enhetskoden din og se om det gj√∏r en forskjell for bildekvaliteten. Pr√∏v ogs√• √• endre belysningen.

Hvis du skulle lage en produksjonsenhet for salg til g√•rder eller fabrikker, hvordan ville du sikret at den gir konsistente resultater hele tiden?

## Quiz etter leksjonen

[Quiz etter leksjonen](https://black-meadow-040d15503.1.azurestaticapps.net/quiz/32)

## Gjennomgang og selvstudium

Du trente din Custom Vision-modell ved hjelp av portalen. Dette avhenger av √• ha tilgjengelige bilder - og i den virkelige verden kan det hende du ikke kan f√• treningsdata som samsvarer med det kameraet p√• enheten din fanger. Du kan omg√• dette ved √• trene direkte fra enheten din ved hjelp av trenings-API-en, for √• trene en modell ved hjelp av bilder tatt fra din IoT-enhet.

* Les om trenings-API-en i [kom i gang med Custom Vision SDK](https://docs.microsoft.com/azure/cognitive-services/custom-vision-service/quickstarts/image-classification?WT.mc_id=academic-17441-jabenn&tabs=visual-studio&pivots=programming-language-python)

## Oppgave

[Reager p√• klassifiseringsresultater](assignment.md)

---

**Ansvarsfraskrivelse**:  
Dette dokumentet er oversatt ved hjelp av AI-oversettelsestjenesten [Co-op Translator](https://github.com/Azure/co-op-translator). Selv om vi streber etter n√∏yaktighet, v√¶r oppmerksom p√• at automatiserte oversettelser kan inneholde feil eller un√∏yaktigheter. Det originale dokumentet p√• sitt opprinnelige spr√•k b√∏r anses som den autoritative kilden. For kritisk informasjon anbefales profesjonell menneskelig oversettelse. Vi er ikke ansvarlige for eventuelle misforst√•elser eller feiltolkninger som oppst√•r ved bruk av denne oversettelsen.