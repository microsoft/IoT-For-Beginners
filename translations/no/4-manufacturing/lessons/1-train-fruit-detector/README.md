<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "f5e63c916d2dd97d58be12aaf76bd9f1",
  "translation_date": "2025-08-27T20:26:36+00:00",
  "source_file": "4-manufacturing/lessons/1-train-fruit-detector/README.md",
  "language_code": "no"
}
-->
# Tren en fruktkvalitetsdetektor

![En sketchnote-oversikt over denne leksjonen](../../../../../translated_images/lesson-15.843d21afdc6fb2bba70cd9db7b7d2f91598859fafda2078b0bdc44954194b6c0.no.jpg)

> Sketchnote av [Nitya Narasimhan](https://github.com/nitya). Klikk p√• bildet for en st√∏rre versjon.

Denne videoen gir en oversikt over Azure Custom Vision-tjenesten, en tjeneste som vil bli dekket i denne leksjonen.

[![Custom Vision ‚Äì Maskinl√¶ring gjort enkelt | The Xamarin Show](https://img.youtube.com/vi/TETcDLJlWR4/0.jpg)](https://www.youtube.com/watch?v=TETcDLJlWR4)

> üé• Klikk p√• bildet ovenfor for √• se videoen

## Quiz f√∏r leksjonen

[Quiz f√∏r leksjonen](https://black-meadow-040d15503.1.azurestaticapps.net/quiz/29)

## Introduksjon

Den nylige fremveksten av Kunstig Intelligens (AI) og Maskinl√¶ring (ML) gir dagens utviklere et bredt spekter av muligheter. ML-modeller kan trenes til √• gjenkjenne ulike ting i bilder, inkludert umoden frukt, og dette kan brukes i IoT-enheter for √• hjelpe til med √• sortere produkter enten under innh√∏sting eller under prosessering i fabrikker eller lagre.

I denne leksjonen vil du l√¶re om bildegjenkjenning ‚Äì √• bruke ML-modeller til √• skille mellom bilder av ulike ting. Du vil l√¶re hvordan du trener en bildegjenkjenner til √• skille mellom frukt som er god og frukt som er d√•rlig, enten umoden, overmoden, skadet eller r√•tten.

I denne leksjonen dekker vi:

* [Bruke AI og ML til √• sortere mat](../../../../../4-manufacturing/lessons/1-train-fruit-detector)
* [Bildegjenkjenning via maskinl√¶ring](../../../../../4-manufacturing/lessons/1-train-fruit-detector)
* [Trene en bildegjenkjenner](../../../../../4-manufacturing/lessons/1-train-fruit-detector)
* [Teste bildegjenkjenneren din](../../../../../4-manufacturing/lessons/1-train-fruit-detector)
* [Trene bildegjenkjenneren din p√• nytt](../../../../../4-manufacturing/lessons/1-train-fruit-detector)

## Bruke AI og ML til √• sortere mat

√Ö mate verdens befolkning er utfordrende, spesielt til en pris som gj√∏r mat tilgjengelig for alle. En av de st√∏rste kostnadene er arbeidskraft, s√• b√∏nder vender seg i √∏kende grad til automatisering og verkt√∏y som IoT for √• redusere arbeidskostnadene. H√•ndplukking er arbeidskrevende (og ofte fysisk krevende arbeid) og blir erstattet av maskiner, spesielt i rikere land. Til tross for kostnadsbesparelsene ved √• bruke maskiner til innh√∏sting, er det en ulempe ‚Äì evnen til √• sortere mat mens den h√∏stes.

Ikke alle avlinger modnes jevnt. Tomater, for eksempel, kan fortsatt ha noen gr√∏nne frukter p√• planten n√•r majoriteten er klar for innh√∏sting. Selv om det er sl√∏sing √• h√∏ste disse tidlig, er det billigere og enklere for bonden √• h√∏ste alt med maskiner og kvitte seg med den umodne frukten senere.

‚úÖ Ta en titt p√• ulike frukter eller gr√∏nnsaker, enten de vokser i n√¶rheten av deg p√• g√•rder eller i hagen din, eller i butikker. Er de alle like modne, eller ser du variasjon?

Den √∏kte bruken av automatisert innh√∏sting flyttet sorteringen av produkter fra innh√∏stingen til fabrikken. Mat ble transportert p√• lange transportb√•nd med team av mennesker som plukket ut produkter som ikke oppfylte kvalitetsstandardene. Innh√∏stingen ble billigere takket v√¶re maskiner, men det var fortsatt en kostnad forbundet med manuell sortering av mat.

![Hvis en r√∏d tomat oppdages, fortsetter den sin reise uforstyrret. Hvis en gr√∏nn tomat oppdages, blir den dyttet inn i en avfallsb√∏tte av en spak](../../../../../translated_images/optical-tomato-sorting.61aa134bdda4e5b1bfb16a212c1e35a6ef0c426cbb8b1c975f79d7bfbf48d068.no.png)

Den neste utviklingen var √• bruke maskiner til √• sortere, enten innebygd i innh√∏stingsmaskinen eller i prosesseringsanleggene. Den f√∏rste generasjonen av disse maskinene brukte optiske sensorer til √• oppdage farger, og styrte aktuatorer for √• skyve gr√∏nne tomater inn i en avfallsb√∏tte ved hjelp av spaker eller lufttrykk, mens r√∏de tomater fortsatte p√• et nettverk av transportb√•nd.

I denne videoen, n√•r tomater faller fra ett transportb√•nd til et annet, blir gr√∏nne tomater oppdaget og dyttet inn i en b√∏tte ved hjelp av spaker.

‚úÖ Hvilke forhold ville du trenge i en fabrikk eller p√• et jorde for at disse optiske sensorene skal fungere riktig?

De nyeste utviklingene av disse sorteringsmaskinene drar nytte av AI og ML, ved √• bruke modeller som er trent til √• skille god frukt fra d√•rlig, ikke bare ved √•penbare fargeforskjeller som gr√∏nne tomater vs r√∏de, men ogs√• ved mer subtile forskjeller i utseende som kan indikere sykdom eller skader.

## Bildegjenkjenning via maskinl√¶ring

Tradisjonell programmering inneb√¶rer at du tar data, bruker en algoritme p√• dataene, og f√•r et resultat. For eksempel, i det forrige prosjektet tok du GPS-koordinater og en geofence, brukte en algoritme levert av Azure Maps, og fikk tilbake et resultat om punktet var innenfor eller utenfor geofencen. Du gir mer data, du f√•r mer output.

![Tradisjonell utvikling tar input og en algoritme og gir output. Maskinl√¶ring bruker input og output-data for √• trene en modell, og denne modellen kan ta nye input-data for √• generere nye output](../../../../../translated_images/traditional-vs-ml.5c20c169621fa539ca84a2cd9a49f6ff7410b3a6c6b46c97ff2af3f99db3c66b.no.png)

Maskinl√¶ring snur dette rundt ‚Äì du starter med data og kjente resultater, og maskinl√¶ringsalgoritmen l√¶rer fra dataene. Du kan deretter ta den trente algoritmen, kalt en *maskinl√¶ringsmodell* eller *modell*, og gi den nye data for √• f√• nye resultater.

> üéì Prosessen der en maskinl√¶ringsalgoritme l√¶rer fra dataene kalles *trening*. Inputene og de kjente resultatene kalles *treningsdata*.

For eksempel kan du gi en modell millioner av bilder av umodne bananer som input-treningsdata, med treningsresultatet satt til `umoden`, og millioner av bilder av modne bananer som treningsdata med resultatet satt til `moden`. ML-algoritmen vil deretter lage en modell basert p√• disse dataene. Du kan deretter gi denne modellen et nytt bilde av en banan, og den vil forutsi om bildet viser en moden eller umoden banan.

> üéì Resultatene fra ML-modeller kalles *prediksjoner*.

![2 bananer, en moden med en prediksjon p√• 99,7 % moden, 0,3 % umoden, og en umoden med en prediksjon p√• 1,4 % moden, 98,6 % umoden](../../../../../translated_images/bananas-ripe-vs-unripe-predictions.8d0e2034014aa50ece4e4589e724b142da0681f35470fe3db3f7d51240f69c85.no.png)

ML-modeller gir ikke et bin√¶rt svar, men heller sannsynligheter. For eksempel kan en modell bli gitt et bilde av en banan og forutsi `moden` med 99,7 % og `umoden` med 0,3 %. Koden din vil deretter velge den beste prediksjonen og avgj√∏re at bananen er moden.

ML-modellen som brukes til √• oppdage bilder som dette kalles en *bildegjenkjenner* ‚Äì den f√•r merkelappede bilder og klassifiserer nye bilder basert p√• disse merkelappene.

> üíÅ Dette er en forenkling, og det finnes mange andre m√•ter √• trene modeller p√• som ikke alltid krever merkelappede resultater, som for eksempel usupervisert l√¶ring. Hvis du vil l√¶re mer om ML, sjekk ut [ML for nybegynnere, et 24-leksjonskurs om maskinl√¶ring](https://aka.ms/ML-beginners).

## Trene en bildegjenkjenner

For √• trene en bildegjenkjenner med suksess trenger du millioner av bilder. Det viser seg at n√•r du f√∏rst har en bildegjenkjenner trent p√• millioner eller milliarder av ulike bilder, kan du gjenbruke den og trene den p√• nytt med et lite sett bilder og oppn√• gode resultater, ved hjelp av en prosess kalt *transfer learning*.

> üéì Transfer learning er n√•r du overf√∏rer l√¶ringen fra en eksisterende ML-modell til en ny modell basert p√• nye data.

N√•r en bildegjenkjenner har blitt trent p√• et bredt spekter av bilder, er dens interne mekanismer gode til √• gjenkjenne former, farger og m√∏nstre. Transfer learning lar modellen bruke det den allerede har l√¶rt om √• gjenkjenne bildeelementer, og bruke det til √• gjenkjenne nye bilder.

![N√•r du kan gjenkjenne former, kan de settes sammen i ulike konfigurasjoner for √• lage en b√•t eller en katt](../../../../../translated_images/shapes-to-images.1a309f0ea88dd66fafa4da6d38e88806ce174cc6a88081efb32852230ed55de8.no.png)

Du kan tenke p√• dette som barneb√∏ker om former, der du, n√•r du kan gjenkjenne en halvsirkel, et rektangel og en trekant, kan gjenkjenne en seilb√•t eller en katt avhengig av konfigurasjonen av disse formene. Bildegjenkjenneren kan gjenkjenne formene, og transfer learning l√¶rer den hvilken kombinasjon som utgj√∏r en b√•t eller en katt ‚Äì eller en moden banan.

Det finnes et bredt spekter av verkt√∏y som kan hjelpe deg med dette, inkludert skybaserte tjenester som kan hjelpe deg med √• trene modellen din og deretter bruke den via web-API-er.

> üíÅ √Ö trene disse modellene krever mye datakraft, vanligvis via grafikkprosessorer (GPU-er). Den samme spesialiserte maskinvaren som gj√∏r spillene p√• Xbox-en din fantastiske, kan ogs√• brukes til √• trene maskinl√¶ringsmodeller. Ved √• bruke skyen kan du leie tid p√• kraftige datamaskiner med GPU-er for √• trene disse modellene, og f√• tilgang til den datakraften du trenger, kun for den tiden du trenger den.

## Custom Vision

Custom Vision er et skybasert verkt√∏y for √• trene bildegjenkjenner. Det lar deg trene en gjenkjenner ved hjelp av bare et lite antall bilder. Du kan laste opp bilder gjennom en nettportal, et web-API eller et SDK, og gi hvert bilde en *merkelapp* som klassifiserer bildet. Deretter trener du modellen og tester den for √• se hvor godt den fungerer. N√•r du er forn√∏yd med modellen, kan du publisere versjoner av den som kan n√•s via et web-API eller et SDK.

![Azure Custom Vision-logoen](../../../../../translated_images/custom-vision-logo.d3d4e7c8a87ec9daf825e72e210576c3cbf60312577be7a139e22dd97ab7f1e6.no.png)

> üíÅ Du kan trene en Custom Vision-modell med s√• lite som 5 bilder per klassifisering, men flere bilder gir bedre resultater. Du kan oppn√• bedre resultater med minst 30 bilder.

Custom Vision er en del av en rekke AI-verkt√∏y fra Microsoft kalt Cognitive Services. Dette er AI-verkt√∏y som kan brukes enten uten trening eller med en liten mengde trening. De inkluderer talegjenkjenning og oversettelse, spr√•kforst√•else og bildeanalyse. Disse er tilgjengelige med en gratis niv√• som tjenester i Azure.

> üíÅ Gratisniv√•et er mer enn nok til √• lage en modell, trene den og deretter bruke den til utviklingsarbeid. Du kan lese om begrensningene for gratisniv√•et p√• [Custom Vision Limits and quotas-siden p√• Microsoft Docs](https://docs.microsoft.com/azure/cognitive-services/custom-vision-service/limits-and-quotas?WT.mc_id=academic-17441-jabenn).

### Oppgave ‚Äì opprett en Cognitive Services-ressurs

For √• bruke Custom Vision m√• du f√∏rst opprette to Cognitive Services-ressurser i Azure ved hjelp av Azure CLI, √©n for Custom Vision-trening og √©n for Custom Vision-prediksjon.

1. Opprett en ressursgruppe for dette prosjektet kalt `fruit-quality-detector`.

1. Bruk f√∏lgende kommando for √• opprette en gratis Custom Vision-treningsressurs:

    ```sh
    az cognitiveservices account create --name fruit-quality-detector-training \
                                        --resource-group fruit-quality-detector \
                                        --kind CustomVision.Training \
                                        --sku F0 \
                                        --yes \
                                        --location <location>
    ```

    Erstatt `<location>` med plasseringen du brukte da du opprettet ressursgruppen.

    Dette vil opprette en Custom Vision-treningsressurs i ressursgruppen din. Den vil bli kalt `fruit-quality-detector-training` og bruke `F0` SKU, som er gratisniv√•et. Alternativet `--yes` betyr at du godtar vilk√•rene og betingelsene for Cognitive Services.

> üíÅ Bruk `S0` SKU hvis du allerede har en gratis konto som bruker noen av Cognitive Services.

1. Bruk f√∏lgende kommando for √• opprette en gratis Custom Vision-prediksjonsressurs:

    ```sh
    az cognitiveservices account create --name fruit-quality-detector-prediction \
                                        --resource-group fruit-quality-detector \
                                        --kind CustomVision.Prediction \
                                        --sku F0 \
                                        --yes \
                                        --location <location>
    ```

    Erstatt `<location>` med plasseringen du brukte da du opprettet ressursgruppen.

    Dette vil opprette en Custom Vision-prediksjonsressurs i ressursgruppen din. Den vil bli kalt `fruit-quality-detector-prediction` og bruke `F0` SKU, som er gratisniv√•et. Alternativet `--yes` betyr at du godtar vilk√•rene og betingelsene for Cognitive Services.

### Oppgave ‚Äì opprett et bildegjenkjennerprosjekt

1. √Öpne Custom Vision-portalen p√• [CustomVision.ai](https://customvision.ai), og logg inn med Microsoft-kontoen du brukte for Azure-kontoen din.

1. F√∏lg [seksjonen for √• opprette et nytt prosjekt i hurtigstarten for √• bygge en gjenkjenner p√• Microsoft Docs](https://docs.microsoft.com/azure/cognitive-services/custom-vision-service/getting-started-build-a-classifier?WT.mc_id=academic-17441-jabenn#create-a-new-project) for √• opprette et nytt Custom Vision-prosjekt. Brukergrensesnittet kan endres, og disse dokumentene er alltid den mest oppdaterte referansen.

    Kall prosjektet ditt `fruit-quality-detector`.

    N√•r du oppretter prosjektet ditt, m√• du s√∏rge for √• bruke `fruit-quality-detector-training`-ressursen du opprettet tidligere. Bruk en *Klassifisering*-prosjekttype, en *Multiklasse*-klassifiseringstype og *Mat*-domenet.

    ![Innstillingene for Custom Vision-prosjektet med navnet satt til fruit-quality-detector, ingen beskrivelse, ressursen satt til fruit-quality-detector-training, prosjekttypen satt til klassifisering, klassifiseringstypene satt til multiklasse og domenene satt til mat](../../../../../translated_images/custom-vision-create-project.cf46325b92d8b131089f6647cf5e07b664cb77850e106d66e3c057b6b69756c6.no.png)

‚úÖ Ta deg tid til √• utforske Custom Vision-brukergrensesnittet for bildegjenkjenneren din.

### Oppgave ‚Äì tren bildegjenkjennerprosjektet ditt

For √• trene en bildegjenkjenner trenger du flere bilder av frukt, b√•de av god og d√•rlig kvalitet, som du kan merke som god og d√•rlig, for eksempel en moden og en overmoden banan.
üíÅ Disse klassifiseringsmodellene kan klassifisere bilder av hva som helst, s√• hvis du ikke har frukt tilgjengelig med ulik kvalitet, kan du bruke to forskjellige typer frukt, eller katter og hunder!
Ideelt sett b√∏r hvert bilde kun vise frukten, med enten en konsistent bakgrunn eller et bredt utvalg av bakgrunner. S√∏rg for at det ikke er noe i bakgrunnen som er spesifikt for moden vs umoden frukt.

> üíÅ Det er viktig √• unng√• spesifikke bakgrunner eller spesifikke elementer som ikke er relatert til det som klassifiseres for hver tag. Ellers kan det hende at klassifiseringsmodellen bare klassifiserer basert p√• bakgrunnen. Det var en klassifiseringsmodell for hudkreft som ble trent p√• f√∏flekker, b√•de normale og kreftfremkallende. De kreftfremkallende hadde alle linjaler ved siden av for √• m√•le st√∏rrelsen. Det viste seg at modellen var nesten 100 % n√∏yaktig til √• identifisere linjaler i bilder, ikke kreftfremkallende f√∏flekker.

Bildeklassifiseringsmodeller kj√∏rer p√• sv√¶rt lav oppl√∏sning. For eksempel kan Custom Vision bruke trenings- og prediksjonsbilder opptil 10240x10240, men trener og kj√∏rer modellen p√• bilder i 227x227. St√∏rre bilder blir krympet til denne st√∏rrelsen, s√• s√∏rg for at det du klassifiserer tar opp en stor del av bildet. Ellers kan det bli for lite i det mindre bildet som brukes av modellen.

1. Samle bilder til klassifiseringsmodellen din. Du trenger minst 5 bilder for hver etikett for √• trene modellen, men jo flere, jo bedre. Du vil ogs√• trenge noen ekstra bilder for √• teste modellen. Disse bildene b√∏r alle v√¶re forskjellige bilder av samme ting. For eksempel:

    * Bruk 2 modne bananer, ta noen bilder av hver fra forskjellige vinkler, minst 7 bilder (5 for trening, 2 for testing), men helst flere.

        ![Bilder av 2 forskjellige bananer](../../../../../translated_images/banana-training-images.530eb203346d73bc23b8b990fb4609470bf4ff7c942ccc13d4cfffeed9be1ad4.no.png)

    * Gjenta samme prosess med 2 umodne bananer.

    Du b√∏r ha minst 10 treningsbilder, med minst 5 modne og 5 umodne, og 4 testbilder, 2 modne og 2 umodne. Bildene dine b√∏r v√¶re i png- eller jpeg-format og mindre enn 6 MB. Hvis du for eksempel tar dem med en iPhone, kan de v√¶re h√∏yoppl√∏selige HEIC-bilder, s√• de m√• konverteres og muligens krympes. Jo flere bilder, jo bedre, og du b√∏r ha et lignende antall modne og umodne.

    Hvis du ikke har b√•de moden og umoden frukt, kan du bruke forskjellige frukter eller andre to objekter du har tilgjengelig. Du kan ogs√• finne noen eksempelbilder i [images](../../../../../4-manufacturing/lessons/1-train-fruit-detector/images)-mappen av modne og umodne bananer som du kan bruke.

1. F√∏lg [seksjonen for opplasting og tagging av bilder i hurtigstarten for √• bygge en klassifiseringsmodell p√• Microsoft Docs](https://docs.microsoft.com/azure/cognitive-services/custom-vision-service/getting-started-build-a-classifier?WT.mc_id=academic-17441-jabenn#upload-and-tag-images) for √• laste opp treningsbildene dine. Merk de modne fruktene som `ripe`, og de umodne som `unripe`.

    ![Opplastingsdialoger som viser opplasting av bilder av modne og umodne bananer](../../../../../translated_images/image-upload-bananas.0751639f3815e0ec42bdbc6254d1e4357a185834d1ae10c9948a0e7d6d336695.no.png)

1. F√∏lg [seksjonen for √• trene klassifiseringsmodellen i hurtigstarten p√• Microsoft Docs](https://docs.microsoft.com/azure/cognitive-services/custom-vision-service/getting-started-build-a-classifier?WT.mc_id=academic-17441-jabenn#train-the-classifier) for √• trene bildeklassifiseringsmodellen p√• de opplastede bildene dine.

    Du vil f√• et valg av treningstype. Velg **Quick Training**.

Modellen vil deretter trenes. Det vil ta noen minutter f√∏r treningen er fullf√∏rt.

> üçå Hvis du bestemmer deg for √• spise frukten din mens modellen trenes, s√∏rg for at du har nok bilder til testing f√∏rst!

## Test bildeklassifiseringsmodellen din

N√•r modellen din er trent, kan du teste den ved √• gi den et nytt bilde √• klassifisere.

### Oppgave - test bildeklassifiseringsmodellen din

1. F√∏lg [dokumentasjonen for √• teste modellen din p√• Microsoft Docs](https://docs.microsoft.com/azure/cognitive-services/custom-vision-service/test-your-model?WT.mc_id=academic-17441-jabenn#test-your-model) for √• teste bildeklassifiseringsmodellen din. Bruk testbildene du opprettet tidligere, ikke noen av bildene du brukte til trening.

    ![En umoden banan klassifisert som umoden med 98,9 % sannsynlighet, moden med 1,1 % sannsynlighet](../../../../../translated_images/banana-unripe-quick-test-prediction.dae9b5e1c4ef7c64886422438850ea14f0be6ac918c217ea3b255c685abfabe7.no.png)

1. Pr√∏v alle testbildene du har tilgang til og observer sannsynlighetene.

## Tren bildeklassifiseringsmodellen din p√• nytt

N√•r du tester modellen din, kan det hende at den ikke gir de resultatene du forventer. Bildeklassifiseringsmodeller bruker maskinl√¶ring for √• gj√∏re prediksjoner om hva som er i et bilde, basert p√• sannsynligheter for at bestemte trekk ved et bilde betyr at det samsvarer med en bestemt etikett. Den forst√•r ikke hva som er i bildet ‚Äì den vet ikke hva en banan er eller forst√•r hva som gj√∏r en banan til en banan i stedet for en b√•t. Du kan forbedre modellen din ved √• trene den p√• nytt med bilder den klassifiserer feil.

Hver gang du gj√∏r en prediksjon ved hjelp av hurtigtestalternativet, lagres bildet og resultatene. Du kan bruke disse bildene til √• trene modellen din p√• nytt.

### Oppgave - tren bildeklassifiseringsmodellen din p√• nytt

1. F√∏lg [dokumentasjonen for √• bruke det predikerte bildet til trening p√• Microsoft Docs](https://docs.microsoft.com/azure/cognitive-services/custom-vision-service/test-your-model?WT.mc_id=academic-17441-jabenn#use-the-predicted-image-for-training) for √• trene modellen din p√• nytt, ved √• bruke riktig tag for hvert bilde.

1. N√•r modellen din er trent p√• nytt, test den p√• nye bilder.

---

## üöÄ Utfordring

Hva tror du vil skje hvis du bruker et bilde av et jordb√¶r med en modell trent p√• bananer, eller et bilde av en oppbl√•sbar banan, eller en person i et banankostyme, eller til og med en gul tegneseriefigur som noen fra Simpsons?

Pr√∏v det og se hva prediksjonene er. Du kan finne bilder √• pr√∏ve med ved √• bruke [Bing Image search](https://www.bing.com/images/trending).

## Quiz etter forelesning

[Quiz etter forelesning](https://black-meadow-040d15503.1.azurestaticapps.net/quiz/30)

## Gjennomgang og selvstudium

* N√•r du trente modellen din, ville du ha sett verdier for *Precision*, *Recall* og *AP* som vurderer modellen som ble opprettet. Les om hva disse verdiene er ved √• bruke [seksjonen for √• evaluere klassifiseringsmodellen i hurtigstarten p√• Microsoft Docs](https://docs.microsoft.com/azure/cognitive-services/custom-vision-service/getting-started-build-a-classifier?WT.mc_id=academic-17441-jabenn#evaluate-the-classifier)
* Les om hvordan du kan forbedre modellen din fra [hvordan forbedre Custom Vision-modellen din p√• Microsoft Docs](https://docs.microsoft.com/azure/cognitive-services/custom-vision-service/getting-started-improving-your-classifier?WT.mc_id=academic-17441-jabenn)

## Oppgave

[Tren modellen din for flere frukter og gr√∏nnsaker](assignment.md)

---

**Ansvarsfraskrivelse**:  
Dette dokumentet er oversatt ved hjelp av AI-oversettelsestjenesten [Co-op Translator](https://github.com/Azure/co-op-translator). Selv om vi streber etter n√∏yaktighet, v√¶r oppmerksom p√• at automatiserte oversettelser kan inneholde feil eller un√∏yaktigheter. Det originale dokumentet p√• sitt opprinnelige spr√•k b√∏r anses som den autoritative kilden. For kritisk informasjon anbefales profesjonell menneskelig oversettelse. Vi er ikke ansvarlige for misforst√•elser eller feiltolkninger som oppst√•r ved bruk av denne oversettelsen.