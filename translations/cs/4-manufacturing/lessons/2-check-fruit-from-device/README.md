<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "557f4ee96b752e0651d2e6e74aa6bd14",
  "translation_date": "2025-08-27T20:54:03+00:00",
  "source_file": "4-manufacturing/lessons/2-check-fruit-from-device/README.md",
  "language_code": "cs"
}
-->
# Kontrola kvality ovoce pomocÃ­ IoT zaÅ™Ã­zenÃ­

![PÅ™ehled tÃ©to lekce ve formÄ› sketchnote](../../../../../translated_images/lesson-16.215daf18b00631fbdfd64c6fc2dc6044dff5d544288825d8076f9fb83d964c23.cs.jpg)

> Sketchnote od [Nitya Narasimhan](https://github.com/nitya). KliknÄ›te na obrÃ¡zek pro vÄ›tÅ¡Ã­ verzi.

## KvÃ­z pÅ™ed lekcÃ­

[KvÃ­z pÅ™ed lekcÃ­](https://black-meadow-040d15503.1.azurestaticapps.net/quiz/31)

## Ãšvod

V minulÃ© lekci jste se nauÄili o klasifikÃ¡torech obrÃ¡zkÅ¯ a o tom, jak je trÃ©novat k rozpoznÃ¡vÃ¡nÃ­ dobrÃ©ho a Å¡patnÃ©ho ovoce. Abyste mohli tento klasifikÃ¡tor obrÃ¡zkÅ¯ pouÅ¾Ã­t v aplikaci IoT, potÅ™ebujete bÃ½t schopni zachytit obrÃ¡zek pomocÃ­ nÄ›jakÃ©ho typu kamery a poslat tento obrÃ¡zek do cloudu k analÃ½ze.

V tÃ©to lekci se nauÄÃ­te o kamerovÃ½ch senzorech a o tom, jak je pouÅ¾Ã­t s IoT zaÅ™Ã­zenÃ­m k zachycenÃ­ obrÃ¡zku. TakÃ© se nauÄÃ­te, jak volat klasifikÃ¡tor obrÃ¡zkÅ¯ z vaÅ¡eho IoT zaÅ™Ã­zenÃ­.

V tÃ©to lekci se zamÄ›Å™Ã­me na:

* [KamerovÃ© senzory](../../../../../4-manufacturing/lessons/2-check-fruit-from-device)
* [ZachycenÃ­ obrÃ¡zku pomocÃ­ IoT zaÅ™Ã­zenÃ­](../../../../../4-manufacturing/lessons/2-check-fruit-from-device)
* [PublikovÃ¡nÃ­ vaÅ¡eho klasifikÃ¡toru obrÃ¡zkÅ¯](../../../../../4-manufacturing/lessons/2-check-fruit-from-device)
* [Klasifikace obrÃ¡zkÅ¯ z vaÅ¡eho IoT zaÅ™Ã­zenÃ­](../../../../../4-manufacturing/lessons/2-check-fruit-from-device)
* [ZlepÅ¡enÃ­ modelu](../../../../../4-manufacturing/lessons/2-check-fruit-from-device)

## KamerovÃ© senzory

KamerovÃ© senzory, jak nÃ¡zev napovÃ­dÃ¡, jsou kamery, kterÃ© mÅ¯Å¾ete pÅ™ipojit k vaÅ¡emu IoT zaÅ™Ã­zenÃ­. Mohou poÅ™izovat statickÃ© obrÃ¡zky nebo zachytÃ¡vat streamovanÃ© video. NÄ›kterÃ© vracejÃ­ surovÃ¡ obrazovÃ¡ data, jinÃ© komprimujÃ­ obrazovÃ¡ data do souborÅ¯, jako je JPEG nebo PNG. Obvykle jsou kamery, kterÃ© fungujÃ­ s IoT zaÅ™Ã­zenÃ­mi, mnohem menÅ¡Ã­ a majÃ­ niÅ¾Å¡Ã­ rozliÅ¡enÃ­, neÅ¾ na jakÃ© jste zvyklÃ­, ale mÅ¯Å¾ete zÃ­skat kamery s vysokÃ½m rozliÅ¡enÃ­m, kterÃ© se vyrovnajÃ­ Å¡piÄkovÃ½m telefonÅ¯m. MÅ¯Å¾ete si poÅ™Ã­dit rÅ¯znÃ© vymÄ›nitelnÃ© objektivy, sestavy s vÃ­ce kamerami, infraÄervenÃ© termÃ¡lnÃ­ kamery nebo UV kamery.

![SvÄ›tlo ze scÃ©ny prochÃ¡zÃ­ objektivem a je zaostÅ™eno na CMOS senzor](../../../../../translated_images/cmos-sensor.75f9cd74decb137149a4c9ea825251a4549497d67c0ae2776159e6102bb53aa9.cs.png)

VÄ›tÅ¡ina kamerovÃ½ch senzorÅ¯ pouÅ¾Ã­vÃ¡ obrazovÃ© senzory, kde kaÅ¾dÃ½ pixel je fotodioda. Objektiv zaostÅ™uje obraz na obrazovÃ½ senzor a tisÃ­ce nebo miliony fotodiod detekujÃ­ svÄ›tlo dopadajÃ­cÃ­ na kaÅ¾dou z nich a zaznamenÃ¡vajÃ­ to jako obrazovÃ¡ data.

> ğŸ’ Objektivy obracejÃ­ obrazy, kamerovÃ½ senzor je pak otoÄÃ­ zpÄ›t sprÃ¡vnÃ½m smÄ›rem. TotÃ©Å¾ se dÄ›je ve vaÅ¡ich oÄÃ­ch â€“ to, co vidÃ­te, je detekovÃ¡no vzhÅ¯ru nohama na zadnÃ­ stranÄ› vaÅ¡eho oka a vÃ¡Å¡ mozek to opravuje.

> ğŸ“ ObrazovÃ½ senzor je znÃ¡mÃ½ jako senzor s aktivnÃ­m pixelem (APS) a nejpopulÃ¡rnÄ›jÅ¡Ã­m typem APS je senzor z komplementÃ¡rnÃ­ho polovodiÄe na bÃ¡zi oxidu kovu, nebo CMOS. MoÅ¾nÃ¡ jste slyÅ¡eli termÃ­n CMOS senzor pouÅ¾Ã­vanÃ½ pro kamerovÃ© senzory.

KamerovÃ© senzory jsou digitÃ¡lnÃ­ senzory, kterÃ© posÃ­lajÃ­ obrazovÃ¡ data jako digitÃ¡lnÃ­ data, obvykle s pomocÃ­ knihovny, kterÃ¡ zajiÅ¡Å¥uje komunikaci. Kamery se pÅ™ipojujÃ­ pomocÃ­ protokolÅ¯ jako SPI, kterÃ© jim umoÅ¾ÅˆujÃ­ posÃ­lat velkÃ© mnoÅ¾stvÃ­ dat â€“ obrÃ¡zky jsou podstatnÄ› vÄ›tÅ¡Ã­ neÅ¾ jednotlivÃ© ÄÃ­sla ze senzorÅ¯, jako je senzor teploty.

âœ… JakÃ© jsou omezenÃ­ velikosti obrÃ¡zkÅ¯ u IoT zaÅ™Ã­zenÃ­? Zamyslete se nad omezenÃ­mi, zejmÃ©na u hardwaru mikrokontrolÃ©rÅ¯.

## ZachycenÃ­ obrÃ¡zku pomocÃ­ IoT zaÅ™Ã­zenÃ­

VaÅ¡e IoT zaÅ™Ã­zenÃ­ mÅ¯Å¾ete pouÅ¾Ã­t k zachycenÃ­ obrÃ¡zku, kterÃ½ bude klasifikovÃ¡n.

### Ãškol â€“ zachycenÃ­ obrÃ¡zku pomocÃ­ IoT zaÅ™Ã­zenÃ­

ProjdÄ›te si relevantnÃ­ nÃ¡vod k zachycenÃ­ obrÃ¡zku pomocÃ­ vaÅ¡eho IoT zaÅ™Ã­zenÃ­:

* [Arduino - Wio Terminal](wio-terminal-camera.md)
* [JednodeskovÃ½ poÄÃ­taÄ - Raspberry Pi](pi-camera.md)
* [JednodeskovÃ½ poÄÃ­taÄ - VirtuÃ¡lnÃ­ zaÅ™Ã­zenÃ­](virtual-device-camera.md)

## PublikovÃ¡nÃ­ vaÅ¡eho klasifikÃ¡toru obrÃ¡zkÅ¯

V minulÃ© lekci jste trÃ©novali svÅ¯j klasifikÃ¡tor obrÃ¡zkÅ¯. NeÅ¾ ho budete moci pouÅ¾Ã­t z vaÅ¡eho IoT zaÅ™Ã­zenÃ­, musÃ­te model publikovat.

### Iterace modelu

KdyÅ¾ vÃ¡Å¡ model trÃ©noval v minulÃ© lekci, moÅ¾nÃ¡ jste si vÅ¡imli, Å¾e na zÃ¡loÅ¾ce **VÃ½kon** se na stranÄ› zobrazujÃ­ iterace. KdyÅ¾ jste model poprvÃ© trÃ©novali, vidÄ›li jste *Iteraci 1* bÄ›hem trÃ©novÃ¡nÃ­. KdyÅ¾ jste model zlepÅ¡ovali pomocÃ­ predikÄnÃ­ch obrÃ¡zkÅ¯, vidÄ›li jste *Iteraci 2* bÄ›hem trÃ©novÃ¡nÃ­.

PokaÅ¾dÃ©, kdyÅ¾ model trÃ©nujete, zÃ­skÃ¡te novou iteraci. To je zpÅ¯sob, jak sledovat rÅ¯znÃ© verze vaÅ¡eho modelu trÃ©novanÃ© na rÅ¯znÃ½ch datovÃ½ch sadÃ¡ch. KdyÅ¾ provedete **RychlÃ½ test**, je zde rozbalovacÃ­ nabÃ­dka, kterou mÅ¯Å¾ete pouÅ¾Ã­t k vÃ½bÄ›ru iterace, abyste mohli porovnat vÃ½sledky napÅ™Ã­Ä vÃ­ce iteracemi.

KdyÅ¾ jste s iteracÃ­ spokojeni, mÅ¯Å¾ete ji publikovat, aby byla dostupnÃ¡ pro pouÅ¾itÃ­ z externÃ­ch aplikacÃ­. TÃ­mto zpÅ¯sobem mÅ¯Å¾ete mÃ­t publikovanou verzi, kterou pouÅ¾Ã­vajÃ­ vaÅ¡e zaÅ™Ã­zenÃ­, a zÃ¡roveÅˆ pracovat na novÃ© verzi pÅ™es vÃ­ce iteracÃ­, kterou publikujete, aÅ¾ budete s nÃ­ spokojeni.

### Ãškol â€“ publikovÃ¡nÃ­ iterace

Iterace se publikujÃ­ z portÃ¡lu Custom Vision.

1. SpusÅ¥te portÃ¡l Custom Vision na [CustomVision.ai](https://customvision.ai) a pÅ™ihlaste se, pokud ho jeÅ¡tÄ› nemÃ¡te otevÅ™enÃ½. PotÃ© otevÅ™ete svÅ¯j projekt `fruit-quality-detector`.

1. Vyberte zÃ¡loÅ¾ku **VÃ½kon** z moÅ¾nostÃ­ nahoÅ™e.

1. Vyberte nejnovÄ›jÅ¡Ã­ iteraci ze seznamu *Iterace* na stranÄ›.

1. KliknÄ›te na tlaÄÃ­tko **Publikovat** pro danou iteraci.

    ![TlaÄÃ­tko publikovat](../../../../../translated_images/custom-vision-publish-button.b7174e1977b0c33b8b72d4e5b1326c779e0af196f3849d09985ee2d7d5493a39.cs.png)

1. V dialogu *Publikovat model* nastavte *PredikÄnÃ­ zdroj* na zdroj `fruit-quality-detector-prediction`, kterÃ½ jste vytvoÅ™ili v minulÃ© lekci. NÃ¡zev ponechte jako `Iteration2` a kliknÄ›te na tlaÄÃ­tko **Publikovat**.

1. Po publikovÃ¡nÃ­ kliknÄ›te na tlaÄÃ­tko **PredikÄnÃ­ URL**. ZobrazÃ­ se podrobnosti o predikÄnÃ­m API, kterÃ© budete potÅ™ebovat k volÃ¡nÃ­ modelu z vaÅ¡eho IoT zaÅ™Ã­zenÃ­. SpodnÃ­ ÄÃ¡st je oznaÄena *Pokud mÃ¡te soubor s obrÃ¡zkem*, a to jsou detaily, kterÃ© potÅ™ebujete. ZkopÃ­rujte URL, kterÃ© bude vypadat nÄ›jak takto:

    ```output
    https://<location>.api.cognitive.microsoft.com/customvision/v3.0/Prediction/<id>/classify/iterations/Iteration2/image
    ```

    Kde `<location>` bude lokalita, kterou jste pouÅ¾ili pÅ™i vytvÃ¡Å™enÃ­ vaÅ¡eho zdroje Custom Vision, a `<id>` bude dlouhÃ© ID sloÅ¾enÃ© z pÃ­smen a ÄÃ­sel.

    TakÃ© si zkopÃ­rujte hodnotu *Prediction-Key*. Toto je bezpeÄnostnÃ­ klÃ­Ä, kterÃ½ musÃ­te pÅ™edat pÅ™i volÃ¡nÃ­ modelu. Pouze aplikace, kterÃ© pÅ™edajÃ­ tento klÃ­Ä, majÃ­ povolenÃ­ pouÅ¾Ã­vat model, vÅ¡echny ostatnÃ­ aplikace jsou odmÃ­tnuty.

    ![Dialog predikÄnÃ­ho API zobrazujÃ­cÃ­ URL a klÃ­Ä](../../../../../translated_images/custom-vision-prediction-key-endpoint.30c569ffd0338864f319911f052d5e9b8c5066cb0800a26dd6f7ff5713130ad8.cs.png)

âœ… KdyÅ¾ je publikovÃ¡na novÃ¡ iterace, bude mÃ­t jinÃ½ nÃ¡zev. Jak si myslÃ­te, Å¾e byste zmÄ›nili iteraci, kterou IoT zaÅ™Ã­zenÃ­ pouÅ¾Ã­vÃ¡?

## Klasifikace obrÃ¡zkÅ¯ z vaÅ¡eho IoT zaÅ™Ã­zenÃ­

NynÃ­ mÅ¯Å¾ete pouÅ¾Ã­t tyto pÅ™ipojovacÃ­ Ãºdaje k volÃ¡nÃ­ klasifikÃ¡toru obrÃ¡zkÅ¯ z vaÅ¡eho IoT zaÅ™Ã­zenÃ­.

### Ãškol â€“ klasifikace obrÃ¡zkÅ¯ z vaÅ¡eho IoT zaÅ™Ã­zenÃ­

ProjdÄ›te si relevantnÃ­ nÃ¡vod k klasifikaci obrÃ¡zkÅ¯ pomocÃ­ vaÅ¡eho IoT zaÅ™Ã­zenÃ­:

* [Arduino - Wio Terminal](wio-terminal-classify-image.md)
* [JednodeskovÃ½ poÄÃ­taÄ - Raspberry Pi/VirtuÃ¡lnÃ­ IoT zaÅ™Ã­zenÃ­](single-board-computer-classify-image.md)

## ZlepÅ¡enÃ­ modelu

MÅ¯Å¾e se stÃ¡t, Å¾e vÃ½sledky, kterÃ© zÃ­skÃ¡te pÅ™i pouÅ¾itÃ­ kamery pÅ™ipojenÃ© k vaÅ¡emu IoT zaÅ™Ã­zenÃ­, neodpovÃ­dajÃ­ tomu, co byste oÄekÃ¡vali. Predikce nejsou vÅ¾dy tak pÅ™esnÃ© jako pÅ™i pouÅ¾itÃ­ obrÃ¡zkÅ¯ nahranÃ½ch z vaÅ¡eho poÄÃ­taÄe. To je zpÅ¯sobeno tÃ­m, Å¾e model byl trÃ©novÃ¡n na jinÃ½ch datech, neÅ¾ kterÃ¡ jsou pouÅ¾Ã­vÃ¡na pro predikce.

Abyste dosÃ¡hli nejlepÅ¡Ã­ch vÃ½sledkÅ¯ u klasifikÃ¡toru obrÃ¡zkÅ¯, chcete model trÃ©novat na obrÃ¡zcÃ­ch, kterÃ© jsou co nejpodobnÄ›jÅ¡Ã­ obrÃ¡zkÅ¯m pouÅ¾Ã­vanÃ½m pro predikce. Pokud jste napÅ™Ã­klad pouÅ¾ili kameru telefonu k zachycenÃ­ obrÃ¡zkÅ¯ pro trÃ©novÃ¡nÃ­, kvalita obrÃ¡zku, ostrost a barvy budou odliÅ¡nÃ© od kamery pÅ™ipojenÃ© k IoT zaÅ™Ã­zenÃ­.

![2 obrÃ¡zky banÃ¡nÅ¯, jeden s nÃ­zkÃ½m rozliÅ¡enÃ­m a Å¡patnÃ½m osvÄ›tlenÃ­m z IoT zaÅ™Ã­zenÃ­, druhÃ½ s vysokÃ½m rozliÅ¡enÃ­m a dobrÃ½m osvÄ›tlenÃ­m z telefonu](../../../../../translated_images/banana-picture-compare.174df164dc326a42cf7fb051a7497e6113c620e91552d92ca914220305d47d9a.cs.png)

Na obrÃ¡zku vÃ½Å¡e byl obrÃ¡zek banÃ¡nu vlevo poÅ™Ã­zen pomocÃ­ kamery Raspberry Pi, zatÃ­mco obrÃ¡zek vpravo byl poÅ™Ã­zen stejnÃ©ho banÃ¡nu na stejnÃ©m mÃ­stÄ› pomocÃ­ iPhonu. Je zde znatelnÃ½ rozdÃ­l v kvalitÄ› â€“ obrÃ¡zek z iPhonu je ostÅ™ejÅ¡Ã­, s jasnÄ›jÅ¡Ã­mi barvami a vÄ›tÅ¡Ã­m kontrastem.

âœ… Co dalÅ¡Ã­ho by mohlo zpÅ¯sobit, Å¾e obrÃ¡zky zachycenÃ© vaÅ¡Ã­m IoT zaÅ™Ã­zenÃ­m majÃ­ nesprÃ¡vnÃ© predikce? Zamyslete se nad prostÅ™edÃ­m, ve kterÃ©m mÅ¯Å¾e bÃ½t IoT zaÅ™Ã­zenÃ­ pouÅ¾ito, jakÃ© faktory mohou ovlivnit zachycenÃ½ obrÃ¡zek?

Pro zlepÅ¡enÃ­ modelu ho mÅ¯Å¾ete znovu trÃ©novat pomocÃ­ obrÃ¡zkÅ¯ zachycenÃ½ch z IoT zaÅ™Ã­zenÃ­.

### Ãškol â€“ zlepÅ¡enÃ­ modelu

1. Klasifikujte vÃ­ce obrÃ¡zkÅ¯ zralÃ©ho i nezralÃ©ho ovoce pomocÃ­ vaÅ¡eho IoT zaÅ™Ã­zenÃ­.

1. Na portÃ¡lu Custom Vision znovu trÃ©nujte model pomocÃ­ obrÃ¡zkÅ¯ na zÃ¡loÅ¾ce *Predikce*.

    > âš ï¸ MÅ¯Å¾ete se odkazovat na [instrukce pro znovu trÃ©novÃ¡nÃ­ vaÅ¡eho klasifikÃ¡toru v lekci 1, pokud je to potÅ™eba](../1-train-fruit-detector/README.md#retrain-your-image-classifier).

1. Pokud vaÅ¡e obrÃ¡zky vypadajÃ­ velmi odliÅ¡nÄ› od pÅ¯vodnÃ­ch pouÅ¾itÃ½ch pro trÃ©novÃ¡nÃ­, mÅ¯Å¾ete vÅ¡echny pÅ¯vodnÃ­ obrÃ¡zky smazat tÃ­m, Å¾e je vyberete na zÃ¡loÅ¾ce *TrÃ©novacÃ­ obrÃ¡zky* a kliknete na tlaÄÃ­tko **Smazat**. Pro vÃ½bÄ›r obrÃ¡zku na nÄ›j najeÄte kurzorem a objevÃ­ se zaÅ¡krtÃ¡vacÃ­ polÃ­Äko, kliknÄ›te na nÄ›j pro vÃ½bÄ›r nebo zruÅ¡enÃ­ vÃ½bÄ›ru obrÃ¡zku.

1. TrÃ©nujte novou iteraci modelu a publikujte ji pomocÃ­ vÃ½Å¡e uvedenÃ½ch krokÅ¯.

1. Aktualizujte URL koncovÃ©ho bodu ve vaÅ¡em kÃ³du a znovu spusÅ¥te aplikaci.

1. Opakujte tyto kroky, dokud nebudete spokojeni s vÃ½sledky predikcÃ­.

---

## ğŸš€ VÃ½zva

Jak moc ovlivÅˆuje rozliÅ¡enÃ­ obrÃ¡zku nebo osvÄ›tlenÃ­ predikci?

Zkuste zmÄ›nit rozliÅ¡enÃ­ obrÃ¡zkÅ¯ ve vaÅ¡em kÃ³du zaÅ™Ã­zenÃ­ a zjistÄ›te, zda to mÃ¡ vliv na kvalitu obrÃ¡zkÅ¯. TakÃ© zkuste zmÄ›nit osvÄ›tlenÃ­.

Pokud byste mÄ›li vytvoÅ™it produkÄnÃ­ zaÅ™Ã­zenÃ­ na prodej farmÃ¡m nebo tovÃ¡rnÃ¡m, jak byste zajistili, Å¾e bude poskytovat konzistentnÃ­ vÃ½sledky po celou dobu?

## KvÃ­z po lekci

[KvÃ­z po lekci](https://black-meadow-040d15503.1.azurestaticapps.net/quiz/32)

## PÅ™ehled & Samostudium

SvÅ¯j model Custom Vision jste trÃ©novali pomocÃ­ portÃ¡lu. To zÃ¡visÃ­ na dostupnosti obrÃ¡zkÅ¯ â€“ a v reÃ¡lnÃ©m svÄ›tÄ› nemusÃ­te bÃ½t schopni zÃ­skat trÃ©novacÃ­ data, kterÃ¡ odpovÃ­dajÃ­ tomu, co kamera na vaÅ¡em zaÅ™Ã­zenÃ­ zachytÃ­. MÅ¯Å¾ete to obejÃ­t tÃ­m, Å¾e budete trÃ©novat pÅ™Ã­mo z vaÅ¡eho zaÅ™Ã­zenÃ­ pomocÃ­ trÃ©novacÃ­ho API, abyste trÃ©novali model pomocÃ­ obrÃ¡zkÅ¯ zachycenÃ½ch z vaÅ¡eho IoT zaÅ™Ã­zenÃ­.

* PÅ™eÄtÄ›te si o trÃ©novacÃ­m API v [rychlÃ©m startu pouÅ¾Ã­vÃ¡nÃ­ Custom Vision SDK](https://docs.microsoft.com/azure/cognitive-services/custom-vision-service/quickstarts/image-classification?WT.mc_id=academic-17441-jabenn&tabs=visual-studio&pivots=programming-language-python)

## ZadÃ¡nÃ­

[Reagujte na vÃ½sledky klasifikace](assignment.md)

---

**ProhlÃ¡Å¡enÃ­**:  
Tento dokument byl pÅ™eloÅ¾en pomocÃ­ sluÅ¾by pro automatickÃ½ pÅ™eklad [Co-op Translator](https://github.com/Azure/co-op-translator). AÄkoli se snaÅ¾Ã­me o pÅ™esnost, mÄ›jte prosÃ­m na pamÄ›ti, Å¾e automatickÃ© pÅ™eklady mohou obsahovat chyby nebo nepÅ™esnosti. PÅ¯vodnÃ­ dokument v jeho pÅ¯vodnÃ­m jazyce by mÄ›l bÃ½t povaÅ¾ovÃ¡n za autoritativnÃ­ zdroj. Pro dÅ¯leÅ¾itÃ© informace doporuÄujeme profesionÃ¡lnÃ­ lidskÃ½ pÅ™eklad. NeodpovÃ­dÃ¡me za Å¾Ã¡dnÃ¡ nedorozumÄ›nÃ­ nebo nesprÃ¡vnÃ© interpretace vyplÃ½vajÃ­cÃ­ z pouÅ¾itÃ­ tohoto pÅ™ekladu.