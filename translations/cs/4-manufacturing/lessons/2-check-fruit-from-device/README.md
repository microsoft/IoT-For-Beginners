<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "557f4ee96b752e0651d2e6e74aa6bd14",
  "translation_date": "2025-08-27T20:54:03+00:00",
  "source_file": "4-manufacturing/lessons/2-check-fruit-from-device/README.md",
  "language_code": "cs"
}
-->
# Kontrola kvality ovoce pomoc√≠ IoT za≈ô√≠zen√≠

![P≈ôehled t√©to lekce ve formƒõ sketchnote](../../../../../translated_images/lesson-16.215daf18b00631fbdfd64c6fc2dc6044dff5d544288825d8076f9fb83d964c23.cs.jpg)

> Sketchnote od [Nitya Narasimhan](https://github.com/nitya). Kliknƒõte na obr√°zek pro vƒõt≈°√≠ verzi.

## Kv√≠z p≈ôed lekc√≠

[Kv√≠z p≈ôed lekc√≠](https://black-meadow-040d15503.1.azurestaticapps.net/quiz/31)

## √övod

V minul√© lekci jste se nauƒçili o klasifik√°torech obr√°zk≈Ø a o tom, jak je tr√©novat k rozpozn√°v√°n√≠ dobr√©ho a ≈°patn√©ho ovoce. Abyste mohli tento klasifik√°tor obr√°zk≈Ø pou≈æ√≠t v aplikaci IoT, pot≈ôebujete b√Ωt schopni zachytit obr√°zek pomoc√≠ nƒõjak√©ho typu kamery a poslat tento obr√°zek do cloudu k anal√Ωze.

V t√©to lekci se nauƒç√≠te o kamerov√Ωch senzorech a o tom, jak je pou≈æ√≠t s IoT za≈ô√≠zen√≠m k zachycen√≠ obr√°zku. Tak√© se nauƒç√≠te, jak volat klasifik√°tor obr√°zk≈Ø z va≈°eho IoT za≈ô√≠zen√≠.

V t√©to lekci se zamƒõ≈ô√≠me na:

* [Kamerov√© senzory](../../../../../4-manufacturing/lessons/2-check-fruit-from-device)
* [Zachycen√≠ obr√°zku pomoc√≠ IoT za≈ô√≠zen√≠](../../../../../4-manufacturing/lessons/2-check-fruit-from-device)
* [Publikov√°n√≠ va≈°eho klasifik√°toru obr√°zk≈Ø](../../../../../4-manufacturing/lessons/2-check-fruit-from-device)
* [Klasifikace obr√°zk≈Ø z va≈°eho IoT za≈ô√≠zen√≠](../../../../../4-manufacturing/lessons/2-check-fruit-from-device)
* [Zlep≈°en√≠ modelu](../../../../../4-manufacturing/lessons/2-check-fruit-from-device)

## Kamerov√© senzory

Kamerov√© senzory, jak n√°zev napov√≠d√°, jsou kamery, kter√© m≈Ø≈æete p≈ôipojit k va≈°emu IoT za≈ô√≠zen√≠. Mohou po≈ôizovat statick√© obr√°zky nebo zachyt√°vat streamovan√© video. Nƒõkter√© vracej√≠ surov√° obrazov√° data, jin√© komprimuj√≠ obrazov√° data do soubor≈Ø, jako je JPEG nebo PNG. Obvykle jsou kamery, kter√© funguj√≠ s IoT za≈ô√≠zen√≠mi, mnohem men≈°√≠ a maj√≠ ni≈æ≈°√≠ rozli≈°en√≠, ne≈æ na jak√© jste zvykl√≠, ale m≈Ø≈æete z√≠skat kamery s vysok√Ωm rozli≈°en√≠m, kter√© se vyrovnaj√≠ ≈°piƒçkov√Ωm telefon≈Øm. M≈Ø≈æete si po≈ô√≠dit r≈Øzn√© vymƒõniteln√© objektivy, sestavy s v√≠ce kamerami, infraƒçerven√© term√°ln√≠ kamery nebo UV kamery.

![Svƒõtlo ze sc√©ny proch√°z√≠ objektivem a je zaost≈ôeno na CMOS senzor](../../../../../translated_images/cmos-sensor.75f9cd74decb137149a4c9ea825251a4549497d67c0ae2776159e6102bb53aa9.cs.png)

Vƒõt≈°ina kamerov√Ωch senzor≈Ø pou≈æ√≠v√° obrazov√© senzory, kde ka≈æd√Ω pixel je fotodioda. Objektiv zaost≈ôuje obraz na obrazov√Ω senzor a tis√≠ce nebo miliony fotodiod detekuj√≠ svƒõtlo dopadaj√≠c√≠ na ka≈ædou z nich a zaznamen√°vaj√≠ to jako obrazov√° data.

> üíÅ Objektivy obracej√≠ obrazy, kamerov√Ω senzor je pak otoƒç√≠ zpƒõt spr√°vn√Ωm smƒõrem. Tot√©≈æ se dƒõje ve va≈°ich oƒç√≠ch ‚Äì to, co vid√≠te, je detekov√°no vzh≈Øru nohama na zadn√≠ stranƒõ va≈°eho oka a v√°≈° mozek to opravuje.

> üéì Obrazov√Ω senzor je zn√°m√Ω jako senzor s aktivn√≠m pixelem (APS) a nejpopul√°rnƒõj≈°√≠m typem APS je senzor z komplement√°rn√≠ho polovodiƒçe na b√°zi oxidu kovu, nebo CMOS. Mo≈æn√° jste sly≈°eli term√≠n CMOS senzor pou≈æ√≠van√Ω pro kamerov√© senzory.

Kamerov√© senzory jsou digit√°ln√≠ senzory, kter√© pos√≠laj√≠ obrazov√° data jako digit√°ln√≠ data, obvykle s pomoc√≠ knihovny, kter√° zaji≈°≈•uje komunikaci. Kamery se p≈ôipojuj√≠ pomoc√≠ protokol≈Ø jako SPI, kter√© jim umo≈æ≈àuj√≠ pos√≠lat velk√© mno≈æstv√≠ dat ‚Äì obr√°zky jsou podstatnƒõ vƒõt≈°√≠ ne≈æ jednotliv√© ƒç√≠sla ze senzor≈Ø, jako je senzor teploty.

‚úÖ Jak√© jsou omezen√≠ velikosti obr√°zk≈Ø u IoT za≈ô√≠zen√≠? Zamyslete se nad omezen√≠mi, zejm√©na u hardwaru mikrokontrol√©r≈Ø.

## Zachycen√≠ obr√°zku pomoc√≠ IoT za≈ô√≠zen√≠

Va≈°e IoT za≈ô√≠zen√≠ m≈Ø≈æete pou≈æ√≠t k zachycen√≠ obr√°zku, kter√Ω bude klasifikov√°n.

### √ökol ‚Äì zachycen√≠ obr√°zku pomoc√≠ IoT za≈ô√≠zen√≠

Projdƒõte si relevantn√≠ n√°vod k zachycen√≠ obr√°zku pomoc√≠ va≈°eho IoT za≈ô√≠zen√≠:

* [Arduino - Wio Terminal](wio-terminal-camera.md)
* [Jednodeskov√Ω poƒç√≠taƒç - Raspberry Pi](pi-camera.md)
* [Jednodeskov√Ω poƒç√≠taƒç - Virtu√°ln√≠ za≈ô√≠zen√≠](virtual-device-camera.md)

## Publikov√°n√≠ va≈°eho klasifik√°toru obr√°zk≈Ø

V minul√© lekci jste tr√©novali sv≈Øj klasifik√°tor obr√°zk≈Ø. Ne≈æ ho budete moci pou≈æ√≠t z va≈°eho IoT za≈ô√≠zen√≠, mus√≠te model publikovat.

### Iterace modelu

Kdy≈æ v√°≈° model tr√©noval v minul√© lekci, mo≈æn√° jste si v≈°imli, ≈æe na z√°lo≈æce **V√Ωkon** se na stranƒõ zobrazuj√≠ iterace. Kdy≈æ jste model poprv√© tr√©novali, vidƒõli jste *Iteraci 1* bƒõhem tr√©nov√°n√≠. Kdy≈æ jste model zlep≈°ovali pomoc√≠ predikƒçn√≠ch obr√°zk≈Ø, vidƒõli jste *Iteraci 2* bƒõhem tr√©nov√°n√≠.

Poka≈æd√©, kdy≈æ model tr√©nujete, z√≠sk√°te novou iteraci. To je zp≈Øsob, jak sledovat r≈Øzn√© verze va≈°eho modelu tr√©novan√© na r≈Øzn√Ωch datov√Ωch sad√°ch. Kdy≈æ provedete **Rychl√Ω test**, je zde rozbalovac√≠ nab√≠dka, kterou m≈Ø≈æete pou≈æ√≠t k v√Ωbƒõru iterace, abyste mohli porovnat v√Ωsledky nap≈ô√≠ƒç v√≠ce iteracemi.

Kdy≈æ jste s iterac√≠ spokojeni, m≈Ø≈æete ji publikovat, aby byla dostupn√° pro pou≈æit√≠ z extern√≠ch aplikac√≠. T√≠mto zp≈Øsobem m≈Ø≈æete m√≠t publikovanou verzi, kterou pou≈æ√≠vaj√≠ va≈°e za≈ô√≠zen√≠, a z√°rove≈à pracovat na nov√© verzi p≈ôes v√≠ce iterac√≠, kterou publikujete, a≈æ budete s n√≠ spokojeni.

### √ökol ‚Äì publikov√°n√≠ iterace

Iterace se publikuj√≠ z port√°lu Custom Vision.

1. Spus≈•te port√°l Custom Vision na [CustomVision.ai](https://customvision.ai) a p≈ôihlaste se, pokud ho je≈°tƒõ nem√°te otev≈ôen√Ω. Pot√© otev≈ôete sv≈Øj projekt `fruit-quality-detector`.

1. Vyberte z√°lo≈æku **V√Ωkon** z mo≈ænost√≠ naho≈ôe.

1. Vyberte nejnovƒõj≈°√≠ iteraci ze seznamu *Iterace* na stranƒõ.

1. Kliknƒõte na tlaƒç√≠tko **Publikovat** pro danou iteraci.

    ![Tlaƒç√≠tko publikovat](../../../../../translated_images/custom-vision-publish-button.b7174e1977b0c33b8b72d4e5b1326c779e0af196f3849d09985ee2d7d5493a39.cs.png)

1. V dialogu *Publikovat model* nastavte *Predikƒçn√≠ zdroj* na zdroj `fruit-quality-detector-prediction`, kter√Ω jste vytvo≈ôili v minul√© lekci. N√°zev ponechte jako `Iteration2` a kliknƒõte na tlaƒç√≠tko **Publikovat**.

1. Po publikov√°n√≠ kliknƒõte na tlaƒç√≠tko **Predikƒçn√≠ URL**. Zobraz√≠ se podrobnosti o predikƒçn√≠m API, kter√© budete pot≈ôebovat k vol√°n√≠ modelu z va≈°eho IoT za≈ô√≠zen√≠. Spodn√≠ ƒç√°st je oznaƒçena *Pokud m√°te soubor s obr√°zkem*, a to jsou detaily, kter√© pot≈ôebujete. Zkop√≠rujte URL, kter√© bude vypadat nƒõjak takto:

    ```output
    https://<location>.api.cognitive.microsoft.com/customvision/v3.0/Prediction/<id>/classify/iterations/Iteration2/image
    ```

    Kde `<location>` bude lokalita, kterou jste pou≈æili p≈ôi vytv√°≈ôen√≠ va≈°eho zdroje Custom Vision, a `<id>` bude dlouh√© ID slo≈æen√© z p√≠smen a ƒç√≠sel.

    Tak√© si zkop√≠rujte hodnotu *Prediction-Key*. Toto je bezpeƒçnostn√≠ kl√≠ƒç, kter√Ω mus√≠te p≈ôedat p≈ôi vol√°n√≠ modelu. Pouze aplikace, kter√© p≈ôedaj√≠ tento kl√≠ƒç, maj√≠ povolen√≠ pou≈æ√≠vat model, v≈°echny ostatn√≠ aplikace jsou odm√≠tnuty.

    ![Dialog predikƒçn√≠ho API zobrazuj√≠c√≠ URL a kl√≠ƒç](../../../../../translated_images/custom-vision-prediction-key-endpoint.30c569ffd0338864f319911f052d5e9b8c5066cb0800a26dd6f7ff5713130ad8.cs.png)

‚úÖ Kdy≈æ je publikov√°na nov√° iterace, bude m√≠t jin√Ω n√°zev. Jak si mysl√≠te, ≈æe byste zmƒõnili iteraci, kterou IoT za≈ô√≠zen√≠ pou≈æ√≠v√°?

## Klasifikace obr√°zk≈Ø z va≈°eho IoT za≈ô√≠zen√≠

Nyn√≠ m≈Ø≈æete pou≈æ√≠t tyto p≈ôipojovac√≠ √∫daje k vol√°n√≠ klasifik√°toru obr√°zk≈Ø z va≈°eho IoT za≈ô√≠zen√≠.

### √ökol ‚Äì klasifikace obr√°zk≈Ø z va≈°eho IoT za≈ô√≠zen√≠

Projdƒõte si relevantn√≠ n√°vod k klasifikaci obr√°zk≈Ø pomoc√≠ va≈°eho IoT za≈ô√≠zen√≠:

* [Arduino - Wio Terminal](wio-terminal-classify-image.md)
* [Jednodeskov√Ω poƒç√≠taƒç - Raspberry Pi/Virtu√°ln√≠ IoT za≈ô√≠zen√≠](single-board-computer-classify-image.md)

## Zlep≈°en√≠ modelu

M≈Ø≈æe se st√°t, ≈æe v√Ωsledky, kter√© z√≠sk√°te p≈ôi pou≈æit√≠ kamery p≈ôipojen√© k va≈°emu IoT za≈ô√≠zen√≠, neodpov√≠daj√≠ tomu, co byste oƒçek√°vali. Predikce nejsou v≈ædy tak p≈ôesn√© jako p≈ôi pou≈æit√≠ obr√°zk≈Ø nahran√Ωch z va≈°eho poƒç√≠taƒçe. To je zp≈Øsobeno t√≠m, ≈æe model byl tr√©nov√°n na jin√Ωch datech, ne≈æ kter√° jsou pou≈æ√≠v√°na pro predikce.

Abyste dos√°hli nejlep≈°√≠ch v√Ωsledk≈Ø u klasifik√°toru obr√°zk≈Ø, chcete model tr√©novat na obr√°zc√≠ch, kter√© jsou co nejpodobnƒõj≈°√≠ obr√°zk≈Øm pou≈æ√≠van√Ωm pro predikce. Pokud jste nap≈ô√≠klad pou≈æili kameru telefonu k zachycen√≠ obr√°zk≈Ø pro tr√©nov√°n√≠, kvalita obr√°zku, ostrost a barvy budou odli≈°n√© od kamery p≈ôipojen√© k IoT za≈ô√≠zen√≠.

![2 obr√°zky ban√°n≈Ø, jeden s n√≠zk√Ωm rozli≈°en√≠m a ≈°patn√Ωm osvƒõtlen√≠m z IoT za≈ô√≠zen√≠, druh√Ω s vysok√Ωm rozli≈°en√≠m a dobr√Ωm osvƒõtlen√≠m z telefonu](../../../../../translated_images/banana-picture-compare.174df164dc326a42cf7fb051a7497e6113c620e91552d92ca914220305d47d9a.cs.png)

Na obr√°zku v√Ω≈°e byl obr√°zek ban√°nu vlevo po≈ô√≠zen pomoc√≠ kamery Raspberry Pi, zat√≠mco obr√°zek vpravo byl po≈ô√≠zen stejn√©ho ban√°nu na stejn√©m m√≠stƒõ pomoc√≠ iPhonu. Je zde znateln√Ω rozd√≠l v kvalitƒõ ‚Äì obr√°zek z iPhonu je ost≈ôej≈°√≠, s jasnƒõj≈°√≠mi barvami a vƒõt≈°√≠m kontrastem.

‚úÖ Co dal≈°√≠ho by mohlo zp≈Øsobit, ≈æe obr√°zky zachycen√© va≈°√≠m IoT za≈ô√≠zen√≠m maj√≠ nespr√°vn√© predikce? Zamyslete se nad prost≈ôed√≠m, ve kter√©m m≈Ø≈æe b√Ωt IoT za≈ô√≠zen√≠ pou≈æito, jak√© faktory mohou ovlivnit zachycen√Ω obr√°zek?

Pro zlep≈°en√≠ modelu ho m≈Ø≈æete znovu tr√©novat pomoc√≠ obr√°zk≈Ø zachycen√Ωch z IoT za≈ô√≠zen√≠.

### √ökol ‚Äì zlep≈°en√≠ modelu

1. Klasifikujte v√≠ce obr√°zk≈Ø zral√©ho i nezral√©ho ovoce pomoc√≠ va≈°eho IoT za≈ô√≠zen√≠.

1. Na port√°lu Custom Vision znovu tr√©nujte model pomoc√≠ obr√°zk≈Ø na z√°lo≈æce *Predikce*.

    > ‚ö†Ô∏è M≈Ø≈æete se odkazovat na [instrukce pro znovu tr√©nov√°n√≠ va≈°eho klasifik√°toru v lekci 1, pokud je to pot≈ôeba](../1-train-fruit-detector/README.md#retrain-your-image-classifier).

1. Pokud va≈°e obr√°zky vypadaj√≠ velmi odli≈°nƒõ od p≈Øvodn√≠ch pou≈æit√Ωch pro tr√©nov√°n√≠, m≈Ø≈æete v≈°echny p≈Øvodn√≠ obr√°zky smazat t√≠m, ≈æe je vyberete na z√°lo≈æce *Tr√©novac√≠ obr√°zky* a kliknete na tlaƒç√≠tko **Smazat**. Pro v√Ωbƒõr obr√°zku na nƒõj najeƒète kurzorem a objev√≠ se za≈°krt√°vac√≠ pol√≠ƒçko, kliknƒõte na nƒõj pro v√Ωbƒõr nebo zru≈°en√≠ v√Ωbƒõru obr√°zku.

1. Tr√©nujte novou iteraci modelu a publikujte ji pomoc√≠ v√Ω≈°e uveden√Ωch krok≈Ø.

1. Aktualizujte URL koncov√©ho bodu ve va≈°em k√≥du a znovu spus≈•te aplikaci.

1. Opakujte tyto kroky, dokud nebudete spokojeni s v√Ωsledky predikc√≠.

---

## üöÄ V√Ωzva

Jak moc ovliv≈àuje rozli≈°en√≠ obr√°zku nebo osvƒõtlen√≠ predikci?

Zkuste zmƒõnit rozli≈°en√≠ obr√°zk≈Ø ve va≈°em k√≥du za≈ô√≠zen√≠ a zjistƒõte, zda to m√° vliv na kvalitu obr√°zk≈Ø. Tak√© zkuste zmƒõnit osvƒõtlen√≠.

Pokud byste mƒõli vytvo≈ôit produkƒçn√≠ za≈ô√≠zen√≠ na prodej farm√°m nebo tov√°rn√°m, jak byste zajistili, ≈æe bude poskytovat konzistentn√≠ v√Ωsledky po celou dobu?

## Kv√≠z po lekci

[Kv√≠z po lekci](https://black-meadow-040d15503.1.azurestaticapps.net/quiz/32)

## P≈ôehled & Samostudium

Sv≈Øj model Custom Vision jste tr√©novali pomoc√≠ port√°lu. To z√°vis√≠ na dostupnosti obr√°zk≈Ø ‚Äì a v re√°ln√©m svƒõtƒõ nemus√≠te b√Ωt schopni z√≠skat tr√©novac√≠ data, kter√° odpov√≠daj√≠ tomu, co kamera na va≈°em za≈ô√≠zen√≠ zachyt√≠. M≈Ø≈æete to obej√≠t t√≠m, ≈æe budete tr√©novat p≈ô√≠mo z va≈°eho za≈ô√≠zen√≠ pomoc√≠ tr√©novac√≠ho API, abyste tr√©novali model pomoc√≠ obr√°zk≈Ø zachycen√Ωch z va≈°eho IoT za≈ô√≠zen√≠.

* P≈ôeƒçtƒõte si o tr√©novac√≠m API v [rychl√©m startu pou≈æ√≠v√°n√≠ Custom Vision SDK](https://docs.microsoft.com/azure/cognitive-services/custom-vision-service/quickstarts/image-classification?WT.mc_id=academic-17441-jabenn&tabs=visual-studio&pivots=programming-language-python)

## Zad√°n√≠

[Reagujte na v√Ωsledky klasifikace](assignment.md)

---

**Prohl√°≈°en√≠**:  
Tento dokument byl p≈ôelo≈æen pomoc√≠ slu≈æby pro automatick√Ω p≈ôeklad [Co-op Translator](https://github.com/Azure/co-op-translator). Aƒçkoli se sna≈æ√≠me o p≈ôesnost, mƒõjte pros√≠m na pamƒõti, ≈æe automatick√© p≈ôeklady mohou obsahovat chyby nebo nep≈ôesnosti. P≈Øvodn√≠ dokument v jeho p≈Øvodn√≠m jazyce by mƒõl b√Ωt pova≈æov√°n za autoritativn√≠ zdroj. Pro d≈Øle≈æit√© informace doporuƒçujeme profesion√°ln√≠ lidsk√Ω p≈ôeklad. Neodpov√≠d√°me za ≈æ√°dn√° nedorozumƒõn√≠ nebo nespr√°vn√© interpretace vypl√Ωvaj√≠c√≠ z pou≈æit√≠ tohoto p≈ôekladu.