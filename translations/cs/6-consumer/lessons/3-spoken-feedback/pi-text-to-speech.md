<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "606f3af1c78e3741e48ce77c31cea626",
  "translation_date": "2025-08-27T21:13:26+00:00",
  "source_file": "6-consumer/lessons/3-spoken-feedback/pi-text-to-speech.md",
  "language_code": "cs"
}
-->
# P콏evod textu na 콏e캜 - Raspberry Pi

V t칠to 캜치sti lekce nap칤코ete k칩d pro p콏evod textu na 콏e캜 pomoc칤 slu쬭y pro p콏evod 콏e캜i.

## P콏evod textu na 콏e캜 pomoc칤 slu쬭y pro p콏evod 콏e캜i

Text lze odeslat do slu쬭y pro p콏evod 콏e캜i pomoc칤 REST API, aby se z칤skal zvukov칳 soubor, kter칳 lze p콏ehr치t na va코em IoT za콏칤zen칤. P콏i po쬬davku na p콏evod 콏e캜i je nutn칠 ur캜it hlas, kter칳 se m치 pou쮂셦, proto쬰 콏e캜 m콢쬰 b칳t generov치na pomoc칤 r콢zn칳ch hlas콢.

Ka쬯칳 jazyk podporuje r콢zn칠 hlasy a m콢쬰te prov칠st REST po쬬davek na slu쬭u pro p콏evod 콏e캜i, abyste z칤skali seznam podporovan칳ch hlas콢 pro ka쬯칳 jazyk.

### 칔kol - z칤sk치n칤 hlasu

1. Otev콏ete projekt `smart-timer` ve VS Code.

1. P콏idejte n치sleduj칤c칤 k칩d nad funkci `say`, abyste z칤skali seznam hlas콢 pro dan칳 jazyk:

    ```python
    def get_voice():
        url = f'https://{location}.tts.speech.microsoft.com/cognitiveservices/voices/list'
    
        headers = {
            'Authorization': 'Bearer ' + get_access_token()
        }
    
        response = requests.get(url, headers=headers)
        voices_json = json.loads(response.text)
    
        first_voice = next(x for x in voices_json if x['Locale'].lower() == language.lower() and x['VoiceType'] == 'Neural')
        return first_voice['ShortName']
    
    voice = get_voice()
    print(f'Using voice {voice}')
    ```

    Tento k칩d definuje funkci nazvanou `get_voice`, kter치 vyu쮂셨치 slu쬭u pro p콏evod 콏e캜i k z칤sk치n칤 seznamu hlas콢. Pot칠 najde prvn칤 hlas, kter칳 odpov칤d치 pou쮂셨an칠mu jazyku.

    Tato funkce je n치sledn캩 vol치na k ulo쬰n칤 prvn칤ho hlasu a n치zev hlasu je vyti코t캩n do konzole. Tento hlas lze po쬬dovat jednou a jeho hodnota se pou쬴je p콏i ka쬯칠m vol치n칤 pro p콏evod textu na 콏e캜.

    > 游누 Kompletn칤 seznam podporovan칳ch hlas콢 najdete v [dokumentaci o podpo콏e jazyk콢 a hlas콢 na Microsoft Docs](https://docs.microsoft.com/azure/cognitive-services/speech-service/language-support?WT.mc_id=academic-17441-jabenn#text-to-speech). Pokud chcete pou쮂셦 konkr칠tn칤 hlas, m콢쬰te tuto funkci odstranit a pevn캩 nastavit hlas na n치zev hlasu z t칠to dokumentace. Nap콏칤klad:
    >
    > ```python
    > voice = 'hi-IN-SwaraNeural'
    > ```

### 칔kol - p콏evod textu na 콏e캜

1. Pod t칤mto k칩dem definujte konstantu pro form치t zvuku, kter칳 m치 b칳t z칤sk치n ze slu쬭y pro p콏evod 콏e캜i. P콏i po쬬davku na zvuk m콢쬰te pou쮂셦 r콢zn칠 form치ty.

    ```python
    playback_format = 'riff-48khz-16bit-mono-pcm'
    ```

    Form치t, kter칳 m콢쬰te pou쮂셦, z치vis칤 na va코em hardwaru. Pokud p콏i p콏ehr치v치n칤 zvuku dostanete chyby `Invalid sample rate`, zm캩켿te tuto hodnotu na jinou. Seznam podporovan칳ch hodnot najdete v [dokumentaci REST API pro p콏evod textu na 콏e캜 na Microsoft Docs](https://docs.microsoft.com/azure/cognitive-services/speech-service/rest-text-to-speech?WT.mc_id=academic-17441-jabenn#audio-outputs). Budete muset pou쮂셦 zvuk ve form치tu `riff` a hodnoty, kter칠 m콢쬰te vyzkou코et, jsou `riff-16khz-16bit-mono-pcm`, `riff-24khz-16bit-mono-pcm` a `riff-48khz-16bit-mono-pcm`.

1. Pod t칤mto k칩dem deklarujte funkci nazvanou `get_speech`, kter치 p콏evede text na 콏e캜 pomoc칤 REST API slu쬭y pro p콏evod 콏e캜i:

    ```python
    def get_speech(text):
    ```

1. Ve funkci `get_speech` definujte URL, kter칠 se m치 volat, a hlavi캜ky, kter칠 se maj칤 p콏edat:

    ```python
        url = f'https://{location}.tts.speech.microsoft.com/cognitiveservices/v1'
    
        headers = {
            'Authorization': 'Bearer ' + get_access_token(),
            'Content-Type': 'application/ssml+xml',
            'X-Microsoft-OutputFormat': playback_format
        }
    ```

    T칤m se nastav칤 hlavi캜ky pro pou쬴t칤 vygenerovan칠ho p콏칤stupov칠ho tokenu, obsah se nastav칤 na SSML a definuje se po쬬dovan칳 form치t zvuku.

1. Pod t칤mto k칩dem definujte SSML, kter칠 se m치 odeslat do REST API:

    ```python
    ssml =  f'<speak version=\'1.0\' xml:lang=\'{language}\'>'
    ssml += f'<voice xml:lang=\'{language}\' name=\'{voice}\'>'
    ssml += text
    ssml += '</voice>'
    ssml += '</speak>'
    ```

    Toto SSML nastavuje jazyk a hlas, kter칳 se m치 pou쮂셦, spolu s textem, kter칳 se m치 p콏ev칠st.

1. Nakonec p콏idejte k칩d do t칠to funkce, kter칳 provede REST po쬬davek a vr치t칤 bin치rn칤 zvukov치 data:

    ```python
    response = requests.post(url, headers=headers, data=ssml.encode('utf-8'))
    return io.BytesIO(response.content)
    ```

### 칔kol - p콏ehr치n칤 zvuku

1. Pod funkc칤 `get_speech` definujte novou funkci pro p콏ehr치n칤 zvuku vr치cen칠ho vol치n칤m REST API:

    ```python
    def play_speech(speech):
    ```

1. Parametr `speech` p콏edan칳 t칠to funkci bude bin치rn칤 zvukov치 data vr치cen치 z REST API. Pou쬴jte n치sleduj칤c칤 k칩d k otev콏en칤 tohoto souboru jako zvukov칠ho souboru a jeho p콏ed치n칤 PyAudio pro p콏ehr치n칤 zvuku:

    ```python
    def play_speech(speech):
        with wave.open(speech, 'rb') as wave_file:
            stream = audio.open(format=audio.get_format_from_width(wave_file.getsampwidth()),
                                channels=wave_file.getnchannels(),
                                rate=wave_file.getframerate(),
                                output_device_index=speaker_card_number,
                                output=True)

            data = wave_file.readframes(4096)

            while len(data) > 0:
                stream.write(data)
                data = wave_file.readframes(4096)

            stream.stop_stream()
            stream.close()
    ```

    Tento k칩d pou쮂셨치 PyAudio stream, stejn캩 jako p콏i zachyt치v치n칤 zvuku. Rozd칤l je v tom, 쬰 stream je nastaven jako v칳stupn칤 stream a data jsou 캜tena ze zvukov칳ch dat a pos칤l치na do streamu.

    M칤sto pevn칠ho nastaven칤 detail콢 streamu, jako je vzorkovac칤 frekvence, jsou tyto informace 캜teny ze zvukov칳ch dat.

1. Nahra캞te obsah funkce `say` n치sleduj칤c칤m k칩dem:

    ```python
    speech = get_speech(text)
    play_speech(speech)
    ```

    Tento k칩d p콏evede text na 콏e캜 jako bin치rn칤 zvukov치 data a p콏ehraje zvuk.

1. Spus콘te aplikaci a ujist캩te se, 쬰 funk캜n칤 aplikace tak칠 b캩쮂. Nastavte n캩kolik 캜asova캜콢 a usly코칤te hlasovou odpov캩캞, kter치 ozn치m칤, 쬰 v치코 캜asova캜 byl nastaven, a pot칠 dal코칤 hlasovou odpov캩캞, kdy 캜asova캜 skon캜칤.

    Pokud dostanete chyby `Invalid sample rate`, zm캩켿te `playback_format`, jak bylo pops치no v칳코e.

> 游누 Tento k칩d najdete ve slo쬮e [code-spoken-response/pi](../../../../../6-consumer/lessons/3-spoken-feedback/code-spoken-response/pi).

游 V치코 program 캜asova캜e byl 칰sp캩코n칳!

---

**Prohl치코en칤**:  
Tento dokument byl p콏elo쬰n pomoc칤 slu쬭y AI pro p콏eklady [Co-op Translator](https://github.com/Azure/co-op-translator). A캜koli se sna쮂셠e o p콏esnost, m캩jte pros칤m na pam캩ti, 쬰 automatizovan칠 p콏eklady mohou obsahovat chyby nebo nep콏esnosti. P콢vodn칤 dokument v jeho p콢vodn칤m jazyce by m캩l b칳t pova쬺v치n za autoritativn칤 zdroj. Pro d콢le쬴t칠 informace se doporu캜uje profesion치ln칤 lidsk칳 p콏eklad. Neodpov칤d치me za 쮂멳n치 nedorozum캩n칤 nebo nespr치vn칠 interpretace vypl칳vaj칤c칤 z pou쬴t칤 tohoto p콏ekladu.