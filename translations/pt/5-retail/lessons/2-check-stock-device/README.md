<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "1c9e5fa8b7be726c75a97232b1e41c97",
  "translation_date": "2025-08-25T20:44:23+00:00",
  "source_file": "5-retail/lessons/2-check-stock-device/README.md",
  "language_code": "pt"
}
-->
# Verificar stock a partir de um dispositivo IoT

![Uma vis√£o geral ilustrada desta li√ß√£o](../../../../../translated_images/lesson-20.0211df9551a8abb300fc8fcf7dc2789468dea2eabe9202273ac077b0ba37f15e.pt.jpg)

> Ilustra√ß√£o por [Nitya Narasimhan](https://github.com/nitya). Clique na imagem para uma vers√£o maior.

## Question√°rio pr√©-aula

[Question√°rio pr√©-aula](https://black-meadow-040d15503.1.azurestaticapps.net/quiz/39)

## Introdu√ß√£o

Na li√ß√£o anterior, aprendeste sobre os diferentes usos da dete√ß√£o de objetos no setor de retalho. Tamb√©m aprendeste a treinar um detetor de objetos para identificar stock. Nesta li√ß√£o, vais aprender a usar o teu detetor de objetos a partir de um dispositivo IoT para contar stock.

Nesta li√ß√£o, vamos abordar:

* [Contagem de stock](../../../../../5-retail/lessons/2-check-stock-device)
* [Chamar o teu detetor de objetos a partir do teu dispositivo IoT](../../../../../5-retail/lessons/2-check-stock-device)
* [Caixas delimitadoras](../../../../../5-retail/lessons/2-check-stock-device)
* [Re-treinar o modelo](../../../../../5-retail/lessons/2-check-stock-device)
* [Contar stock](../../../../../5-retail/lessons/2-check-stock-device)

> üóë Esta √© a √∫ltima li√ß√£o deste projeto, por isso, depois de completares esta li√ß√£o e o exerc√≠cio, n√£o te esque√ßas de limpar os servi√ßos na nuvem. Vais precisar dos servi√ßos para completar o exerc√≠cio, por isso certifica-te de que o fazes primeiro.
>
> Consulta [o guia para limpar o teu projeto](../../../clean-up.md) se necess√°rio para obter instru√ß√µes sobre como fazer isso.

## Contagem de stock

Os detetores de objetos podem ser usados para verificar stock, seja contando os itens ou garantindo que est√£o no local correto. Dispositivos IoT com c√¢maras podem ser instalados por toda a loja para monitorizar o stock, come√ßando por √°reas cr√≠ticas onde √© importante repor os itens, como zonas onde s√£o armazenados poucos produtos de alto valor.

Por exemplo, se uma c√¢mara estiver apontada para uma prateleira que pode conter 8 latas de polpa de tomate, e o detetor de objetos apenas detetar 7 latas, ent√£o falta uma e precisa de ser reposta.

![7 latas de polpa de tomate numa prateleira, 4 na fila de cima, 3 na de baixo](../../../../../translated_images/stock-7-cans-tomato-paste.f86059cc573d7becaa89a0eafb9d2cd7e2fe37405a530fe565990e2333d0e4a1.pt.png)

Na imagem acima, um detetor de objetos detetou 7 latas de polpa de tomate numa prateleira que pode conter 8 latas. N√£o s√≥ o dispositivo IoT pode enviar uma notifica√ß√£o sobre a necessidade de reposi√ß√£o, como tamb√©m pode indicar a localiza√ß√£o do item em falta, informa√ß√£o importante caso estejas a usar rob√¥s para repor prateleiras.

> üíÅ Dependendo da loja e da popularidade do produto, provavelmente n√£o seria necess√°rio repor se apenas uma lata estivesse em falta. Terias de construir um algoritmo que determine quando repor com base nos teus produtos, clientes e outros crit√©rios.

‚úÖ Em que outros cen√°rios poderias combinar dete√ß√£o de objetos e rob√¥s?

Por vezes, o stock errado pode estar nas prateleiras. Isto pode acontecer devido a erro humano ao repor, ou clientes que mudam de ideia sobre uma compra e colocam um item no primeiro espa√ßo dispon√≠vel. Quando se trata de um item n√£o perec√≠vel, como produtos enlatados, isto √© apenas um inc√≥modo. Se for um item perec√≠vel, como produtos congelados ou refrigerados, pode significar que o produto j√° n√£o pode ser vendido, pois pode ser imposs√≠vel determinar quanto tempo esteve fora do congelador.

A dete√ß√£o de objetos pode ser usada para identificar itens inesperados, alertando novamente um humano ou rob√¥ para devolver o item assim que for detetado.

![Uma lata de milho beb√© fora do lugar na prateleira de polpa de tomate](../../../../../translated_images/stock-rogue-corn.be1f3ada8c4578544641af66671c1711a4c02297f14cc7f503354dae0d30a954.pt.png)

Na imagem acima, uma lata de milho beb√© foi colocada na prateleira ao lado da polpa de tomate. O detetor de objetos detetou isto, permitindo que o dispositivo IoT notifique um humano ou rob√¥ para devolver a lata ao local correto.

## Chamar o teu detetor de objetos a partir do teu dispositivo IoT

O detetor de objetos que treinaste na √∫ltima li√ß√£o pode ser chamado a partir do teu dispositivo IoT.

### Tarefa - publicar uma itera√ß√£o do teu detetor de objetos

As itera√ß√µes s√£o publicadas a partir do portal Custom Vision.

1. Abre o portal Custom Vision em [CustomVision.ai](https://customvision.ai) e inicia sess√£o se ainda n√£o o tiveres aberto. Depois, abre o teu projeto `stock-detector`.

1. Seleciona o separador **Performance** nas op√ß√µes no topo.

1. Seleciona a √∫ltima itera√ß√£o na lista *Iterations* na lateral.

1. Clica no bot√£o **Publish** para a itera√ß√£o.

    ![O bot√£o de publica√ß√£o](../../../../../translated_images/custom-vision-object-detector-publish-button.34ee379fc650ccb9856c3868d0003f413b9529f102fc73c37168c98d721cc293.pt.png)

1. No di√°logo *Publish Model*, define o *Prediction resource* como o recurso `stock-detector-prediction` que criaste na √∫ltima li√ß√£o. Mant√©m o nome como `Iteration2` e clica no bot√£o **Publish**.

1. Depois de publicado, clica no bot√£o **Prediction URL**. Isto mostrar√° os detalhes da API de previs√£o, e vais precisar deles para chamar o modelo a partir do teu dispositivo IoT. A sec√ß√£o inferior est√° rotulada como *If you have an image file*, e s√£o esses os detalhes que precisas. Copia o URL mostrado, que ser√° algo como:

    ```output
    https://<location>.api.cognitive.microsoft.com/customvision/v3.0/Prediction/<id>/detect/iterations/Iteration2/image
    ```

    Onde `<location>` ser√° a localiza√ß√£o que usaste ao criar o recurso Custom Vision, e `<id>` ser√° um ID longo composto por letras e n√∫meros.

    Tamb√©m copia o valor *Prediction-Key*. Esta √© uma chave segura que tens de passar ao chamar o modelo. Apenas aplica√ß√µes que passam esta chave podem usar o modelo; quaisquer outras aplica√ß√µes ser√£o rejeitadas.

    ![O di√°logo da API de previs√£o mostrando o URL e a chave](../../../../../translated_images/custom-vision-prediction-key-endpoint.30c569ffd0338864f319911f052d5e9b8c5066cb0800a26dd6f7ff5713130ad8.pt.png)

‚úÖ Quando uma nova itera√ß√£o √© publicada, ter√° um nome diferente. Como achas que poderias alterar a itera√ß√£o que um dispositivo IoT est√° a usar?

### Tarefa - chamar o teu detetor de objetos a partir do teu dispositivo IoT

Segue o guia relevante abaixo para usar o detetor de objetos a partir do teu dispositivo IoT:

* [Arduino - Wio Terminal](wio-terminal-object-detector.md)
* [Computador de placa √∫nica - Raspberry Pi/Dispositivo virtual](single-board-computer-object-detector.md)

## Caixas delimitadoras

Quando usas o detetor de objetos, n√£o s√≥ recebes os objetos detetados com as suas etiquetas e probabilidades, mas tamb√©m as caixas delimitadoras dos objetos. Estas definem onde o detetor de objetos identificou o objeto com a probabilidade dada.

> üíÅ Uma caixa delimitadora √© uma √°rea que define os limites do objeto detetado.

Os resultados de uma previs√£o no separador **Predictions** no Custom Vision t√™m as caixas delimitadoras desenhadas na imagem enviada para previs√£o.

![4 latas de polpa de tomate numa prateleira com previs√µes para as 4 dete√ß√µes de 35.8%, 33.5%, 25.7% e 16.6%](../../../../../translated_images/custom-vision-stock-prediction.942266ab1bcca3410ecdf23643b9f5f570cfab2345235074e24c51f285777613.pt.png)

Na imagem acima, foram detetadas 4 latas de polpa de tomate. Nos resultados, um quadrado vermelho √© sobreposto para cada objeto detetado na imagem, indicando a caixa delimitadora para o objeto.

‚úÖ Abre as previs√µes no Custom Vision e verifica as caixas delimitadoras.

As caixas delimitadoras s√£o definidas com 4 valores - topo, esquerda, altura e largura. Estes valores est√£o numa escala de 0-1, representando as posi√ß√µes como uma percentagem do tamanho da imagem. A origem (posi√ß√£o 0,0) √© o canto superior esquerdo da imagem, ent√£o o valor de topo √© a dist√¢ncia desde o topo, e o fundo da caixa delimitadora √© o topo mais a altura.

![Uma caixa delimitadora em torno de uma lata de polpa de tomate](../../../../../translated_images/bounding-box.1420a7ea0d3d15f71e1ffb5cf4b2271d184fac051f990abc541975168d163684.pt.png)

A imagem acima tem 600 pixels de largura e 800 pixels de altura. A caixa delimitadora come√ßa a 320 pixels abaixo, dando uma coordenada de topo de 0.4 (800 x 0.4 = 320). A partir da esquerda, a caixa delimitadora come√ßa a 240 pixels, dando uma coordenada de esquerda de 0.4 (600 x 0.4 = 240). A altura da caixa delimitadora √© de 240 pixels, dando um valor de altura de 0.3 (800 x 0.3 = 240). A largura da caixa delimitadora √© de 120 pixels, dando um valor de largura de 0.2 (600 x 0.2 = 120).

| Coordenada | Valor |
| ---------- | ----: |
| Topo       | 0.4   |
| Esquerda   | 0.4   |
| Altura     | 0.3   |
| Largura    | 0.2   |

Usar valores percentuais de 0-1 significa que, independentemente do tamanho da imagem, a caixa delimitadora come√ßa a 0.4 do caminho ao longo e abaixo, e tem 0.3 da altura e 0.2 da largura.

Podes usar caixas delimitadoras combinadas com probabilidades para avaliar a precis√£o de uma dete√ß√£o. Por exemplo, um detetor de objetos pode detetar m√∫ltiplos objetos que se sobrep√µem, como detetar uma lata dentro de outra. O teu c√≥digo pode analisar as caixas delimitadoras, perceber que isso √© imposs√≠vel e ignorar quaisquer objetos que tenham uma sobreposi√ß√£o significativa com outros objetos.

![Duas caixas delimitadoras sobrepondo-se a uma lata de polpa de tomate](../../../../../translated_images/overlap-object-detection.d431e03cae75072a2760430eca7f2c5fdd43045bfd72dadcbf12711f7cd6c2ae.pt.png)

No exemplo acima, uma caixa delimitadora indicou uma lata de polpa de tomate prevista com 78.3%. Uma segunda caixa delimitadora √© ligeiramente menor e est√° dentro da primeira, com uma probabilidade de 64.3%. O teu c√≥digo pode verificar as caixas delimitadoras, ver que se sobrep√µem completamente e ignorar a probabilidade mais baixa, pois n√£o h√° como uma lata estar dentro de outra.

‚úÖ Consegues pensar numa situa√ß√£o em que seria v√°lido detetar um objeto dentro de outro?

## Re-treinar o modelo

Tal como com o classificador de imagens, podes re-treinar o teu modelo usando dados capturados pelo teu dispositivo IoT. Usar estes dados do mundo real garantir√° que o teu modelo funciona bem quando usado a partir do teu dispositivo IoT.

Ao contr√°rio do classificador de imagens, n√£o podes simplesmente etiquetar uma imagem. Em vez disso, precisas de rever cada caixa delimitadora detetada pelo modelo. Se a caixa estiver em torno do objeto errado, precisa de ser eliminada; se estiver na localiza√ß√£o errada, precisa de ser ajustada.

### Tarefa - re-treinar o modelo

1. Certifica-te de que capturaste uma variedade de imagens usando o teu dispositivo IoT.

1. No separador **Predictions**, seleciona uma imagem. Vais ver caixas vermelhas indicando as caixas delimitadoras dos objetos detetados.

1. Analisa cada caixa delimitadora. Seleciona-a primeiro e vais ver um pop-up mostrando a etiqueta. Usa os controlos nos cantos da caixa delimitadora para ajustar o tamanho, se necess√°rio. Se a etiqueta estiver errada, remove-a com o bot√£o **X** e adiciona a etiqueta correta. Se a caixa delimitadora n√£o contiver um objeto, elimina-a com o bot√£o de caixote do lixo.

1. Fecha o editor quando terminares e a imagem ser√° movida do separador **Predictions** para o separador **Training Images**. Repete o processo para todas as previs√µes.

1. Usa o bot√£o **Train** para re-treinar o teu modelo. Depois de treinado, publica a itera√ß√£o e atualiza o teu dispositivo IoT para usar o URL da nova itera√ß√£o.

1. Reimplementa o teu c√≥digo e testa o teu dispositivo IoT.

## Contar stock

Usando uma combina√ß√£o do n√∫mero de objetos detetados e das caixas delimitadoras, podes contar o stock numa prateleira.

### Tarefa - contar stock

Segue o guia relevante abaixo para contar stock usando os resultados do detetor de objetos a partir do teu dispositivo IoT:

* [Arduino - Wio Terminal](wio-terminal-count-stock.md)
* [Computador de placa √∫nica - Raspberry Pi/Dispositivo virtual](single-board-computer-count-stock.md)

---

## üöÄ Desafio

Consegues detetar stock incorreto? Treina o teu modelo com m√∫ltiplos objetos e depois atualiza a tua aplica√ß√£o para te alertar se for detetado o stock errado.

Talvez at√© possas levar isto mais longe e detetar stock lado a lado na mesma prateleira, verificando se algo foi colocado no lugar errado ao definir limites nas caixas delimitadoras.

## Question√°rio p√≥s-aula

[Question√°rio p√≥s-aula](https://black-meadow-040d15503.1.azurestaticapps.net/quiz/40)

## Revis√£o & Estudo Individual

* Aprende mais sobre como arquitetar um sistema de dete√ß√£o de stock de ponta a ponta no guia [Out of stock detection at the edge pattern guide on Microsoft Docs](https://docs.microsoft.com/hybrid/app-solutions/pattern-out-of-stock-at-edge?WT.mc_id=academic-17441-jabenn)
* Descobre outras formas de construir solu√ß√µes de retalho de ponta a ponta combinando uma variedade de servi√ßos IoT e na nuvem assistindo ao v√≠deo [Behind the scenes of a retail solution - Hands On! no YouTube](https://www.youtube.com/watch?v=m3Pc300x2Mw).

## Exerc√≠cio

[Usa o teu detetor de objetos na ponta](assignment.md)

**Aviso Legal**:  
Este documento foi traduzido utilizando o servi√ßo de tradu√ß√£o por IA [Co-op Translator](https://github.com/Azure/co-op-translator). Embora nos esforcemos pela precis√£o, esteja ciente de que tradu√ß√µes autom√°ticas podem conter erros ou imprecis√µes. O documento original na sua l√≠ngua nativa deve ser considerado a fonte autorit√°ria. Para informa√ß√µes cr√≠ticas, recomenda-se a tradu√ß√£o profissional realizada por humanos. N√£o nos responsabilizamos por quaisquer mal-entendidos ou interpreta√ß√µes incorretas decorrentes do uso desta tradu√ß√£o.