<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "a202fa5889790a3777bfc33dd9f4b459",
  "translation_date": "2025-08-25T22:38:18+00:00",
  "source_file": "6-consumer/lessons/3-spoken-feedback/wio-terminal-text-to-speech.md",
  "language_code": "pt"
}
-->
# Texto para fala - Wio Terminal

Nesta parte da li√ß√£o, ir√° converter texto em fala para fornecer feedback falado.

## Texto para fala

O SDK dos servi√ßos de fala que utilizou na √∫ltima li√ß√£o para converter fala em texto pode ser usado para converter texto de volta em fala.

## Obter uma lista de vozes

Ao solicitar fala, √© necess√°rio fornecer a voz a ser usada, pois a fala pode ser gerada utilizando uma variedade de vozes diferentes. Cada idioma suporta uma gama de vozes distintas, e pode obter a lista de vozes suportadas para cada idioma a partir do SDK dos servi√ßos de fala. Aqui entram as limita√ß√µes dos microcontroladores - a chamada para obter a lista de vozes suportadas pelos servi√ßos de texto para fala √© um documento JSON com mais de 77KB de tamanho, demasiado grande para ser processado pelo Wio Terminal. No momento da escrita, a lista completa cont√©m 215 vozes, cada uma definida por um documento JSON como o seguinte:

```json
{
    "Name": "Microsoft Server Speech Text to Speech Voice (en-US, AriaNeural)",
    "DisplayName": "Aria",
    "LocalName": "Aria",
    "ShortName": "en-US-AriaNeural",
    "Gender": "Female",
    "Locale": "en-US",
    "StyleList": [
        "chat",
        "customerservice",
        "narration-professional",
        "newscast-casual",
        "newscast-formal",
        "cheerful",
        "empathetic"
    ],
    "SampleRateHertz": "24000",
    "VoiceType": "Neural",
    "Status": "GA"
}
```

Este JSON √© para a voz **Aria**, que tem v√°rios estilos de voz. Tudo o que √© necess√°rio ao converter texto em fala √© o nome curto, `en-US-AriaNeural`.

Em vez de descarregar e decodificar esta lista inteira no seu microcontrolador, precisar√° escrever algum c√≥digo sem servidor para recuperar a lista de vozes para o idioma que est√° a usar e chamar isto a partir do seu Wio Terminal. O seu c√≥digo pode ent√£o escolher uma voz apropriada da lista, como a primeira que encontrar.

### Tarefa - criar uma fun√ß√£o sem servidor para obter uma lista de vozes

1. Abra o seu projeto `smart-timer-trigger` no VS Code e abra o terminal, garantindo que o ambiente virtual est√° ativado. Caso contr√°rio, encerre e recrie o terminal.

1. Abra o ficheiro `local.settings.json` e adicione configura√ß√µes para a chave da API de fala e localiza√ß√£o:

    ```json
    "SPEECH_KEY": "<key>",
    "SPEECH_LOCATION": "<location>"
    ```

    Substitua `<key>` pela chave da API do recurso de servi√ßo de fala. Substitua `<location>` pela localiza√ß√£o que utilizou ao criar o recurso de servi√ßo de fala.

1. Adicione um novo trigger HTTP a esta aplica√ß√£o chamado `get-voices` usando o seguinte comando dentro do terminal do VS Code na pasta raiz do projeto da aplica√ß√£o de fun√ß√µes:

    ```sh
    func new --name get-voices --template "HTTP trigger"
    ```

    Isto criar√° um trigger HTTP chamado `get-voices`.

1. Substitua o conte√∫do do ficheiro `__init__.py` na pasta `get-voices` pelo seguinte:

    ```python
    import json
    import os
    import requests
    
    import azure.functions as func
    
    def main(req: func.HttpRequest) -> func.HttpResponse:
        location = os.environ['SPEECH_LOCATION']
        speech_key = os.environ['SPEECH_KEY']
    
        req_body = req.get_json()
        language = req_body['language']
    
        url = f'https://{location}.tts.speech.microsoft.com/cognitiveservices/voices/list'
    
        headers = {
            'Ocp-Apim-Subscription-Key': speech_key
        }
    
        response = requests.get(url, headers=headers)
        voices_json = json.loads(response.text)
    
        voices = filter(lambda x: x['Locale'].lower() == language.lower(), voices_json)
        voices = map(lambda x: x['ShortName'], voices)
    
        return func.HttpResponse(json.dumps(list(voices)), status_code=200)
    ```

    Este c√≥digo faz uma solicita√ß√£o HTTP ao endpoint para obter as vozes. Esta lista de vozes √© um grande bloco de JSON com vozes para todos os idiomas, ent√£o as vozes para o idioma passado no corpo da solicita√ß√£o s√£o filtradas, e o nome curto √© extra√≠do e retornado como uma lista JSON. O nome curto √© o valor necess√°rio para converter texto em fala, ent√£o apenas este valor √© retornado.

    > üíÅ Pode alterar o filtro conforme necess√°rio para selecionar apenas as vozes que deseja.

    Isto reduz o tamanho dos dados de 77KB (no momento da escrita) para um documento JSON muito menor. Por exemplo, para vozes dos EUA, isto √© 408 bytes.

1. Execute a sua aplica√ß√£o de fun√ß√µes localmente. Pode ent√£o cham√°-la usando uma ferramenta como curl da mesma forma que testou o trigger HTTP `text-to-timer`. Certifique-se de passar o seu idioma como um corpo JSON:

    ```json
    {
        "language":"<language>"
    }
    ```

    Substitua `<language>` pelo seu idioma, como `en-GB` ou `zh-CN`.

> üíÅ Pode encontrar este c√≥digo na pasta [code-spoken-response/functions](../../../../../6-consumer/lessons/3-spoken-feedback/code-spoken-response/functions).

### Tarefa - recuperar a voz do seu Wio Terminal

1. Abra o projeto `smart-timer` no VS Code, caso ainda n√£o esteja aberto.

1. Abra o ficheiro de cabe√ßalho `config.h` e adicione o URL para a sua aplica√ß√£o de fun√ß√µes:

    ```cpp
    const char *GET_VOICES_FUNCTION_URL = "<URL>";
    ```

    Substitua `<URL>` pelo URL do trigger HTTP `get-voices` na sua aplica√ß√£o de fun√ß√µes. Este ser√° o mesmo valor de `TEXT_TO_TIMER_FUNCTION_URL`, exceto com um nome de fun√ß√£o `get-voices` em vez de `text-to-timer`.

1. Crie um novo ficheiro na pasta `src` chamado `text_to_speech.h`. Este ser√° usado para definir uma classe para converter de texto para fala.

1. Adicione as seguintes diretivas de inclus√£o ao topo do novo ficheiro `text_to_speech.h`:

    ```cpp
    #pragma once

    #include <Arduino.h>
    #include <ArduinoJson.h>
    #include <HTTPClient.h>
    #include <Seeed_FS.h>
    #include <SD/Seeed_SD.h>
    #include <WiFiClient.h>
    #include <WiFiClientSecure.h>
    
    #include "config.h"
    #include "speech_to_text.h"
    ```

1. Adicione o seguinte c√≥digo abaixo para declarar a classe `TextToSpeech`, juntamente com uma inst√¢ncia que pode ser usada no resto da aplica√ß√£o:

    ```cpp
    class TextToSpeech
    {
    public:
    private:
    };
    
    TextToSpeech textToSpeech;
    ```

1. Para chamar a sua aplica√ß√£o de fun√ß√µes, precisa declarar um cliente WiFi. Adicione o seguinte √† se√ß√£o `private` da classe:

    ```cpp
    WiFiClient _client;
    ```

1. Na se√ß√£o `private`, adicione um campo para a voz selecionada:

    ```cpp
    String _voice;
    ```

1. Na se√ß√£o `public`, adicione uma fun√ß√£o `init` que ir√° obter a primeira voz:

    ```cpp
    void init()
    {
    }
    ```

1. Para obter as vozes, um documento JSON precisa ser enviado √† aplica√ß√£o de fun√ß√µes com o idioma. Adicione o seguinte c√≥digo √† fun√ß√£o `init` para criar este documento JSON:

    ```cpp
    DynamicJsonDocument doc(1024);
    doc["language"] = LANGUAGE;

    String body;
    serializeJson(doc, body);
    ```

1. Em seguida, crie um `HTTPClient` e use-o para chamar a aplica√ß√£o de fun√ß√µes para obter as vozes, enviando o documento JSON:

    ```cpp
    HTTPClient httpClient;
    httpClient.begin(_client, GET_VOICES_FUNCTION_URL);

    int httpResponseCode = httpClient.POST(body);
    ```

1. Abaixo disso, adicione c√≥digo para verificar o c√≥digo de resposta e, se for 200 (sucesso), ent√£o extraia a lista de vozes, recuperando a primeira da lista:

    ```cpp
    if (httpResponseCode == 200)
    {
        String result = httpClient.getString();
        Serial.println(result);

        DynamicJsonDocument doc(1024);
        deserializeJson(doc, result.c_str());

        JsonArray obj = doc.as<JsonArray>();
        _voice = obj[0].as<String>();

        Serial.print("Using voice ");
        Serial.println(_voice);
    }
    else
    {
        Serial.print("Failed to get voices - error ");
        Serial.println(httpResponseCode);
    }
    ```

1. Ap√≥s isso, encerre a conex√£o do cliente HTTP:

    ```cpp
    httpClient.end();
    ```

1. Abra o ficheiro `main.cpp` e adicione a seguinte diretiva de inclus√£o no topo para incluir este novo ficheiro de cabe√ßalho:

    ```cpp
    #include "text_to_speech.h"
    ```

1. Na fun√ß√£o `setup`, abaixo da chamada para `speechToText.init();`, adicione o seguinte para inicializar a classe `TextToSpeech`:

    ```cpp
    textToSpeech.init();
    ```

1. Compile este c√≥digo, carregue-o no seu Wio Terminal e teste-o atrav√©s do monitor serial. Certifique-se de que a sua aplica√ß√£o de fun√ß√µes est√° em execu√ß√£o.

    Ver√° a lista de vozes dispon√≠veis retornada pela aplica√ß√£o de fun√ß√µes, juntamente com a voz selecionada.

    ```output
    --- Available filters and text transformations: colorize, debug, default, direct, hexlify, log2file, nocontrol, printable, send_on_enter, time
    --- More details at http://bit.ly/pio-monitor-filters
    --- Miniterm on /dev/cu.usbmodem1101  9600,8,N,1 ---
    --- Quit: Ctrl+C | Menu: Ctrl+T | Help: Ctrl+T followed by Ctrl+H ---
    Connecting to WiFi..
    Connected!
    Got access token.
    ["en-US-JennyNeural", "en-US-JennyMultilingualNeural", "en-US-GuyNeural", "en-US-AriaNeural", "en-US-AmberNeural", "en-US-AnaNeural", "en-US-AshleyNeural", "en-US-BrandonNeural", "en-US-ChristopherNeural", "en-US-CoraNeural", "en-US-ElizabethNeural", "en-US-EricNeural", "en-US-JacobNeural", "en-US-MichelleNeural", "en-US-MonicaNeural", "en-US-AriaRUS", "en-US-BenjaminRUS", "en-US-GuyRUS", "en-US-ZiraRUS"]
    Using voice en-US-JennyNeural
    Ready.
    ```

## Converter texto em fala

Depois de ter uma voz para usar, ela pode ser usada para converter texto em fala. As mesmas limita√ß√µes de mem√≥ria com vozes tamb√©m se aplicam ao converter texto em fala, ent√£o precisar√° gravar a fala num cart√£o SD pronto para ser reproduzido atrav√©s do ReSpeaker.

> üíÅ Em li√ß√µes anteriores deste projeto, utilizou mem√≥ria flash para armazenar fala capturada do microfone. Esta li√ß√£o utiliza um cart√£o SD, pois √© mais f√°cil reproduzir √°udio a partir dele usando as bibliotecas de √°udio da Seeed.

H√° tamb√©m outra limita√ß√£o a considerar, os dados de √°udio dispon√≠veis do servi√ßo de fala e os formatos que o Wio Terminal suporta. Ao contr√°rio de computadores completos, as bibliotecas de √°udio para microcontroladores podem ser muito limitadas nos formatos de √°udio que suportam. Por exemplo, a biblioteca Seeed Arduino Audio que pode reproduzir som atrav√©s do ReSpeaker s√≥ suporta √°udio com uma taxa de amostragem de 44.1KHz. Os servi√ßos de fala da Azure podem fornecer √°udio em v√°rios formatos, mas nenhum deles utiliza esta taxa de amostragem, fornecendo apenas 8KHz, 16KHz, 24KHz e 48KHz. Isto significa que o √°udio precisa ser reamostrado para 44.1KHz, algo que exigiria mais recursos do que o Wio Terminal possui, especialmente mem√≥ria.

Quando √© necess√°rio manipular dados como este, √© frequentemente melhor usar c√≥digo sem servidor, especialmente se os dados forem obtidos atrav√©s de uma chamada web. O Wio Terminal pode chamar uma fun√ß√£o sem servidor, passando o texto a ser convertido, e a fun√ß√£o sem servidor pode tanto chamar o servi√ßo de fala para converter texto em fala, como tamb√©m reamostrar o √°udio para a taxa de amostragem necess√°ria. Pode ent√£o retornar o √°udio no formato que o Wio Terminal precisa para ser armazenado no cart√£o SD e reproduzido atrav√©s do ReSpeaker.

### Tarefa - criar uma fun√ß√£o sem servidor para converter texto em fala

1. Abra o seu projeto `smart-timer-trigger` no VS Code e abra o terminal, garantindo que o ambiente virtual est√° ativado. Caso contr√°rio, encerre e recrie o terminal.

1. Adicione um novo trigger HTTP a esta aplica√ß√£o chamado `text-to-speech` usando o seguinte comando dentro do terminal do VS Code na pasta raiz do projeto da aplica√ß√£o de fun√ß√µes:

    ```sh
    func new --name text-to-speech --template "HTTP trigger"
    ```

    Isto criar√° um trigger HTTP chamado `text-to-speech`.

1. O pacote Pip [librosa](https://librosa.org) tem fun√ß√µes para reamostrar √°udio, ent√£o adicione-o ao ficheiro `requirements.txt`:

    ```sh
    librosa
    ```

    Depois de adicionar isto, instale os pacotes Pip usando o seguinte comando no terminal do VS Code:

    ```sh
    pip install -r requirements.txt
    ```

    > ‚ö†Ô∏è Se estiver a usar Linux, incluindo Raspberry Pi OS, pode precisar instalar `libsndfile` com o seguinte comando:
    >
    > ```sh
    > sudo apt update
    > sudo apt install libsndfile1-dev
    > ```

1. Para converter texto em fala, n√£o pode usar diretamente a chave da API de fala, em vez disso, precisa solicitar um token de acesso, usando a chave da API para autenticar a solicita√ß√£o do token de acesso. Abra o ficheiro `__init__.py` da pasta `text-to-speech` e substitua todo o c√≥digo nele pelo seguinte:

    ```python
    import io
    import os
    import requests
    
    import librosa
    import soundfile as sf
    import azure.functions as func
    
    location = os.environ['SPEECH_LOCATION']
    speech_key = os.environ['SPEECH_KEY']
    
    def get_access_token():
        headers = {
            'Ocp-Apim-Subscription-Key': speech_key
        }
    
        token_endpoint = f'https://{location}.api.cognitive.microsoft.com/sts/v1.0/issuetoken'
        response = requests.post(token_endpoint, headers=headers)
        return str(response.text)
    ```

    Isto define constantes para a localiza√ß√£o e chave de fala que ser√£o lidas das configura√ß√µes. Em seguida, define a fun√ß√£o `get_access_token` que ir√° recuperar um token de acesso para o servi√ßo de fala.

1. Abaixo deste c√≥digo, adicione o seguinte:

    ```python
    playback_format = 'riff-48khz-16bit-mono-pcm'

    def main(req: func.HttpRequest) -> func.HttpResponse:
        req_body = req.get_json()
        language = req_body['language']
        voice = req_body['voice']
        text = req_body['text']
    
        url = f'https://{location}.tts.speech.microsoft.com/cognitiveservices/v1'
    
        headers = {
            'Authorization': 'Bearer ' + get_access_token(),
            'Content-Type': 'application/ssml+xml',
            'X-Microsoft-OutputFormat': playback_format
        }
    
        ssml =  f'<speak version=\'1.0\' xml:lang=\'{language}\'>'
        ssml += f'<voice xml:lang=\'{language}\' name=\'{voice}\'>'
        ssml += text
        ssml += '</voice>'
        ssml += '</speak>'
    
        response = requests.post(url, headers=headers, data=ssml.encode('utf-8'))
    
        raw_audio, sample_rate = librosa.load(io.BytesIO(response.content), sr=48000)
        resampled = librosa.resample(raw_audio, sample_rate, 44100)
        
        output_buffer = io.BytesIO()
        sf.write(output_buffer, resampled, 44100, 'PCM_16', format='wav')
        output_buffer.seek(0)
    
        return func.HttpResponse(output_buffer.read(), status_code=200)
    ```

    Isto define o trigger HTTP que converte o texto em fala. Extrai o texto a ser convertido, o idioma e a voz do corpo JSON enviado na solicita√ß√£o, constr√≥i algum SSML para solicitar a fala, e ent√£o chama a API REST relevante autenticando usando o token de acesso. Esta chamada √† API REST retorna o √°udio codificado como um ficheiro WAV mono de 16 bits e 48KHz, definido pelo valor de `playback_format`, que √© enviado na chamada √† API REST.

    Isto √© ent√£o reamostrado por `librosa` de uma taxa de amostragem de 48KHz para uma taxa de amostragem de 44.1KHz, e este √°udio √© guardado num buffer bin√°rio que √© ent√£o retornado.

1. Execute a sua aplica√ß√£o de fun√ß√µes localmente ou implemente-a na nuvem. Pode ent√£o cham√°-la usando uma ferramenta como curl da mesma forma que testou o trigger HTTP `text-to-timer`. Certifique-se de passar o idioma, voz e texto como corpo JSON:

    ```json
    {
        "language": "<language>",
        "voice": "<voice>",
        "text": "<text>"
    }
    ```

    Substitua `<language>` pelo seu idioma, como `en-GB` ou `zh-CN`. Substitua `<voice>` pela voz que deseja usar. Substitua `<text>` pelo texto que deseja converter em fala. Pode guardar o resultado num ficheiro e reproduzi-lo com qualquer leitor de √°udio que suporte ficheiros WAV.

    Por exemplo, para converter "Hello" em fala usando ingl√™s dos EUA com a voz Jenny Neural, com a aplica√ß√£o de fun√ß√µes a ser executada localmente, pode usar o seguinte comando curl:

    ```sh
    curl -X GET 'http://localhost:7071/api/text-to-speech' \
         -H 'Content-Type: application/json' \
         -o hello.wav \
         -d '{
           "language":"en-US",
           "voice": "en-US-JennyNeural",
           "text": "Hello"
         }'
    ```

    Isto ir√° guardar o √°udio em `hello.wav` no diret√≥rio atual.

> üíÅ Pode encontrar este c√≥digo na pasta [code-spoken-response/functions](../../../../../6-consumer/lessons/3-spoken-feedback/code-spoken-response/functions).

### Tarefa - recuperar a fala do seu Wio Terminal

1. Abra o projeto `smart-timer` no VS Code, caso ainda n√£o esteja aberto.

1. Abra o ficheiro de cabe√ßalho `config.h` e adicione o URL para a sua aplica√ß√£o de fun√ß√µes:

    ```cpp
    const char *TEXT_TO_SPEECH_FUNCTION_URL = "<URL>";
    ```

    Substitua `<URL>` pelo URL do trigger HTTP `text-to-speech` na sua aplica√ß√£o de fun√ß√µes. Este ser√° o mesmo valor de `TEXT_TO_TIMER_FUNCTION_URL`, exceto com um nome de fun√ß√£o `text-to-speech` em vez de `text-to-timer`.

1. Abra o ficheiro de cabe√ßalho `text_to_speech.h` e adicione o seguinte m√©todo √† se√ß√£o `public` da classe `TextToSpeech`:

    ```cpp
    void convertTextToSpeech(String text)
    {
    }
    ```

1. Ao m√©todo `convertTextToSpeech`, adicione o seguinte c√≥digo para criar o JSON a ser enviado √† aplica√ß√£o de fun√ß√µes:

    ```cpp
    DynamicJsonDocument doc(1024);
    doc["language"] = LANGUAGE;
    doc["voice"] = _voice;
    doc["text"] = text;

    String body;
    serializeJson(doc, body);
    ```

    Isto escreve o idioma, voz e texto no documento JSON e, em seguida, serializa-o para uma string.

1. Abaixo disso, adicione o seguinte c√≥digo para chamar a aplica√ß√£o de fun√ß√µes:

    ```cpp
    HTTPClient httpClient;
    httpClient.begin(_client, TEXT_TO_SPEECH_FUNCTION_URL);

    int httpResponseCode = httpClient.POST(body);
    ```

    Isto cria um `HTTPClient` e faz uma solicita√ß√£o POST usando o documento JSON ao trigger HTTP de texto para fala.

1. Se a chamada funcionar, os dados bin√°rios brutos retornados pela chamada √† aplica√ß√£o de fun√ß√µes podem ser transmitidos para um ficheiro no cart√£o SD. Adicione o seguinte c√≥digo para fazer isso:

    ```cpp
    if (httpResponseCode == 200)
    {            
        File wav_file = SD.open("SPEECH.WAV", FILE_WRITE);
        httpClient.writeToStream(&wav_file);
        wav_file.close();
    }
    else
    {
        Serial.print("Failed to get speech - error ");
        Serial.println(httpResponseCode);
    }
    ```

    Este c√≥digo verifica a resposta e, se for 200 (sucesso), os dados bin√°rios s√£o transmitidos para um ficheiro na raiz do cart√£o SD chamado `SPEECH.WAV`.

1. No final deste m√©todo, feche a conex√£o HTTP:

    ```cpp
    httpClient.end();
    ```

1. O texto a ser falado pode agora ser convertido em √°udio. No ficheiro `main.cpp`, adicione a seguinte linha ao final da fun√ß√£o `say` para converter o texto a ser dito em √°udio:
### Tarefa - reproduzir √°udio no seu Wio Terminal

**Em breve**

## Implantar a sua aplica√ß√£o de fun√ß√µes na nuvem

O motivo para executar a aplica√ß√£o de fun√ß√µes localmente √© que o pacote `librosa` do Pip no Linux tem uma depend√™ncia de uma biblioteca que n√£o est√° instalada por padr√£o e precisar√° ser instalada antes que a aplica√ß√£o de fun√ß√µes possa ser executada. Aplica√ß√µes de fun√ß√µes s√£o sem servidor - n√£o h√° servidores que voc√™ possa gerenciar diretamente, ent√£o n√£o h√° como instalar essa biblioteca antecipadamente.

A maneira de resolver isso √© implantar a sua aplica√ß√£o de fun√ß√µes usando um cont√™iner Docker. Este cont√™iner √© implantado pela nuvem sempre que √© necess√°rio iniciar uma nova inst√¢ncia da sua aplica√ß√£o de fun√ß√µes (como quando a demanda excede os recursos dispon√≠veis ou se a aplica√ß√£o de fun√ß√µes n√£o foi usada por um tempo e foi encerrada).

Voc√™ pode encontrar as instru√ß√µes para configurar uma aplica√ß√£o de fun√ß√µes e implant√°-la via Docker na [documenta√ß√£o sobre criar uma fun√ß√£o no Linux usando uma imagem personalizada no Microsoft Docs](https://docs.microsoft.com/azure/azure-functions/functions-create-function-linux-custom-image?WT.mc_id=academic-17441-jabenn&tabs=bash%2Cazurecli&pivots=programming-language-python).

Depois de implantada, voc√™ pode adaptar o c√≥digo do seu Wio Terminal para acessar essa fun√ß√£o:

1. Adicione o certificado do Azure Functions ao `config.h`:

    ```cpp
    const char *FUNCTIONS_CERTIFICATE =
        "-----BEGIN CERTIFICATE-----\r\n"
        "MIIFWjCCBEKgAwIBAgIQDxSWXyAgaZlP1ceseIlB4jANBgkqhkiG9w0BAQsFADBa\r\n"
        "MQswCQYDVQQGEwJJRTESMBAGA1UEChMJQmFsdGltb3JlMRMwEQYDVQQLEwpDeWJl\r\n"
        "clRydXN0MSIwIAYDVQQDExlCYWx0aW1vcmUgQ3liZXJUcnVzdCBSb290MB4XDTIw\r\n"
        "MDcyMTIzMDAwMFoXDTI0MTAwODA3MDAwMFowTzELMAkGA1UEBhMCVVMxHjAcBgNV\r\n"
        "BAoTFU1pY3Jvc29mdCBDb3Jwb3JhdGlvbjEgMB4GA1UEAxMXTWljcm9zb2Z0IFJT\r\n"
        "QSBUTFMgQ0EgMDEwggIiMA0GCSqGSIb3DQEBAQUAA4ICDwAwggIKAoICAQCqYnfP\r\n"
        "mmOyBoTzkDb0mfMUUavqlQo7Rgb9EUEf/lsGWMk4bgj8T0RIzTqk970eouKVuL5R\r\n"
        "IMW/snBjXXgMQ8ApzWRJCZbar879BV8rKpHoAW4uGJssnNABf2n17j9TiFy6BWy+\r\n"
        "IhVnFILyLNK+W2M3zK9gheiWa2uACKhuvgCca5Vw/OQYErEdG7LBEzFnMzTmJcli\r\n"
        "W1iCdXby/vI/OxbfqkKD4zJtm45DJvC9Dh+hpzqvLMiK5uo/+aXSJY+SqhoIEpz+\r\n"
        "rErHw+uAlKuHFtEjSeeku8eR3+Z5ND9BSqc6JtLqb0bjOHPm5dSRrgt4nnil75bj\r\n"
        "c9j3lWXpBb9PXP9Sp/nPCK+nTQmZwHGjUnqlO9ebAVQD47ZisFonnDAmjrZNVqEX\r\n"
        "F3p7laEHrFMxttYuD81BdOzxAbL9Rb/8MeFGQjE2Qx65qgVfhH+RsYuuD9dUw/3w\r\n"
        "ZAhq05yO6nk07AM9c+AbNtRoEcdZcLCHfMDcbkXKNs5DJncCqXAN6LhXVERCw/us\r\n"
        "G2MmCMLSIx9/kwt8bwhUmitOXc6fpT7SmFvRAtvxg84wUkg4Y/Gx++0j0z6StSeN\r\n"
        "0EJz150jaHG6WV4HUqaWTb98Tm90IgXAU4AW2GBOlzFPiU5IY9jt+eXC2Q6yC/Zp\r\n"
        "TL1LAcnL3Qa/OgLrHN0wiw1KFGD51WRPQ0Sh7QIDAQABo4IBJTCCASEwHQYDVR0O\r\n"
        "BBYEFLV2DDARzseSQk1Mx1wsyKkM6AtkMB8GA1UdIwQYMBaAFOWdWTCCR1jMrPoI\r\n"
        "VDaGezq1BE3wMA4GA1UdDwEB/wQEAwIBhjAdBgNVHSUEFjAUBggrBgEFBQcDAQYI\r\n"
        "KwYBBQUHAwIwEgYDVR0TAQH/BAgwBgEB/wIBADA0BggrBgEFBQcBAQQoMCYwJAYI\r\n"
        "KwYBBQUHMAGGGGh0dHA6Ly9vY3NwLmRpZ2ljZXJ0LmNvbTA6BgNVHR8EMzAxMC+g\r\n"
        "LaArhilodHRwOi8vY3JsMy5kaWdpY2VydC5jb20vT21uaXJvb3QyMDI1LmNybDAq\r\n"
        "BgNVHSAEIzAhMAgGBmeBDAECATAIBgZngQwBAgIwCwYJKwYBBAGCNyoBMA0GCSqG\r\n"
        "SIb3DQEBCwUAA4IBAQCfK76SZ1vae4qt6P+dTQUO7bYNFUHR5hXcA2D59CJWnEj5\r\n"
        "na7aKzyowKvQupW4yMH9fGNxtsh6iJswRqOOfZYC4/giBO/gNsBvwr8uDW7t1nYo\r\n"
        "DYGHPpvnpxCM2mYfQFHq576/TmeYu1RZY29C4w8xYBlkAA8mDJfRhMCmehk7cN5F\r\n"
        "JtyWRj2cZj/hOoI45TYDBChXpOlLZKIYiG1giY16vhCRi6zmPzEwv+tk156N6cGS\r\n"
        "Vm44jTQ/rs1sa0JSYjzUaYngoFdZC4OfxnIkQvUIA4TOFmPzNPEFdjcZsgbeEz4T\r\n"
        "cGHTBPK4R28F44qIMCtHRV55VMX53ev6P3hRddJb\r\n"
        "-----END CERTIFICATE-----\r\n";
    ```

1. Altere todas as inclus√µes de `<WiFiClient.h>` para `<WiFiClientSecure.h>`.

1. Substitua todos os campos `WiFiClient` por `WiFiClientSecure`.

1. Em cada classe que tenha um campo `WiFiClientSecure`, adicione um construtor e configure o certificado nesse construtor:

    ```cpp
    _client.setCACert(FUNCTIONS_CERTIFICATE);
    ```

**Aviso Legal**:  
Este documento foi traduzido utilizando o servi√ßo de tradu√ß√£o por IA [Co-op Translator](https://github.com/Azure/co-op-translator). Embora nos esforcemos pela precis√£o, esteja ciente de que tradu√ß√µes autom√°ticas podem conter erros ou imprecis√µes. O documento original na sua l√≠ngua nativa deve ser considerado a fonte autorit√°ria. Para informa√ß√µes cr√≠ticas, recomenda-se a tradu√ß√£o profissional realizada por humanos. N√£o nos responsabilizamos por quaisquer mal-entendidos ou interpreta√ß√µes incorretas decorrentes do uso desta tradu√ß√£o.