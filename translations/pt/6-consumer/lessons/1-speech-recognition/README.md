<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "6d6aa1be033625d201a190fc9c5cbfb4",
  "translation_date": "2025-08-25T22:41:44+00:00",
  "source_file": "6-consumer/lessons/1-speech-recognition/README.md",
  "language_code": "pt"
}
-->
# Reconhecer fala com um dispositivo IoT

![Uma vis√£o geral ilustrada desta li√ß√£o](../../../../../translated_images/lesson-21.e34de51354d6606fb5ee08d8c89d0222eea0a2a7aaf744a8805ae847c4f69dc4.pt.jpg)

> Ilustra√ß√£o por [Nitya Narasimhan](https://github.com/nitya). Clique na imagem para uma vers√£o maior.

Este v√≠deo oferece uma vis√£o geral do servi√ßo de fala do Azure, um t√≥pico que ser√° abordado nesta li√ß√£o:

[![Como come√ßar a usar seu recurso de Fala dos Servi√ßos Cognitivos do canal do YouTube da Microsoft Azure](https://img.youtube.com/vi/iW0Fw0l3mrA/0.jpg)](https://www.youtube.com/watch?v=iW0Fw0l3mrA)

> üé• Clique na imagem acima para assistir ao v√≠deo

## Question√°rio pr√©-aula

[Question√°rio pr√©-aula](https://black-meadow-040d15503.1.azurestaticapps.net/quiz/41)

## Introdu√ß√£o

'Alexa, define um temporizador de 12 minutos'

'Alexa, qual o status do temporizador?'

'Alexa, define um temporizador de 8 minutos chamado cozer br√≥colos a vapor'

Os dispositivos inteligentes est√£o a tornar-se cada vez mais comuns. N√£o apenas como colunas inteligentes como HomePods, Echos e Google Homes, mas tamb√©m integrados nos nossos telem√≥veis, rel√≥gios, e at√© em lumin√°rias e termostatos.

> üíÅ Tenho pelo menos 19 dispositivos na minha casa com assistentes de voz, e isso s√£o apenas os que conhe√ßo!

O controlo por voz aumenta a acessibilidade, permitindo que pessoas com mobilidade limitada interajam com dispositivos. Seja uma defici√™ncia permanente, como nascer sem bra√ßos, ou uma defici√™ncia tempor√°ria, como bra√ßos partidos, ou at√© mesmo ter as m√£os ocupadas com compras ou crian√ßas pequenas, poder controlar a nossa casa com a voz em vez das m√£os abre um mundo de possibilidades. Gritar 'Hey Siri, fecha a porta da garagem' enquanto lida com uma troca de fralda e uma crian√ßa irrequieta pode ser uma pequena, mas eficaz, melhoria na vida.

Um dos usos mais populares para assistentes de voz √© definir temporizadores, especialmente na cozinha. Poder definir m√∫ltiplos temporizadores apenas com a voz √© uma grande ajuda - n√£o √© necess√°rio parar de amassar massa, mexer sopa ou limpar as m√£os sujas de recheio de bolinhos para usar um temporizador f√≠sico.

Nesta li√ß√£o, aprender√° a integrar reconhecimento de voz em dispositivos IoT. Aprender√° sobre microfones como sensores, como capturar √°udio de um microfone ligado a um dispositivo IoT e como usar IA para converter o que √© ouvido em texto. Ao longo deste projeto, construir√° um temporizador de cozinha inteligente, capaz de definir temporizadores usando a sua voz em v√°rios idiomas.

Nesta li√ß√£o, abordaremos:

* [Microfones](../../../../../6-consumer/lessons/1-speech-recognition)
* [Capturar √°udio do seu dispositivo IoT](../../../../../6-consumer/lessons/1-speech-recognition)
* [Fala para texto](../../../../../6-consumer/lessons/1-speech-recognition)
* [Converter fala em texto](../../../../../6-consumer/lessons/1-speech-recognition)

## Microfones

Os microfones s√£o sensores anal√≥gicos que convertem ondas sonoras em sinais el√©tricos. Vibra√ß√µes no ar fazem com que componentes no microfone se movam ligeiramente, causando pequenas altera√ß√µes nos sinais el√©tricos. Estas altera√ß√µes s√£o ent√£o amplificadas para gerar uma sa√≠da el√©trica.

### Tipos de microfones

Os microfones existem em v√°rios tipos:

* Din√¢mico - Microfones din√¢micos t√™m um √≠man ligado a um diafragma m√≥vel que se move numa bobina de fio, criando uma corrente el√©trica. Isto √© o oposto da maioria das colunas, que usam uma corrente el√©trica para mover um √≠man numa bobina de fio, movendo um diafragma para criar som. Isso significa que colunas podem ser usadas como microfones din√¢micos, e microfones din√¢micos podem ser usados como colunas. Em dispositivos como interfones, onde o utilizador est√° a ouvir ou a falar, mas n√£o ambos ao mesmo tempo, um √∫nico dispositivo pode atuar como coluna e microfone.

    Microfones din√¢micos n√£o precisam de energia para funcionar, o sinal el√©trico √© criado inteiramente pelo microfone.

    ![Patti Smith a cantar num microfone Shure SM58 (tipo cardioide din√¢mico)](../../../../../translated_images/dynamic-mic.8babac890a2d80dfb0874b5bf37d4b851fe2aeb9da6fd72945746176978bf3bb.pt.jpg)

* Fita - Microfones de fita s√£o semelhantes aos din√¢micos, exceto que t√™m uma fita met√°lica em vez de um diafragma. Esta fita move-se num campo magn√©tico, gerando uma corrente el√©trica. Tal como os microfones din√¢micos, os de fita n√£o precisam de energia para funcionar.

    ![Edmund Lowe, ator americano, em p√© junto a um microfone de r√°dio (etiquetado para a rede azul da NBC), segurando um gui√£o, 1942](../../../../../translated_images/ribbon-mic.eacc8e092c7441caee6d7a81e2f40e1675bf36269848964c7c09c9a9acb05127.pt.jpg)

* Condensador - Microfones de condensador t√™m um diafragma met√°lico fino e uma placa met√°lica fixa. A eletricidade √© aplicada a ambos e, √† medida que o diafragma vibra, a carga est√°tica entre as placas muda, gerando um sinal. Microfones de condensador precisam de energia para funcionar - chamada de *Phantom power*.

    ![Microfone de condensador de pequeno diafragma C451B da AKG Acoustics](../../../../../translated_images/condenser-mic.6f6ed5b76ca19e0ec3fd0c544601542d4479a6cb7565db336de49fbbf69f623e.pt.jpg)

* MEMS - Microfones de sistemas microeletromec√¢nicos, ou MEMS, s√£o microfones num chip. Eles t√™m um diafragma sens√≠vel √† press√£o gravado num chip de sil√≠cio e funcionam de forma semelhante a um microfone de condensador. Estes microfones podem ser min√∫sculos e integrados em circuitos.

    ![Um microfone MEMS numa placa de circuito](../../../../../translated_images/mems-microphone.80574019e1f5e4d9ee72fed720ecd25a39fc2969c91355d17ebb24ba4159e4c4.pt.png)

    Na imagem acima, o chip etiquetado como **LEFT** √© um microfone MEMS, com um diafragma min√∫sculo com menos de um mil√≠metro de largura.

‚úÖ Fa√ßa uma pesquisa: Que microfones tem √† sua volta - seja no seu computador, telem√≥vel, auscultadores ou noutros dispositivos? Que tipo de microfones s√£o?

### √Åudio digital

O √°udio √© um sinal anal√≥gico que transporta informa√ß√µes muito detalhadas. Para converter este sinal em digital, o √°udio precisa de ser amostrado milhares de vezes por segundo.

> üéì Amostragem √© o processo de converter o sinal de √°udio num valor digital que representa o sinal naquele momento espec√≠fico.

![Um gr√°fico de linha mostrando um sinal, com pontos discretos em intervalos fixos](../../../../../translated_images/sampling.6f4fadb3f2d9dfe7618f9edfe75a350e6b3f74293ec84f02ab69c19d2afe3d73.pt.png)

O √°udio digital √© amostrado usando Modula√ß√£o por C√≥digo de Pulso, ou PCM. O PCM envolve a leitura da voltagem do sinal e a sele√ß√£o do valor discreto mais pr√≥ximo dessa voltagem usando um tamanho definido.

> üíÅ Pode pensar no PCM como a vers√£o de sensor da modula√ß√£o por largura de pulso, ou PWM (PWM foi abordado na [li√ß√£o 3 do projeto introdut√≥rio](../../../1-getting-started/lessons/3-sensors-and-actuators/README.md#pulse-width-modulation)). O PCM envolve converter um sinal anal√≥gico em digital, enquanto o PWM converte um sinal digital em anal√≥gico.

Por exemplo, a maioria dos servi√ßos de streaming de m√∫sica oferece √°udio de 16 bits ou 24 bits. Isso significa que convertem a voltagem num valor que cabe num n√∫mero inteiro de 16 bits ou 24 bits. O √°udio de 16 bits ajusta o valor num intervalo de -32.768 a 32.767, enquanto o de 24 bits est√° no intervalo de -8.388.608 a 8.388.607. Quanto mais bits, mais pr√≥ximo o som amostrado estar√° do que os nossos ouvidos realmente ouvem.

> üíÅ Talvez j√° tenha ouvido falar de √°udio de 8 bits, frequentemente referido como LoFi. Este √© o √°udio amostrado usando apenas 8 bits, ou seja, -128 a 127. O √°udio dos primeiros computadores era limitado a 8 bits devido a restri√ß√µes de hardware, sendo frequentemente associado a jogos retro.

Estas amostras s√£o feitas milhares de vezes por segundo, usando taxas de amostragem bem definidas, medidas em KHz (milhares de leituras por segundo). Os servi√ßos de streaming de m√∫sica usam 48KHz para a maioria dos √°udios, mas alguns √°udios 'sem perdas' usam at√© 96KHz ou mesmo 192KHz. Quanto maior a taxa de amostragem, mais pr√≥ximo o √°udio estar√° do original, at√© certo ponto. H√° debate sobre se os humanos conseguem perceber a diferen√ßa acima de 48KHz.

‚úÖ Fa√ßa uma pesquisa: Se usa um servi√ßo de streaming de m√∫sica, qual a taxa de amostragem e tamanho que ele utiliza? Se usa CDs, qual a taxa de amostragem e tamanho do √°udio em CD?

Existem v√°rios formatos diferentes para dados de √°udio. Provavelmente j√° ouviu falar de ficheiros mp3 - dados de √°udio comprimidos para serem menores sem perder qualidade. O √°udio n√£o comprimido √© frequentemente armazenado como um ficheiro WAV - este √© um ficheiro com 44 bytes de informa√ß√µes de cabe√ßalho, seguido por dados de √°udio brutos. O cabe√ßalho cont√©m informa√ß√µes como a taxa de amostragem (por exemplo, 16000 para 16KHz), tamanho da amostra (16 para 16 bits) e o n√∫mero de canais. Ap√≥s o cabe√ßalho, o ficheiro WAV cont√©m os dados de √°udio brutos.

> üéì Canais referem-se a quantos fluxos de √°udio diferentes comp√µem o √°udio. Por exemplo, para √°udio est√©reo com esquerda e direita, haveria 2 canais. Para som surround 7.1 num sistema de cinema em casa, seriam 8.

### Tamanho dos dados de √°udio

Os dados de √°udio s√£o relativamente grandes. Por exemplo, capturar √°udio n√£o comprimido de 16 bits a 16KHz (uma taxa suficiente para uso com modelos de reconhecimento de fala) consome 32KB de dados por segundo de √°udio:

* 16 bits significam 2 bytes por amostra (1 byte equivale a 8 bits).
* 16KHz s√£o 16.000 amostras por segundo.
* 16.000 x 2 bytes = 32.000 bytes por segundo.

Isto pode parecer uma pequena quantidade de dados, mas se estiver a usar um microcontrolador com mem√≥ria limitada, pode ser muito. Por exemplo, o Wio Terminal tem 192KB de mem√≥ria, que precisa de armazenar o c√≥digo do programa e vari√°veis. Mesmo que o c√≥digo do programa fosse min√∫sculo, n√£o poderia capturar mais de 5 segundos de √°udio.

Os microcontroladores podem aceder a armazenamento adicional, como cart√µes SD ou mem√≥ria flash. Ao construir um dispositivo IoT que captura √°udio, precisar√° garantir n√£o apenas que tem armazenamento adicional, mas que o seu c√≥digo grava o √°udio capturado diretamente nesse armazenamento. Quando enviar para a nuvem, deve transmitir do armazenamento para a solicita√ß√£o web. Assim, evita esgotar a mem√≥ria ao tentar armazenar todo o bloco de dados de √°udio na mem√≥ria de uma s√≥ vez.

## Capturar √°udio do seu dispositivo IoT

O seu dispositivo IoT pode ser ligado a um microfone para capturar √°udio, pronto para convers√£o em texto. Tamb√©m pode ser ligado a colunas para reproduzir √°udio. Em li√ß√µes futuras, isso ser√° usado para fornecer feedback de √°udio, mas √© √∫til configurar as colunas agora para testar o microfone.

### Tarefa - configurar o microfone e as colunas

Siga o guia relevante para configurar o microfone e as colunas para o seu dispositivo IoT:

* [Arduino - Wio Terminal](wio-terminal-microphone.md)
* [Computador de placa √∫nica - Raspberry Pi](pi-microphone.md)
* [Computador de placa √∫nica - Dispositivo virtual](virtual-device-microphone.md)

### Tarefa - capturar √°udio

Siga o guia relevante para capturar √°udio no seu dispositivo IoT:

* [Arduino - Wio Terminal](wio-terminal-audio.md)
* [Computador de placa √∫nica - Raspberry Pi](pi-audio.md)
* [Computador de placa √∫nica - Dispositivo virtual](virtual-device-audio.md)

## Fala para texto

Fala para texto, ou reconhecimento de fala, envolve o uso de IA para converter palavras num sinal de √°udio em texto.

### Modelos de reconhecimento de fala

Para converter fala em texto, amostras do sinal de √°udio s√£o agrupadas e alimentadas num modelo de aprendizagem autom√°tica baseado numa Rede Neural Recorrente (RNN). Este √© um tipo de modelo de aprendizagem autom√°tica que pode usar dados anteriores para tomar decis√µes sobre dados recebidos. Por exemplo, a RNN pode detetar um bloco de amostras de √°udio como o som 'Hel', e quando recebe outro que parece ser o som 'lo', pode combinar isso com o som anterior, descobrir que 'Hello' √© uma palavra v√°lida e selecionar isso como o resultado.

Os modelos de ML sempre aceitam dados do mesmo tamanho a cada vez. O classificador de imagens que construiu numa li√ß√£o anterior redimensiona imagens para um tamanho fixo antes de process√°-las. O mesmo acontece com os modelos de fala, que precisam processar blocos de √°udio de tamanho fixo. Os modelos de fala precisam ser capazes de combinar as sa√≠das de v√°rias previs√µes para obter a resposta, permitindo distinguir entre 'Hi' e 'Highway', ou 'flock' e 'floccinaucinihilipilification'.

Os modelos de fala tamb√©m s√£o avan√ßados o suficiente para entender o contexto e podem corrigir as palavras detetadas √† medida que mais sons s√£o processados. Por exemplo, se disser "Fui √†s lojas para comprar duas bananas e uma ma√ß√£ tamb√©m", usaria tr√™s palavras que soam iguais, mas s√£o escritas de forma diferente - to, two e too. Os modelos de fala conseguem entender o contexto e usar a grafia apropriada da palavra.
üíÅ Alguns servi√ßos de voz permitem personaliza√ß√£o para funcionar melhor em ambientes ruidosos, como f√°bricas, ou com palavras espec√≠ficas de setores, como nomes qu√≠micos. Estas personaliza√ß√µes s√£o treinadas fornecendo √°udio de exemplo e uma transcri√ß√£o, e funcionam atrav√©s de aprendizagem por transfer√™ncia, da mesma forma que treinaste um classificador de imagens usando apenas algumas imagens numa li√ß√£o anterior.
### Privacidade

Ao utilizar a convers√£o de voz para texto num dispositivo IoT de consumo, a privacidade √© extremamente importante. Estes dispositivos ouvem continuamente o √°udio, e como consumidor, n√£o quer que tudo o que diz seja enviado para a cloud e convertido em texto. N√£o s√≥ isso consome muita largura de banda da Internet, como tamb√©m tem enormes implica√ß√µes para a privacidade, especialmente quando alguns fabricantes de dispositivos inteligentes selecionam aleatoriamente √°udios para [serem validados por humanos em rela√ß√£o ao texto gerado, para ajudar a melhorar o modelo](https://www.theverge.com/2019/4/10/18305378/amazon-alexa-ai-voice-assistant-annotation-listen-private-recordings).

Quer que o seu dispositivo inteligente envie √°udio para a cloud apenas quando o est√° a utilizar, e n√£o quando ouve sons na sua casa, que podem incluir reuni√µes privadas ou intera√ß√µes √≠ntimas. A maioria dos dispositivos inteligentes funciona com uma *palavra de ativa√ß√£o*, uma frase-chave como "Alexa", "Hey Siri" ou "OK Google", que faz com que o dispositivo 'acorde' e ou√ßa o que est√° a dizer at√© detetar uma pausa no discurso, indicando que terminou de falar com o dispositivo.

> üéì A dete√ß√£o de palavras de ativa√ß√£o tamb√©m √© conhecida como *Keyword spotting* ou *Keyword recognition*.

Estas palavras de ativa√ß√£o s√£o detetadas no dispositivo, e n√£o na cloud. Estes dispositivos inteligentes possuem pequenos modelos de IA que funcionam no pr√≥prio dispositivo, ouvindo a palavra de ativa√ß√£o, e quando esta √© detetada, come√ßam a transmitir o √°udio para a cloud para reconhecimento. Estes modelos s√£o muito especializados e apenas ouvem a palavra de ativa√ß√£o.

> üíÅ Algumas empresas de tecnologia est√£o a adicionar mais privacidade aos seus dispositivos, realizando parte da convers√£o de voz para texto no pr√≥prio dispositivo. A Apple anunciou que, como parte das atualiza√ß√µes do iOS e macOS de 2021, suportar√° a convers√£o de voz para texto no dispositivo, sendo capaz de lidar com muitos pedidos sem necessidade de usar a cloud. Isto √© poss√≠vel gra√ßas aos processadores potentes nos seus dispositivos, que conseguem executar modelos de ML.

‚úÖ Quais acha que s√£o as implica√ß√µes √©ticas e de privacidade de armazenar o √°udio enviado para a cloud? Este √°udio deve ser armazenado e, se sim, como? Considera que o uso de grava√ß√µes para aplica√ß√£o da lei √© uma boa troca pela perda de privacidade?

A dete√ß√£o de palavras de ativa√ß√£o geralmente utiliza uma t√©cnica conhecida como TinyML, que consiste em converter modelos de ML para que possam ser executados em microcontroladores. Estes modelos s√£o pequenos em tamanho e consomem muito pouca energia para funcionar.

Para evitar a complexidade de treinar e usar um modelo de palavra de ativa√ß√£o, o temporizador inteligente que est√° a construir nesta li√ß√£o usar√° um bot√£o para ativar o reconhecimento de voz.

> üíÅ Se quiser experimentar criar um modelo de dete√ß√£o de palavras de ativa√ß√£o para executar no Wio Terminal ou Raspberry Pi, veja este [tutorial de resposta √† sua voz da Edge Impulse](https://docs.edgeimpulse.com/docs/responding-to-your-voice). Se quiser usar o seu computador para isso, pode experimentar o [guia r√°pido de in√≠cio com palavras-chave personalizadas na documenta√ß√£o da Microsoft](https://docs.microsoft.com/azure/cognitive-services/speech-service/keyword-recognition-overview?WT.mc_id=academic-17441-jabenn).

## Converter voz em texto

![Log√≥tipo dos servi√ßos de voz](../../../../../translated_images/azure-speech-logo.a1f08c4befb0159f2cb5d692d3baf5b599e7b44759d316da907bda1508f46a4a.pt.png)

Tal como na classifica√ß√£o de imagens num projeto anterior, existem servi√ßos de IA pr√©-constru√≠dos que podem receber √°udio como ficheiro e convert√™-lo em texto. Um desses servi√ßos √© o Speech Service, parte dos Cognitive Services, servi√ßos de IA pr√©-constru√≠dos que pode usar nas suas aplica√ß√µes.

### Tarefa - configurar um recurso de IA de voz

1. Crie um Grupo de Recursos para este projeto chamado `smart-timer`.

1. Use o seguinte comando para criar um recurso de voz gratuito:

    ```sh
    az cognitiveservices account create --name smart-timer \
                                        --resource-group smart-timer \
                                        --kind SpeechServices \
                                        --sku F0 \
                                        --yes \
                                        --location <location>
    ```

    Substitua `<location>` pela localiza√ß√£o que utilizou ao criar o Grupo de Recursos.

1. Vai precisar de uma chave de API para aceder ao recurso de voz a partir do seu c√≥digo. Execute o seguinte comando para obter a chave:

    ```sh
    az cognitiveservices account keys list --name smart-timer \
                                           --resource-group smart-timer \
                                           --output table
    ```

    Guarde uma c√≥pia de uma das chaves.

### Tarefa - converter voz em texto

Siga o guia relevante para converter voz em texto no seu dispositivo IoT:

* [Arduino - Wio Terminal](wio-terminal-speech-to-text.md)
* [Computador de placa √∫nica - Raspberry Pi](pi-speech-to-text.md)
* [Computador de placa √∫nica - Dispositivo virtual](virtual-device-speech-to-text.md)

---

## üöÄ Desafio

O reconhecimento de voz existe h√° muito tempo e est√° continuamente a melhorar. Pesquise as capacidades atuais e compare como estas evolu√≠ram ao longo do tempo, incluindo a precis√£o das transcri√ß√µes feitas por m√°quinas em compara√ß√£o com as feitas por humanos.

O que acha que o futuro reserva para o reconhecimento de voz?

## Question√°rio p√≥s-aula

[Question√°rio p√≥s-aula](https://black-meadow-040d15503.1.azurestaticapps.net/quiz/42)

## Revis√£o e Autoestudo

* Leia sobre os diferentes tipos de microfones e como funcionam no [artigo sobre a diferen√ßa entre microfones din√¢micos e condensadores no Musician's HQ](https://musicianshq.com/whats-the-difference-between-dynamic-and-condenser-microphones/).
* Leia mais sobre o servi√ßo de voz dos Cognitive Services na [documenta√ß√£o do servi√ßo de voz na Microsoft Docs](https://docs.microsoft.com/azure/cognitive-services/speech-service/?WT.mc_id=academic-17441-jabenn).
* Leia sobre dete√ß√£o de palavras-chave na [documenta√ß√£o de reconhecimento de palavras-chave na Microsoft Docs](https://docs.microsoft.com/azure/cognitive-services/speech-service/keyword-recognition-overview?WT.mc_id=academic-17441-jabenn).

## Tarefa

[](assignment.md)

**Aviso Legal**:  
Este documento foi traduzido utilizando o servi√ßo de tradu√ß√£o por IA [Co-op Translator](https://github.com/Azure/co-op-translator). Embora nos esforcemos para garantir a precis√£o, √© importante notar que tradu√ß√µes autom√°ticas podem conter erros ou imprecis√µes. O documento original na sua l√≠ngua nativa deve ser considerado a fonte autorit√°ria. Para informa√ß√µes cr√≠ticas, recomenda-se a tradu√ß√£o profissional realizada por humanos. N√£o nos responsabilizamos por quaisquer mal-entendidos ou interpreta√ß√µes incorretas decorrentes do uso desta tradu√ß√£o.