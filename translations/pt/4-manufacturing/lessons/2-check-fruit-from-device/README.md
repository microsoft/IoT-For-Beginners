<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "557f4ee96b752e0651d2e6e74aa6bd14",
  "translation_date": "2025-08-25T20:56:01+00:00",
  "source_file": "4-manufacturing/lessons/2-check-fruit-from-device/README.md",
  "language_code": "pt"
}
-->
# Verificar a qualidade de frutas com um dispositivo IoT

![Uma vis√£o geral ilustrada desta li√ß√£o](../../../../../translated_images/lesson-16.215daf18b00631fbdfd64c6fc2dc6044dff5d544288825d8076f9fb83d964c23.pt.jpg)

> Ilustra√ß√£o por [Nitya Narasimhan](https://github.com/nitya). Clique na imagem para uma vers√£o maior.

## Question√°rio pr√©-aula

[Question√°rio pr√©-aula](https://black-meadow-040d15503.1.azurestaticapps.net/quiz/31)

## Introdu√ß√£o

Na √∫ltima li√ß√£o, aprendeste sobre classificadores de imagens e como trein√°-los para detetar frutas boas e m√°s. Para usar este classificador de imagens numa aplica√ß√£o IoT, precisas de capturar uma imagem com algum tipo de c√¢mara e envi√°-la para a nuvem para ser classificada.

Nesta li√ß√£o, vais aprender sobre sensores de c√¢mara e como us√°-los com um dispositivo IoT para capturar uma imagem. Tamb√©m vais aprender a chamar o classificador de imagens a partir do teu dispositivo IoT.

Nesta li√ß√£o, abordaremos:

* [Sensores de c√¢mara](../../../../../4-manufacturing/lessons/2-check-fruit-from-device)
* [Capturar uma imagem usando um dispositivo IoT](../../../../../4-manufacturing/lessons/2-check-fruit-from-device)
* [Publicar o teu classificador de imagens](../../../../../4-manufacturing/lessons/2-check-fruit-from-device)
* [Classificar imagens a partir do teu dispositivo IoT](../../../../../4-manufacturing/lessons/2-check-fruit-from-device)
* [Melhorar o modelo](../../../../../4-manufacturing/lessons/2-check-fruit-from-device)

## Sensores de c√¢mara

Os sensores de c√¢mara, como o nome sugere, s√£o c√¢maras que podes conectar ao teu dispositivo IoT. Eles podem tirar imagens est√°ticas ou capturar v√≠deo em streaming. Alguns retornam dados de imagem brutos, enquanto outros comprimem os dados em ficheiros de imagem como JPEG ou PNG. Normalmente, as c√¢maras que funcionam com dispositivos IoT s√£o muito menores e t√™m uma resolu√ß√£o mais baixa do que aquelas a que est√°s habituado, mas tamb√©m existem c√¢maras de alta resolu√ß√£o que rivalizam com os melhores telem√≥veis. Podes encontrar lentes intercambi√°veis, configura√ß√µes com v√°rias c√¢maras, c√¢maras t√©rmicas de infravermelhos ou c√¢maras UV.

![A luz de uma cena passa por uma lente e √© focada num sensor CMOS](../../../../../translated_images/cmos-sensor.75f9cd74decb137149a4c9ea825251a4549497d67c0ae2776159e6102bb53aa9.pt.png)

A maioria dos sensores de c√¢mara utiliza sensores de imagem onde cada pixel √© um fotod√≠odo. Uma lente foca a imagem no sensor de imagem, e milhares ou milh√µes de fotod√≠odos detetam a luz que incide sobre cada um, registando-a como dados de pixel.

> üíÅ As lentes invertem as imagens, e o sensor da c√¢mara depois corrige a imagem para a orienta√ß√£o correta. O mesmo acontece nos teus olhos - o que v√™s √© detetado de cabe√ßa para baixo na parte de tr√°s do olho, e o teu c√©rebro corrige isso.

> üéì O sensor de imagem √© conhecido como Sensor de Pixel Ativo (APS), e o tipo mais popular de APS √© o sensor de semicondutor de √≥xido met√°lico complementar, ou CMOS. Talvez j√° tenhas ouvido o termo sensor CMOS usado para sensores de c√¢mara.

Os sensores de c√¢mara s√£o digitais, enviando dados de imagem como dados digitais, geralmente com a ajuda de uma biblioteca que fornece a comunica√ß√£o. As c√¢maras conectam-se usando protocolos como SPI para permitir o envio de grandes quantidades de dados - as imagens s√£o substancialmente maiores do que n√∫meros √∫nicos de sensores como um sensor de temperatura.

‚úÖ Quais s√£o as limita√ß√µes em rela√ß√£o ao tamanho das imagens em dispositivos IoT? Pensa nas restri√ß√µes, especialmente no hardware de microcontroladores.

## Capturar uma imagem usando um dispositivo IoT

Podes usar o teu dispositivo IoT para capturar uma imagem a ser classificada.

### Tarefa - capturar uma imagem usando um dispositivo IoT

Segue o guia relevante para capturar uma imagem usando o teu dispositivo IoT:

* [Arduino - Wio Terminal](wio-terminal-camera.md)
* [Computador de placa √∫nica - Raspberry Pi](pi-camera.md)
* [Computador de placa √∫nica - Dispositivo virtual](virtual-device-camera.md)

## Publicar o teu classificador de imagens

Treinaste o teu classificador de imagens na √∫ltima li√ß√£o. Antes de o usares no teu dispositivo IoT, precisas de publicar o modelo.

### Itera√ß√µes do modelo

Quando o teu modelo estava a ser treinado na √∫ltima li√ß√£o, talvez tenhas notado que o separador **Performance** mostra itera√ß√µes no lado. Quando treinaste o modelo pela primeira vez, viste *Iteration 1* em treino. Quando melhoraste o modelo usando as imagens de previs√£o, viste *Iteration 2* em treino.

Sempre que treinas o modelo, obt√©ns uma nova itera√ß√£o. Esta √© uma forma de acompanhar as diferentes vers√µes do teu modelo treinadas em diferentes conjuntos de dados. Quando fazes um **Quick Test**, h√° um menu suspenso que podes usar para selecionar a itera√ß√£o, permitindo comparar os resultados entre v√°rias itera√ß√µes.

Quando estiveres satisfeito com uma itera√ß√£o, podes public√°-la para que fique dispon√≠vel para ser usada por aplica√ß√µes externas. Desta forma, podes ter uma vers√£o publicada que √© usada pelos teus dispositivos, enquanto trabalhas numa nova vers√£o ao longo de v√°rias itera√ß√µes, publicando-a apenas quando estiveres satisfeito com ela.

### Tarefa - publicar uma itera√ß√£o

As itera√ß√µes s√£o publicadas a partir do portal Custom Vision.

1. Acede ao portal Custom Vision em [CustomVision.ai](https://customvision.ai) e inicia sess√£o, caso ainda n√£o o tenhas aberto. Depois, abre o teu projeto `fruit-quality-detector`.

1. Seleciona o separador **Performance** nas op√ß√µes no topo.

1. Seleciona a itera√ß√£o mais recente na lista *Iterations* no lado.

1. Clica no bot√£o **Publish** para a itera√ß√£o.

    ![O bot√£o de publica√ß√£o](../../../../../translated_images/custom-vision-publish-button.b7174e1977b0c33b8b72d4e5b1326c779e0af196f3849d09985ee2d7d5493a39.pt.png)

1. Na janela *Publish Model*, define o *Prediction resource* como o recurso `fruit-quality-detector-prediction` que criaste na √∫ltima li√ß√£o. Mant√©m o nome como `Iteration2` e clica no bot√£o **Publish**.

1. Depois de publicado, clica no bot√£o **Prediction URL**. Isto mostrar√° os detalhes da API de previs√£o, que precisar√°s para chamar o modelo a partir do teu dispositivo IoT. A sec√ß√£o inferior est√° rotulada como *If you have an image file*, e s√£o estes os detalhes que precisas. Copia o URL mostrado, que ser√° algo como:

    ```output
    https://<location>.api.cognitive.microsoft.com/customvision/v3.0/Prediction/<id>/classify/iterations/Iteration2/image
    ```

    Onde `<location>` ser√° a localiza√ß√£o que usaste ao criar o teu recurso de vis√£o personalizada, e `<id>` ser√° um ID longo composto por letras e n√∫meros.

    Tamb√©m copia o valor da *Prediction-Key*. Esta √© uma chave segura que tens de passar ao chamar o modelo. Apenas aplica√ß√µes que fornecem esta chave podem usar o modelo; quaisquer outras aplica√ß√µes ser√£o rejeitadas.

    ![A janela da API de previs√£o mostrando o URL e a chave](../../../../../translated_images/custom-vision-prediction-key-endpoint.30c569ffd0338864f319911f052d5e9b8c5066cb0800a26dd6f7ff5713130ad8.pt.png)

‚úÖ Quando uma nova itera√ß√£o √© publicada, ter√° um nome diferente. Como achas que podes alterar a itera√ß√£o que um dispositivo IoT est√° a usar?

## Classificar imagens a partir do teu dispositivo IoT

Agora podes usar estes detalhes de conex√£o para chamar o classificador de imagens a partir do teu dispositivo IoT.

### Tarefa - classificar imagens a partir do teu dispositivo IoT

Segue o guia relevante para classificar imagens usando o teu dispositivo IoT:

* [Arduino - Wio Terminal](wio-terminal-classify-image.md)
* [Computador de placa √∫nica - Raspberry Pi/Dispositivo IoT virtual](single-board-computer-classify-image.md)

## Melhorar o modelo

Podes descobrir que os resultados obtidos ao usar a c√¢mara conectada ao teu dispositivo IoT n√£o correspondem ao que esperavas. As previs√µes nem sempre s√£o t√£o precisas quanto as imagens carregadas a partir do teu computador. Isto acontece porque o modelo foi treinado com dados diferentes dos usados para previs√µes.

Para obter os melhores resultados de um classificador de imagens, deves treinar o modelo com imagens o mais semelhantes poss√≠vel √†s usadas para previs√µes. Por exemplo, se usaste a c√¢mara do teu telem√≥vel para capturar imagens para treino, a qualidade, nitidez e cor da imagem ser√£o diferentes de uma c√¢mara conectada a um dispositivo IoT.

![2 imagens de bananas, uma de baixa resolu√ß√£o com pouca ilumina√ß√£o de um dispositivo IoT, e outra de alta resolu√ß√£o com boa ilumina√ß√£o de um telem√≥vel](../../../../../translated_images/banana-picture-compare.174df164dc326a42cf7fb051a7497e6113c620e91552d92ca914220305d47d9a.pt.png)

Na imagem acima, a foto da banana √† esquerda foi tirada com uma c√¢mara Raspberry Pi, enquanto a da direita foi tirada da mesma banana no mesmo local com um iPhone. H√° uma diferen√ßa not√°vel na qualidade - a foto do iPhone √© mais n√≠tida, com cores mais vivas e maior contraste.

‚úÖ O que mais pode causar previs√µes incorretas nas imagens capturadas pelo teu dispositivo IoT? Pensa no ambiente em que um dispositivo IoT pode ser usado e nos fatores que podem afetar a imagem capturada.

Para melhorar o modelo, podes trein√°-lo novamente usando as imagens capturadas pelo dispositivo IoT.

### Tarefa - melhorar o modelo

1. Classifica v√°rias imagens de frutas maduras e n√£o maduras usando o teu dispositivo IoT.

1. No portal Custom Vision, treina novamente o modelo usando as imagens no separador *Predictions*.

    > ‚ö†Ô∏è Podes consultar [as instru√ß√µes para treinar novamente o teu classificador na li√ß√£o 1, se necess√°rio](../1-train-fruit-detector/README.md#retrain-your-image-classifier).

1. Se as tuas imagens forem muito diferentes das originais usadas para treino, podes eliminar todas as imagens originais selecionando-as no separador *Training Images* e clicando no bot√£o **Delete**. Para selecionar uma imagem, move o cursor sobre ela e aparecer√° um visto; clica nesse visto para selecionar ou desmarcar a imagem.

1. Treina uma nova itera√ß√£o do modelo e publica-a usando os passos acima.

1. Atualiza o URL do endpoint no teu c√≥digo e executa novamente a aplica√ß√£o.

1. Repete estes passos at√© estares satisfeito com os resultados das previs√µes.

---

## üöÄ Desafio

Quanto a resolu√ß√£o da imagem ou a ilumina√ß√£o afetam a previs√£o?

Tenta alterar a resolu√ß√£o das imagens no c√≥digo do teu dispositivo e v√™ se isso faz diferen√ßa na qualidade das imagens. Tamb√©m experimenta alterar a ilumina√ß√£o.

Se fosses criar um dispositivo de produ√ß√£o para vender a quintas ou f√°bricas, como garantias resultados consistentes o tempo todo?

## Question√°rio p√≥s-aula

[Question√°rio p√≥s-aula](https://black-meadow-040d15503.1.azurestaticapps.net/quiz/32)

## Revis√£o e Autoestudo

Treinaste o teu modelo de vis√£o personalizada usando o portal. Isto depende de teres imagens dispon√≠veis - e no mundo real, pode n√£o ser poss√≠vel obter dados de treino que correspondam ao que a c√¢mara do teu dispositivo captura. Podes contornar isto treinando diretamente a partir do teu dispositivo usando a API de treino, para treinar um modelo com imagens capturadas pelo teu dispositivo IoT.

* L√™ sobre a API de treino no [in√≠cio r√°pido do SDK de Custom Vision](https://docs.microsoft.com/azure/cognitive-services/custom-vision-service/quickstarts/image-classification?WT.mc_id=academic-17441-jabenn&tabs=visual-studio&pivots=programming-language-python)

## Tarefa

[Responder aos resultados da classifica√ß√£o](assignment.md)

**Aviso Legal**:  
Este documento foi traduzido utilizando o servi√ßo de tradu√ß√£o por IA [Co-op Translator](https://github.com/Azure/co-op-translator). Embora nos esforcemos pela precis√£o, esteja ciente de que tradu√ß√µes autom√°ticas podem conter erros ou imprecis√µes. O documento original na sua l√≠ngua nativa deve ser considerado a fonte autorit√°ria. Para informa√ß√µes cr√≠ticas, recomenda-se a tradu√ß√£o profissional realizada por humanos. N√£o nos responsabilizamos por quaisquer mal-entendidos ou interpreta√ß√µes incorretas decorrentes do uso desta tradu√ß√£o.