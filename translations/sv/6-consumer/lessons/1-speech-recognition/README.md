<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "6d6aa1be033625d201a190fc9c5cbfb4",
  "translation_date": "2025-08-27T21:00:10+00:00",
  "source_file": "6-consumer/lessons/1-speech-recognition/README.md",
  "language_code": "sv"
}
-->
# K√§nna igen tal med en IoT-enhet

![En sketchnote-√∂versikt av denna lektion](../../../../../translated_images/lesson-21.e34de51354d6606fb5ee08d8c89d0222eea0a2a7aaf744a8805ae847c4f69dc4.sv.jpg)

> Sketchnote av [Nitya Narasimhan](https://github.com/nitya). Klicka p√• bilden f√∂r en st√∂rre version.

Den h√§r videon ger en √∂versikt av Azure talservice, ett √§mne som kommer att behandlas i denna lektion:

[![Hur man kommer ig√•ng med din Cognitive Services Speech-resurs fr√•n Microsoft Azures YouTube-kanal](https://img.youtube.com/vi/iW0Fw0l3mrA/0.jpg)](https://www.youtube.com/watch?v=iW0Fw0l3mrA)

> üé• Klicka p√• bilden ovan f√∂r att se en video

## Quiz f√∂re f√∂rel√§sningen

[Quiz f√∂re f√∂rel√§sningen](https://black-meadow-040d15503.1.azurestaticapps.net/quiz/41)

## Introduktion

'Alexa, s√§tt en timer p√• 12 minuter'

'Alexa, timerstatus'

'Alexa, s√§tt en timer p√• 8 minuter som heter √•ngkok broccoli'

Smarta enheter blir alltmer vanliga. Inte bara som smarta h√∂gtalare som HomePods, Echos och Google Homes, utan √§ven inbyggda i v√•ra telefoner, klockor och till och med lampor och termostater.

> üíÅ Jag har minst 19 enheter i mitt hem som har r√∂stassistenter, och det √§r bara de jag k√§nner till!

R√∂ststyrning √∂kar tillg√§ngligheten genom att l√•ta personer med begr√§nsad r√∂relsef√∂rm√•ga interagera med enheter. Oavsett om det handlar om en permanent funktionsneds√§ttning, som att vara f√∂dd utan armar, eller en tillf√§llig skada som brutna armar, eller att ha h√§nderna fulla med shopping eller sm√• barn, kan m√∂jligheten att styra v√•ra hem med r√∂sten ist√§llet f√∂r h√§nderna √∂ppna upp en v√§rld av tillg√•ng. Att ropa 'Hej Siri, st√§ng garageporten' medan man hanterar ett bl√∂jbyte och en trotsig sm√•tting kan vara en liten men effektiv f√∂rb√§ttring i livet.

En av de mer popul√§ra anv√§ndningarna f√∂r r√∂stassistenter √§r att st√§lla in timers, s√§rskilt k√∂kstimers. Att kunna st√§lla in flera timers med bara r√∂sten √§r en stor hj√§lp i k√∂ket - ingen anledning att avbryta kn√•dning av deg, omr√∂rning av soppa eller reng√∂ra h√§nderna fr√•n dumplingsfyllning f√∂r att anv√§nda en fysisk timer.

I denna lektion kommer du att l√§ra dig hur man bygger in r√∂stigenk√§nning i IoT-enheter. Du kommer att l√§ra dig om mikrofoner som sensorer, hur man f√•ngar ljud fr√•n en mikrofon ansluten till en IoT-enhet och hur man anv√§nder AI f√∂r att konvertera det som h√∂rs till text. Under resten av detta projekt kommer du att bygga en smart k√∂kstimer som kan st√§lla in timers med din r√∂st p√• flera spr√•k.

I denna lektion kommer vi att behandla:

* [Mikrofoner](../../../../../6-consumer/lessons/1-speech-recognition)
* [F√•nga ljud fr√•n din IoT-enhet](../../../../../6-consumer/lessons/1-speech-recognition)
* [Tal till text](../../../../../6-consumer/lessons/1-speech-recognition)
* [Konvertera tal till text](../../../../../6-consumer/lessons/1-speech-recognition)

## Mikrofoner

Mikrofoner √§r analoga sensorer som omvandlar ljudv√•gor till elektriska signaler. Vibrationer i luften f√•r komponenter i mikrofonen att r√∂ra sig sm√• m√§ngder, och dessa orsakar sm√• f√∂r√§ndringar i elektriska signaler. Dessa f√∂r√§ndringar f√∂rst√§rks sedan f√∂r att generera en elektrisk output.

### Mikrofontyper

Mikrofoner finns i olika typer:

* Dynamisk - Dynamiska mikrofoner har en magnet som √§r f√§st vid en r√∂rlig membran som r√∂r sig i en tr√•dspole och skapar en elektrisk str√∂m. Detta √§r motsatsen till de flesta h√∂gtalare, som anv√§nder en elektrisk str√∂m f√∂r att flytta en magnet i en tr√•dspole och flytta ett membran f√∂r att skapa ljud. Detta inneb√§r att h√∂gtalare kan anv√§ndas som dynamiska mikrofoner, och dynamiska mikrofoner kan anv√§ndas som h√∂gtalare. I enheter som intercoms d√§r en anv√§ndare antingen lyssnar eller talar, men inte b√•da, kan en enhet fungera som b√•de h√∂gtalare och mikrofon.

    Dynamiska mikrofoner beh√∂ver ingen str√∂m f√∂r att fungera, den elektriska signalen skapas helt av mikrofonen.

    ![Patti Smith sjunger i en Shure SM58 (dynamisk kardioidtyp) mikrofon](../../../../../translated_images/dynamic-mic.8babac890a2d80dfb0874b5bf37d4b851fe2aeb9da6fd72945746176978bf3bb.sv.jpg)

* Band - Bandmikrofoner liknar dynamiska mikrofoner, f√∂rutom att de har ett metallband ist√§llet f√∂r ett membran. Detta band r√∂r sig i ett magnetf√§lt och genererar en elektrisk str√∂m. Precis som dynamiska mikrofoner beh√∂ver bandmikrofoner ingen str√∂m f√∂r att fungera.

    ![Edmund Lowe, amerikansk sk√•despelare, st√•r vid radiomikrofon (m√§rkt f√∂r (NBC) Blue Network), h√•ller manus, 1942](../../../../../translated_images/ribbon-mic.eacc8e092c7441caee6d7a81e2f40e1675bf36269848964c7c09c9a9acb05127.sv.jpg)

* Kondensator - Kondensatormikrofoner har ett tunt metallmembran och en fast metallbakplatta. Elektricitet appliceras p√• b√•da dessa och n√§r membranet vibrerar √§ndras den statiska laddningen mellan plattorna och genererar en signal. Kondensatormikrofoner beh√∂ver str√∂m f√∂r att fungera - kallad *Phantom power*.

    ![C451B sm√•membran kondensatormikrofon av AKG Acoustics](../../../../../translated_images/condenser-mic.6f6ed5b76ca19e0ec3fd0c544601542d4479a6cb7565db336de49fbbf69f623e.sv.jpg)

* MEMS - Mikroelektromekaniska systemmikrofoner, eller MEMS, √§r mikrofoner p√• ett chip. De har ett tryckk√§nsligt membran etsad p√• ett kiselchip och fungerar liknande en kondensatormikrofon. Dessa mikrofoner kan vara mycket sm√• och integreras i kretsar.

    ![En MEMS-mikrofon p√• ett kretskort](../../../../../translated_images/mems-microphone.80574019e1f5e4d9ee72fed720ecd25a39fc2969c91355d17ebb24ba4159e4c4.sv.png)

    P√• bilden ovan √§r chipet m√§rkt **LEFT** en MEMS-mikrofon, med ett litet membran mindre √§n en millimeter brett.

‚úÖ G√∂r lite forskning: Vilka mikrofoner har du runt dig - antingen i din dator, din telefon, ditt headset eller i andra enheter. Vilken typ av mikrofoner √§r de?

### Digitalt ljud

Ljud √§r en analog signal som b√§r mycket finf√∂rdelad information. F√∂r att konvertera denna signal till digitalt m√•ste ljudet samplas m√•nga tusen g√•nger per sekund.

> üéì Sampling inneb√§r att konvertera ljudsignalen till ett digitalt v√§rde som representerar signalen vid den tidpunkten.

![Ett linjediagram som visar en signal, med diskreta punkter vid fasta intervaller](../../../../../translated_images/sampling.6f4fadb3f2d9dfe7618f9edfe75a350e6b3f74293ec84f02ab69c19d2afe3d73.sv.png)

Digitalt ljud samplas med hj√§lp av Pulse Code Modulation, eller PCM. PCM inneb√§r att l√§sa sp√§nningen i signalen och v√§lja det n√§rmaste diskreta v√§rdet till den sp√§nningen med en definierad storlek.

> üíÅ Du kan t√§nka p√• PCM som sensorversionen av pulsbreddsmodulering, eller PWM (PWM behandlades tidigare i [lektion 3 i introduktionsprojektet](../../../1-getting-started/lessons/3-sensors-and-actuators/README.md#pulse-width-modulation)). PCM inneb√§r att konvertera en analog signal till digital, PWM inneb√§r att konvertera en digital signal till analog.

Till exempel erbjuder de flesta streamingtj√§nster f√∂r musik 16-bitars eller 24-bitars ljud. Detta inneb√§r att de konverterar sp√§nningen till ett v√§rde som passar in i ett 16-bitars heltal eller 24-bitars heltal. 16-bitars ljud passar v√§rdet i ett nummer som str√§cker sig fr√•n -32,768 till 32,767, 24-bitars √§r i intervallet ‚àí8,388,608 till 8,388,607. Ju fler bitar, desto n√§rmare √§r samplingen det v√•ra √∂ron faktiskt h√∂r.

> üíÅ Du kanske har h√∂rt talas om 8-bitars ljud, ofta kallat LoFi. Detta √§r ljud som samplas med endast 8 bitar, allts√• -128 till 127. Den f√∂rsta datorljudet var begr√§nsat till 8 bitar p√• grund av h√•rdvarubegr√§nsningar, s√• detta ses ofta i retrospel.

Dessa samplingar tas m√•nga tusen g√•nger per sekund, med v√§ldefinierade samplingsfrekvenser m√§tta i KHz (tusen avl√§sningar per sekund). Streamingtj√§nster f√∂r musik anv√§nder 48KHz f√∂r de flesta ljud, men vissa 'f√∂rlustfria' ljud anv√§nder upp till 96KHz eller till och med 192KHz. Ju h√∂gre samplingsfrekvens, desto n√§rmare originalet kommer ljudet att vara, upp till en viss punkt. Det finns debatt om huruvida m√§nniskor kan m√§rka skillnaden √∂ver 48KHz.

‚úÖ G√∂r lite forskning: Om du anv√§nder en streamingtj√§nst f√∂r musik, vilken samplingsfrekvens och storlek anv√§nder den? Om du anv√§nder CD-skivor, vad √§r samplingsfrekvensen och storleken p√• CD-ljud?

Det finns ett antal olika format f√∂r ljuddata. Du har f√∂rmodligen h√∂rt talas om mp3-filer - ljuddata som komprimeras f√∂r att g√∂ra den mindre utan att f√∂rlora n√•gon kvalitet. Okomprimerat ljud lagras ofta som en WAV-fil - detta √§r en fil med 44 byte headerinformation, f√∂ljt av r√• ljuddata. Headern inneh√•ller information som samplingsfrekvensen (till exempel 16000 f√∂r 16KHz) och samplingsstorleken (16 f√∂r 16-bitars), samt antalet kanaler. Efter headern inneh√•ller WAV-filen den r√•a ljuddatan.

> üéì Kanaler h√§nvisar till hur m√•nga olika ljudstr√∂mmar som utg√∂r ljudet. Till exempel, f√∂r stereoljud med v√§nster och h√∂ger, skulle det finnas 2 kanaler. F√∂r 7.1 surroundljud f√∂r ett hemmabiosystem skulle detta vara 8.

### Ljuddatas storlek

Ljuddata √§r relativt stora. Till exempel, att f√•nga okomprimerat 16-bitars ljud vid 16KHz (en tillr√§ckligt bra frekvens f√∂r anv√§ndning med tal-till-text-modeller), tar 32KB data f√∂r varje sekund av ljud:

* 16-bitars inneb√§r 2 byte per sampling (1 byte √§r 8 bitar).
* 16KHz √§r 16,000 samplingar per sekund.
* 16,000 x 2 byte = 32,000 byte per sekund.

Detta l√•ter som en liten m√§ngd data, men om du anv√§nder en mikrokontroller med begr√§nsat minne kan detta vara mycket. Till exempel har Wio Terminal 192KB minne, och det m√•ste lagra programkod och variabler. √Ñven om din programkod var liten, skulle du inte kunna f√•nga mer √§n 5 sekunder av ljud.

Mikrokontroller kan komma √•t ytterligare lagring, s√•som SD-kort eller flashminne. N√§r du bygger en IoT-enhet som f√•ngar ljud m√•ste du s√§kerst√§lla att du inte bara har ytterligare lagring, utan att din kod skriver det ljud som f√•ngas fr√•n din mikrofon direkt till den lagringen, och n√§r du skickar det till molnet, str√∂mmar fr√•n lagring till webbf√∂rfr√•gan. P√• s√• s√§tt kan du undvika att f√• slut p√• minne genom att f√∂rs√∂ka h√•lla hela ljudblocket i minnet samtidigt.

## F√•nga ljud fr√•n din IoT-enhet

Din IoT-enhet kan anslutas till en mikrofon f√∂r att f√•nga ljud, redo att konverteras till text. Den kan ocks√• anslutas till h√∂gtalare f√∂r att spela upp ljud. I senare lektioner kommer detta att anv√§ndas f√∂r att ge ljudfeedback, men det √§r anv√§ndbart att konfigurera h√∂gtalare nu f√∂r att testa mikrofonen.

### Uppgift - konfigurera din mikrofon och h√∂gtalare

F√∂lj den relevanta guiden f√∂r att konfigurera mikrofonen och h√∂gtalarna f√∂r din IoT-enhet:

* [Arduino - Wio Terminal](wio-terminal-microphone.md)
* [Enkorts-dator - Raspberry Pi](pi-microphone.md)
* [Enkorts-dator - Virtuell enhet](virtual-device-microphone.md)

### Uppgift - f√•nga ljud

F√∂lj den relevanta guiden f√∂r att f√•nga ljud p√• din IoT-enhet:

* [Arduino - Wio Terminal](wio-terminal-audio.md)
* [Enkorts-dator - Raspberry Pi](pi-audio.md)
* [Enkorts-dator - Virtuell enhet](virtual-device-audio.md)

## Tal till text

Tal till text, eller taligenk√§nning, inneb√§r att anv√§nda AI f√∂r att konvertera ord i en ljudsignal till text.

### Taligenk√§nningsmodeller

F√∂r att konvertera tal till text grupperas samplingar fr√•n ljudsignalen och matas in i en maskininl√§rningsmodell baserad p√• ett Recurrent Neural Network (RNN). Detta √§r en typ av maskininl√§rningsmodell som kan anv√§nda tidigare data f√∂r att fatta beslut om inkommande data. Till exempel kan RNN uppt√§cka ett block av ljudsamplingar som ljudet 'Hel', och n√§r det f√•r ett annat som det tror √§r ljudet 'lo', kan det kombinera detta med det tidigare ljudet, hitta att 'Hello' √§r ett giltigt ord och v√§lja det som resultat.

ML-modeller accepterar alltid data av samma storlek varje g√•ng. Bildklassificeraren du byggde i en tidigare lektion √§ndrar storleken p√• bilder till en fast storlek och bearbetar dem. Samma sak g√§ller f√∂r talmodeller, de m√•ste bearbeta ljudbitar av fast storlek. Talmodeller m√•ste kunna kombinera resultaten av flera f√∂ruts√§gelser f√∂r att f√• svaret, f√∂r att kunna skilja mellan 'Hej' och 'Motorv√§g', eller 'flock' och 'floccinaucinihilipilification'.

Talmodeller √§r ocks√• tillr√§ckligt avancerade f√∂r att f√∂rst√• sammanhang och kan korrigera de ord de uppt√§cker n√§r fler ljud bearbetas. Till exempel, om du s√§ger "Jag gick till aff√§ren f√∂r att k√∂pa tv√• bananer och ett √§pple ocks√•", skulle du anv√§nda tre ord som l√•ter likadana men stavas olika - till, tv√• och ocks√•. Talmodeller kan f√∂rst√• sammanhanget och anv√§nda den l√§mpliga stavningen av ordet.
üíÅ Vissa taligenk√§nningstj√§nster till√•ter anpassning f√∂r att fungera b√§ttre i bullriga milj√∂er som fabriker, eller med branschspecifika ord som kemiska namn. Dessa anpassningar tr√§nas genom att tillhandah√•lla exempel p√• ljud och en transkription, och fungerar med hj√§lp av transfer learning, precis som n√§r du tr√§nade en bildklassificerare med bara n√•gra f√• bilder i en tidigare lektion.
### Sekretess

N√§r man anv√§nder tal-till-text p√• en konsument-IoT-enhet √§r sekretess otroligt viktigt. Dessa enheter lyssnar kontinuerligt p√• ljud, s√• som konsument vill du inte att allt du s√§ger skickas till molnet och omvandlas till text. Detta skulle inte bara anv√§nda mycket internetbandbredd, utan det har ocks√• stora sekretessimplikationer, s√§rskilt n√§r vissa tillverkare av smarta enheter slumpm√§ssigt v√§ljer ljud f√∂r [m√§nniskor att validera mot den genererade texten f√∂r att f√∂rb√§ttra deras modell](https://www.theverge.com/2019/4/10/18305378/amazon-alexa-ai-voice-assistant-annotation-listen-private-recordings).

Du vill bara att din smarta enhet ska skicka ljud till molnet f√∂r bearbetning n√§r du anv√§nder den, inte n√§r den h√∂r ljud i ditt hem, ljud som kan inkludera privata m√∂ten eller intima interaktioner. De flesta smarta enheter fungerar med ett *v√§ckningsord*, en nyckelfras som "Alexa", "Hej Siri" eller "OK Google" som f√•r enheten att 'vakna' och lyssna p√• vad du s√§ger tills den uppt√§cker en paus i ditt tal, vilket indikerar att du har slutat prata med enheten.

> üéì V√§ckningsordsdetektion kallas ocks√• f√∂r *Keyword spotting* eller *Keyword recognition*.

Dessa v√§ckningsord uppt√§cks p√• enheten, inte i molnet. Dessa smarta enheter har sm√• AI-modeller som k√∂rs p√• enheten och lyssnar efter v√§ckningsordet, och n√§r det uppt√§cks b√∂rjar de str√∂mma ljudet till molnet f√∂r igenk√§nning. Dessa modeller √§r mycket specialiserade och lyssnar bara efter v√§ckningsordet.

> üíÅ Vissa teknikf√∂retag l√§gger till mer sekretess i sina enheter och g√∂r en del av tal-till-text-konverteringen p√• enheten. Apple har meddelat att som en del av deras iOS- och macOS-uppdateringar 2021 kommer de att st√∂dja tal-till-text-konvertering p√• enheten och kunna hantera m√•nga f√∂rfr√•gningar utan att beh√∂va anv√§nda molnet. Detta √§r m√∂jligt tack vare kraftfulla processorer i deras enheter som kan k√∂ra ML-modeller.

‚úÖ Vad tycker du √§r de sekretess- och etiska implikationerna av att lagra ljud som skickas till molnet? B√∂r detta ljud lagras, och i s√• fall hur? Tycker du att anv√§ndningen av inspelningar f√∂r brottsbek√§mpning √§r en bra kompromiss f√∂r f√∂rlusten av sekretess?

V√§ckningsordsdetektion anv√§nder vanligtvis en teknik som kallas TinyML, vilket inneb√§r att ML-modeller konverteras f√∂r att kunna k√∂ras p√• mikrokontroller. Dessa modeller √§r sm√• i storlek och f√∂rbrukar mycket lite str√∂m f√∂r att k√∂ras.

F√∂r att undvika komplexiteten i att tr√§na och anv√§nda en v√§ckningsordsmodell kommer den smarta timern du bygger i denna lektion att anv√§nda en knapp f√∂r att aktivera taligenk√§nning.

> üíÅ Om du vill prova att skapa en v√§ckningsordsdetektionsmodell f√∂r att k√∂ra p√• Wio Terminal eller Raspberry Pi, kolla in denna [handledning om att svara p√• din r√∂st fr√•n Edge Impulse](https://docs.edgeimpulse.com/docs/responding-to-your-voice). Om du vill anv√§nda din dator f√∂r detta kan du prova [komma ig√•ng med Custom Keyword snabbstart p√• Microsoft Docs](https://docs.microsoft.com/azure/cognitive-services/speech-service/keyword-recognition-overview?WT.mc_id=academic-17441-jabenn).

## Konvertera tal till text

![Logotyp f√∂r tal-tj√§nster](../../../../../translated_images/azure-speech-logo.a1f08c4befb0159f2cb5d692d3baf5b599e7b44759d316da907bda1508f46a4a.sv.png)

Precis som med bildklassificering i ett tidigare projekt finns det f√∂rbyggda AI-tj√§nster som kan ta tal som en ljudfil och konvertera det till text. En s√•dan tj√§nst √§r Speech Service, en del av Cognitive Services, f√∂rbyggda AI-tj√§nster som du kan anv√§nda i dina appar.

### Uppgift - konfigurera en AI-resurs f√∂r tal

1. Skapa en resursgrupp f√∂r detta projekt som heter `smart-timer`.

1. Anv√§nd f√∂ljande kommando f√∂r att skapa en gratis talresurs:

    ```sh
    az cognitiveservices account create --name smart-timer \
                                        --resource-group smart-timer \
                                        --kind SpeechServices \
                                        --sku F0 \
                                        --yes \
                                        --location <location>
    ```

    Ers√§tt `<location>` med platsen du anv√§nde n√§r du skapade resursgruppen.

1. Du kommer att beh√∂va en API-nyckel f√∂r att komma √•t talresursen fr√•n din kod. K√∂r f√∂ljande kommando f√∂r att f√• nyckeln:

    ```sh
    az cognitiveservices account keys list --name smart-timer \
                                           --resource-group smart-timer \
                                           --output table
    ```

    Ta en kopia av en av nycklarna.

### Uppgift - konvertera tal till text

F√∂lj den relevanta guiden f√∂r att konvertera tal till text p√• din IoT-enhet:

* [Arduino - Wio Terminal](wio-terminal-speech-to-text.md)
* [Enkortsdator - Raspberry Pi](pi-speech-to-text.md)
* [Enkortsdator - Virtuell enhet](virtual-device-speech-to-text.md)

---

## üöÄ Utmaning

Taligenk√§nning har funnits l√§nge och f√∂rb√§ttras kontinuerligt. Unders√∂k de nuvarande m√∂jligheterna och j√§mf√∂r hur dessa har utvecklats √∂ver tid, inklusive hur exakta maskintranskriptioner √§r j√§mf√∂rt med m√§nskliga.

Vad tror du framtiden har att erbjuda f√∂r taligenk√§nning?

## Efterf√∂rel√§sningsquiz

[Efterf√∂rel√§sningsquiz](https://black-meadow-040d15503.1.azurestaticapps.net/quiz/42)

## Granskning & Sj√§lvstudier

* L√§s om de olika mikrofontyperna och hur de fungerar i artikeln [vad √§r skillnaden mellan dynamiska och kondensatormikrofoner p√• Musician's HQ](https://musicianshq.com/whats-the-difference-between-dynamic-and-condenser-microphones/).
* L√§s mer om Cognitive Services tal-tj√§nst i [dokumentationen om tal-tj√§nsten p√• Microsoft Docs](https://docs.microsoft.com/azure/cognitive-services/speech-service/?WT.mc_id=academic-17441-jabenn).
* L√§s om keyword spotting i [dokumentationen om keyword recognition p√• Microsoft Docs](https://docs.microsoft.com/azure/cognitive-services/speech-service/keyword-recognition-overview?WT.mc_id=academic-17441-jabenn).

## Uppgift

[](assignment.md)

---

**Ansvarsfriskrivning**:  
Detta dokument har √∂versatts med hj√§lp av AI-√∂vers√§ttningstj√§nsten [Co-op Translator](https://github.com/Azure/co-op-translator). √Ñven om vi str√§var efter noggrannhet, b√∂r det noteras att automatiska √∂vers√§ttningar kan inneh√•lla fel eller felaktigheter. Det ursprungliga dokumentet p√• dess ursprungliga spr√•k b√∂r betraktas som den auktoritativa k√§llan. F√∂r kritisk information rekommenderas professionell m√§nsklig √∂vers√§ttning. Vi ansvarar inte f√∂r eventuella missf√∂rst√•nd eller feltolkningar som uppst√•r vid anv√§ndning av denna √∂vers√§ttning.