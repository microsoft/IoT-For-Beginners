<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "1c9e5fa8b7be726c75a97232b1e41c97",
  "translation_date": "2025-08-27T22:15:53+00:00",
  "source_file": "5-retail/lessons/2-check-stock-device/README.md",
  "language_code": "sv"
}
-->
# Kontrollera lager fr√•n en IoT-enhet

![En sketchnote-√∂versikt av denna lektion](../../../../../translated_images/lesson-20.0211df9551a8abb300fc8fcf7dc2789468dea2eabe9202273ac077b0ba37f15e.sv.jpg)

> Sketchnote av [Nitya Narasimhan](https://github.com/nitya). Klicka p√• bilden f√∂r en st√∂rre version.

## Quiz f√∂re f√∂rel√§sningen

[Quiz f√∂re f√∂rel√§sningen](https://black-meadow-040d15503.1.azurestaticapps.net/quiz/39)

## Introduktion

I den f√∂reg√•ende lektionen l√§rde du dig om de olika anv√§ndningsomr√•dena f√∂r objektdetektering inom detaljhandeln. Du l√§rde dig ocks√• hur man tr√§nar en objektdetektor f√∂r att identifiera lager. I denna lektion kommer du att l√§ra dig hur du anv√§nder din objektdetektor fr√•n din IoT-enhet f√∂r att r√§kna lager.

I denna lektion kommer vi att t√§cka:

* [Lagerber√§kning](../../../../../5-retail/lessons/2-check-stock-device)
* [Anropa din objektdetektor fr√•n din IoT-enhet](../../../../../5-retail/lessons/2-check-stock-device)
* [Avgr√§nsningsrutor](../../../../../5-retail/lessons/2-check-stock-device)
* [Tr√§na om modellen](../../../../../5-retail/lessons/2-check-stock-device)
* [R√§kna lager](../../../../../5-retail/lessons/2-check-stock-device)

> üóë Detta √§r den sista lektionen i detta projekt, s√• efter att du har slutf√∂rt lektionen och uppgiften, gl√∂m inte att st√§da upp dina molntj√§nster. Du kommer att beh√∂va tj√§nsterna f√∂r att slutf√∂ra uppgiften, s√• se till att g√∂ra det f√∂rst.
>
> Se [guiden f√∂r att st√§da upp ditt projekt](../../../clean-up.md) vid behov f√∂r instruktioner om hur du g√∂r detta.

## Lagerber√§kning

Objektdetektorer kan anv√§ndas f√∂r lagerkontroll, antingen f√∂r att r√§kna lager eller f√∂r att s√§kerst√§lla att lager finns d√§r det ska vara. IoT-enheter med kameror kan placeras runt hela butiken f√∂r att √∂vervaka lager, med b√∂rjan vid hotspots d√§r det √§r viktigt att fylla p√• varor, s√•som omr√•den d√§r sm√• m√§ngder av h√∂gv√§rdesprodukter lagras.

Till exempel, om en kamera pekar p√• en hylla som kan h√•lla 8 burkar tomatpur√©, och en objektdetektor bara uppt√§cker 7 burkar, saknas en och beh√∂ver fyllas p√•.

![7 burkar tomatpur√© p√• en hylla, 4 p√• den √∂vre raden, 3 p√• den nedre](../../../../../translated_images/stock-7-cans-tomato-paste.f86059cc573d7becaa89a0eafb9d2cd7e2fe37405a530fe565990e2333d0e4a1.sv.png)

I bilden ovan har en objektdetektor uppt√§ckt 7 burkar tomatpur√© p√• en hylla som kan h√•lla 8 burkar. IoT-enheten kan inte bara skicka en notifikation om behovet av p√•fyllning, utan kan √§ven ge en indikation om var den saknade varan finns, viktig information om du anv√§nder robotar f√∂r att fylla p√• hyllor.

> üíÅ Beroende p√• butiken och varans popularitet skulle p√•fyllning f√∂rmodligen inte ske om bara 1 burk saknas. Du skulle beh√∂va bygga en algoritm som avg√∂r n√§r p√•fyllning ska ske baserat p√• dina produkter, kunder och andra kriterier.

‚úÖ I vilka andra scenarier skulle du kunna kombinera objektdetektering och robotar?

Ibland kan fel lager finnas p√• hyllorna. Detta kan bero p√• m√§nskliga misstag vid p√•fyllning, eller att kunder √§ndrar sig om ett k√∂p och l√§gger tillbaka en vara p√• f√∂rsta b√§sta plats. N√§r det g√§ller icke-f√§rskvaror som konserver √§r detta en irritation. Om det √§r en f√§rskvara som frysta eller kylda varor kan detta inneb√§ra att produkten inte l√§ngre kan s√§ljas eftersom det kan vara om√∂jligt att avg√∂ra hur l√§nge varan varit utanf√∂r frysen.

Objektdetektering kan anv√§ndas f√∂r att uppt√§cka ov√§ntade varor, och √•terigen varna en m√§nniska eller robot f√∂r att returnera varan s√• snart den uppt√§cks.

![En burk babymajs p√• tomatpur√©hyllan](../../../../../translated_images/stock-rogue-corn.be1f3ada8c4578544641af66671c1711a4c02297f14cc7f503354dae0d30a954.sv.png)

I bilden ovan har en burk babymajs placerats p√• hyllan bredvid tomatpur√©n. Objektdetektorn har uppt√§ckt detta, vilket g√∂r att IoT-enheten kan notifiera en m√§nniska eller robot att returnera burken till dess r√§tta plats.

## Anropa din objektdetektor fr√•n din IoT-enhet

Objektdetektorn du tr√§nade i den senaste lektionen kan anropas fr√•n din IoT-enhet.

### Uppgift - publicera en iteration av din objektdetektor

Iterationer publiceras fr√•n Custom Vision-portalen.

1. √ñppna Custom Vision-portalen p√• [CustomVision.ai](https://customvision.ai) och logga in om du inte redan har den √∂ppen. √ñppna sedan ditt projekt `stock-detector`.

1. V√§lj fliken **Performance** fr√•n alternativen h√∂gst upp.

1. V√§lj den senaste iterationen fr√•n listan *Iterations* p√• sidan.

1. Klicka p√• knappen **Publish** f√∂r iterationen.

    ![Publiceringsknappen](../../../../../translated_images/custom-vision-object-detector-publish-button.34ee379fc650ccb9856c3868d0003f413b9529f102fc73c37168c98d721cc293.sv.png)

1. I dialogrutan *Publish Model*, st√§ll in *Prediction resource* till resursen `stock-detector-prediction` som du skapade i den senaste lektionen. L√•t namnet vara `Iteration2` och klicka p√• knappen **Publish**.

1. N√§r den har publicerats, klicka p√• knappen **Prediction URL**. Detta visar detaljer om prediktions-API:et, och du kommer att beh√∂va dessa f√∂r att anropa modellen fr√•n din IoT-enhet. Den nedre sektionen √§r m√§rkt *If you have an image file*, och det √§r dessa detaljer du vill ha. Ta en kopia av den visade URL:en som kommer att se ut ungef√§r s√• h√§r:

    ```output
    https://<location>.api.cognitive.microsoft.com/customvision/v3.0/Prediction/<id>/detect/iterations/Iteration2/image
    ```

    D√§r `<location>` √§r platsen du anv√§nde n√§r du skapade din Custom Vision-resurs, och `<id>` √§r ett l√•ngt ID best√•ende av bokst√§ver och siffror.

    Ta ocks√• en kopia av v√§rdet *Prediction-Key*. Detta √§r en s√§ker nyckel som du m√•ste skicka n√§r du anropar modellen. Endast applikationer som skickar denna nyckel f√•r anv√§nda modellen, alla andra applikationer avvisas.

    ![Dialogrutan f√∂r prediktions-API som visar URL och nyckel](../../../../../translated_images/custom-vision-prediction-key-endpoint.30c569ffd0338864f319911f052d5e9b8c5066cb0800a26dd6f7ff5713130ad8.sv.png)

‚úÖ N√§r en ny iteration publiceras kommer den att ha ett annat namn. Hur tror du att du skulle √§ndra iterationen som en IoT-enhet anv√§nder?

### Uppgift - anropa din objektdetektor fr√•n din IoT-enhet

F√∂lj relevant guide nedan f√∂r att anv√§nda objektdetektorn fr√•n din IoT-enhet:

* [Arduino - Wio Terminal](wio-terminal-object-detector.md)
* [Enkorts-dator - Raspberry Pi/Virtual device](single-board-computer-object-detector.md)

## Avgr√§nsningsrutor

N√§r du anv√§nder objektdetektorn f√•r du inte bara tillbaka de uppt√§ckta objekten med deras taggar och sannolikheter, utan du f√•r ocks√• avgr√§nsningsrutorna f√∂r objekten. Dessa definierar var objektdetektorn uppt√§ckte objektet med den angivna sannolikheten.

> üíÅ En avgr√§nsningsruta √§r en ruta som definierar omr√•det som inneh√•ller det uppt√§ckta objektet, en ruta som definierar gr√§nsen f√∂r objektet.

Resultaten av en prediktion i fliken **Predictions** i Custom Vision har avgr√§nsningsrutorna ritade p√• bilden som skickades f√∂r prediktion.

![4 burkar tomatpur√© p√• en hylla med prediktioner f√∂r de 4 uppt√§ckterna med 35.8%, 33.5%, 25.7% och 16.6%](../../../../../translated_images/custom-vision-stock-prediction.942266ab1bcca3410ecdf23643b9f5f570cfab2345235074e24c51f285777613.sv.png)

I bilden ovan uppt√§cktes 4 burkar tomatpur√©. I resultaten √§r en r√∂d fyrkant √∂verlagd f√∂r varje objekt som uppt√§cktes i bilden, vilket indikerar avgr√§nsningsrutan f√∂r bilden.

‚úÖ √ñppna prediktionerna i Custom Vision och kolla in avgr√§nsningsrutorna.

Avgr√§nsningsrutor definieras med 4 v√§rden - top, left, height och width. Dessa v√§rden √§r p√• en skala fr√•n 0-1, vilket representerar positionerna som en procentandel av bildens storlek. Ursprungspunkten (positionen 0,0) √§r det √∂vre v√§nstra h√∂rnet av bilden, s√• top-v√§rdet √§r avst√•ndet fr√•n toppen, och botten av avgr√§nsningsrutan √§r top plus height.

![En avgr√§nsningsruta runt en burk tomatpur√©](../../../../../translated_images/bounding-box.1420a7ea0d3d15f71e1ffb5cf4b2271d184fac051f990abc541975168d163684.sv.png)

Bilden ovan √§r 600 pixlar bred och 800 pixlar h√∂g. Avgr√§nsningsrutan b√∂rjar 320 pixlar ner, vilket ger ett top-koordinat p√• 0.4 (800 x 0.4 = 320). Fr√•n v√§nster b√∂rjar avgr√§nsningsrutan 240 pixlar in, vilket ger ett left-koordinat p√• 0.4 (600 x 0.4 = 240). H√∂jden p√• avgr√§nsningsrutan √§r 240 pixlar, vilket ger ett height-v√§rde p√• 0.3 (800 x 0.3 = 240). Bredden p√• avgr√§nsningsrutan √§r 120 pixlar, vilket ger ett width-v√§rde p√• 0.2 (600 x 0.2 = 120).

| Koordinat | V√§rde |
| ---------- | ----: |
| Top        | 0.4   |
| Left       | 0.4   |
| Height     | 0.3   |
| Width      | 0.2   |

Att anv√§nda procentv√§rden fr√•n 0-1 inneb√§r att oavsett vilken storlek bilden skalas till, b√∂rjar avgr√§nsningsrutan 0.4 av v√§gen l√§ngs och ner, och √§r 0.3 av h√∂jden och 0.2 av bredden.

Du kan anv√§nda avgr√§nsningsrutor kombinerat med sannolikheter f√∂r att utv√§rdera hur korrekt en uppt√§ckt √§r. Till exempel kan en objektdetektor uppt√§cka flera objekt som √∂verlappar, till exempel uppt√§cka en burk inuti en annan. Din kod kan titta p√• avgr√§nsningsrutorna, f√∂rst√• att detta √§r om√∂jligt, och ignorera alla objekt som har en betydande √∂verlappning med andra objekt.

![Tv√• avgr√§nsningsrutor som √∂verlappar en burk tomatpur√©](../../../../../translated_images/overlap-object-detection.d431e03cae75072a2760430eca7f2c5fdd43045bfd72dadcbf12711f7cd6c2ae.sv.png)

I exemplet ovan indikerar en avgr√§nsningsruta en f√∂rutsedd burk tomatpur√© med 78.3%. En andra avgr√§nsningsruta √§r n√•got mindre och ligger inuti den f√∂rsta avgr√§nsningsrutan med en sannolikhet p√• 64.3%. Din kod kan kontrollera avgr√§nsningsrutorna, se att de √∂verlappar helt, och ignorera den l√§gre sannolikheten eftersom det inte √§r m√∂jligt att en burk √§r inuti en annan.

‚úÖ Kan du t√§nka dig en situation d√§r det √§r giltigt att uppt√§cka ett objekt inuti ett annat?

## Tr√§na om modellen

Precis som med bildklassificeraren kan du tr√§na om din modell med data som samlats in av din IoT-enhet. Att anv√§nda denna verkliga data kommer att s√§kerst√§lla att din modell fungerar bra n√§r den anv√§nds fr√•n din IoT-enhet.

Till skillnad fr√•n bildklassificeraren kan du inte bara tagga en bild. Ist√§llet m√•ste du granska varje avgr√§nsningsruta som uppt√§ckts av modellen. Om rutan √§r runt fel sak m√•ste den tas bort, om den √§r p√• fel plats m√•ste den justeras.

### Uppgift - tr√§na om modellen

1. Se till att du har samlat in en m√§ngd bilder med din IoT-enhet.

1. Fr√•n fliken **Predictions**, v√§lj en bild. Du kommer att se r√∂da rutor som indikerar avgr√§nsningsrutorna f√∂r de uppt√§ckta objekten.

1. G√• igenom varje avgr√§nsningsruta. V√§lj den f√∂rst s√• ser du en popup som visar taggen. Anv√§nd handtagen i h√∂rnen p√• avgr√§nsningsrutan f√∂r att justera storleken vid behov. Om taggen √§r fel, ta bort den med knappen **X** och l√§gg till r√§tt tagg. Om avgr√§nsningsrutan inte inneh√•ller ett objekt, ta bort den med papperskorgsknappen.

1. St√§ng redigeraren n√§r du √§r klar och bilden flyttas fr√•n fliken **Predictions** till fliken **Training Images**. Upprepa processen f√∂r alla prediktioner.

1. Anv√§nd knappen **Train** f√∂r att tr√§na om din modell. N√§r den har tr√§nats, publicera iterationen och uppdatera din IoT-enhet f√∂r att anv√§nda URL:en f√∂r den nya iterationen.

1. √Öterimplementera din kod och testa din IoT-enhet.

## R√§kna lager

Med en kombination av antalet uppt√§ckta objekt och avgr√§nsningsrutorna kan du r√§kna lagret p√• en hylla.

### Uppgift - r√§kna lager

F√∂lj relevant guide nedan f√∂r att r√§kna lager med resultaten fr√•n objektdetektorn fr√•n din IoT-enhet:

* [Arduino - Wio Terminal](wio-terminal-count-stock.md)
* [Enkorts-dator - Raspberry Pi/Virtual device](single-board-computer-count-stock.md)

---

## üöÄ Utmaning

Kan du uppt√§cka felaktigt lager? Tr√§na din modell p√• flera objekt och uppdatera sedan din app f√∂r att varna dig om fel lager uppt√§cks.

Kanske ta detta √§nnu l√§ngre och uppt√§cka lager sida vid sida p√• samma hylla, och se om n√•got har placerats p√• fel plats genom att definiera gr√§nser f√∂r avgr√§nsningsrutorna.

## Quiz efter f√∂rel√§sningen

[Quiz efter f√∂rel√§sningen](https://black-meadow-040d15503.1.azurestaticapps.net/quiz/40)

## Granskning & Sj√§lvstudier

* L√§s mer om hur man arkitekterar ett end-to-end lagerdetekteringssystem fr√•n [Out of stock detection at the edge pattern guide p√• Microsoft Docs](https://docs.microsoft.com/hybrid/app-solutions/pattern-out-of-stock-at-edge?WT.mc_id=academic-17441-jabenn)
* L√§r dig andra s√§tt att bygga end-to-end l√∂sningar f√∂r detaljhandeln genom att kombinera en rad IoT- och molntj√§nster genom att titta p√• denna [Behind the scenes of a retail solution - Hands On! video p√• YouTube](https://www.youtube.com/watch?v=m3Pc300x2Mw).

## Uppgift

[Anv√§nd din objektdetektor vid kanten](assignment.md)

---

**Ansvarsfriskrivning**:  
Detta dokument har √∂versatts med hj√§lp av AI-√∂vers√§ttningstj√§nsten [Co-op Translator](https://github.com/Azure/co-op-translator). √Ñven om vi str√§var efter noggrannhet, v√§nligen notera att automatiska √∂vers√§ttningar kan inneh√•lla fel eller felaktigheter. Det ursprungliga dokumentet p√• dess originalspr√•k b√∂r betraktas som den auktoritativa k√§llan. F√∂r kritisk information rekommenderas professionell m√§nsklig √∂vers√§ttning. Vi ansvarar inte f√∂r eventuella missf√∂rst√•nd eller feltolkningar som uppst√•r vid anv√§ndning av denna √∂vers√§ttning.