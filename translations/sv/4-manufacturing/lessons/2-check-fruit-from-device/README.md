<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "557f4ee96b752e0651d2e6e74aa6bd14",
  "translation_date": "2025-08-27T20:40:03+00:00",
  "source_file": "4-manufacturing/lessons/2-check-fruit-from-device/README.md",
  "language_code": "sv"
}
-->
# Kontrollera fruktkvalitet med en IoT-enhet

![En sketchnote-√∂versikt av denna lektion](../../../../../translated_images/lesson-16.215daf18b00631fbdfd64c6fc2dc6044dff5d544288825d8076f9fb83d964c23.sv.jpg)

> Sketchnote av [Nitya Narasimhan](https://github.com/nitya). Klicka p√• bilden f√∂r en st√∂rre version.

## Quiz f√∂re f√∂rel√§sningen

[Quiz f√∂re f√∂rel√§sningen](https://black-meadow-040d15503.1.azurestaticapps.net/quiz/31)

## Introduktion

I den senaste lektionen l√§rde du dig om bildklassificerare och hur man tr√§nar dem f√∂r att identifiera bra och d√•lig frukt. F√∂r att anv√§nda denna bildklassificerare i en IoT-applikation beh√∂ver du kunna ta en bild med n√•gon form av kamera och skicka denna bild till molnet f√∂r att klassificeras.

I denna lektion kommer du att l√§ra dig om kamerasensorer och hur man anv√§nder dem med en IoT-enhet f√∂r att ta en bild. Du kommer ocks√• att l√§ra dig hur man anropar bildklassificeraren fr√•n din IoT-enhet.

I denna lektion kommer vi att t√§cka:

* [Kamerasensorer](../../../../../4-manufacturing/lessons/2-check-fruit-from-device)
* [Ta en bild med en IoT-enhet](../../../../../4-manufacturing/lessons/2-check-fruit-from-device)
* [Publicera din bildklassificerare](../../../../../4-manufacturing/lessons/2-check-fruit-from-device)
* [Klassificera bilder fr√•n din IoT-enhet](../../../../../4-manufacturing/lessons/2-check-fruit-from-device)
* [F√∂rb√§ttra modellen](../../../../../4-manufacturing/lessons/2-check-fruit-from-device)

## Kamerasensorer

Kamerasensorer, som namnet antyder, √§r kameror som du kan ansluta till din IoT-enhet. De kan ta stillbilder eller spela in str√∂mmande video. Vissa returnerar r√• bilddata, medan andra komprimerar bilddata till en bildfil som JPEG eller PNG. Vanligtvis √§r kamerorna som fungerar med IoT-enheter mycket mindre och har l√§gre uppl√∂sning √§n vad du kanske √§r van vid, men det finns h√∂guppl√∂sta kameror som kan m√§ta sig med toppmoderna mobiltelefoner. Du kan f√• alla m√∂jliga utbytbara linser, flera kameraupps√§ttningar, infrar√∂da termiska kameror eller UV-kameror.

![Ljuset fr√•n en scen passerar genom en lins och fokuseras p√• en CMOS-sensor](../../../../../translated_images/cmos-sensor.75f9cd74decb137149a4c9ea825251a4549497d67c0ae2776159e6102bb53aa9.sv.png)

De flesta kamerasensorer anv√§nder bildsensorer d√§r varje pixel √§r en fotodiod. En lins fokuserar bilden p√• bildsensorn, och tusentals eller miljoner fotodioder registrerar ljuset som faller p√• var och en och sparar det som pixeldata.

> üíÅ Linser inverterar bilder, och kamerasensorn v√§nder sedan bilden r√§tt igen. Det √§r samma sak med dina √∂gon - det du ser registreras upp och ner p√• baksidan av ditt √∂ga, och din hj√§rna korrigerar det.

> üéì Bildsensorn kallas f√∂r en Active-Pixel Sensor (APS), och den mest popul√§ra typen av APS √§r en komplement√§r metalloxid-halvledarsensor, eller CMOS. Du kanske har h√∂rt termen CMOS-sensor anv√§ndas f√∂r kamerasensorer.

Kamerasensorer √§r digitala sensorer som skickar bilddata som digital data, vanligtvis med hj√§lp av ett bibliotek som tillhandah√•ller kommunikationen. Kameror ansluter med protokoll som SPI f√∂r att kunna skicka stora m√§ngder data - bilder √§r betydligt st√∂rre √§n enstaka siffror fr√•n en sensor, som en temperatursensor.

‚úÖ Vilka begr√§nsningar finns kring bildstorlek med IoT-enheter? T√§nk p√• begr√§nsningarna, s√§rskilt p√• mikrocontroller-h√•rdvara.

## Ta en bild med en IoT-enhet

Du kan anv√§nda din IoT-enhet f√∂r att ta en bild som ska klassificeras.

### Uppgift - ta en bild med en IoT-enhet

F√∂lj den relevanta guiden f√∂r att ta en bild med din IoT-enhet:

* [Arduino - Wio Terminal](wio-terminal-camera.md)
* [Enkorts-dator - Raspberry Pi](pi-camera.md)
* [Enkorts-dator - Virtuell enhet](virtual-device-camera.md)

## Publicera din bildklassificerare

Du tr√§nade din bildklassificerare i den senaste lektionen. Innan du kan anv√§nda den fr√•n din IoT-enhet m√•ste du publicera modellen.

### Modelliterationer

N√§r din modell tr√§nades i den senaste lektionen kanske du m√§rkte att fliken **Prestanda** visar iterationer p√• sidan. N√§r du f√∂rst tr√§nade modellen s√•g du *Iteration 1* under tr√§ning. N√§r du f√∂rb√§ttrade modellen med hj√§lp av f√∂ruts√§gelsebilder s√•g du *Iteration 2* under tr√§ning.

Varje g√•ng du tr√§nar modellen f√•r du en ny iteration. Detta √§r ett s√§tt att h√•lla reda p√• de olika versionerna av din modell som tr√§nats p√• olika dataset. N√§r du g√∂r ett **Snabbtest** finns det en rullgardinsmeny som du kan anv√§nda f√∂r att v√§lja iteration, s√• att du kan j√§mf√∂ra resultaten mellan flera iterationer.

N√§r du √§r n√∂jd med en iteration kan du publicera den f√∂r att g√∂ra den tillg√§nglig f√∂r anv√§ndning fr√•n externa applikationer. P√• s√• s√§tt kan du ha en publicerad version som anv√§nds av dina enheter, och sedan arbeta p√• en ny version √∂ver flera iterationer och publicera den n√§r du √§r n√∂jd med den.

### Uppgift - publicera en iteration

Iterationer publiceras fr√•n Custom Vision-portalen.

1. √ñppna Custom Vision-portalen p√• [CustomVision.ai](https://customvision.ai) och logga in om du inte redan har den √∂ppen. √ñppna sedan ditt projekt `fruit-quality-detector`.

1. V√§lj fliken **Prestanda** fr√•n alternativen h√∂gst upp.

1. V√§lj den senaste iterationen fr√•n listan *Iterationer* p√• sidan.

1. V√§lj knappen **Publicera** f√∂r iterationen.

    ![Publiceringsknappen](../../../../../translated_images/custom-vision-publish-button.b7174e1977b0c33b8b72d4e5b1326c779e0af196f3849d09985ee2d7d5493a39.sv.png)

1. I dialogrutan *Publicera modell*, st√§ll in *F√∂ruts√§gelse-resurs* till resursen `fruit-quality-detector-prediction` som du skapade i den senaste lektionen. L√§mna namnet som `Iteration2` och v√§lj knappen **Publicera**.

1. N√§r den har publicerats, v√§lj knappen **F√∂ruts√§gelse-URL**. Detta visar detaljer om f√∂ruts√§gelse-API:et, och du kommer att beh√∂va dessa f√∂r att anropa modellen fr√•n din IoT-enhet. Den nedre sektionen √§r m√§rkt *Om du har en bildfil*, och detta √§r detaljerna du vill ha. Ta en kopia av URL:en som visas, som kommer att se ut ungef√§r s√• h√§r:

    ```output
    https://<location>.api.cognitive.microsoft.com/customvision/v3.0/Prediction/<id>/classify/iterations/Iteration2/image
    ```

    D√§r `<location>` √§r platsen du anv√§nde n√§r du skapade din Custom Vision-resurs, och `<id>` √§r ett l√•ngt ID best√•ende av bokst√§ver och siffror.

    Ta ocks√• en kopia av v√§rdet *F√∂ruts√§gelse-nyckel*. Detta √§r en s√§ker nyckel som du m√•ste skicka n√§r du anropar modellen. Endast applikationer som skickar denna nyckel f√•r anv√§nda modellen, alla andra applikationer avvisas.

    ![Dialogrutan f√∂r f√∂ruts√§gelse-API som visar URL och nyckel](../../../../../translated_images/custom-vision-prediction-key-endpoint.30c569ffd0338864f319911f052d5e9b8c5066cb0800a26dd6f7ff5713130ad8.sv.png)

‚úÖ N√§r en ny iteration publiceras kommer den att ha ett annat namn. Hur tror du att du skulle √§ndra iterationen som en IoT-enhet anv√§nder?

## Klassificera bilder fr√•n din IoT-enhet

Du kan nu anv√§nda dessa anslutningsdetaljer f√∂r att anropa bildklassificeraren fr√•n din IoT-enhet.

### Uppgift - klassificera bilder fr√•n din IoT-enhet

F√∂lj den relevanta guiden f√∂r att klassificera bilder med din IoT-enhet:

* [Arduino - Wio Terminal](wio-terminal-classify-image.md)
* [Enkorts-dator - Raspberry Pi/Virtuell IoT-enhet](single-board-computer-classify-image.md)

## F√∂rb√§ttra modellen

Du kanske m√§rker att resultaten du f√•r n√§r du anv√§nder kameran ansluten till din IoT-enhet inte matchar vad du f√∂rv√§ntar dig. F√∂ruts√§gelserna √§r inte alltid lika exakta som n√§r du anv√§nder bilder som laddats upp fr√•n din dator. Detta beror p√• att modellen tr√§nades p√• annan data √§n den som anv√§nds f√∂r f√∂ruts√§gelser.

F√∂r att f√• b√§sta resultat f√∂r en bildklassificerare vill du tr√§na modellen med bilder som √§r s√• lika de bilder som anv√§nds f√∂r f√∂ruts√§gelser som m√∂jligt. Om du till exempel anv√§nde din telefonkamera f√∂r att ta bilder f√∂r tr√§ning, kommer bildkvaliteten, sk√§rpan och f√§rgen att skilja sig fr√•n en kamera ansluten till en IoT-enhet.

![2 bananbilder, en l√•guppl√∂st med d√•lig belysning fr√•n en IoT-enhet, och en h√∂guppl√∂st med bra belysning fr√•n en telefon](../../../../../translated_images/banana-picture-compare.174df164dc326a42cf7fb051a7497e6113c620e91552d92ca914220305d47d9a.sv.png)

I bilden ovan togs bananbilden till v√§nster med en Raspberry Pi-kamera, medan den till h√∂ger togs av samma banan p√• samma plats med en iPhone. Det √§r en m√§rkbar skillnad i kvalitet - iPhone-bilden √§r skarpare, med ljusare f√§rger och mer kontrast.

‚úÖ Vad kan annars orsaka att bilder som tas av din IoT-enhet ger felaktiga f√∂ruts√§gelser? T√§nk p√• milj√∂n d√§r en IoT-enhet kan anv√§ndas, vilka faktorer kan p√•verka bilden som tas?

F√∂r att f√∂rb√§ttra modellen kan du tr√§na om den med bilder som tagits fr√•n IoT-enheten.

### Uppgift - f√∂rb√§ttra modellen

1. Klassificera flera bilder av b√•de mogen och omogen frukt med din IoT-enhet.

1. I Custom Vision-portalen, tr√§na om modellen med bilderna p√• fliken *F√∂ruts√§gelser*.

    > ‚ö†Ô∏è Du kan h√§nvisa till [instruktionerna f√∂r att tr√§na om din klassificerare i lektion 1 om det beh√∂vs](../1-train-fruit-detector/README.md#retrain-your-image-classifier).

1. Om dina bilder ser v√§ldigt olika ut j√§mf√∂rt med de ursprungliga som anv√§ndes f√∂r tr√§ning, kan du ta bort alla ursprungliga bilder genom att v√§lja dem p√• fliken *Tr√§ningsbilder* och v√§lja knappen **Ta bort**. F√∂r att v√§lja en bild, flytta mark√∂ren √∂ver den och en bock visas, v√§lj den bocken f√∂r att v√§lja eller avmarkera bilden.

1. Tr√§na en ny iteration av modellen och publicera den med stegen ovan.

1. Uppdatera endpoint-URL:en i din kod och k√∂r appen igen.

1. Upprepa dessa steg tills du √§r n√∂jd med resultaten av f√∂ruts√§gelserna.

---

## üöÄ Utmaning

Hur mycket p√•verkar bilduppl√∂sning eller belysning f√∂ruts√§gelsen?

Prova att √§ndra uppl√∂sningen p√• bilderna i din enhetskod och se om det g√∂r n√•gon skillnad f√∂r bildkvaliteten. Prova ocks√• att √§ndra belysningen.

Om du skulle skapa en produktionsenhet att s√§lja till g√•rdar eller fabriker, hur skulle du s√§kerst√§lla att den ger konsekventa resultat hela tiden?

## Quiz efter f√∂rel√§sningen

[Quiz efter f√∂rel√§sningen](https://black-meadow-040d15503.1.azurestaticapps.net/quiz/32)

## Granskning & Sj√§lvstudier

Du tr√§nade din Custom Vision-modell med hj√§lp av portalen. Detta f√∂ruts√§tter att du har tillg√•ng till bilder - och i verkligheten kanske du inte kan f√• tr√§ningsdata som matchar vad kameran p√• din enhet f√•ngar. Du kan kringg√• detta genom att tr√§na direkt fr√•n din enhet med hj√§lp av tr√§nings-API:et, f√∂r att tr√§na en modell med bilder som tagits fr√•n din IoT-enhet.

* L√§s om tr√§nings-API:et i [snabbstarten f√∂r att anv√§nda Custom Vision SDK](https://docs.microsoft.com/azure/cognitive-services/custom-vision-service/quickstarts/image-classification?WT.mc_id=academic-17441-jabenn&tabs=visual-studio&pivots=programming-language-python)

## Uppgift

[Reagera p√• klassificeringsresultat](assignment.md)

---

**Ansvarsfriskrivning**:  
Detta dokument har √∂versatts med hj√§lp av AI-√∂vers√§ttningstj√§nsten [Co-op Translator](https://github.com/Azure/co-op-translator). √Ñven om vi str√§var efter noggrannhet, b√∂r du vara medveten om att automatiserade √∂vers√§ttningar kan inneh√•lla fel eller felaktigheter. Det ursprungliga dokumentet p√• dess ursprungliga spr√•k b√∂r betraktas som den auktoritativa k√§llan. F√∂r kritisk information rekommenderas professionell m√§nsklig √∂vers√§ttning. Vi ansvarar inte f√∂r eventuella missf√∂rst√•nd eller feltolkningar som uppst√•r vid anv√§ndning av denna √∂vers√§ttning.