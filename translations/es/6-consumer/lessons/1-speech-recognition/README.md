<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "6d6aa1be033625d201a190fc9c5cbfb4",
  "translation_date": "2025-08-26T15:35:19+00:00",
  "source_file": "6-consumer/lessons/1-speech-recognition/README.md",
  "language_code": "es"
}
-->
# Reconocer voz con un dispositivo IoT

![Una visi√≥n general ilustrada de esta lecci√≥n](../../../../../translated_images/lesson-21.e34de51354d6606fb5ee08d8c89d0222eea0a2a7aaf744a8805ae847c4f69dc4.es.jpg)

> Ilustraci√≥n por [Nitya Narasimhan](https://github.com/nitya). Haz clic en la imagen para una versi√≥n m√°s grande.

Este video ofrece una visi√≥n general del servicio de voz de Azure, un tema que se cubrir√° en esta lecci√≥n:

[![C√≥mo empezar a usar tu recurso de Cognitive Services Speech desde el canal de YouTube de Microsoft Azure](https://img.youtube.com/vi/iW0Fw0l3mrA/0.jpg)](https://www.youtube.com/watch?v=iW0Fw0l3mrA)

> üé• Haz clic en la imagen de arriba para ver el video

## Cuestionario previo a la lecci√≥n

[Cuestionario previo a la lecci√≥n](https://black-meadow-040d15503.1.azurestaticapps.net/quiz/41)

## Introducci√≥n

'Alexa, pon un temporizador de 12 minutos'

'Alexa, estado del temporizador'

'Alexa, pon un temporizador de 8 minutos llamado br√≥coli al vapor'

Los dispositivos inteligentes est√°n volvi√©ndose cada vez m√°s comunes. No solo como altavoces inteligentes como HomePods, Echos y Google Homes, sino tambi√©n integrados en nuestros tel√©fonos, relojes, e incluso en l√°mparas y termostatos.

> üíÅ Tengo al menos 19 dispositivos en mi casa que tienen asistentes de voz, ¬°y eso es solo los que conozco!

El control por voz aumenta la accesibilidad al permitir que personas con movilidad limitada interact√∫en con dispositivos. Ya sea una discapacidad permanente como haber nacido sin brazos, una discapacidad temporal como brazos rotos, o simplemente tener las manos ocupadas con compras o ni√±os peque√±os, poder controlar nuestra casa con la voz en lugar de las manos abre un mundo de posibilidades. Gritar 'Hey Siri, cierra la puerta del garaje' mientras lidias con un cambio de pa√±al y un ni√±o inquieto puede ser una peque√±a pero efectiva mejora en la vida.

Uno de los usos m√°s populares de los asistentes de voz es configurar temporizadores, especialmente temporizadores de cocina. Poder configurar m√∫ltiples temporizadores solo con tu voz es de gran ayuda en la cocina: no necesitas detenerte a amasar masa, revolver sopa o limpiar tus manos llenas de relleno de dumplings para usar un temporizador f√≠sico.

En esta lecci√≥n aprender√°s a integrar el reconocimiento de voz en dispositivos IoT. Aprender√°s sobre los micr√≥fonos como sensores, c√≥mo capturar audio desde un micr√≥fono conectado a un dispositivo IoT, y c√≥mo usar IA para convertir lo que se escucha en texto. A lo largo del resto de este proyecto construir√°s un temporizador de cocina inteligente, capaz de configurar temporizadores usando tu voz en m√∫ltiples idiomas.

En esta lecci√≥n cubriremos:

* [Micr√≥fonos](../../../../../6-consumer/lessons/1-speech-recognition)
* [Capturar audio desde tu dispositivo IoT](../../../../../6-consumer/lessons/1-speech-recognition)
* [De voz a texto](../../../../../6-consumer/lessons/1-speech-recognition)
* [Convertir voz a texto](../../../../../6-consumer/lessons/1-speech-recognition)

## Micr√≥fonos

Los micr√≥fonos son sensores anal√≥gicos que convierten las ondas sonoras en se√±ales el√©ctricas. Las vibraciones en el aire hacen que los componentes del micr√≥fono se muevan peque√±as cantidades, lo que provoca cambios min√∫sculos en las se√±ales el√©ctricas. Estos cambios se amplifican para generar una salida el√©ctrica.

### Tipos de micr√≥fonos

Los micr√≥fonos vienen en una variedad de tipos:

* Din√°micos - Los micr√≥fonos din√°micos tienen un im√°n unido a un diafragma m√≥vil que se mueve en una bobina de alambre creando una corriente el√©ctrica. Esto es lo opuesto a la mayor√≠a de los altavoces, que usan una corriente el√©ctrica para mover un im√°n en una bobina de alambre, moviendo un diafragma para crear sonido. Esto significa que los altavoces pueden usarse como micr√≥fonos din√°micos, y los micr√≥fonos din√°micos pueden usarse como altavoces. En dispositivos como intercomunicadores, donde un usuario est√° escuchando o hablando, pero no ambos, un dispositivo puede actuar como altavoz y micr√≥fono.

    Los micr√≥fonos din√°micos no necesitan energ√≠a para funcionar, la se√±al el√©ctrica se genera completamente desde el micr√≥fono.

    ![Patti Smith cantando en un micr√≥fono Shure SM58 (tipo cardioide din√°mico)](../../../../../translated_images/dynamic-mic.8babac890a2d80dfb0874b5bf37d4b851fe2aeb9da6fd72945746176978bf3bb.es.jpg)

* De cinta - Los micr√≥fonos de cinta son similares a los din√°micos, excepto que tienen una cinta met√°lica en lugar de un diafragma. Esta cinta se mueve en un campo magn√©tico generando una corriente el√©ctrica. Al igual que los micr√≥fonos din√°micos, los de cinta no necesitan energ√≠a para funcionar.

    ![Edmund Lowe, actor estadounidense, de pie frente a un micr√≥fono de radio (etiquetado para la Red Azul de NBC), sosteniendo un guion, 1942](../../../../../translated_images/ribbon-mic.eacc8e092c7441caee6d7a81e2f40e1675bf36269848964c7c09c9a9acb05127.es.jpg)

* Condensador - Los micr√≥fonos de condensador tienen un diafragma met√°lico delgado y una placa trasera met√°lica fija. Se aplica electricidad a ambos, y a medida que el diafragma vibra, la carga est√°tica entre las placas cambia generando una se√±al. Los micr√≥fonos de condensador necesitan energ√≠a para funcionar, llamada *Phantom power*.

    ![Micr√≥fono de condensador de diafragma peque√±o C451B de AKG Acoustics](../../../../../translated_images/condenser-mic.6f6ed5b76ca19e0ec3fd0c544601542d4479a6cb7565db336de49fbbf69f623e.es.jpg)

* MEMS - Los micr√≥fonos de sistemas microelectromec√°nicos, o MEMS, son micr√≥fonos en un chip. Tienen un diafragma sensible a la presi√≥n grabado en un chip de silicio, y funcionan de manera similar a un micr√≥fono de condensador. Estos micr√≥fonos pueden ser diminutos e integrarse en circuitos.

    ![Un micr√≥fono MEMS en una placa de circuito](../../../../../translated_images/mems-microphone.80574019e1f5e4d9ee72fed720ecd25a39fc2969c91355d17ebb24ba4159e4c4.es.png)

    En la imagen de arriba, el chip etiquetado como **LEFT** es un micr√≥fono MEMS, con un diafragma diminuto de menos de un mil√≠metro de ancho.

‚úÖ Investiga: ¬øQu√© micr√≥fonos tienes a tu alrededor, ya sea en tu computadora, tu tel√©fono, tus auriculares o en otros dispositivos? ¬øQu√© tipo de micr√≥fonos son?

### Audio digital

El audio es una se√±al anal√≥gica que transporta informaci√≥n muy detallada. Para convertir esta se√±al en digital, el audio debe ser muestreado miles de veces por segundo.

> üéì Muestrear significa convertir la se√±al de audio en un valor digital que representa la se√±al en ese momento.

![Un gr√°fico de l√≠neas que muestra una se√±al, con puntos discretos en intervalos fijos](../../../../../translated_images/sampling.6f4fadb3f2d9dfe7618f9edfe75a350e6b3f74293ec84f02ab69c19d2afe3d73.es.png)

El audio digital se muestrea utilizando Modulaci√≥n por C√≥digo de Pulsos, o PCM. PCM implica leer el voltaje de la se√±al y seleccionar el valor discreto m√°s cercano a ese voltaje utilizando un tama√±o definido.

> üíÅ Puedes pensar en PCM como la versi√≥n de sensor de la modulaci√≥n por ancho de pulso, o PWM (PWM se cubri√≥ en [la lecci√≥n 3 del proyecto de introducci√≥n](../../../1-getting-started/lessons/3-sensors-and-actuators/README.md#pulse-width-modulation)). PCM implica convertir una se√±al anal√≥gica a digital, PWM implica convertir una se√±al digital a anal√≥gica.

Por ejemplo, la mayor√≠a de los servicios de m√∫sica en streaming ofrecen audio de 16 bits o 24 bits. Esto significa que convierten el voltaje en un valor que cabe en un entero de 16 bits o 24 bits. El audio de 16 bits ajusta el valor en un rango de -32,768 a 32,767, el de 24 bits en el rango ‚àí8,388,608 a 8,388,607. Cuantos m√°s bits, m√°s cerca estar√° la muestra de lo que realmente escuchan nuestros o√≠dos.

> üíÅ Tal vez hayas o√≠do hablar del audio de 8 bits, a menudo referido como LoFi. Este es audio muestreado usando solo 8 bits, es decir, -128 a 127. El primer audio de computadora estaba limitado a 8 bits debido a limitaciones de hardware, por lo que a menudo se ve en juegos retro.

Estas muestras se toman miles de veces por segundo, utilizando tasas de muestreo bien definidas medidas en KHz (miles de lecturas por segundo). Los servicios de m√∫sica en streaming usan 48KHz para la mayor√≠a del audio, pero algunos audios 'sin p√©rdida' usan hasta 96KHz o incluso 192KHz. Cuanto mayor sea la tasa de muestreo, m√°s cerca estar√° el audio del original, hasta cierto punto. Existe debate sobre si los humanos pueden notar la diferencia por encima de los 48KHz.

‚úÖ Investiga: Si usas un servicio de m√∫sica en streaming, ¬øqu√© tasa de muestreo y tama√±o utiliza? Si usas CDs, ¬øcu√°l es la tasa de muestreo y tama√±o del audio en CD?

Existen varios formatos diferentes para datos de audio. Probablemente hayas o√≠do hablar de archivos mp3: datos de audio comprimidos para hacerlos m√°s peque√±os sin perder calidad. El audio sin comprimir a menudo se almacena como un archivo WAV: este es un archivo con 44 bytes de informaci√≥n de encabezado, seguido de datos de audio sin procesar. El encabezado contiene informaci√≥n como la tasa de muestreo (por ejemplo, 16000 para 16KHz) y el tama√±o de la muestra (16 para 16 bits), y el n√∫mero de canales. Despu√©s del encabezado, el archivo WAV contiene los datos de audio sin procesar.

> üéì Los canales se refieren a cu√°ntos flujos de audio diferentes conforman el audio. Por ejemplo, para audio est√©reo con izquierda y derecha, habr√≠a 2 canales. Para sonido envolvente 7.1 en un sistema de cine en casa, ser√≠an 8.

### Tama√±o de los datos de audio

Los datos de audio son relativamente grandes. Por ejemplo, capturar audio sin comprimir de 16 bits a 16KHz (una tasa suficientemente buena para usar con un modelo de voz a texto) requiere 32KB de datos por cada segundo de audio:

* 16 bits significa 2 bytes por muestra (1 byte son 8 bits).
* 16KHz son 16,000 muestras por segundo.
* 16,000 x 2 bytes = 32,000 bytes por segundo.

Esto puede parecer una peque√±a cantidad de datos, pero si est√°s usando un microcontrolador con memoria limitada, puede ser mucho. Por ejemplo, el Wio Terminal tiene 192KB de memoria, y esa memoria debe almacenar el c√≥digo del programa y las variables. Incluso si tu c√≥digo de programa fuera diminuto, no podr√≠as capturar m√°s de 5 segundos de audio.

Los microcontroladores pueden acceder a almacenamiento adicional, como tarjetas SD o memoria flash. Al construir un dispositivo IoT que capture audio, necesitar√°s asegurarte de que no solo tienes almacenamiento adicional, sino que tu c√≥digo escribe el audio capturado desde tu micr√≥fono directamente en ese almacenamiento, y al enviarlo a la nube, lo transmite desde el almacenamiento a la solicitud web. De esta manera, puedes evitar quedarte sin memoria al intentar mantener todo el bloque de datos de audio en la memoria a la vez.

## Capturar audio desde tu dispositivo IoT

Tu dispositivo IoT puede conectarse a un micr√≥fono para capturar audio, listo para convertirlo en texto. Tambi√©n puede conectarse a altavoces para emitir audio. En lecciones posteriores, esto se usar√° para dar retroalimentaci√≥n de audio, pero es √∫til configurar los altavoces ahora para probar el micr√≥fono.

### Tarea - configurar tu micr√≥fono y altavoces

Sigue la gu√≠a correspondiente para configurar el micr√≥fono y los altavoces de tu dispositivo IoT:

* [Arduino - Wio Terminal](wio-terminal-microphone.md)
* [Computadora de placa √∫nica - Raspberry Pi](pi-microphone.md)
* [Computadora de placa √∫nica - Dispositivo virtual](virtual-device-microphone.md)

### Tarea - capturar audio

Sigue la gu√≠a correspondiente para capturar audio en tu dispositivo IoT:

* [Arduino - Wio Terminal](wio-terminal-audio.md)
* [Computadora de placa √∫nica - Raspberry Pi](pi-audio.md)
* [Computadora de placa √∫nica - Dispositivo virtual](virtual-device-audio.md)

## De voz a texto

De voz a texto, o reconocimiento de voz, implica usar IA para convertir palabras en una se√±al de audio a texto.

### Modelos de reconocimiento de voz

Para convertir voz a texto, las muestras de la se√±al de audio se agrupan y se alimentan a un modelo de aprendizaje autom√°tico basado en una red neuronal recurrente (RNN). Este es un tipo de modelo de aprendizaje autom√°tico que puede usar datos previos para tomar decisiones sobre datos entrantes. Por ejemplo, la RNN podr√≠a detectar un bloque de muestras de audio como el sonido 'Hel', y cuando recibe otro que cree que es el sonido 'lo', puede combinar esto con el sonido anterior, encontrar que 'Hello' es una palabra v√°lida y seleccionarla como resultado.

Los modelos de aprendizaje autom√°tico siempre aceptan datos del mismo tama√±o cada vez. El clasificador de im√°genes que construiste en una lecci√≥n anterior redimensiona las im√°genes a un tama√±o fijo y las procesa. Lo mismo ocurre con los modelos de voz, tienen que procesar bloques de audio de tama√±o fijo. Los modelos de voz necesitan poder combinar los resultados de m√∫ltiples predicciones para obtener la respuesta, lo que les permite distinguir entre 'Hi' y 'Highway', o 'flock' y 'floccinaucinihilipilification'.

Los modelos de voz tambi√©n son lo suficientemente avanzados como para entender el contexto y pueden corregir las palabras que detectan a medida que se procesan m√°s sonidos. Por ejemplo, si dices "Fui a las tiendas a comprar dos pl√°tanos y una manzana tambi√©n", usar√≠as tres palabras que suenan igual pero se escriben diferente: to, two y too. Los modelos de voz son capaces de entender el contexto y usar la ortograf√≠a adecuada de la palabra.
üíÅ Algunos servicios de voz permiten personalizaci√≥n para que funcionen mejor en entornos ruidosos como f√°bricas, o con palabras espec√≠ficas de la industria, como nombres de productos qu√≠micos. Estas personalizaciones se entrenan proporcionando audio de muestra y una transcripci√≥n, y funcionan mediante aprendizaje por transferencia, de la misma manera que entrenaste un clasificador de im√°genes utilizando solo unas pocas im√°genes en una lecci√≥n anterior.
### Privacidad

Cuando se utiliza la conversi√≥n de voz a texto en un dispositivo IoT para consumidores, la privacidad es incre√≠blemente importante. Estos dispositivos escuchan audio de manera continua, por lo que, como consumidor, no quieres que todo lo que dices se env√≠e a la nube y se convierta en texto. Esto no solo consumir√≠a mucho ancho de banda de Internet, sino que tambi√©n tiene enormes implicaciones de privacidad, especialmente cuando algunos fabricantes de dispositivos inteligentes seleccionan aleatoriamente audio para [que humanos lo validen contra el texto generado para ayudar a mejorar su modelo](https://www.theverge.com/2019/4/10/18305378/amazon-alexa-ai-voice-assistant-annotation-listen-private-recordings).

Solo quieres que tu dispositivo inteligente env√≠e audio a la nube para su procesamiento cuando lo est√°s utilizando, no cuando escucha audio en tu hogar, audio que podr√≠a incluir reuniones privadas o interacciones √≠ntimas. La forma en que la mayor√≠a de los dispositivos inteligentes funcionan es con una *palabra de activaci√≥n*, una frase clave como "Alexa", "Hey Siri" o "OK Google" que hace que el dispositivo 'despierte' y escuche lo que est√°s diciendo hasta que detecta una pausa en tu discurso, indicando que has terminado de hablar con el dispositivo.

> üéì La detecci√≥n de palabras de activaci√≥n tambi√©n se conoce como *detecci√≥n de palabras clave* o *reconocimiento de palabras clave*.

Estas palabras de activaci√≥n se detectan en el dispositivo, no en la nube. Estos dispositivos inteligentes tienen peque√±os modelos de IA que funcionan en el dispositivo y que escuchan la palabra de activaci√≥n, y cuando se detecta, comienzan a transmitir el audio a la nube para su reconocimiento. Estos modelos est√°n muy especializados y solo escuchan la palabra de activaci√≥n.

> üíÅ Algunas empresas tecnol√≥gicas est√°n a√±adiendo m√°s privacidad a sus dispositivos y realizando parte de la conversi√≥n de voz a texto en el propio dispositivo. Apple anunci√≥ que, como parte de sus actualizaciones de iOS y macOS en 2021, soportar√°n la conversi√≥n de voz a texto en el dispositivo y podr√°n manejar muchas solicitudes sin necesidad de usar la nube. Esto es posible gracias a los potentes procesadores en sus dispositivos que pueden ejecutar modelos de aprendizaje autom√°tico.

‚úÖ ¬øCu√°les crees que son las implicaciones √©ticas y de privacidad de almacenar el audio enviado a la nube? ¬øDeber√≠a almacenarse este audio, y si es as√≠, c√≥mo? ¬øCrees que el uso de grabaciones para la aplicaci√≥n de la ley es un buen intercambio por la p√©rdida de privacidad?

La detecci√≥n de palabras de activaci√≥n generalmente utiliza una t√©cnica conocida como TinyML, que consiste en convertir modelos de aprendizaje autom√°tico para que puedan ejecutarse en microcontroladores. Estos modelos son peque√±os en tama√±o y consumen muy poca energ√≠a para funcionar.

Para evitar la complejidad de entrenar y usar un modelo de palabras de activaci√≥n, el temporizador inteligente que est√°s construyendo en esta lecci√≥n utilizar√° un bot√≥n para activar el reconocimiento de voz.

> üíÅ Si quieres intentar crear un modelo de detecci√≥n de palabras de activaci√≥n para ejecutarlo en el Wio Terminal o Raspberry Pi, consulta este [tutorial de respuesta a tu voz de Edge Impulse](https://docs.edgeimpulse.com/docs/responding-to-your-voice). Si deseas usar tu computadora para hacerlo, puedes probar el [inicio r√°pido de palabras clave personalizadas en la documentaci√≥n de Microsoft](https://docs.microsoft.com/azure/cognitive-services/speech-service/keyword-recognition-overview?WT.mc_id=academic-17441-jabenn).

## Convertir voz a texto

![Logotipo de servicios de voz](../../../../../translated_images/azure-speech-logo.a1f08c4befb0159f2cb5d692d3baf5b599e7b44759d316da907bda1508f46a4a.es.png)

Al igual que con la clasificaci√≥n de im√°genes en un proyecto anterior, existen servicios de IA preconstruidos que pueden tomar voz como archivo de audio y convertirla en texto. Uno de estos servicios es el Servicio de Voz, parte de los Servicios Cognitivos, servicios de IA preconstruidos que puedes usar en tus aplicaciones.

### Tarea - configurar un recurso de IA de voz

1. Crea un Grupo de Recursos para este proyecto llamado `smart-timer`.

1. Usa el siguiente comando para crear un recurso de voz gratuito:

    ```sh
    az cognitiveservices account create --name smart-timer \
                                        --resource-group smart-timer \
                                        --kind SpeechServices \
                                        --sku F0 \
                                        --yes \
                                        --location <location>
    ```

    Sustituye `<location>` por la ubicaci√≥n que utilizaste al crear el Grupo de Recursos.

1. Necesitar√°s una clave de API para acceder al recurso de voz desde tu c√≥digo. Ejecuta el siguiente comando para obtener la clave:

    ```sh
    az cognitiveservices account keys list --name smart-timer \
                                           --resource-group smart-timer \
                                           --output table
    ```

    Copia una de las claves.

### Tarea - convertir voz a texto

Sigue la gu√≠a correspondiente para convertir voz a texto en tu dispositivo IoT:

* [Arduino - Wio Terminal](wio-terminal-speech-to-text.md)
* [Computadora de placa √∫nica - Raspberry Pi](pi-speech-to-text.md)
* [Computadora de placa √∫nica - Dispositivo virtual](virtual-device-speech-to-text.md)

---

## üöÄ Desaf√≠o

El reconocimiento de voz ha existido durante mucho tiempo y est√° mejorando continuamente. Investiga las capacidades actuales y compara c√≥mo han evolucionado con el tiempo, incluyendo qu√© tan precisas son las transcripciones autom√°ticas en comparaci√≥n con las humanas.

¬øQu√© crees que depara el futuro para el reconocimiento de voz?

## Cuestionario posterior a la clase

[Cuestionario posterior a la clase](https://black-meadow-040d15503.1.azurestaticapps.net/quiz/42)

## Revisi√≥n y autoestudio

* Lee sobre los diferentes tipos de micr√≥fonos y c√≥mo funcionan en el [art√≠culo sobre las diferencias entre micr√≥fonos din√°micos y de condensador en Musician's HQ](https://musicianshq.com/whats-the-difference-between-dynamic-and-condenser-microphones/).
* Lee m√°s sobre el servicio de voz de los Servicios Cognitivos en la [documentaci√≥n del servicio de voz en Microsoft Docs](https://docs.microsoft.com/azure/cognitive-services/speech-service/?WT.mc_id=academic-17441-jabenn).
* Lee sobre la detecci√≥n de palabras clave en la [documentaci√≥n de reconocimiento de palabras clave en Microsoft Docs](https://docs.microsoft.com/azure/cognitive-services/speech-service/keyword-recognition-overview?WT.mc_id=academic-17441-jabenn).

## Asignaci√≥n

[](assignment.md)

---

**Descargo de responsabilidad**:  
Este documento ha sido traducido utilizando el servicio de traducci√≥n autom√°tica [Co-op Translator](https://github.com/Azure/co-op-translator). Aunque nos esforzamos por garantizar la precisi√≥n, tenga en cuenta que las traducciones automatizadas pueden contener errores o imprecisiones. El documento original en su idioma nativo debe considerarse como la fuente autorizada. Para informaci√≥n cr√≠tica, se recomienda una traducci√≥n profesional realizada por humanos. No nos hacemos responsables de malentendidos o interpretaciones err√≥neas que puedan surgir del uso de esta traducci√≥n.