<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "557f4ee96b752e0651d2e6e74aa6bd14",
  "translation_date": "2025-08-26T14:10:00+00:00",
  "source_file": "4-manufacturing/lessons/2-check-fruit-from-device/README.md",
  "language_code": "es"
}
-->
# Verificar la calidad de la fruta desde un dispositivo IoT

![Un resumen visual de esta lecci√≥n](../../../../../translated_images/lesson-16.215daf18b00631fbdfd64c6fc2dc6044dff5d544288825d8076f9fb83d964c23.es.jpg)

> Resumen visual por [Nitya Narasimhan](https://github.com/nitya). Haz clic en la imagen para una versi√≥n m√°s grande.

## Cuestionario previo a la lecci√≥n

[Cuestionario previo a la lecci√≥n](https://black-meadow-040d15503.1.azurestaticapps.net/quiz/31)

## Introducci√≥n

En la lecci√≥n anterior aprendiste sobre clasificadores de im√°genes y c√≥mo entrenarlos para detectar frutas buenas y malas. Para usar este clasificador de im√°genes en una aplicaci√≥n IoT, necesitas capturar una imagen con alg√∫n tipo de c√°mara y enviarla a la nube para ser clasificada.

En esta lecci√≥n aprender√°s sobre sensores de c√°mara y c√≥mo usarlos con un dispositivo IoT para capturar una imagen. Tambi√©n aprender√°s c√≥mo llamar al clasificador de im√°genes desde tu dispositivo IoT.

En esta lecci√≥n cubriremos:

* [Sensores de c√°mara](../../../../../4-manufacturing/lessons/2-check-fruit-from-device)
* [Capturar una imagen usando un dispositivo IoT](../../../../../4-manufacturing/lessons/2-check-fruit-from-device)
* [Publicar tu clasificador de im√°genes](../../../../../4-manufacturing/lessons/2-check-fruit-from-device)
* [Clasificar im√°genes desde tu dispositivo IoT](../../../../../4-manufacturing/lessons/2-check-fruit-from-device)
* [Mejorar el modelo](../../../../../4-manufacturing/lessons/2-check-fruit-from-device)

## Sensores de c√°mara

Los sensores de c√°mara, como su nombre lo indica, son c√°maras que puedes conectar a tu dispositivo IoT. Pueden tomar im√°genes fijas o capturar video en streaming. Algunos devuelven datos de imagen sin procesar, mientras que otros comprimen los datos en un archivo de imagen como JPEG o PNG. Por lo general, las c√°maras que funcionan con dispositivos IoT son mucho m√°s peque√±as y de menor resoluci√≥n que las que podr√≠as estar acostumbrado a usar, aunque tambi√©n puedes encontrar c√°maras de alta resoluci√≥n que rivalizan con los mejores tel√©fonos. Adem√°s, puedes obtener lentes intercambiables, configuraciones de m√∫ltiples c√°maras, c√°maras t√©rmicas infrarrojas o c√°maras UV.

![La luz de una escena pasa a trav√©s de una lente y se enfoca en un sensor CMOS](../../../../../translated_images/cmos-sensor.75f9cd74decb137149a4c9ea825251a4549497d67c0ae2776159e6102bb53aa9.es.png)

La mayor√≠a de los sensores de c√°mara utilizan sensores de imagen donde cada p√≠xel es un fotodiodo. Una lente enfoca la imagen en el sensor de imagen, y miles o millones de fotodiodos detectan la luz que incide en cada uno, registr√°ndola como datos de p√≠xeles.

> üíÅ Las lentes invierten las im√°genes, y el sensor de la c√°mara las voltea nuevamente para que queden en la orientaci√≥n correcta. Esto es similar a lo que ocurre en tus ojos: lo que ves se detecta al rev√©s en la parte posterior de tu ojo, y tu cerebro lo corrige.

> üéì El sensor de imagen se conoce como Sensor de P√≠xel Activo (APS), y el tipo m√°s popular de APS es un sensor de semiconductor complementario de √≥xido met√°lico, o CMOS. Es posible que hayas escuchado el t√©rmino sensor CMOS para referirse a los sensores de c√°mara.

Los sensores de c√°mara son digitales, enviando datos de imagen como datos digitales, generalmente con la ayuda de una biblioteca que facilita la comunicaci√≥n. Las c√°maras se conectan utilizando protocolos como SPI para permitirles enviar grandes cantidades de datos, ya que las im√°genes son sustancialmente m√°s grandes que los datos de un solo n√∫mero de un sensor, como un sensor de temperatura.

‚úÖ ¬øCu√°les son las limitaciones en cuanto al tama√±o de las im√°genes en dispositivos IoT? Piensa en las restricciones, especialmente en el hardware de microcontroladores.

## Capturar una imagen usando un dispositivo IoT

Puedes usar tu dispositivo IoT para capturar una imagen que ser√° clasificada.

### Tarea - capturar una imagen usando un dispositivo IoT

Sigue la gu√≠a correspondiente para capturar una imagen usando tu dispositivo IoT:

* [Arduino - Wio Terminal](wio-terminal-camera.md)
* [Computadora de placa √∫nica - Raspberry Pi](pi-camera.md)
* [Computadora de placa √∫nica - Dispositivo virtual](virtual-device-camera.md)

## Publicar tu clasificador de im√°genes

Entrenaste tu clasificador de im√°genes en la lecci√≥n anterior. Antes de poder usarlo desde tu dispositivo IoT, necesitas publicar el modelo.

### Iteraciones del modelo

Cuando tu modelo se entren√≥ en la lecci√≥n anterior, es posible que hayas notado que la pesta√±a **Performance** muestra iteraciones en el lado. Cuando entrenaste el modelo por primera vez, habr√≠as visto *Iteration 1* en entrenamiento. Cuando mejoraste el modelo usando las im√°genes de predicci√≥n, habr√≠as visto *Iteration 2* en entrenamiento.

Cada vez que entrenas el modelo, obtienes una nueva iteraci√≥n. Esto sirve para realizar un seguimiento de las diferentes versiones de tu modelo entrenadas con diferentes conjuntos de datos. Cuando realizas una **Quick Test**, hay un men√∫ desplegable que puedes usar para seleccionar la iteraci√≥n y comparar los resultados entre m√∫ltiples iteraciones.

Cuando est√©s satisfecho con una iteraci√≥n, puedes publicarla para que est√© disponible para ser utilizada desde aplicaciones externas. De esta manera, puedes tener una versi√≥n publicada que sea utilizada por tus dispositivos, mientras trabajas en una nueva versi√≥n a lo largo de m√∫ltiples iteraciones, y luego publicarla cuando est√©s satisfecho con ella.

### Tarea - publicar una iteraci√≥n

Las iteraciones se publican desde el portal de Custom Vision.

1. Abre el portal de Custom Vision en [CustomVision.ai](https://customvision.ai) e inicia sesi√≥n si no lo tienes abierto ya. Luego abre tu proyecto `fruit-quality-detector`.

1. Selecciona la pesta√±a **Performance** de las opciones en la parte superior.

1. Selecciona la √∫ltima iteraci√≥n de la lista *Iterations* en el lado.

1. Haz clic en el bot√≥n **Publish** para la iteraci√≥n.

    ![El bot√≥n de publicar](../../../../../translated_images/custom-vision-publish-button.b7174e1977b0c33b8b72d4e5b1326c779e0af196f3849d09985ee2d7d5493a39.es.png)

1. En el cuadro de di√°logo *Publish Model*, configura el *Prediction resource* en el recurso `fruit-quality-detector-prediction` que creaste en la lecci√≥n anterior. Deja el nombre como `Iteration2` y selecciona el bot√≥n **Publish**.

1. Una vez publicado, selecciona el bot√≥n **Prediction URL**. Esto mostrar√° los detalles de la API de predicci√≥n, y necesitar√°s estos datos para llamar al modelo desde tu dispositivo IoT. La secci√≥n inferior est√° etiquetada como *If you have an image file*, y estos son los detalles que necesitas. Copia la URL que se muestra, que ser√° algo como:

    ```output
    https://<location>.api.cognitive.microsoft.com/customvision/v3.0/Prediction/<id>/classify/iterations/Iteration2/image
    ```

    Donde `<location>` ser√° la ubicaci√≥n que usaste al crear tu recurso de visi√≥n personalizada, y `<id>` ser√° un ID largo compuesto por letras y n√∫meros.

    Tambi√©n copia el valor de la *Prediction-Key*. Esta es una clave segura que debes pasar al llamar al modelo. Solo las aplicaciones que pasen esta clave podr√°n usar el modelo; cualquier otra aplicaci√≥n ser√° rechazada.

    ![El cuadro de di√°logo de la API de predicci√≥n mostrando la URL y la clave](../../../../../translated_images/custom-vision-prediction-key-endpoint.30c569ffd0338864f319911f052d5e9b8c5066cb0800a26dd6f7ff5713130ad8.es.png)

‚úÖ Cuando se publica una nueva iteraci√≥n, tendr√° un nombre diferente. ¬øC√≥mo crees que podr√≠as cambiar la iteraci√≥n que est√° usando un dispositivo IoT?

## Clasificar im√°genes desde tu dispositivo IoT

Ahora puedes usar estos detalles de conexi√≥n para llamar al clasificador de im√°genes desde tu dispositivo IoT.

### Tarea - clasificar im√°genes desde tu dispositivo IoT

Sigue la gu√≠a correspondiente para clasificar im√°genes usando tu dispositivo IoT:

* [Arduino - Wio Terminal](wio-terminal-classify-image.md)
* [Computadora de placa √∫nica - Raspberry Pi/Dispositivo IoT virtual](single-board-computer-classify-image.md)

## Mejorar el modelo

Es posible que los resultados que obtengas al usar la c√°mara conectada a tu dispositivo IoT no coincidan con lo que esperabas. Las predicciones no siempre son tan precisas como al usar im√°genes cargadas desde tu computadora. Esto se debe a que el modelo fue entrenado con datos diferentes a los que se est√°n utilizando para las predicciones.

Para obtener los mejores resultados de un clasificador de im√°genes, debes entrenar el modelo con im√°genes que sean lo m√°s similares posible a las im√°genes utilizadas para las predicciones. Por ejemplo, si usaste la c√°mara de tu tel√©fono para capturar im√°genes para el entrenamiento, la calidad, nitidez y color de las im√°genes ser√°n diferentes a las de una c√°mara conectada a un dispositivo IoT.

![2 im√°genes de un pl√°tano, una de baja resoluci√≥n con poca iluminaci√≥n de un dispositivo IoT, y otra de alta resoluci√≥n con buena iluminaci√≥n de un tel√©fono](../../../../../translated_images/banana-picture-compare.174df164dc326a42cf7fb051a7497e6113c620e91552d92ca914220305d47d9a.es.png)

En la imagen anterior, la foto del pl√°tano a la izquierda fue tomada con una c√°mara Raspberry Pi, mientras que la de la derecha fue tomada del mismo pl√°tano en la misma ubicaci√≥n con un iPhone. Hay una diferencia notable en la calidad: la foto del iPhone es m√°s n√≠tida, con colores m√°s brillantes y mayor contraste.

‚úÖ ¬øQu√© otros factores podr√≠an causar que las im√°genes capturadas por tu dispositivo IoT generen predicciones incorrectas? Piensa en el entorno en el que podr√≠a usarse un dispositivo IoT y qu√© factores pueden afectar la imagen capturada.

Para mejorar el modelo, puedes reentrenarlo usando las im√°genes capturadas desde el dispositivo IoT.

### Tarea - mejorar el modelo

1. Clasifica m√∫ltiples im√°genes de frutas maduras e inmaduras usando tu dispositivo IoT.

1. En el portal de Custom Vision, reentrena el modelo usando las im√°genes en la pesta√±a *Predictions*.

    > ‚ö†Ô∏è Puedes consultar [las instrucciones para reentrenar tu clasificador en la lecci√≥n 1 si es necesario](../1-train-fruit-detector/README.md#retrain-your-image-classifier).

1. Si tus im√°genes son muy diferentes a las originales usadas para entrenar, puedes eliminar todas las im√°genes originales seleccion√°ndolas en la pesta√±a *Training Images* y haciendo clic en el bot√≥n **Delete**. Para seleccionar una imagen, mueve el cursor sobre ella y aparecer√° una marca de verificaci√≥n; selecciona esa marca para seleccionar o deseleccionar la imagen.

1. Entrena una nueva iteraci√≥n del modelo y publ√≠cala siguiendo los pasos anteriores.

1. Actualiza la URL del endpoint en tu c√≥digo y vuelve a ejecutar la aplicaci√≥n.

1. Repite estos pasos hasta que est√©s satisfecho con los resultados de las predicciones.

---

## üöÄ Desaf√≠o

¬øQu√© tanto afecta la resoluci√≥n de la imagen o la iluminaci√≥n a la predicci√≥n?

Prueba cambiar la resoluci√≥n de las im√°genes en el c√≥digo de tu dispositivo y observa si hace una diferencia en la calidad de las im√°genes. Tambi√©n prueba cambiar la iluminaci√≥n.

Si fueras a crear un dispositivo de producci√≥n para vender a granjas o f√°bricas, ¬øc√≥mo garantizar√≠as que ofrezca resultados consistentes todo el tiempo?

## Cuestionario posterior a la lecci√≥n

[Cuestionario posterior a la lecci√≥n](https://black-meadow-040d15503.1.azurestaticapps.net/quiz/32)

## Revisi√≥n y autoestudio

Entrenaste tu modelo de visi√≥n personalizada usando el portal. Esto depende de tener im√°genes disponibles, y en el mundo real puede que no consigas datos de entrenamiento que coincidan con lo que captura la c√°mara de tu dispositivo. Puedes solucionar esto entrenando directamente desde tu dispositivo usando la API de entrenamiento, para entrenar un modelo con im√°genes capturadas desde tu dispositivo IoT.

* Lee sobre la API de entrenamiento en el [inicio r√°pido del SDK de Custom Vision](https://docs.microsoft.com/azure/cognitive-services/custom-vision-service/quickstarts/image-classification?WT.mc_id=academic-17441-jabenn&tabs=visual-studio&pivots=programming-language-python)

## Tarea

[Responder a los resultados de clasificaci√≥n](assignment.md)

---

**Descargo de responsabilidad**:  
Este documento ha sido traducido utilizando el servicio de traducci√≥n autom√°tica [Co-op Translator](https://github.com/Azure/co-op-translator). Aunque nos esforzamos por garantizar la precisi√≥n, tenga en cuenta que las traducciones autom√°ticas pueden contener errores o imprecisiones. El documento original en su idioma nativo debe considerarse como la fuente autorizada. Para informaci√≥n cr√≠tica, se recomienda una traducci√≥n profesional realizada por humanos. No nos hacemos responsables de malentendidos o interpretaciones err√≥neas que puedan surgir del uso de esta traducci√≥n.