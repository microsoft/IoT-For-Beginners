<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "3ba7150ffc4a6999f6c3cfb4906ec7df",
  "translation_date": "2025-08-26T14:13:24+00:00",
  "source_file": "4-manufacturing/lessons/2-check-fruit-from-device/virtual-device-camera.md",
  "language_code": "es"
}
-->
# Captura una imagen - Hardware IoT Virtual

En esta parte de la lecci칩n, agregar치s un sensor de c치mara a tu dispositivo IoT virtual y leer치s im치genes desde 칠l.

## Hardware

El dispositivo IoT virtual usar치 una c치mara simulada que env칤a im치genes desde archivos o desde tu c치mara web.

### Agregar la c치mara a CounterFit

Para usar una c치mara virtual, necesitas agregar una a la aplicaci칩n CounterFit.

#### Tarea - agregar la c치mara a CounterFit

Agrega la c치mara a la aplicaci칩n CounterFit.

1. Crea una nueva aplicaci칩n en Python en tu computadora dentro de una carpeta llamada `fruit-quality-detector` con un 칰nico archivo llamado `app.py` y un entorno virtual de Python, y agrega los paquetes pip de CounterFit.

    > 丘멆잺 Puedes consultar [las instrucciones para crear y configurar un proyecto de Python con CounterFit en la lecci칩n 1 si es necesario](../../../1-getting-started/lessons/1-introduction-to-iot/virtual-device.md).

1. Instala un paquete adicional de Pip para agregar un shim de CounterFit que pueda comunicarse con sensores de c치mara simulando algunas funciones del paquete [Picamera Pip](https://pypi.org/project/picamera/). Aseg칰rate de instalarlo desde una terminal con el entorno virtual activado.

    ```sh
    pip install counterfit-shims-picamera
    ```

1. Aseg칰rate de que la aplicaci칩n web de CounterFit est칠 en ejecuci칩n.

1. Crea una c치mara:

    1. En el cuadro *Create sensor* del panel *Sensors*, despliega el men칰 *Sensor type* y selecciona *Camera*.

    1. Establece el *Name* como `Picamera`.

    1. Selecciona el bot칩n **Add** para crear la c치mara.

    ![La configuraci칩n de la c치mara](../../../../../translated_images/counterfit-create-camera.a5de97f59c0bd3cbe0416d7e89a3cfe86d19fbae05c641c53a91286412af0a34.es.png)

    La c치mara ser치 creada y aparecer치 en la lista de sensores.

    ![La c치mara creada](../../../../../translated_images/counterfit-camera.001ec52194c8ee5d3f617173da2c79e1df903d10882adc625cbfc493525125d4.es.png)

## Programar la c치mara

El dispositivo IoT virtual ahora puede ser programado para usar la c치mara virtual.

### Tarea - programar la c치mara

Programa el dispositivo.

1. Aseg칰rate de que la aplicaci칩n `fruit-quality-detector` est칠 abierta en VS Code.

1. Abre el archivo `app.py`.

1. Agrega el siguiente c칩digo al inicio de `app.py` para conectar la aplicaci칩n a CounterFit:

    ```python
    from counterfit_connection import CounterFitConnection
    CounterFitConnection.init('127.0.0.1', 5000)
    ```

1. Agrega el siguiente c칩digo a tu archivo `app.py`:

    ```python
    import io
    from counterfit_shims_picamera import PiCamera
    ```

    Este c칩digo importa algunas bibliotecas necesarias, incluyendo la clase `PiCamera` de la biblioteca counterfit_shims_picamera.

1. Agrega el siguiente c칩digo debajo de este para inicializar la c치mara:

    ```python
    camera = PiCamera()
    camera.resolution = (640, 480)
    camera.rotation = 0
    ```

    Este c칩digo crea un objeto PiCamera, establece la resoluci칩n en 640x480. Aunque se admiten resoluciones m치s altas, el clasificador de im치genes funciona con im치genes mucho m치s peque침as (227x227), por lo que no es necesario capturar y enviar im치genes m치s grandes.

    La l칤nea `camera.rotation = 0` establece la rotaci칩n de la imagen en grados. Si necesitas rotar la imagen de la c치mara web o del archivo, ajusta este valor seg칰n sea necesario. Por ejemplo, si deseas cambiar la imagen de un pl치tano en una c치mara web en modo horizontal a modo vertical, establece `camera.rotation = 90`.

1. Agrega el siguiente c칩digo debajo de este para capturar la imagen como datos binarios:

    ```python
    image = io.BytesIO()
    camera.capture(image, 'jpeg')
    image.seek(0)
    ```

    Este c칩digo crea un objeto `BytesIO` para almacenar datos binarios. La imagen se lee desde la c치mara como un archivo JPEG y se almacena en este objeto. Este objeto tiene un indicador de posici칩n para saber d칩nde est치 en los datos, de modo que se puedan escribir m치s datos al final si es necesario. La l칤nea `image.seek(0)` mueve esta posici칩n al inicio para que todos los datos puedan leerse m치s tarde.

1. Debajo de esto, agrega lo siguiente para guardar la imagen en un archivo:

    ```python
    with open('image.jpg', 'wb') as image_file:
        image_file.write(image.read())
    ```

    Este c칩digo abre un archivo llamado `image.jpg` para escritura, luego lee todos los datos del objeto `BytesIO` y los escribe en el archivo.

    > 游누 Puedes capturar la imagen directamente en un archivo en lugar de un objeto `BytesIO` pasando el nombre del archivo a la llamada `camera.capture`. La raz칩n para usar el objeto `BytesIO` es que m치s adelante en esta lecci칩n podr치s enviar la imagen a tu clasificador de im치genes.

1. Configura la imagen que la c치mara en CounterFit capturar치. Puedes establecer la *Source* como *File*, luego subir un archivo de imagen, o establecer la *Source* como *WebCam*, y las im치genes se capturar치n desde tu c치mara web. Aseg칰rate de seleccionar el bot칩n **Set** despu칠s de elegir una imagen o tu c치mara web.

    ![CounterFit con un archivo configurado como fuente de imagen y una c치mara web mostrando a una persona sosteniendo un pl치tano en la vista previa de la c치mara](../../../../../translated_images/counterfit-camera-options.eb3bd5150a8e7dffbf24bc5bcaba0cf2cdef95fbe6bbe393695d173817d6b8df.es.png)

1. Se capturar치 una imagen y se guardar치 como `image.jpg` en la carpeta actual. Ver치s este archivo en el explorador de VS Code. Selecciona el archivo para ver la imagen. Si necesita rotaci칩n, actualiza la l칤nea `camera.rotation = 0` seg칰n sea necesario y toma otra foto.

> 游누 Puedes encontrar este c칩digo en la carpeta [code-camera/virtual-iot-device](../../../../../4-manufacturing/lessons/2-check-fruit-from-device/code-camera/virtual-iot-device).

游 춰Tu programa de c치mara fue un 칠xito!

---

**Descargo de responsabilidad**:  
Este documento ha sido traducido utilizando el servicio de traducci칩n autom치tica [Co-op Translator](https://github.com/Azure/co-op-translator). Aunque nos esforzamos por garantizar la precisi칩n, tenga en cuenta que las traducciones automatizadas pueden contener errores o imprecisiones. El documento original en su idioma nativo debe considerarse como la fuente autorizada. Para informaci칩n cr칤tica, se recomienda una traducci칩n profesional realizada por humanos. No nos hacemos responsables de malentendidos o interpretaciones err칩neas que puedan surgir del uso de esta traducci칩n.