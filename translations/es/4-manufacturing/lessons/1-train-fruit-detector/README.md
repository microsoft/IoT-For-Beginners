<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "f5e63c916d2dd97d58be12aaf76bd9f1",
  "translation_date": "2025-08-26T14:07:54+00:00",
  "source_file": "4-manufacturing/lessons/1-train-fruit-detector/README.md",
  "language_code": "es"
}
-->
# Entrena un detector de calidad de frutas

![Una vista general ilustrada de esta lecci√≥n](../../../../../translated_images/lesson-15.843d21afdc6fb2bba70cd9db7b7d2f91598859fafda2078b0bdc44954194b6c0.es.jpg)

> Ilustraci√≥n por [Nitya Narasimhan](https://github.com/nitya). Haz clic en la imagen para una versi√≥n m√°s grande.

Este video ofrece una visi√≥n general del servicio Azure Custom Vision, un servicio que se cubrir√° en esta lecci√≥n.

[![Custom Vision ‚Äì Machine Learning Made Easy | The Xamarin Show](https://img.youtube.com/vi/TETcDLJlWR4/0.jpg)](https://www.youtube.com/watch?v=TETcDLJlWR4)

> üé• Haz clic en la imagen de arriba para ver el video

## Cuestionario previo a la lecci√≥n

[Cuestionario previo a la lecci√≥n](https://black-meadow-040d15503.1.azurestaticapps.net/quiz/29)

## Introducci√≥n

El reciente auge de la Inteligencia Artificial (IA) y el Aprendizaje Autom√°tico (ML) est√° proporcionando una amplia gama de capacidades a los desarrolladores de hoy en d√≠a. Los modelos de ML pueden entrenarse para reconocer diferentes cosas en im√°genes, incluyendo frutas inmaduras, y esto puede usarse en dispositivos IoT para ayudar a clasificar productos, ya sea durante la cosecha o durante el procesamiento en f√°bricas o almacenes.

En esta lecci√≥n aprender√°s sobre la clasificaci√≥n de im√°genes: usar modelos de ML para distinguir entre im√°genes de diferentes cosas. Aprender√°s c√≥mo entrenar un clasificador de im√°genes para distinguir entre frutas que est√°n en buen estado y frutas que est√°n en mal estado, ya sea demasiado maduras, golpeadas o podridas.

En esta lecci√≥n cubriremos:

* [Usar IA y ML para clasificar alimentos](../../../../../4-manufacturing/lessons/1-train-fruit-detector)
* [Clasificaci√≥n de im√°genes mediante Aprendizaje Autom√°tico](../../../../../4-manufacturing/lessons/1-train-fruit-detector)
* [Entrenar un clasificador de im√°genes](../../../../../4-manufacturing/lessons/1-train-fruit-detector)
* [Probar tu clasificador de im√°genes](../../../../../4-manufacturing/lessons/1-train-fruit-detector)
* [Reentrenar tu clasificador de im√°genes](../../../../../4-manufacturing/lessons/1-train-fruit-detector)

## Usar IA y ML para clasificar alimentos

Alimentar a la poblaci√≥n mundial es dif√≠cil, especialmente a un precio que haga que los alimentos sean asequibles para todos. Uno de los mayores costos es la mano de obra, por lo que los agricultores est√°n recurriendo cada vez m√°s a la automatizaci√≥n y herramientas como IoT para reducir sus costos laborales. La cosecha manual es intensiva en mano de obra (y a menudo un trabajo agotador), y est√° siendo reemplazada por maquinaria, especialmente en pa√≠ses m√°s ricos. A pesar de los ahorros en costos al usar maquinaria para cosechar, hay un inconveniente: la capacidad de clasificar los alimentos mientras se cosechan.

No todos los cultivos maduran de manera uniforme. Los tomates, por ejemplo, pueden tener algunos frutos verdes en la planta cuando la mayor√≠a est√° lista para cosechar. Aunque es un desperdicio cosechar estos frutos verdes, es m√°s barato y f√°cil para el agricultor cosechar todo usando maquinaria y desechar los productos inmaduros m√°s tarde.

‚úÖ Observa diferentes frutas o verduras, ya sea creciendo cerca de ti en granjas o en tu jard√≠n, o en tiendas. ¬øEst√°n todas en el mismo grado de madurez, o ves variaciones?

El auge de la cosecha automatizada traslad√≥ la clasificaci√≥n de productos de la cosecha a la f√°brica. Los alimentos viajar√≠an en largas cintas transportadoras con equipos de personas revisando los productos y eliminando cualquier cosa que no cumpliera con el est√°ndar de calidad requerido. La cosecha era m√°s barata gracias a la maquinaria, pero todav√≠a hab√≠a un costo asociado con la clasificaci√≥n manual de los alimentos.

![Si se detecta un tomate rojo, contin√∫a su trayecto sin interrupciones. Si se detecta un tomate verde, se lanza a un contenedor de desechos mediante una palanca](../../../../../translated_images/optical-tomato-sorting.61aa134bdda4e5b1bfb16a212c1e35a6ef0c426cbb8b1c975f79d7bfbf48d068.es.png)

La siguiente evoluci√≥n fue usar m√°quinas para clasificar, ya sea integradas en la cosechadora o en las plantas de procesamiento. La primera generaci√≥n de estas m√°quinas usaba sensores √≥pticos para detectar colores, controlando actuadores para empujar tomates verdes a un contenedor de desechos usando palancas o r√°fagas de aire, dejando que los tomates rojos continuaran en una red de cintas transportadoras.

En este video, mientras los tomates caen de una cinta transportadora a otra, los tomates verdes son detectados y lanzados a un contenedor usando palancas.

‚úÖ ¬øQu√© condiciones necesitar√≠as en una f√°brica o en un campo para que estos sensores √≥pticos funcionen correctamente?

Las √∫ltimas evoluciones de estas m√°quinas de clasificaci√≥n aprovechan la IA y el ML, utilizando modelos entrenados para distinguir productos buenos de malos, no solo por diferencias obvias de color como tomates verdes frente a rojos, sino por diferencias m√°s sutiles en apariencia que pueden indicar enfermedad o golpes.

## Clasificaci√≥n de im√°genes mediante Aprendizaje Autom√°tico

La programaci√≥n tradicional consiste en tomar datos, aplicar un algoritmo a los datos y obtener un resultado. Por ejemplo, en el √∫ltimo proyecto tomaste coordenadas GPS y una geocerca, aplicaste un algoritmo proporcionado por Azure Maps y obtuviste un resultado sobre si el punto estaba dentro o fuera de la geocerca. Introduces m√°s datos, obtienes m√°s resultados.

![El desarrollo tradicional toma datos de entrada y un algoritmo y da un resultado. El aprendizaje autom√°tico usa datos de entrada y salida para entrenar un modelo, y este modelo puede tomar nuevos datos de entrada para generar nuevos resultados](../../../../../translated_images/traditional-vs-ml.5c20c169621fa539ca84a2cd9a49f6ff7410b3a6c6b46c97ff2af3f99db3c66b.es.png)

El aprendizaje autom√°tico cambia esto: comienzas con datos y resultados conocidos, y el algoritmo de aprendizaje autom√°tico aprende de los datos. Luego puedes tomar ese algoritmo entrenado, llamado *modelo de aprendizaje autom√°tico* o *modelo*, e introducir nuevos datos para obtener nuevos resultados.

> üéì El proceso de un algoritmo de aprendizaje autom√°tico aprendiendo de los datos se llama *entrenamiento*. Los datos de entrada y los resultados conocidos se llaman *datos de entrenamiento*.

Por ejemplo, podr√≠as darle a un modelo millones de im√°genes de pl√°tanos inmaduros como datos de entrenamiento de entrada, con el resultado de entrenamiento configurado como `inmaduro`, y millones de im√°genes de pl√°tanos maduros como datos de entrenamiento con el resultado configurado como `maduro`. El algoritmo de ML entonces crear√° un modelo basado en estos datos. Luego le das a este modelo una nueva imagen de un pl√°tano y predice si la nueva imagen es de un pl√°tano maduro o inmaduro.

> üéì Los resultados de los modelos de ML se llaman *predicciones*

![2 pl√°tanos, uno maduro con una predicci√≥n de 99.7% maduro, 0.3% inmaduro, y uno inmaduro con una predicci√≥n de 1.4% maduro, 98.6% inmaduro](../../../../../translated_images/bananas-ripe-vs-unripe-predictions.8d0e2034014aa50ece4e4589e724b142da0681f35470fe3db3f7d51240f69c85.es.png)

Los modelos de ML no dan una respuesta binaria, en cambio, dan probabilidades. Por ejemplo, un modelo puede recibir una imagen de un pl√°tano y predecir `maduro` con un 99.7% y `inmaduro` con un 0.3%. Tu c√≥digo luego elegir√≠a la mejor predicci√≥n y decidir√≠a que el pl√°tano est√° maduro.

El modelo de ML utilizado para detectar im√°genes como esta se llama *clasificador de im√°genes*: se le dan im√°genes etiquetadas y luego clasifica nuevas im√°genes bas√°ndose en estas etiquetas.

> üíÅ Esto es una simplificaci√≥n, y hay muchas otras formas de entrenar modelos que no siempre necesitan resultados etiquetados, como el aprendizaje no supervisado. Si quieres aprender m√°s sobre ML, consulta [ML para principiantes, un curr√≠culo de 24 lecciones sobre Aprendizaje Autom√°tico](https://aka.ms/ML-beginners).

## Entrenar un clasificador de im√°genes

Para entrenar con √©xito un clasificador de im√°genes necesitas millones de im√°genes. Sin embargo, una vez que tienes un clasificador de im√°genes entrenado con millones o miles de millones de im√°genes variadas, puedes reutilizarlo y reentrenarlo usando un peque√±o conjunto de im√°genes y obtener excelentes resultados, utilizando un proceso llamado *aprendizaje por transferencia*.

> üéì El aprendizaje por transferencia es cuando transfieres el aprendizaje de un modelo de ML existente a un nuevo modelo basado en nuevos datos.

Una vez que un clasificador de im√°genes ha sido entrenado para una amplia variedad de im√°genes, sus componentes internos son excelentes para reconocer formas, colores y patrones. El aprendizaje por transferencia permite que el modelo tome lo que ya ha aprendido al reconocer partes de im√°genes y lo use para reconocer nuevas im√°genes.

![Una vez que puedes reconocer formas, pueden colocarse en diferentes configuraciones para formar un barco o un gato](../../../../../translated_images/shapes-to-images.1a309f0ea88dd66fafa4da6d38e88806ce174cc6a88081efb32852230ed55de8.es.png)

Puedes pensar en esto como los libros de formas para ni√±os, donde una vez que puedes reconocer un semic√≠rculo, un rect√°ngulo y un tri√°ngulo, puedes reconocer un velero o un gato dependiendo de la configuraci√≥n de estas formas. El clasificador de im√°genes puede reconocer las formas, y el aprendizaje por transferencia le ense√±a qu√© combinaci√≥n forma un barco o un gato, o un pl√°tano maduro.

Hay una amplia gama de herramientas que pueden ayudarte a hacer esto, incluyendo servicios basados en la nube que pueden ayudarte a entrenar tu modelo y luego usarlo a trav√©s de APIs web.

> üíÅ Entrenar estos modelos requiere mucha potencia de c√≥mputo, generalmente mediante Unidades de Procesamiento Gr√°fico (GPUs). El mismo hardware especializado que hace que los juegos en tu Xbox se vean incre√≠bles tambi√©n puede usarse para entrenar modelos de aprendizaje autom√°tico. Al usar la nube, puedes alquilar tiempo en computadoras potentes con GPUs para entrenar estos modelos, obteniendo acceso a la potencia de c√≥mputo que necesitas, solo por el tiempo que la necesitas.

## Custom Vision

Custom Vision es una herramienta basada en la nube para entrenar clasificadores de im√°genes. Te permite entrenar un clasificador usando solo un peque√±o n√∫mero de im√°genes. Puedes subir im√°genes a trav√©s de un portal web, una API web o un SDK, dando a cada imagen una *etiqueta* que clasifique esa imagen. Luego entrenas el modelo y lo pruebas para ver qu√© tan bien funciona. Una vez que est√©s satisfecho con el modelo, puedes publicar versiones de este que pueden ser accesibles a trav√©s de una API web o un SDK.

![El logo de Azure Custom Vision](../../../../../translated_images/custom-vision-logo.d3d4e7c8a87ec9daf825e72e210576c3cbf60312577be7a139e22dd97ab7f1e6.es.png)

> üíÅ Puedes entrenar un modelo de Custom Vision con tan solo 5 im√°genes por clasificaci√≥n, pero m√°s es mejor. Puedes obtener mejores resultados con al menos 30 im√°genes.

Custom Vision es parte de una gama de herramientas de IA de Microsoft llamadas Cognitive Services. Estas son herramientas de IA que pueden usarse ya sea sin ning√∫n entrenamiento o con una peque√±a cantidad de entrenamiento. Incluyen reconocimiento y traducci√≥n de voz, comprensi√≥n del lenguaje y an√°lisis de im√°genes. Estas est√°n disponibles con un nivel gratuito como servicios en Azure.

> üíÅ El nivel gratuito es m√°s que suficiente para crear un modelo, entrenarlo y luego usarlo para trabajos de desarrollo. Puedes leer sobre los l√≠mites del nivel gratuito en la [p√°gina de l√≠mites y cuotas de Custom Vision en la documentaci√≥n de Microsoft](https://docs.microsoft.com/azure/cognitive-services/custom-vision-service/limits-and-quotas?WT.mc_id=academic-17441-jabenn).

### Tarea - crear un recurso de servicios cognitivos

Para usar Custom Vision, primero necesitas crear dos recursos de servicios cognitivos en Azure usando la CLI de Azure, uno para el entrenamiento de Custom Vision y otro para la predicci√≥n de Custom Vision.

1. Crea un Grupo de Recursos para este proyecto llamado `fruit-quality-detector`.

1. Usa el siguiente comando para crear un recurso gratuito de entrenamiento de Custom Vision:

    ```sh
    az cognitiveservices account create --name fruit-quality-detector-training \
                                        --resource-group fruit-quality-detector \
                                        --kind CustomVision.Training \
                                        --sku F0 \
                                        --yes \
                                        --location <location>
    ```

    Reemplaza `<location>` con la ubicaci√≥n que usaste al crear el Grupo de Recursos.

    Esto crear√° un recurso de entrenamiento de Custom Vision en tu Grupo de Recursos. Se llamar√° `fruit-quality-detector-training` y usar√° el SKU `F0`, que es el nivel gratuito. La opci√≥n `--yes` significa que aceptas los t√©rminos y condiciones de los servicios cognitivos.

> üíÅ Usa el SKU `S0` si ya tienes una cuenta gratuita usando cualquiera de los Servicios Cognitivos.

1. Usa el siguiente comando para crear un recurso gratuito de predicci√≥n de Custom Vision:

    ```sh
    az cognitiveservices account create --name fruit-quality-detector-prediction \
                                        --resource-group fruit-quality-detector \
                                        --kind CustomVision.Prediction \
                                        --sku F0 \
                                        --yes \
                                        --location <location>
    ```

    Reemplaza `<location>` con la ubicaci√≥n que usaste al crear el Grupo de Recursos.

    Esto crear√° un recurso de predicci√≥n de Custom Vision en tu Grupo de Recursos. Se llamar√° `fruit-quality-detector-prediction` y usar√° el SKU `F0`, que es el nivel gratuito. La opci√≥n `--yes` significa que aceptas los t√©rminos y condiciones de los servicios cognitivos.

### Tarea - crear un proyecto de clasificador de im√°genes

1. Abre el portal de Custom Vision en [CustomVision.ai](https://customvision.ai) e inicia sesi√≥n con la cuenta de Microsoft que usaste para tu cuenta de Azure.

1. Sigue la [secci√≥n de creaci√≥n de un nuevo proyecto en el inicio r√°pido para construir un clasificador en la documentaci√≥n de Microsoft](https://docs.microsoft.com/azure/cognitive-services/custom-vision-service/getting-started-build-a-classifier?WT.mc_id=academic-17441-jabenn#create-a-new-project) para crear un nuevo proyecto de Custom Vision. La interfaz de usuario puede cambiar y esta documentaci√≥n siempre ser√° la referencia m√°s actualizada.

    Llama a tu proyecto `fruit-quality-detector`.

    Cuando crees tu proyecto, aseg√∫rate de usar el recurso `fruit-quality-detector-training` que creaste anteriormente. Usa un tipo de proyecto *Clasificaci√≥n*, un tipo de clasificaci√≥n *Multiclase* y el dominio *Alimentos*.

    ![La configuraci√≥n para el proyecto de Custom Vision con el nombre configurado como fruit-quality-detector, sin descripci√≥n, el recurso configurado como fruit-quality-detector-training, el tipo de proyecto configurado como clasificaci√≥n, el tipo de clasificaci√≥n configurado como multiclase y el dominio configurado como alimentos](../../../../../translated_images/custom-vision-create-project.cf46325b92d8b131089f6647cf5e07b664cb77850e106d66e3c057b6b69756c6.es.png)

‚úÖ T√≥mate un tiempo para explorar la interfaz de usuario de Custom Vision para tu clasificador de im√°genes.

### Tarea - entrenar tu proyecto de clasificador de im√°genes

Para entrenar un clasificador de im√°genes, necesitar√°s m√∫ltiples im√°genes de frutas, tanto de buena como de mala calidad, para etiquetarlas como buenas y malas, como un pl√°tano maduro y uno demasiado maduro.
üíÅ Estos clasificadores pueden clasificar im√°genes de cualquier cosa, as√≠ que si no tienes frutas de diferentes calidades a mano, puedes usar dos tipos diferentes de frutas, ¬°o gatos y perros!
Idealmente, cada imagen deber√≠a mostrar solo la fruta, con un fondo consistente o una amplia variedad de fondos. Aseg√∫rate de que no haya nada en el fondo que sea espec√≠fico para frutas maduras o inmaduras.

> üíÅ Es importante no tener fondos espec√≠ficos ni elementos que no est√©n relacionados con lo que se est√° clasificando para cada etiqueta, de lo contrario, el clasificador podr√≠a clasificar bas√°ndose en el fondo. Hubo un clasificador para c√°ncer de piel que se entren√≥ con lunares normales y cancerosos, y los cancerosos siempre ten√≠an reglas para medir el tama√±o. Result√≥ que el clasificador era casi 100% preciso identificando reglas en las im√°genes, no lunares cancerosos.

Los clasificadores de im√°genes funcionan con resoluciones muy bajas. Por ejemplo, Custom Vision puede tomar im√°genes de entrenamiento y predicci√≥n de hasta 10240x10240, pero entrena y ejecuta el modelo en im√°genes de 227x227. Las im√°genes m√°s grandes se reducen a este tama√±o, as√≠ que aseg√∫rate de que el objeto que est√°s clasificando ocupe una gran parte de la imagen, de lo contrario, podr√≠a ser demasiado peque√±o en la imagen reducida utilizada por el clasificador.

1. Re√∫ne im√°genes para tu clasificador. Necesitar√°s al menos 5 im√°genes para cada etiqueta para entrenar el clasificador, pero mientras m√°s, mejor. Tambi√©n necesitar√°s algunas im√°genes adicionales para probar el clasificador. Estas im√°genes deben ser diferentes im√°genes del mismo objeto. Por ejemplo:

    * Usando 2 pl√°tanos maduros, toma algunas fotos de cada uno desde diferentes √°ngulos, tomando al menos 7 fotos (5 para entrenar, 2 para probar), pero idealmente m√°s.

        ![Fotos de 2 pl√°tanos diferentes](../../../../../translated_images/banana-training-images.530eb203346d73bc23b8b990fb4609470bf4ff7c942ccc13d4cfffeed9be1ad4.es.png)

    * Repite el mismo proceso usando 2 pl√°tanos inmaduros.

    Deber√≠as tener al menos 10 im√°genes de entrenamiento, con al menos 5 maduras y 5 inmaduras, y 4 im√°genes de prueba, 2 maduras y 2 inmaduras. Tus im√°genes deben ser png o jpeg, de menos de 6MB. Si las creas con un iPhone, por ejemplo, podr√≠an ser im√°genes HEIC de alta resoluci√≥n, por lo que necesitar√°n ser convertidas y posiblemente reducidas. Mientras m√°s im√°genes tengas, mejor, y deber√≠as tener un n√∫mero similar de maduras e inmaduras.

    Si no tienes frutas maduras e inmaduras, puedes usar diferentes frutas o cualquier par de objetos que tengas disponibles. Tambi√©n puedes encontrar algunas im√°genes de ejemplo en la carpeta [images](../../../../../4-manufacturing/lessons/1-train-fruit-detector/images) de pl√°tanos maduros e inmaduros que puedes usar.

1. Sigue la [secci√≥n de subir y etiquetar im√°genes del tutorial r√°pido para construir un clasificador en la documentaci√≥n de Microsoft](https://docs.microsoft.com/azure/cognitive-services/custom-vision-service/getting-started-build-a-classifier?WT.mc_id=academic-17441-jabenn#upload-and-tag-images) para subir tus im√°genes de entrenamiento. Etiqueta las frutas maduras como `ripe` y las inmaduras como `unripe`.

    ![Los di√°logos de subida mostrando la carga de im√°genes de pl√°tanos maduros e inmaduros](../../../../../translated_images/image-upload-bananas.0751639f3815e0ec42bdbc6254d1e4357a185834d1ae10c9948a0e7d6d336695.es.png)

1. Sigue la [secci√≥n de entrenar el clasificador del tutorial r√°pido para construir un clasificador en la documentaci√≥n de Microsoft](https://docs.microsoft.com/azure/cognitive-services/custom-vision-service/getting-started-build-a-classifier?WT.mc_id=academic-17441-jabenn#train-the-classifier) para entrenar el clasificador de im√°genes con tus im√°genes subidas.

    Se te dar√° una opci√≥n de tipo de entrenamiento. Selecciona **Quick Training**.

El clasificador comenzar√° a entrenarse. Tomar√° unos minutos para completar el entrenamiento.

> üçå Si decides comer tu fruta mientras el clasificador se est√° entrenando, aseg√∫rate de tener suficientes im√°genes para probar primero.

## Prueba tu clasificador de im√°genes

Una vez que tu clasificador est√© entrenado, puedes probarlo d√°ndole una nueva imagen para clasificar.

### Tarea - prueba tu clasificador de im√°genes

1. Sigue la [documentaci√≥n para probar tu modelo en los documentos de Microsoft](https://docs.microsoft.com/azure/cognitive-services/custom-vision-service/test-your-model?WT.mc_id=academic-17441-jabenn#test-your-model) para probar tu clasificador de im√°genes. Usa las im√°genes de prueba que creaste anteriormente, no ninguna de las im√°genes que usaste para entrenar.

    ![Un pl√°tano inmaduro predicho como inmaduro con una probabilidad del 98.9%, maduro con una probabilidad del 1.1%](../../../../../translated_images/banana-unripe-quick-test-prediction.dae9b5e1c4ef7c64886422438850ea14f0be6ac918c217ea3b255c685abfabe7.es.png)

1. Prueba todas las im√°genes de prueba que tengas y observa las probabilidades.

## Reentrena tu clasificador de im√°genes

Cuando pruebes tu clasificador, puede que no d√© los resultados que esperas. Los clasificadores de im√°genes usan aprendizaje autom√°tico para hacer predicciones sobre lo que hay en una imagen, bas√°ndose en probabilidades de que ciertas caracter√≠sticas de una imagen signifiquen que coincide con una etiqueta particular. No entiende lo que hay en la imagen: no sabe qu√© es un pl√°tano ni entiende qu√© hace que un pl√°tano sea un pl√°tano en lugar de un barco. Puedes mejorar tu clasificador reentren√°ndolo con im√°genes en las que se equivoque.

Cada vez que haces una predicci√≥n usando la opci√≥n de prueba r√°pida, la imagen y los resultados se almacenan. Puedes usar estas im√°genes para reentrenar tu modelo.

### Tarea - reentrena tu clasificador de im√°genes

1. Sigue la [documentaci√≥n para usar la imagen predicha para entrenamiento en los documentos de Microsoft](https://docs.microsoft.com/azure/cognitive-services/custom-vision-service/test-your-model?WT.mc_id=academic-17441-jabenn#use-the-predicted-image-for-training) para reentrenar tu modelo, usando la etiqueta correcta para cada imagen.

1. Una vez que tu modelo haya sido reentrenado, prueba con nuevas im√°genes.

---

## üöÄ Desaf√≠o

¬øQu√© crees que pasar√≠a si usas una imagen de una fresa con un modelo entrenado en pl√°tanos, o una imagen de un pl√°tano inflable, o una persona disfrazada de pl√°tano, o incluso un personaje amarillo de caricatura como alguien de Los Simpson?

Pru√©balo y observa cu√°les son las predicciones. Puedes encontrar im√°genes para probar usando [Bing Image search](https://www.bing.com/images/trending).

## Cuestionario post-lectura

[Cuestionario post-lectura](https://black-meadow-040d15503.1.azurestaticapps.net/quiz/30)

## Revisi√≥n y autoestudio

* Cuando entrenaste tu clasificador, habr√°s visto valores para *Precision*, *Recall* y *AP* que califican el modelo creado. Investiga qu√© significan estos valores usando [la secci√≥n de evaluar el clasificador del tutorial r√°pido para construir un clasificador en la documentaci√≥n de Microsoft](https://docs.microsoft.com/azure/cognitive-services/custom-vision-service/getting-started-build-a-classifier?WT.mc_id=academic-17441-jabenn#evaluate-the-classifier)
* Investiga c√≥mo mejorar tu clasificador en [c√≥mo mejorar tu modelo de Custom Vision en la documentaci√≥n de Microsoft](https://docs.microsoft.com/azure/cognitive-services/custom-vision-service/getting-started-improving-your-classifier?WT.mc_id=academic-17441-jabenn)

## Asignaci√≥n

[Entrena tu clasificador para m√∫ltiples frutas y verduras](assignment.md)

---

**Descargo de responsabilidad**:  
Este documento ha sido traducido utilizando el servicio de traducci√≥n autom√°tica [Co-op Translator](https://github.com/Azure/co-op-translator). Si bien nos esforzamos por garantizar la precisi√≥n, tenga en cuenta que las traducciones autom√°ticas pueden contener errores o imprecisiones. El documento original en su idioma nativo debe considerarse como la fuente autorizada. Para informaci√≥n cr√≠tica, se recomienda una traducci√≥n profesional realizada por humanos. No nos hacemos responsables de malentendidos o interpretaciones err√≥neas que puedan surgir del uso de esta traducci√≥n.