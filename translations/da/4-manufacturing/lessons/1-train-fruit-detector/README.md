<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "f5e63c916d2dd97d58be12aaf76bd9f1",
  "translation_date": "2025-08-27T20:25:30+00:00",
  "source_file": "4-manufacturing/lessons/1-train-fruit-detector/README.md",
  "language_code": "da"
}
-->
# Tr√¶n en frugtkvalitetsdetektor

![En sketchnote-oversigt over denne lektion](../../../../../translated_images/lesson-15.843d21afdc6fb2bba70cd9db7b7d2f91598859fafda2078b0bdc44954194b6c0.da.jpg)

> Sketchnote af [Nitya Narasimhan](https://github.com/nitya). Klik p√• billedet for en st√∏rre version.

Denne video giver en oversigt over Azure Custom Vision-tjenesten, som vil blive d√¶kket i denne lektion.

[![Custom Vision ‚Äì Machine Learning Made Easy | The Xamarin Show](https://img.youtube.com/vi/TETcDLJlWR4/0.jpg)](https://www.youtube.com/watch?v=TETcDLJlWR4)

> üé• Klik p√• billedet ovenfor for at se videoen

## Quiz f√∏r lektionen

[Quiz f√∏r lektionen](https://black-meadow-040d15503.1.azurestaticapps.net/quiz/29)

## Introduktion

Den seneste fremgang inden for kunstig intelligens (AI) og maskinl√¶ring (ML) giver nutidens udviklere en bred vifte af muligheder. ML-modeller kan tr√¶nes til at genkende forskellige ting p√• billeder, herunder umodne frugter, og dette kan bruges i IoT-enheder til at hj√¶lpe med at sortere produkter, enten mens de h√∏stes, eller under forarbejdning i fabrikker eller lagre.

I denne lektion vil du l√¶re om billedklassifikation - brugen af ML-modeller til at skelne mellem billeder af forskellige ting. Du vil l√¶re, hvordan man tr√¶ner en billedklassifikator til at skelne mellem frugt, der er god, og frugt, der er d√•rlig, enten undermoden, overmoden, beskadiget eller r√•dden.

I denne lektion d√¶kker vi:

* [Brug af AI og ML til at sortere mad](../../../../../4-manufacturing/lessons/1-train-fruit-detector)
* [Billedklassifikation via maskinl√¶ring](../../../../../4-manufacturing/lessons/1-train-fruit-detector)
* [Tr√¶n en billedklassifikator](../../../../../4-manufacturing/lessons/1-train-fruit-detector)
* [Test din billedklassifikator](../../../../../4-manufacturing/lessons/1-train-fruit-detector)
* [Gen-tr√¶n din billedklassifikator](../../../../../4-manufacturing/lessons/1-train-fruit-detector)

## Brug af AI og ML til at sortere mad

At br√∏df√∏de verdens befolkning er sv√¶rt, is√¶r til en pris, der g√∏r mad overkommelig for alle. En af de st√∏rste omkostninger er arbejdskraft, s√• landm√¶nd vender sig i stigende grad mod automatisering og v√¶rkt√∏jer som IoT for at reducere deres arbejdskraftomkostninger. H√∏stning i h√•nden er arbejdskr√¶vende (og ofte h√•rdt arbejde) og bliver erstattet af maskiner, is√¶r i rigere lande. P√• trods af besparelserne ved at bruge maskiner til at h√∏ste, er der en ulempe - evnen til at sortere mad, mens den h√∏stes.

Ikke alle afgr√∏der modnes j√¶vnt. Tomater, for eksempel, kan stadig have nogle gr√∏nne frugter p√• planten, n√•r st√∏rstedelen er klar til h√∏st. Selvom det er spild at h√∏ste disse tidligt, er det billigere og lettere for landmanden at h√∏ste alt med maskiner og kassere de umodne produkter senere.

‚úÖ Kig p√• forskellige frugter eller gr√∏ntsager, enten der vokser i n√¶rheden af dig p√• g√•rde eller i din have, eller i butikker. Er de alle lige modne, eller ser du variation?

Den stigende automatisering af h√∏st flyttede sorteringen af produkter fra marken til fabrikken. Mad ville rejse p√• lange transportb√•nd med hold af mennesker, der gennemgik produkterne og fjernede alt, der ikke levede op til kvalitetsstandarderne. H√∏st blev billigere takket v√¶re maskiner, men der var stadig en omkostning ved manuelt at sortere mad.

![Hvis en r√∏d tomat registreres, forts√¶tter den sin rejse uforstyrret. Hvis en gr√∏n tomat registreres, skubbes den i en affaldsbeholder af en arm](../../../../../translated_images/optical-tomato-sorting.61aa134bdda4e5b1bfb16a212c1e35a6ef0c426cbb8b1c975f79d7bfbf48d068.da.png)

Den n√¶ste udvikling var at bruge maskiner til at sortere, enten indbygget i h√∏stmaskinen eller i forarbejdningsanl√¶ggene. Den f√∏rste generation af disse maskiner brugte optiske sensorer til at registrere farver og styrede aktuatorer til at skubbe gr√∏nne tomater i en affaldsbeholder ved hj√¶lp af arme eller lufttryk, mens r√∏de tomater fortsatte p√• et netv√¶rk af transportb√•nd.

I denne video, n√•r tomater falder fra et transportb√•nd til et andet, registreres gr√∏nne tomater og skubbes i en beholder ved hj√¶lp af arme.

‚úÖ Hvilke forhold ville du have brug for i en fabrik eller p√• en mark for at disse optiske sensorer fungerer korrekt?

De nyeste udviklinger af disse sorteringsmaskiner udnytter AI og ML, ved at bruge modeller, der er tr√¶net til at skelne mellem god og d√•rlig frugt, ikke kun ved √•benlyse farveforskelle som gr√∏nne tomater vs r√∏de, men ogs√• ved mere subtile forskelle i udseende, der kan indikere sygdom eller skader.

## Billedklassifikation via maskinl√¶ring

Traditionel programmering er, hvor du tager data, anvender en algoritme p√• dataene og f√•r output. For eksempel, i det sidste projekt tog du GPS-koordinater og en geofence, anvendte en algoritme leveret af Azure Maps og fik et resultat om, hvorvidt punktet var inden for eller uden for geofencen. Du indtaster flere data, du f√•r mere output.

![Traditionel udvikling tager input og en algoritme og giver output. Maskinl√¶ring bruger input og outputdata til at tr√¶ne en model, og denne model kan tage nye inputdata for at generere nyt output](../../../../../translated_images/traditional-vs-ml.5c20c169621fa539ca84a2cd9a49f6ff7410b3a6c6b46c97ff2af3f99db3c66b.da.png)

Maskinl√¶ring vender dette om - du starter med data og kendte outputs, og maskinl√¶ringsalgoritmen l√¶rer af dataene. Du kan derefter tage den tr√¶nede algoritme, kaldet en *maskinl√¶ringsmodel* eller *model*, og indtaste nye data og f√• nyt output.

> üéì Processen, hvor en maskinl√¶ringsalgoritme l√¶rer af dataene, kaldes *tr√¶ning*. Input og kendte outputs kaldes *tr√¶ningsdata*.

For eksempel kunne du give en model millioner af billeder af umodne bananer som input tr√¶ningsdata, med tr√¶ningsoutput sat til `umoden`, og millioner af modne bananbilleder som tr√¶ningsdata med output sat til `moden`. ML-algoritmen vil derefter oprette en model baseret p√• disse data. Du giver derefter denne model et nyt billede af en banan, og den vil forudsige, om det nye billede er en moden eller en umoden banan.

> üéì Resultaterne af ML-modeller kaldes *forudsigelser*.

![2 bananer, en moden med en forudsigelse p√• 99,7% moden, 0,3% umoden, og en umoden med en forudsigelse p√• 1,4% moden, 98,6% umoden](../../../../../translated_images/bananas-ripe-vs-unripe-predictions.8d0e2034014aa50ece4e4589e724b142da0681f35470fe3db3f7d51240f69c85.da.png)

ML-modeller giver ikke et bin√¶rt svar, men i stedet sandsynligheder. For eksempel kan en model f√• et billede af en banan og forudsige `moden` med 99,7% og `umoden` med 0,3%. Din kode ville derefter v√¶lge den bedste forudsigelse og beslutte, at bananen er moden.

Den ML-model, der bruges til at registrere billeder som dette, kaldes en *billedklassifikator* - den f√•r m√¶rkede billeder og klassificerer derefter nye billeder baseret p√• disse m√¶rker.

> üíÅ Dette er en forenkling, og der er mange andre m√•der at tr√¶ne modeller p√•, som ikke altid kr√¶ver m√¶rkede outputs, s√•som usuperviseret l√¶ring. Hvis du vil l√¶re mere om ML, kan du tjekke [ML for begyndere, et 24-lektioners kursus om maskinl√¶ring](https://aka.ms/ML-beginners).

## Tr√¶n en billedklassifikator

For at tr√¶ne en billedklassifikator med succes har du brug for millioner af billeder. Som det viser sig, n√•r du f√∏rst har en billedklassifikator tr√¶net p√• millioner eller milliarder af forskellige billeder, kan du genbruge den og gen-tr√¶ne den ved hj√¶lp af et lille s√¶t billeder og opn√• gode resultater ved hj√¶lp af en proces kaldet *transfer learning*.

> üéì Transfer learning er, hvor du overf√∏rer l√¶ring fra en eksisterende ML-model til en ny model baseret p√• nye data.

N√•r en billedklassifikator er blevet tr√¶net til en bred vifte af billeder, er dens interne funktioner gode til at genkende former, farver og m√∏nstre. Transfer learning g√∏r det muligt for modellen at tage det, den allerede har l√¶rt om at genkende billeddele, og bruge det til at genkende nye billeder.

![N√•r du kan genkende former, kan de s√¶ttes sammen i forskellige konfigurationer for at lave en b√•d eller en kat](../../../../../translated_images/shapes-to-images.1a309f0ea88dd66fafa4da6d38e88806ce174cc6a88081efb32852230ed55de8.da.png)

Du kan t√¶nke p√• dette som lidt ligesom b√∏rns formb√∏ger, hvor n√•r du f√∏rst kan genkende en halvcirkel, et rektangel og en trekant, kan du genkende en sejlb√•d eller en kat afh√¶ngigt af konfigurationen af disse former. Billedklassifikatoren kan genkende formerne, og transfer learning l√¶rer den, hvilken kombination der udg√∏r en b√•d eller en kat - eller en moden banan.

Der findes en bred vifte af v√¶rkt√∏jer, der kan hj√¶lpe dig med dette, herunder cloud-baserede tjenester, der kan hj√¶lpe dig med at tr√¶ne din model og derefter bruge den via web-API'er.

> üíÅ Tr√¶ning af disse modeller kr√¶ver meget computerkraft, normalt via Graphics Processing Units, eller GPU'er. Den samme specialiserede hardware, der f√•r spil p√• din Xbox til at se fantastiske ud, kan ogs√• bruges til at tr√¶ne maskinl√¶ringsmodeller. Ved at bruge skyen kan du leje tid p√• kraftfulde computere med GPU'er til at tr√¶ne disse modeller og f√• adgang til den computerkraft, du har brug for, kun i den tid, du har brug for det.

## Custom Vision

Custom Vision er et cloud-baseret v√¶rkt√∏j til tr√¶ning af billedklassifikatorer. Det giver dig mulighed for at tr√¶ne en klassifikator ved kun at bruge et lille antal billeder. Du kan uploade billeder via en webportal, web-API eller et SDK og give hvert billede en *tag*, der angiver klassifikationen af det billede. Du tr√¶ner derefter modellen og tester den for at se, hvor godt den fungerer. N√•r du er tilfreds med modellen, kan du udgive versioner af den, der kan tilg√•s via en web-API eller et SDK.

![Azure Custom Vision-logoet](../../../../../translated_images/custom-vision-logo.d3d4e7c8a87ec9daf825e72e210576c3cbf60312577be7a139e22dd97ab7f1e6.da.png)

> üíÅ Du kan tr√¶ne en Custom Vision-model med s√• lidt som 5 billeder pr. klassifikation, men flere er bedre. Du kan opn√• bedre resultater med mindst 30 billeder.

Custom Vision er en del af en r√¶kke AI-v√¶rkt√∏jer fra Microsoft kaldet Cognitive Services. Disse er AI-v√¶rkt√∏jer, der kan bruges enten uden nogen tr√¶ning eller med en lille m√¶ngde tr√¶ning. De inkluderer talegenkendelse og overs√¶ttelse, sprogforst√•else og billedanalyse. Disse er tilg√¶ngelige med en gratis niveau som tjenester i Azure.

> üíÅ Det gratis niveau er mere end nok til at oprette en model, tr√¶ne den og derefter bruge den til udviklingsarbejde. Du kan l√¶se om gr√¶nserne for det gratis niveau p√• [Custom Vision Limits and quotas-siden p√• Microsoft Docs](https://docs.microsoft.com/azure/cognitive-services/custom-vision-service/limits-and-quotas?WT.mc_id=academic-17441-jabenn).

### Opgave - opret en Cognitive Services-ressource

For at bruge Custom Vision skal du f√∏rst oprette to Cognitive Services-ressourcer i Azure ved hj√¶lp af Azure CLI, en til Custom Vision-tr√¶ning og en til Custom Vision-forudsigelse.

1. Opret en Resource Group til dette projekt kaldet `fruit-quality-detector`.

1. Brug f√∏lgende kommando til at oprette en gratis Custom Vision-tr√¶ningsressource:

    ```sh
    az cognitiveservices account create --name fruit-quality-detector-training \
                                        --resource-group fruit-quality-detector \
                                        --kind CustomVision.Training \
                                        --sku F0 \
                                        --yes \
                                        --location <location>
    ```

    Erstat `<location>` med den placering, du brugte, da du oprettede Resource Group.

    Dette vil oprette en Custom Vision-tr√¶ningsressource i din Resource Group. Den vil blive kaldt `fruit-quality-detector-training` og bruge `F0` sku, som er det gratis niveau. `--yes`-indstillingen betyder, at du accepterer vilk√•rene og betingelserne for Cognitive Services.

> üíÅ Brug `S0` sku, hvis du allerede har en gratis konto, der bruger nogen af Cognitive Services.

1. Brug f√∏lgende kommando til at oprette en gratis Custom Vision-forudsigelsesressource:

    ```sh
    az cognitiveservices account create --name fruit-quality-detector-prediction \
                                        --resource-group fruit-quality-detector \
                                        --kind CustomVision.Prediction \
                                        --sku F0 \
                                        --yes \
                                        --location <location>
    ```

    Erstat `<location>` med den placering, du brugte, da du oprettede Resource Group.

    Dette vil oprette en Custom Vision-forudsigelsesressource i din Resource Group. Den vil blive kaldt `fruit-quality-detector-prediction` og bruge `F0` sku, som er det gratis niveau. `--yes`-indstillingen betyder, at du accepterer vilk√•rene og betingelserne for Cognitive Services.

### Opgave - opret et billedklassifikationsprojekt

1. √Öbn Custom Vision-portalen p√• [CustomVision.ai](https://customvision.ai), og log ind med den Microsoft-konto, du brugte til din Azure-konto.

1. F√∏lg [opret en ny projektsektion i quickstart-guiden til at bygge en klassifikator p√• Microsoft Docs](https://docs.microsoft.com/azure/cognitive-services/custom-vision-service/getting-started-build-a-classifier?WT.mc_id=academic-17441-jabenn#create-a-new-project) for at oprette et nyt Custom Vision-projekt. Brugergr√¶nsefladen kan √¶ndre sig, og disse dokumenter er altid den mest opdaterede reference.

    Kald dit projekt `fruit-quality-detector`.

    N√•r du opretter dit projekt, skal du s√∏rge for at bruge den `fruit-quality-detector-training`-ressource, du oprettede tidligere. Brug en *Classification*-projekttype, en *Multiclass*-klassifikationstype og *Food*-dom√¶net.

    ![Indstillingerne for Custom Vision-projektet med navnet sat til fruit-quality-detector, ingen beskrivelse, ressourcen sat til fruit-quality-detector-training, projekttypen sat til classification, klassifikationstyperne sat til multi class og dom√¶net sat til food](../../../../../translated_images/custom-vision-create-project.cf46325b92d8b131089f6647cf5e07b664cb77850e106d66e3c057b6b69756c6.da.png)

‚úÖ Tag dig tid til at udforske Custom Vision-brugergr√¶nsefladen for din billedklassifikator.

### Opgave - tr√¶n dit billedklassifikationsprojekt

For at tr√¶ne en billedklassifikator skal du bruge flere billeder af frugt, b√•de af god og d√•rlig kvalitet, som du kan m√¶rke som god og d√•rlig, s√•som en moden og en overmoden banan.
üíÅ Disse klassifikatorer kan klassificere billeder af hvad som helst, s√• hvis du ikke har frugt med forskellig kvalitet ved h√•nden, kan du bruge to forskellige typer frugt eller katte og hunde!
Ideelt set b√∏r hvert billede kun vise frugten, enten med en ensartet baggrund eller en bred vifte af baggrunde. S√∏rg for, at der ikke er noget i baggrunden, der er specifikt for moden vs umoden frugt.

> üíÅ Det er vigtigt ikke at have specifikke baggrunde eller specifikke genstande, der ikke er relateret til det, der klassificeres for hver tag, da klassificeringsmodellen ellers kan ende med at klassificere baseret p√• baggrunden. Der var engang en klassificeringsmodel for hudkr√¶ft, der blev tr√¶net p√• b√•de normale og kr√¶ftsyge moderm√¶rker, og de kr√¶ftsyge havde alle linealer ved siden af for at m√•le st√∏rrelsen. Det viste sig, at modellen var n√¶sten 100% n√∏jagtig til at identificere linealer i billeder, ikke kr√¶ftsyge moderm√¶rker.

Billedklassificeringsmodeller k√∏rer ved meget lav opl√∏sning. For eksempel kan Custom Vision tage tr√¶nings- og forudsigelsesbilleder op til 10240x10240, men tr√¶ner og k√∏rer modellen p√• billeder ved 227x227. St√∏rre billeder bliver reduceret til denne st√∏rrelse, s√• s√∏rg for, at det, du klassificerer, fylder en stor del af billedet, ellers kan det v√¶re for sm√•t i det mindre billede, som modellen bruger.

1. Saml billeder til din klassificeringsmodel. Du skal bruge mindst 5 billeder for hver etiket for at tr√¶ne modellen, men jo flere, jo bedre. Du skal ogs√• bruge nogle ekstra billeder til at teste modellen. Disse billeder skal alle v√¶re forskellige billeder af det samme. For eksempel:

    * Brug 2 modne bananer, og tag nogle billeder af hver fra forskellige vinkler, mindst 7 billeder (5 til tr√¶ning, 2 til test), men helst flere.

        ![Fotos af 2 forskellige bananer](../../../../../translated_images/banana-training-images.530eb203346d73bc23b8b990fb4609470bf4ff7c942ccc13d4cfffeed9be1ad4.da.png)

    * Gentag samme proces med 2 umodne bananer.

    Du b√∏r have mindst 10 tr√¶ningsbilleder, med mindst 5 modne og 5 umodne, og 4 testbilleder, 2 modne og 2 umodne. Dine billeder skal v√¶re png eller jpeg, mindre end 6MB. Hvis du for eksempel tager dem med en iPhone, kan de v√¶re h√∏jopl√∏snings-HEIC-billeder, som skal konverteres og muligvis reduceres. Jo flere billeder, jo bedre, og du b√∏r have et lignende antal modne og umodne.

    Hvis du ikke har b√•de modne og umodne frugter, kan du bruge forskellige frugter eller andre genstande, du har til r√•dighed. Du kan ogs√• finde nogle eksempler p√• billeder i [images](../../../../../4-manufacturing/lessons/1-train-fruit-detector/images)-mappen af modne og umodne bananer, som du kan bruge.

1. F√∏lg [upload og tag billeder-sektionen i quickstart-guiden til at bygge en klassificeringsmodel p√• Microsoft Docs](https://docs.microsoft.com/azure/cognitive-services/custom-vision-service/getting-started-build-a-classifier?WT.mc_id=academic-17441-jabenn#upload-and-tag-images) for at uploade dine tr√¶ningsbilleder. Tag de modne frugter som `ripe` og de umodne som `unripe`.

    ![Upload-dialoger, der viser upload af billeder af modne og umodne bananer](../../../../../translated_images/image-upload-bananas.0751639f3815e0ec42bdbc6254d1e4357a185834d1ae10c9948a0e7d6d336695.da.png)

1. F√∏lg [tr√¶n klassificeringsmodellen-sektionen i quickstart-guiden til at bygge en klassificeringsmodel p√• Microsoft Docs](https://docs.microsoft.com/azure/cognitive-services/custom-vision-service/getting-started-build-a-classifier?WT.mc_id=academic-17441-jabenn#train-the-classifier) for at tr√¶ne billedklassificeringsmodellen med dine uploadede billeder.

    Du vil f√• mulighed for at v√¶lge tr√¶ningstype. V√¶lg **Quick Training**.

Modellen vil derefter tr√¶ne. Det vil tage et par minutter, f√∏r tr√¶ningen er f√¶rdig.

> üçå Hvis du beslutter dig for at spise din frugt, mens modellen tr√¶ner, s√• s√∏rg for, at du har nok billeder til at teste med f√∏rst!

## Test din billedklassificeringsmodel

N√•r din model er tr√¶net, kan du teste den ved at give den et nyt billede til klassificering.

### Opgave - test din billedklassificeringsmodel

1. F√∏lg [test din model-dokumentationen p√• Microsoft Docs](https://docs.microsoft.com/azure/cognitive-services/custom-vision-service/test-your-model?WT.mc_id=academic-17441-jabenn#test-your-model) for at teste din billedklassificeringsmodel. Brug de testbilleder, du oprettede tidligere, ikke nogen af de billeder, du brugte til tr√¶ning.

    ![En umoden banan forudsagt som umoden med 98,9% sandsynlighed, moden med 1,1% sandsynlighed](../../../../../translated_images/banana-unripe-quick-test-prediction.dae9b5e1c4ef7c64886422438850ea14f0be6ac918c217ea3b255c685abfabe7.da.png)

1. Pr√∏v alle de testbilleder, du har adgang til, og observer sandsynlighederne.

## Gen-tr√¶n din billedklassificeringsmodel

N√•r du tester din model, kan den muligvis ikke give de resultater, du forventer. Billedklassificeringsmodeller bruger maskinl√¶ring til at lave forudsigelser om, hvad der er i et billede, baseret p√• sandsynligheder for, at bestemte tr√¶k ved et billede betyder, at det matcher en bestemt etiket. Den forst√•r ikke, hvad der er i billedet - den ved ikke, hvad en banan er eller forst√•r, hvad der g√∏r en banan til en banan i stedet for en b√•d. Du kan forbedre din model ved at gen-tr√¶ne den med billeder, den tager fejl af.

Hver gang du laver en forudsigelse ved hj√¶lp af quick test-muligheden, gemmes billedet og resultaterne. Du kan bruge disse billeder til at gen-tr√¶ne din model.

### Opgave - gen-tr√¶n din billedklassificeringsmodel

1. F√∏lg [brug det forudsagte billede til tr√¶ning-dokumentationen p√• Microsoft Docs](https://docs.microsoft.com/azure/cognitive-services/custom-vision-service/test-your-model?WT.mc_id=academic-17441-jabenn#use-the-predicted-image-for-training) for at gen-tr√¶ne din model, ved at bruge den korrekte etiket for hvert billede.

1. N√•r din model er blevet gen-tr√¶net, test den med nye billeder.

---

## üöÄ Udfordring

Hvad tror du, der ville ske, hvis du brugte et billede af en jordb√¶r med en model, der er tr√¶net p√• bananer, eller et billede af en oppustelig banan, eller en person i et banankostume, eller endda en gul tegneseriefigur som en fra Simpsons?

Pr√∏v det og se, hvad forudsigelserne er. Du kan finde billeder at pr√∏ve med ved hj√¶lp af [Bing Image search](https://www.bing.com/images/trending).

## Quiz efter forel√¶sning

[Quiz efter forel√¶sning](https://black-meadow-040d15503.1.azurestaticapps.net/quiz/30)

## Gennemgang & Selvstudie

* N√•r du tr√¶nede din model, ville du have set v√¶rdier for *Precision*, *Recall* og *AP*, der vurderer den model, der blev oprettet. L√¶s om, hvad disse v√¶rdier betyder ved hj√¶lp af [evalu√©r klassificeringsmodellen-sektionen i quickstart-guiden til at bygge en klassificeringsmodel p√• Microsoft Docs](https://docs.microsoft.com/azure/cognitive-services/custom-vision-service/getting-started-build-a-classifier?WT.mc_id=academic-17441-jabenn#evaluate-the-classifier)
* L√¶s om, hvordan du kan forbedre din model fra [hvordan du forbedrer din Custom Vision-model p√• Microsoft Docs](https://docs.microsoft.com/azure/cognitive-services/custom-vision-service/getting-started-improving-your-classifier?WT.mc_id=academic-17441-jabenn)

## Opgave

[Tr√¶n din model til flere frugter og gr√∏ntsager](assignment.md)

---

**Ansvarsfraskrivelse**:  
Dette dokument er blevet oversat ved hj√¶lp af AI-overs√¶ttelsestjenesten [Co-op Translator](https://github.com/Azure/co-op-translator). Selvom vi bestr√¶ber os p√• at sikre n√∏jagtighed, skal det bem√¶rkes, at automatiserede overs√¶ttelser kan indeholde fejl eller un√∏jagtigheder. Det originale dokument p√• dets oprindelige sprog b√∏r betragtes som den autoritative kilde. For kritisk information anbefales professionel menneskelig overs√¶ttelse. Vi er ikke ansvarlige for eventuelle misforst√•elser eller fejltolkninger, der m√•tte opst√• som f√∏lge af brugen af denne overs√¶ttelse.