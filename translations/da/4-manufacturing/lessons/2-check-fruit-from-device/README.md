<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "557f4ee96b752e0651d2e6e74aa6bd14",
  "translation_date": "2025-08-27T20:40:39+00:00",
  "source_file": "4-manufacturing/lessons/2-check-fruit-from-device/README.md",
  "language_code": "da"
}
-->
# Kontroller frugtkvalitet med en IoT-enhed

![En sketchnote oversigt over denne lektion](../../../../../translated_images/lesson-16.215daf18b00631fbdfd64c6fc2dc6044dff5d544288825d8076f9fb83d964c23.da.jpg)

> Sketchnote af [Nitya Narasimhan](https://github.com/nitya). Klik p√• billedet for en st√∏rre version.

## Quiz f√∏r lektionen

[Quiz f√∏r lektionen](https://black-meadow-040d15503.1.azurestaticapps.net/quiz/31)

## Introduktion

I den sidste lektion l√¶rte du om billedklassifikatorer, og hvordan man tr√¶ner dem til at opdage god og d√•rlig frugt. For at bruge denne billedklassifikator i en IoT-applikation skal du kunne tage et billede med en slags kamera og sende dette billede til skyen for at blive klassificeret.

I denne lektion vil du l√¶re om kamerasensorer, og hvordan man bruger dem med en IoT-enhed til at tage et billede. Du vil ogs√• l√¶re, hvordan man kalder billedklassifikatoren fra din IoT-enhed.

I denne lektion d√¶kker vi:

* [Kamerasensorer](../../../../../4-manufacturing/lessons/2-check-fruit-from-device)
* [Tag et billede med en IoT-enhed](../../../../../4-manufacturing/lessons/2-check-fruit-from-device)
* [Publicer din billedklassifikator](../../../../../4-manufacturing/lessons/2-check-fruit-from-device)
* [Klassificer billeder fra din IoT-enhed](../../../../../4-manufacturing/lessons/2-check-fruit-from-device)
* [Forbedr modellen](../../../../../4-manufacturing/lessons/2-check-fruit-from-device)

## Kamerasensorer

Kamerasensorer, som navnet antyder, er kameraer, du kan tilslutte til din IoT-enhed. De kan tage stillbilleder eller optage streamingvideo. Nogle returnerer r√• billeddata, mens andre komprimerer billeddataene til en billedfil som JPEG eller PNG. Normalt er de kameraer, der fungerer med IoT-enheder, meget mindre og har lavere opl√∏sning end dem, du m√•ske er vant til, men du kan f√• kameraer med h√∏j opl√∏sning, der kan konkurrere med de bedste smartphones. Du kan f√• alle slags udskiftelige linser, ops√¶tninger med flere kameraer, infrar√∏de termiske kameraer eller UV-kameraer.

![Lyset fra en scene passerer gennem en linse og fokuseres p√• en CMOS-sensor](../../../../../translated_images/cmos-sensor.75f9cd74decb137149a4c9ea825251a4549497d67c0ae2776159e6102bb53aa9.da.png)

De fleste kamerasensorer bruger billedsensorer, hvor hver pixel er en fotodiode. En linse fokuserer billedet p√• billedsensoren, og tusinder eller millioner af fotodioder registrerer lyset, der falder p√• hver enkelt, og gemmer det som pixeldata.

> üíÅ Linser vender billeder p√• hovedet, og kamerasensoren vender derefter billedet tilbage til den rigtige retning. Det samme sker i dine √∏jne - det, du ser, registreres p√• hovedet p√• bagsiden af dit √∏je, og din hjerne korrigerer det.

> üéì Billedsensoren kaldes en Active-Pixel Sensor (APS), og den mest popul√¶re type APS er en komplement√¶r metal-oxid halvleder-sensor, eller CMOS. Du har m√•ske h√∏rt udtrykket CMOS-sensor brugt om kamerasensorer.

Kamerasensorer er digitale sensorer, der sender billeddata som digitale data, normalt med hj√¶lp fra et bibliotek, der leverer kommunikationen. Kameraer tilsluttes ved hj√¶lp af protokoller som SPI for at sende store m√¶ngder data - billeder er betydeligt st√∏rre end enkeltv√¶rdier fra en sensor som en temperatursensor.

‚úÖ Hvad er begr√¶nsningerne omkring billedst√∏rrelse med IoT-enheder? T√¶nk p√• begr√¶nsningerne, is√¶r p√• mikrocontrollerhardware.

## Tag et billede med en IoT-enhed

Du kan bruge din IoT-enhed til at tage et billede, der skal klassificeres.

### Opgave - tag et billede med en IoT-enhed

F√∏lg den relevante vejledning for at tage et billede med din IoT-enhed:

* [Arduino - Wio Terminal](wio-terminal-camera.md)
* [Single-board computer - Raspberry Pi](pi-camera.md)
* [Single-board computer - Virtuel enhed](virtual-device-camera.md)

## Publicer din billedklassifikator

Du tr√¶nede din billedklassifikator i den sidste lektion. F√∏r du kan bruge den fra din IoT-enhed, skal du publicere modellen.

### Modeliterationer

Da din model blev tr√¶net i den sidste lektion, har du m√•ske bem√¶rket, at fanen **Performance** viser iterationer p√• siden. Da du f√∏rst tr√¶nede modellen, ville du have set *Iteration 1* under tr√¶ning. Da du forbedrede modellen ved hj√¶lp af forudsigelsesbillederne, ville du have set *Iteration 2* under tr√¶ning.

Hver gang du tr√¶ner modellen, f√•r du en ny iteration. Dette er en m√•de at holde styr p√• de forskellige versioner af din model, der er tr√¶net p√• forskellige datas√¶t. N√•r du udf√∏rer en **Quick Test**, er der en rullemenu, du kan bruge til at v√¶lge iterationen, s√• du kan sammenligne resultaterne p√• tv√¶rs af flere iterationer.

N√•r du er tilfreds med en iteration, kan du publicere den, s√• den kan bruges fra eksterne applikationer. P√• denne m√•de kan du have en publiceret version, der bruges af dine enheder, og derefter arbejde p√• en ny version over flere iterationer, og publicere den, n√•r du er tilfreds med den.

### Opgave - publicer en iteration

Iterationer publiceres fra Custom Vision-portalen.

1. √Öbn Custom Vision-portalen p√• [CustomVision.ai](https://customvision.ai) og log ind, hvis du ikke allerede har den √•ben. √Öbn derefter dit `fruit-quality-detector`-projekt.

1. V√¶lg fanen **Performance** fra mulighederne √∏verst.

1. V√¶lg den nyeste iteration fra listen *Iterations* p√• siden.

1. V√¶lg knappen **Publish** for iterationen.

    ![Publiceringsknappen](../../../../../translated_images/custom-vision-publish-button.b7174e1977b0c33b8b72d4e5b1326c779e0af196f3849d09985ee2d7d5493a39.da.png)

1. I dialogboksen *Publish Model* skal du indstille *Prediction resource* til den `fruit-quality-detector-prediction`-ressource, du oprettede i den sidste lektion. Lad navnet v√¶re `Iteration2`, og v√¶lg knappen **Publish**.

1. N√•r den er publiceret, skal du v√¶lge knappen **Prediction URL**. Dette vil vise detaljer om forudsigelses-API'en, og du vil f√• brug for disse for at kalde modellen fra din IoT-enhed. Den nederste sektion er m√¶rket *If you have an image file*, og det er disse detaljer, du skal bruge. Tag en kopi af den viste URL, som vil v√¶re noget i stil med:

    ```output
    https://<location>.api.cognitive.microsoft.com/customvision/v3.0/Prediction/<id>/classify/iterations/Iteration2/image
    ```

    Hvor `<location>` vil v√¶re den placering, du brugte, da du oprettede din Custom Vision-ressource, og `<id>` vil v√¶re en lang ID best√•ende af bogstaver og tal.

    Tag ogs√• en kopi af v√¶rdien *Prediction-Key*. Dette er en sikker n√∏gle, som du skal sende, n√•r du kalder modellen. Kun applikationer, der sender denne n√∏gle, har tilladelse til at bruge modellen, alle andre applikationer afvises.

    ![Dialogboksen for forudsigelses-API, der viser URL og n√∏gle](../../../../../translated_images/custom-vision-prediction-key-endpoint.30c569ffd0338864f319911f052d5e9b8c5066cb0800a26dd6f7ff5713130ad8.da.png)

‚úÖ N√•r en ny iteration publiceres, vil den have et andet navn. Hvordan tror du, du ville √¶ndre den iteration, en IoT-enhed bruger?

## Klassificer billeder fra din IoT-enhed

Du kan nu bruge disse forbindelsesdetaljer til at kalde billedklassifikatoren fra din IoT-enhed.

### Opgave - klassificer billeder fra din IoT-enhed

F√∏lg den relevante vejledning for at klassificere billeder ved hj√¶lp af din IoT-enhed:

* [Arduino - Wio Terminal](wio-terminal-classify-image.md)
* [Single-board computer - Raspberry Pi/Virtuel IoT-enhed](single-board-computer-classify-image.md)

## Forbedr modellen

Du kan opleve, at de resultater, du f√•r, n√•r du bruger kameraet tilsluttet din IoT-enhed, ikke stemmer overens med, hvad du ville forvente. Forudsigelserne er ikke altid lige s√• n√∏jagtige som ved brug af billeder uploadet fra din computer. Dette skyldes, at modellen blev tr√¶net p√• forskellige data end dem, der bruges til forudsigelser.

For at f√• de bedste resultater for en billedklassifikator vil du gerne tr√¶ne modellen med billeder, der er s√• ens som muligt med de billeder, der bruges til forudsigelser. Hvis du for eksempel brugte dit telefonkamera til at tage billeder til tr√¶ning, vil billedkvaliteten, skarpheden og farverne v√¶re anderledes end et kamera tilsluttet en IoT-enhed.

![2 bananbilleder, et lavopl√∏sningsbillede med d√•rlig belysning fra en IoT-enhed, og et h√∏jopl√∏sningsbillede med god belysning fra en telefon](../../../../../translated_images/banana-picture-compare.174df164dc326a42cf7fb051a7497e6113c620e91552d92ca914220305d47d9a.da.png)

P√• billedet ovenfor blev bananbilledet til venstre taget med et Raspberry Pi-kamera, mens det til h√∏jre blev taget af den samme banan p√• samme sted med en iPhone. Der er en tydelig forskel i kvalitet - iPhone-billedet er skarpere, med lysere farver og mere kontrast.

‚úÖ Hvad kan ellers for√•rsage, at de billeder, der tages af din IoT-enhed, giver forkerte forudsigelser? T√¶nk p√• det milj√∏, en IoT-enhed kan bruges i, hvilke faktorer kan p√•virke det billede, der tages?

For at forbedre modellen kan du genoptr√¶ne den ved hj√¶lp af de billeder, der er taget fra IoT-enheden.

### Opgave - forbedr modellen

1. Klassificer flere billeder af b√•de moden og umoden frugt ved hj√¶lp af din IoT-enhed.

1. I Custom Vision-portalen skal du genoptr√¶ne modellen ved hj√¶lp af billederne p√• fanen *Predictions*.

    > ‚ö†Ô∏è Du kan henvise til [instruktionerne for genoptr√¶ning af din klassifikator i lektion 1, hvis det er n√∏dvendigt](../1-train-fruit-detector/README.md#retrain-your-image-classifier).

1. Hvis dine billeder ser meget anderledes ud end de oprindelige, der blev brugt til tr√¶ning, kan du slette alle de oprindelige billeder ved at v√¶lge dem p√• fanen *Training Images* og v√¶lge knappen **Delete**. For at v√¶lge et billede skal du f√∏re din mark√∏r over det, og der vises et flueben, som du kan v√¶lge eller frav√¶lge.

1. Tr√¶n en ny iteration af modellen og publicer den ved hj√¶lp af ovenst√•ende trin.

1. Opdater endpoint-URL'en i din kode, og k√∏r appen igen.

1. Gentag disse trin, indtil du er tilfreds med resultaterne af forudsigelserne.

---

## üöÄ Udfordring

Hvor meget p√•virker billedopl√∏sning eller belysning forudsigelsen?

Pr√∏v at √¶ndre opl√∏sningen af billederne i din enhedskode og se, om det g√∏r en forskel for kvaliteten af billederne. Pr√∏v ogs√• at √¶ndre belysningen.

Hvis du skulle skabe en produktionsenhed til salg til g√•rde eller fabrikker, hvordan ville du sikre, at den giver konsistente resultater hele tiden?

## Quiz efter lektionen

[Quiz efter lektionen](https://black-meadow-040d15503.1.azurestaticapps.net/quiz/32)

## Gennemgang & Selvstudie

Du tr√¶nede din Custom Vision-model ved hj√¶lp af portalen. Dette afh√¶nger af at have billeder tilg√¶ngelige - og i den virkelige verden kan du m√•ske ikke f√• tr√¶ningsdata, der matcher, hvad kameraet p√• din enhed fanger. Du kan omg√• dette ved at tr√¶ne direkte fra din enhed ved hj√¶lp af tr√¶nings-API'en, for at tr√¶ne en model ved hj√¶lp af billeder taget fra din IoT-enhed.

* L√¶s om tr√¶nings-API'en i [quick start for brug af Custom Vision SDK](https://docs.microsoft.com/azure/cognitive-services/custom-vision-service/quickstarts/image-classification?WT.mc_id=academic-17441-jabenn&tabs=visual-studio&pivots=programming-language-python)

## Opgave

[Reager p√• klassifikationsresultater](assignment.md)

---

**Ansvarsfraskrivelse**:  
Dette dokument er blevet oversat ved hj√¶lp af AI-overs√¶ttelsestjenesten [Co-op Translator](https://github.com/Azure/co-op-translator). Selvom vi bestr√¶ber os p√• n√∏jagtighed, skal du v√¶re opm√¶rksom p√•, at automatiserede overs√¶ttelser kan indeholde fejl eller un√∏jagtigheder. Det originale dokument p√• dets oprindelige sprog b√∏r betragtes som den autoritative kilde. For kritisk information anbefales professionel menneskelig overs√¶ttelse. Vi er ikke ansvarlige for eventuelle misforst√•elser eller fejltolkninger, der m√•tte opst√• som f√∏lge af brugen af denne overs√¶ttelse.