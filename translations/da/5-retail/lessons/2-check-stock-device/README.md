<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "1c9e5fa8b7be726c75a97232b1e41c97",
  "translation_date": "2025-08-27T22:16:30+00:00",
  "source_file": "5-retail/lessons/2-check-stock-device/README.md",
  "language_code": "da"
}
-->
# Tjek lager fra en IoT-enhed

![En sketchnote-oversigt over denne lektion](../../../../../translated_images/lesson-20.0211df9551a8abb300fc8fcf7dc2789468dea2eabe9202273ac077b0ba37f15e.da.jpg)

> Sketchnote af [Nitya Narasimhan](https://github.com/nitya). Klik p√• billedet for en st√∏rre version.

## Quiz f√∏r lektionen

[Quiz f√∏r lektionen](https://black-meadow-040d15503.1.azurestaticapps.net/quiz/39)

## Introduktion

I den forrige lektion l√¶rte du om de forskellige anvendelser af objektdetektion i detailhandlen. Du l√¶rte ogs√•, hvordan man tr√¶ner en objektdetektor til at identificere lager. I denne lektion vil du l√¶re, hvordan du bruger din objektdetektor fra din IoT-enhed til at t√¶lle lager.

I denne lektion d√¶kker vi:

* [Lageropt√¶lling](../../../../../5-retail/lessons/2-check-stock-device)
* [Kald din objektdetektor fra din IoT-enhed](../../../../../5-retail/lessons/2-check-stock-device)
* [Afgr√¶nsningsbokse](../../../../../5-retail/lessons/2-check-stock-device)
* [Gen-tr√¶n modellen](../../../../../5-retail/lessons/2-check-stock-device)
* [T√¶l lager](../../../../../5-retail/lessons/2-check-stock-device)

> üóë Dette er den sidste lektion i dette projekt, s√• efter at have gennemf√∏rt denne lektion og opgaven, skal du huske at rydde op i dine cloud-tjenester. Du skal bruge tjenesterne for at fuldf√∏re opgaven, s√• s√∏rg for at g√∏re det f√∏rst.
>
> Se [guiden til at rydde op i dit projekt](../../../clean-up.md), hvis du har brug for instruktioner til, hvordan du g√∏r dette.

## Lageropt√¶lling

Objektdetektorer kan bruges til lagerkontrol, enten til at t√¶lle lager eller sikre, at lageret er, hvor det skal v√¶re. IoT-enheder med kameraer kan placeres rundt om i butikken for at overv√•ge lageret, startende med hotspots, hvor det er vigtigt at genopfylde varer, s√•som omr√•der med sm√• m√¶ngder af h√∏jv√¶rdiartikler.

For eksempel, hvis et kamera peger p√• en hylde, der kan rumme 8 d√•ser tomatpur√©, og en objektdetektor kun registrerer 7 d√•ser, mangler der √©n, som skal genopfyldes.

![7 d√•ser tomatpur√© p√• en hylde, 4 p√• √∏verste r√¶kke, 3 p√• nederste r√¶kke](../../../../../translated_images/stock-7-cans-tomato-paste.f86059cc573d7becaa89a0eafb9d2cd7e2fe37405a530fe565990e2333d0e4a1.da.png)

I billedet ovenfor har en objektdetektor registreret 7 d√•ser tomatpur√© p√• en hylde, der kan rumme 8 d√•ser. Ikke alene kan IoT-enheden sende en notifikation om behovet for genopfyldning, men den kan ogs√• give en indikation af, hvor den manglende vare befinder sig, hvilket er vigtig information, hvis du bruger robotter til at genopfylde hylder.

> üíÅ Afh√¶ngigt af butikken og varens popularitet ville genopfyldning sandsynligvis ikke ske, hvis kun √©n d√•se manglede. Du skal bygge en algoritme, der bestemmer, hvorn√•r der skal genopfyldes, baseret p√• dine varer, kunder og andre kriterier.

‚úÖ I hvilke andre scenarier kunne du kombinere objektdetektion og robotter?

Nogle gange kan det forkerte lager v√¶re p√• hylderne. Dette kan skyldes menneskelige fejl under genopfyldning eller kunder, der ombestemmer sig og placerer en vare p√• den f√∏rste ledige plads. N√•r det drejer sig om ikke-letford√¶rvelige varer som konserves, er dette en irritation. Hvis det er letford√¶rvelige varer som frosne eller k√∏lede produkter, kan det betyde, at varen ikke l√¶ngere kan s√¶lges, da det kan v√¶re umuligt at afg√∏re, hvor l√¶nge varen har v√¶ret ude af fryseren.

Objektdetektion kan bruges til at opdage uventede varer og igen advare en person eller robot om at returnere varen, s√• snart den opdages.

![En vildfaren d√•se babymajs p√• tomatpur√©hylden](../../../../../translated_images/stock-rogue-corn.be1f3ada8c4578544641af66671c1711a4c02297f14cc7f503354dae0d30a954.da.png)

I billedet ovenfor er en d√•se babymajs blevet placeret p√• hylden ved siden af tomatpur√©en. Objektdetektoren har registreret dette, hvilket g√∏r det muligt for IoT-enheden at give besked til en person eller robot om at returnere d√•sen til dens korrekte placering.

## Kald din objektdetektor fra din IoT-enhed

Den objektdetektor, du tr√¶nede i den sidste lektion, kan kaldes fra din IoT-enhed.

### Opgave - udgiv en iteration af din objektdetektor

Iterationer udgives fra Custom Vision-portalen.

1. √Öbn Custom Vision-portalen p√• [CustomVision.ai](https://customvision.ai), og log ind, hvis du ikke allerede har den √•ben. √Öbn derefter dit `stock-detector`-projekt.

1. V√¶lg fanen **Performance** fra mulighederne √∏verst.

1. V√¶lg den nyeste iteration fra listen *Iterations* i siden.

1. V√¶lg knappen **Publish** for iterationen.

    ![Udgiv-knappen](../../../../../translated_images/custom-vision-object-detector-publish-button.34ee379fc650ccb9856c3868d0003f413b9529f102fc73c37168c98d721cc293.da.png)

1. I dialogboksen *Publish Model* skal du indstille *Prediction resource* til den `stock-detector-prediction`-ressource, du oprettede i den sidste lektion. Lad navnet v√¶re `Iteration2`, og v√¶lg knappen **Publish**.

1. N√•r den er udgivet, skal du v√¶lge knappen **Prediction URL**. Dette vil vise detaljer om forudsigelses-API'en, som du skal bruge for at kalde modellen fra din IoT-enhed. Den nederste sektion er m√¶rket *If you have an image file*, og det er disse detaljer, du skal bruge. Tag en kopi af den viste URL, som vil v√¶re noget i stil med:

    ```output
    https://<location>.api.cognitive.microsoft.com/customvision/v3.0/Prediction/<id>/detect/iterations/Iteration2/image
    ```

    Hvor `<location>` vil v√¶re den placering, du brugte, da du oprettede din Custom Vision-ressource, og `<id>` vil v√¶re en lang ID best√•ende af bogstaver og tal.

    Tag ogs√• en kopi af v√¶rdien *Prediction-Key*. Dette er en sikker n√∏gle, som du skal sende, n√•r du kalder modellen. Kun applikationer, der sender denne n√∏gle, har tilladelse til at bruge modellen, alle andre applikationer afvises.

    ![Dialogboksen for forudsigelses-API, der viser URL og n√∏gle](../../../../../translated_images/custom-vision-prediction-key-endpoint.30c569ffd0338864f319911f052d5e9b8c5066cb0800a26dd6f7ff5713130ad8.da.png)

‚úÖ N√•r en ny iteration udgives, vil den have et andet navn. Hvordan tror du, at du ville √¶ndre den iteration, som en IoT-enhed bruger?

### Opgave - kald din objektdetektor fra din IoT-enhed

F√∏lg den relevante guide nedenfor for at bruge objektdetektoren fra din IoT-enhed:

* [Arduino - Wio Terminal](wio-terminal-object-detector.md)
* [Single-board computer - Raspberry Pi/Virtual device](single-board-computer-object-detector.md)

## Afgr√¶nsningsbokse

N√•r du bruger objektdetektoren, f√•r du ikke kun de registrerede objekter med deres tags og sandsynligheder, men ogs√• afgr√¶nsningsboksene for objekterne. Disse definerer, hvor objektdetektoren registrerede objektet med den givne sandsynlighed.

> üíÅ En afgr√¶nsningsboks er en boks, der definerer det omr√•de, der indeholder det registrerede objekt, en boks, der definerer gr√¶nsen for objektet.

Resultaterne af en forudsigelse i fanen **Predictions** i Custom Vision har afgr√¶nsningsboksene tegnet p√• det billede, der blev sendt til forudsigelse.

![4 d√•ser tomatpur√© p√• en hylde med forudsigelser for de 4 registreringer p√• 35,8 %, 33,5 %, 25,7 % og 16,6 %](../../../../../translated_images/custom-vision-stock-prediction.942266ab1bcca3410ecdf23643b9f5f570cfab2345235074e24c51f285777613.da.png)

I billedet ovenfor blev 4 d√•ser tomatpur√© registreret. I resultaterne er en r√∏d firkant overlejret for hvert objekt, der blev registreret i billedet, hvilket angiver afgr√¶nsningsboksen for billedet.

‚úÖ √Öbn forudsigelserne i Custom Vision, og tjek afgr√¶nsningsboksene.

Afgr√¶nsningsbokse defineres med 4 v√¶rdier - top, venstre, h√∏jde og bredde. Disse v√¶rdier er p√• en skala fra 0-1, der repr√¶senterer positionerne som en procentdel af billedets st√∏rrelse. Oprindelsen (0,0-positionen) er √∏verste venstre hj√∏rne af billedet, s√• topv√¶rdien er afstanden fra toppen, og bunden af afgr√¶nsningsboksen er toppen plus h√∏jden.

![En afgr√¶nsningsboks omkring en d√•se tomatpur√©](../../../../../translated_images/bounding-box.1420a7ea0d3d15f71e1ffb5cf4b2271d184fac051f990abc541975168d163684.da.png)

Billedet ovenfor er 600 pixels bredt og 800 pixels h√∏jt. Afgr√¶nsningsboksen starter 320 pixels nede, hvilket giver en topkoordinat p√• 0,4 (800 x 0,4 = 320). Fra venstre starter afgr√¶nsningsboksen 240 pixels inde, hvilket giver en venstre koordinat p√• 0,4 (600 x 0,4 = 240). H√∏jden p√• afgr√¶nsningsboksen er 240 pixels, hvilket giver en h√∏jdev√¶rdi p√• 0,3 (800 x 0,3 = 240). Bredden p√• afgr√¶nsningsboksen er 120 pixels, hvilket giver en breddev√¶rdi p√• 0,2 (600 x 0,2 = 120).

| Koordinat | V√¶rdi |
| --------- | ----: |
| Top       | 0,4   |
| Venstre   | 0,4   |
| H√∏jde     | 0,3   |
| Bredde    | 0,2   |

Ved at bruge procentv√¶rdier fra 0-1 betyder det, at uanset hvilken st√∏rrelse billedet skaleres til, starter afgr√¶nsningsboksen 0,4 af vejen hen og ned og er 0,3 af h√∏jden og 0,2 af bredden.

Du kan bruge afgr√¶nsningsbokse kombineret med sandsynligheder til at evaluere, hvor pr√¶cis en registrering er. For eksempel kan en objektdetektor registrere flere objekter, der overlapper hinanden, for eksempel registrere √©n d√•se inde i en anden. Din kode kunne se p√• afgr√¶nsningsboksene, forst√•, at dette er umuligt, og ignorere eventuelle objekter, der har en betydelig overlapning med andre objekter.

![To afgr√¶nsningsbokse, der overlapper en d√•se tomatpur√©](../../../../../translated_images/overlap-object-detection.d431e03cae75072a2760430eca7f2c5fdd43045bfd72dadcbf12711f7cd6c2ae.da.png)

I eksemplet ovenfor angav en afgr√¶nsningsboks en forudsagt d√•se tomatpur√© med 78,3 %. En anden afgr√¶nsningsboks er lidt mindre og er inde i den f√∏rste afgr√¶nsningsboks med en sandsynlighed p√• 64,3 %. Din kode kan tjekke afgr√¶nsningsboksene, se, at de overlapper fuldst√¶ndigt, og ignorere den lavere sandsynlighed, da det ikke er muligt, at √©n d√•se er inde i en anden.

‚úÖ Kan du t√¶nke p√• en situation, hvor det er gyldigt at registrere √©t objekt inde i et andet?

## Gen-tr√¶n modellen

Ligesom med billedklassifikatoren kan du gen-tr√¶ne din model ved hj√¶lp af data indsamlet af din IoT-enhed. Brug af disse data fra den virkelige verden vil sikre, at din model fungerer godt, n√•r den bruges fra din IoT-enhed.

I mods√¶tning til billedklassifikatoren kan du ikke bare tagge et billede. I stedet skal du gennemg√• hver afgr√¶nsningsboks, der er registreret af modellen. Hvis boksen er omkring det forkerte objekt, skal den slettes, og hvis den er p√• det forkerte sted, skal den justeres.

### Opgave - gen-tr√¶n modellen

1. S√∏rg for, at du har indsamlet en r√¶kke billeder ved hj√¶lp af din IoT-enhed.

1. Fra fanen **Predictions** skal du v√¶lge et billede. Du vil se r√∏de bokse, der angiver afgr√¶nsningsboksene for de registrerede objekter.

1. Gennemg√• hver afgr√¶nsningsboks. V√¶lg den f√∏rst, og du vil se en pop-up, der viser tagget. Brug h√•ndtagene p√• hj√∏rnerne af afgr√¶nsningsboksen til at justere st√∏rrelsen, hvis det er n√∏dvendigt. Hvis tagget er forkert, skal du fjerne det med knappen **X** og tilf√∏je det korrekte tag. Hvis afgr√¶nsningsboksen ikke indeholder et objekt, skal du slette den med skraldespandsknappen.

1. Luk editoren, n√•r du er f√¶rdig, og billedet flyttes fra fanen **Predictions** til fanen **Training Images**. Gentag processen for alle forudsigelser.

1. Brug knappen **Train** til at gen-tr√¶ne din model. N√•r den er tr√¶net, skal du udgive iterationen og opdatere din IoT-enhed til at bruge URL'en for den nye iteration.

1. Genudrul din kode, og test din IoT-enhed.

## T√¶l lager

Ved at kombinere antallet af registrerede objekter og afgr√¶nsningsboksene kan du t√¶lle lageret p√• en hylde.

### Opgave - t√¶l lager

F√∏lg den relevante guide nedenfor for at t√¶lle lager ved hj√¶lp af resultaterne fra objektdetektoren fra din IoT-enhed:

* [Arduino - Wio Terminal](wio-terminal-count-stock.md)
* [Single-board computer - Raspberry Pi/Virtual device](single-board-computer-count-stock.md)

---

## üöÄ Udfordring

Kan du registrere forkert lager? Tr√¶n din model p√• flere objekter, og opdater derefter din app til at advare dig, hvis det forkerte lager registreres.

M√•ske kan du endda tage det et skridt videre og registrere lager side om side p√• samme hylde og se, om noget er blevet placeret forkert ved at definere gr√¶nser for afgr√¶nsningsboksene.

## Quiz efter lektionen

[Quiz efter lektionen](https://black-meadow-040d15503.1.azurestaticapps.net/quiz/40)

## Gennemgang & Selvstudie

* L√¶r mere om, hvordan man arkitekterer et end-to-end lagerdetektionssystem fra [Out of stock detection at the edge pattern guide p√• Microsoft Docs](https://docs.microsoft.com/hybrid/app-solutions/pattern-out-of-stock-at-edge?WT.mc_id=academic-17441-jabenn)
* L√¶r andre m√•der at bygge end-to-end detailhandelsl√∏sninger, der kombinerer en r√¶kke IoT- og cloud-tjenester, ved at se denne [Behind the scenes of a retail solution - Hands On! video p√• YouTube](https://www.youtube.com/watch?v=m3Pc300x2Mw).

## Opgave

[Brug din objektdetektor p√• kanten](assignment.md)

---

**Ansvarsfraskrivelse**:  
Dette dokument er blevet oversat ved hj√¶lp af AI-overs√¶ttelsestjenesten [Co-op Translator](https://github.com/Azure/co-op-translator). Selvom vi bestr√¶ber os p√• at sikre n√∏jagtighed, skal du v√¶re opm√¶rksom p√•, at automatiserede overs√¶ttelser kan indeholde fejl eller un√∏jagtigheder. Det originale dokument p√• dets oprindelige sprog b√∏r betragtes som den autoritative kilde. For kritisk information anbefales professionel menneskelig overs√¶ttelse. Vi p√•tager os ikke ansvar for eventuelle misforst√•elser eller fejltolkninger, der m√•tte opst√• som f√∏lge af brugen af denne overs√¶ttelse.