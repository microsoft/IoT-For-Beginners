<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "8df310a42f902139a01417dacb1ffbef",
  "translation_date": "2025-08-26T21:38:05+00:00",
  "source_file": "5-retail/lessons/1-train-stock-detector/README.md",
  "language_code": "ur"
}
-->
# اسٹاک ڈیٹیکٹر کی تربیت کریں

![اس سبق کا خاکہ](../../../../../translated_images/lesson-19.cf6973cecadf080c4b526310620dc4d6f5994c80fb0139c6f378cc9ca2d435cd.ur.jpg)

> خاکہ [نیتیا نرسمہن](https://github.com/nitya) کی طرف سے۔ بڑی تصویر دیکھنے کے لیے تصویر پر کلک کریں۔

یہ ویڈیو Azure Custom Vision سروس کے ذریعے آبجیکٹ ڈیٹیکشن کا جائزہ پیش کرتی ہے، جو اس سبق میں شامل کی جائے گی۔

[![Custom Vision 2 - Object Detection Made Easy | The Xamarin Show](https://img.youtube.com/vi/wtTYSyBUpFc/0.jpg)](https://www.youtube.com/watch?v=wtTYSyBUpFc)

> 🎥 ویڈیو دیکھنے کے لیے اوپر دی گئی تصویر پر کلک کریں

## لیکچر سے پہلے کا کوئز

[لیکچر سے پہلے کا کوئز](https://black-meadow-040d15503.1.azurestaticapps.net/quiz/37)

## تعارف

پچھلے پروجیکٹ میں، آپ نے AI کا استعمال کرتے ہوئے ایک امیج کلاسیفائر تربیت دی تھی - ایک ماڈل جو یہ بتا سکتا ہے کہ آیا تصویر میں کچھ موجود ہے، جیسے کہ پکا ہوا پھل یا کچا پھل۔ AI ماڈلز کی ایک اور قسم جو تصاویر کے ساتھ استعمال کی جا سکتی ہے وہ آبجیکٹ ڈیٹیکشن ہے۔ یہ ماڈلز تصویر کو ٹیگز کے ذریعے کلاسیفائی نہیں کرتے بلکہ انہیں اشیاء کو پہچاننے کے لیے تربیت دی جاتی ہے، اور وہ تصاویر میں اشیاء کو تلاش کر سکتے ہیں، نہ صرف یہ کہ تصویر موجود ہے بلکہ یہ بھی کہ تصویر میں کہاں موجود ہے۔ اس سے آپ تصاویر میں اشیاء کی گنتی کر سکتے ہیں۔

اس سبق میں آپ آبجیکٹ ڈیٹیکشن کے بارے میں سیکھیں گے، بشمول یہ کہ اسے ریٹیل میں کیسے استعمال کیا جا سکتا ہے۔ آپ یہ بھی سیکھیں گے کہ کلاؤڈ میں آبجیکٹ ڈیٹیکٹر کو کیسے تربیت دی جائے۔

اس سبق میں ہم درج ذیل موضوعات کا احاطہ کریں گے:

* [آبجیکٹ ڈیٹیکشن](../../../../../5-retail/lessons/1-train-stock-detector)
* [ریٹیل میں آبجیکٹ ڈیٹیکشن کا استعمال](../../../../../5-retail/lessons/1-train-stock-detector)
* [آبجیکٹ ڈیٹیکٹر کی تربیت کریں](../../../../../5-retail/lessons/1-train-stock-detector)
* [اپنے آبجیکٹ ڈیٹیکٹر کو ٹیسٹ کریں](../../../../../5-retail/lessons/1-train-stock-detector)
* [اپنے آبجیکٹ ڈیٹیکٹر کو دوبارہ تربیت دیں](../../../../../5-retail/lessons/1-train-stock-detector)

## آبجیکٹ ڈیٹیکشن

آبجیکٹ ڈیٹیکشن AI کا استعمال کرتے ہوئے تصاویر میں اشیاء کو پہچاننے کا عمل ہے۔ پچھلے پروجیکٹ میں تربیت دی گئی امیج کلاسیفائر کے برعکس، آبجیکٹ ڈیٹیکشن تصویر کو مجموعی طور پر بہترین ٹیگ کے طور پر پیش کرنے کے بارے میں نہیں ہے بلکہ تصویر میں ایک یا زیادہ اشیاء کو تلاش کرنے کے بارے میں ہے۔

### آبجیکٹ ڈیٹیکشن بمقابلہ امیج کلاسیفیکیشن

امیج کلاسیفیکیشن تصویر کو مجموعی طور پر کلاسیفائی کرنے کے بارے میں ہے - تصویر کے ہر ٹیگ سے مطابقت رکھنے کے امکانات کیا ہیں۔ آپ کو ماڈل کو تربیت دینے کے لیے استعمال کیے گئے ہر ٹیگ کے امکانات واپس ملتے ہیں۔

![کاجو اور ٹماٹر پیسٹ کی امیج کلاسیفیکیشن](../../../../../translated_images/image-classifier-cashews-tomato.bc2e16ab8f05cf9ac0f59f73e32efc4227f9a5b601b90b2c60f436694547a965.ur.png)

اوپر دی گئی مثال میں، دو تصاویر کو ایک ماڈل کے ذریعے کلاسیفائی کیا گیا ہے جو کاجو کے ڈبے یا ٹماٹر پیسٹ کے کین کو کلاسیفائی کرنے کے لیے تربیت یافتہ ہے۔ پہلی تصویر کاجو کے ڈبے کی ہے، اور امیج کلاسیفائر کے دو نتائج ہیں:

| ٹیگ            | امکان |
| -------------- | ----------: |
| `کاجو`         | 98.4%       |
| `ٹماٹر پیسٹ`   | 1.6%        |

دوسری تصویر ٹماٹر پیسٹ کے کین کی ہے، اور نتائج یہ ہیں:

| ٹیگ            | امکان |
| -------------- | ----------: |
| `کاجو`         | 0.7%        |
| `ٹماٹر پیسٹ`   | 99.3%       |

آپ ان اقدار کو ایک تھریشولڈ فیصد کے ساتھ استعمال کر سکتے ہیں تاکہ یہ پیش گوئی کی جا سکے کہ تصویر میں کیا ہے۔ لیکن اگر تصویر میں ٹماٹر پیسٹ کے متعدد کین یا کاجو اور ٹماٹر پیسٹ دونوں موجود ہوں تو کیا ہوگا؟ نتائج شاید آپ کو وہ نہیں دیں گے جو آپ چاہتے ہیں۔ یہ وہ جگہ ہے جہاں آبجیکٹ ڈیٹیکشن کام آتا ہے۔

آبجیکٹ ڈیٹیکشن ماڈل کو اشیاء کو پہچاننے کے لیے تربیت دینے کے بارے میں ہے۔ اس کے بجائے کہ آپ اسے اشیاء پر مشتمل تصاویر دیں اور اسے بتائیں کہ ہر تصویر ایک ٹیگ یا دوسرا ہے، آپ تصویر کے اس حصے کو نمایاں کرتے ہیں جس میں مخصوص شے موجود ہے، اور اسے ٹیگ کرتے ہیں۔ آپ تصویر میں ایک شے یا متعدد کو ٹیگ کر سکتے ہیں۔ اس طرح ماڈل سیکھتا ہے کہ شے خود کیسی دکھتی ہے، نہ کہ صرف وہ تصاویر جو شے پر مشتمل ہیں۔

جب آپ اسے تصاویر کی پیش گوئی کے لیے استعمال کرتے ہیں، تو ٹیگز اور فیصد کی فہرست واپس حاصل کرنے کے بجائے، آپ کو پتہ چلنے والی اشیاء کی فہرست واپس ملتی ہے، ان کے باؤنڈنگ باکس کے ساتھ اور اس امکان کے ساتھ کہ باؤنڈنگ باکس تفویض کردہ ٹیگ سے میل کھاتا ہے۔

> 🎓 *باؤنڈنگ باکسز* وہ باکسز ہیں جو کسی شے کے ارد گرد ہوتے ہیں۔

![کاجو اور ٹماٹر پیسٹ کی آبجیکٹ ڈیٹیکشن](../../../../../translated_images/object-detector-cashews-tomato.1af7c26686b4db0e709754aeb196f4e73271f54e2085db3bcccb70d4a0d84d97.ur.png)

اوپر دی گئی تصویر میں کاجو کے ڈبے اور ٹماٹر پیسٹ کے تین کین موجود ہیں۔ آبجیکٹ ڈیٹیکٹر نے کاجو کو پہچان لیا، اور باؤنڈنگ باکس واپس کیا جس میں کاجو کے ڈبے کے ہونے کا امکان 97.6% ہے۔ آبجیکٹ ڈیٹیکٹر نے ٹماٹر پیسٹ کے تین کین بھی پہچان لیے ہیں، اور تین الگ الگ باؤنڈنگ باکسز فراہم کیے ہیں، ہر ایک پتہ لگائے گئے کین کے لیے، اور ہر ایک کے پاس امکان ہے کہ باؤنڈنگ باکس میں ٹماٹر پیسٹ کا کین موجود ہے۔

✅ کچھ مختلف منظرنامے سوچیں جن کے لیے آپ امیج پر مبنی AI ماڈلز استعمال کرنا چاہتے ہیں۔ کون سے کلاسیفیکیشن کی ضرورت ہوگی، اور کون سے آبجیکٹ ڈیٹیکشن کی ضرورت ہوگی؟

### آبجیکٹ ڈیٹیکشن کیسے کام کرتا ہے

آبجیکٹ ڈیٹیکشن پیچیدہ ML ماڈلز استعمال کرتا ہے۔ یہ ماڈلز تصویر کو متعدد سیلز میں تقسیم کرتے ہیں، پھر چیک کرتے ہیں کہ آیا باؤنڈنگ باکس کا مرکز تصویر کے مرکز سے میل کھاتا ہے جو ماڈل کو تربیت دینے کے لیے استعمال کی گئی تصاویر میں سے کسی ایک سے میل کھاتا ہے۔ آپ اسے اس طرح سمجھ سکتے ہیں جیسے تصویر کے مختلف حصوں پر امیج کلاسیفائر چلایا جا رہا ہو تاکہ مماثلتیں تلاش کی جا سکیں۔

> 💁 یہ ایک بہت بڑی سادگی ہے۔ آبجیکٹ ڈیٹیکشن کے لیے بہت سی تکنیکیں ہیں، اور آپ ان کے بارے میں مزید پڑھ سکتے ہیں [ویکیپیڈیا پر آبجیکٹ ڈیٹیکشن کے صفحے](https://wikipedia.org/wiki/Object_detection) پر۔

آبجیکٹ ڈیٹیکشن کے لیے مختلف ماڈلز موجود ہیں۔ ایک خاص طور پر مشہور ماڈل [YOLO (You only look once)](https://pjreddie.com/darknet/yolo/) ہے، جو انتہائی تیز ہے اور 20 مختلف کلاسز کی اشیاء کو پہچان سکتا ہے، جیسے لوگ، کتے، بوتلیں اور گاڑیاں۔

✅ YOLO ماڈل کے بارے میں مزید پڑھیں [pjreddie.com/darknet/yolo/](https://pjreddie.com/darknet/yolo/) پر۔

آبجیکٹ ڈیٹیکشن ماڈلز کو ٹرانسفر لرننگ کا استعمال کرتے ہوئے کسٹم اشیاء کو پہچاننے کے لیے دوبارہ تربیت دی جا سکتی ہے۔

## ریٹیل میں آبجیکٹ ڈیٹیکشن کا استعمال

ریٹیل میں آبجیکٹ ڈیٹیکشن کے متعدد استعمال ہیں۔ ان میں شامل ہیں:

* **اسٹاک چیکنگ اور گنتی** - شیلف پر اسٹاک کم ہونے کی پہچان۔ اگر اسٹاک بہت کم ہو، تو عملے یا روبوٹس کو شیلف دوبارہ بھرنے کے لیے نوٹیفیکیشن بھیجے جا سکتے ہیں۔
* **ماسک ڈیٹیکشن** - عوامی صحت کے واقعات کے دوران ماسک پالیسی والے اسٹورز میں، آبجیکٹ ڈیٹیکشن ماسک پہنے ہوئے اور بغیر ماسک والے لوگوں کو پہچان سکتا ہے۔
* **خودکار بلنگ** - شیلف سے اٹھائی گئی اشیاء کو پہچاننا اور گاہکوں کو مناسب بلنگ دینا۔
* **خطرے کی پہچان** - فرش پر ٹوٹے ہوئے اشیاء یا گرے ہوئے مائعات کی پہچان، صفائی کے عملے کو الرٹ کرنا۔

✅ کچھ تحقیق کریں: ریٹیل میں آبجیکٹ ڈیٹیکشن کے مزید استعمال کے کیسز کیا ہو سکتے ہیں؟

## آبجیکٹ ڈیٹیکٹر کی تربیت کریں

آپ Custom Vision کا استعمال کرتے ہوئے آبجیکٹ ڈیٹیکٹر کو تربیت دے سکتے ہیں، بالکل اسی طرح جیسے آپ نے امیج کلاسیفائر کو تربیت دی تھی۔

### کام - آبجیکٹ ڈیٹیکٹر بنائیں

1. اس پروجیکٹ کے لیے ایک ریسورس گروپ بنائیں جسے `stock-detector` کہا جائے۔

1. `stock-detector` ریسورس گروپ میں ایک مفت Custom Vision ٹریننگ ریسورس اور ایک مفت Custom Vision پریڈکشن ریسورس بنائیں۔ انہیں `stock-detector-training` اور `stock-detector-prediction` نام دیں۔

    > 💁 آپ کے پاس صرف ایک مفت ٹریننگ اور پریڈکشن ریسورس ہو سکتا ہے، لہذا اس بات کو یقینی بنائیں کہ آپ نے پہلے کے اسباق سے اپنے پروجیکٹ کو صاف کر دیا ہے۔

    > ⚠️ آپ [پروجیکٹ 4، سبق 1 سے ٹریننگ اور پریڈکشن ریسورسز بنانے کے لیے ہدایات کا حوالہ دے سکتے ہیں](../../../4-manufacturing/lessons/1-train-fruit-detector/README.md#task---create-a-cognitive-services-resource) اگر ضرورت ہو۔

1. Custom Vision پورٹل پر جائیں [CustomVision.ai](https://customvision.ai)، اور اپنے Azure اکاؤنٹ کے لیے استعمال کیے گئے Microsoft اکاؤنٹ کے ساتھ سائن ان کریں۔

1. Microsoft Docs پر [Build an object detector quickstart کے Create a new Project سیکشن](https://docs.microsoft.com/azure/cognitive-services/custom-vision-service/get-started-build-detector?WT.mc_id=academic-17441-jabenn#create-a-new-project) کی پیروی کریں تاکہ ایک نیا Custom Vision پروجیکٹ بنایا جا سکے۔ UI تبدیل ہو سکتا ہے اور یہ دستاویزات ہمیشہ تازہ ترین حوالہ ہیں۔

    اپنے پروجیکٹ کا نام `stock-detector` رکھیں۔

    جب آپ اپنا پروجیکٹ بنائیں، تو اس بات کو یقینی بنائیں کہ آپ نے پہلے بنایا گیا `stock-detector-training` ریسورس استعمال کیا ہے۔ *Object Detection* پروجیکٹ ٹائپ اور *Products on Shelves* ڈومین استعمال کریں۔

    ![Custom Vision پروجیکٹ کے لیے ترتیبات](../../../../../translated_images/custom-vision-create-object-detector-project.32d4fb9aa8e7e7375f8a799bfce517aca970f2cb65e42d4245c5e635c734ab29.ur.png)

    ✅ *Products on Shelves* ڈومین خاص طور پر اسٹور شیلف پر اسٹاک کا پتہ لگانے کے لیے بنایا گیا ہے۔ Microsoft Docs پر [Select a domain documentation](https://docs.microsoft.com/azure/cognitive-services/custom-vision-service/select-domain?WT.mc_id=academic-17441-jabenn#object-detection) میں مختلف ڈومینز کے بارے میں مزید پڑھیں۔

✅ اپنے آبجیکٹ ڈیٹیکٹر کے لیے Custom Vision UI کو دریافت کرنے کے لیے کچھ وقت نکالیں۔

### کام - اپنے آبجیکٹ ڈیٹیکٹر کو تربیت دیں

اپنے ماڈل کو تربیت دینے کے لیے آپ کو ان تصاویر کا ایک سیٹ درکار ہوگا جن میں آپ نے پہچاننے والی اشیاء موجود ہوں۔

1. ایسی تصاویر جمع کریں جن میں پہچاننے والی شے موجود ہو۔ آپ کو ہر شے کے لیے کم از کم 15 تصاویر درکار ہوں گی، مختلف زاویوں اور مختلف روشنی کے حالات میں، لیکن جتنی زیادہ ہوں اتنا بہتر ہے۔ یہ آبجیکٹ ڈیٹیکٹر *Products on Shelves* ڈومین استعمال کرتا ہے، لہذا اشیاء کو اسٹور شیلف پر رکھنے کی کوشش کریں۔ آپ کو ماڈل کی جانچ کے لیے کچھ تصاویر بھی درکار ہوں گی۔ اگر آپ ایک سے زیادہ اشیاء کا پتہ لگا رہے ہیں، تو آپ کچھ جانچ کی تصاویر چاہیں گے جن میں تمام اشیاء موجود ہوں۔

    > 💁 مختلف اشیاء والی تصاویر ان تمام اشیاء کے لیے 15 تصاویر کی کم از کم تعداد میں شمار ہوتی ہیں جو تصویر میں موجود ہیں۔

    آپ کی تصاویر png یا jpeg ہونی چاہئیں، 6MB سے چھوٹی۔ اگر آپ انہیں آئی فون کے ساتھ بناتے ہیں، تو وہ ممکنہ طور پر ہائی ریزولوشن HEIC تصاویر ہوں گی، لہذا انہیں تبدیل اور ممکنہ طور پر چھوٹا کرنے کی ضرورت ہوگی۔ جتنی زیادہ تصاویر ہوں اتنا بہتر، اور آپ کے پاس پکے اور کچے کی ایک جیسی تعداد ہونی چاہیے۔

    ماڈل مصنوعات کے شیلف پر ہونے کے لیے بنایا گیا ہے، لہذا اشیاء کی تصاویر شیلف پر لینے کی کوشش کریں۔

    آپ کچھ مثال تصاویر [images](../../../../../5-retail/lessons/1-train-stock-detector/images) فولڈر میں کاجو اور ٹماٹر پیسٹ کی تلاش کر سکتے ہیں جنہیں آپ استعمال کر سکتے ہیں۔

1. Microsoft Docs پر [Build an object detector quickstart کے Upload and tag images سیکشن](https://docs.microsoft.com/azure/cognitive-services/custom-vision-service/get-started-build-detector?WT.mc_id=academic-17441-jabenn#upload-and-tag-images) کی پیروی کریں تاکہ اپنی تربیت کی تصاویر اپ لوڈ کی جا سکیں۔ ان اشیاء کی اقسام کے مطابق متعلقہ ٹیگز بنائیں جنہیں آپ پہچاننا چاہتے ہیں۔

    ![پکی اور کچی کیلے کی تصاویر اپ لوڈ کرنے کے ڈائیلاگ](../../../../../translated_images/image-upload-object-detector.77c7892c3093cb59b79018edecd678749a75d71a099bc8a2d2f2f76320f88a5b.ur.png)

    جب آپ اشیاء کے لیے باؤنڈنگ باکسز بنائیں، تو انہیں شے کے ارد گرد سخت رکھیں۔ تمام تصاویر کو آؤٹ لائن کرنے میں وقت لگ سکتا ہے، لیکن ٹول ان باؤنڈنگ باکسز کا پتہ لگائے گا جو اسے لگتا ہے، جس سے یہ تیز تر ہو جائے گا۔

    ![ٹماٹر پیسٹ کو ٹیگ کرنا](../../../../../translated_images/object-detector-tag-tomato-paste.f47c362fb0f0eb582f3bc68cf3855fb43a805106395358d41896a269c210b7b4.ur.png)

    > 💁 اگر آپ کے پاس ہر شے کے لیے 15 سے زیادہ تصاویر ہیں، تو آپ 15 کے بعد تربیت دے سکتے ہیں اور **Suggested tags** فیچر استعمال کر سکتے ہیں۔ یہ تربیت یافتہ ماڈل کو بغیر ٹیگ والی تصویر میں اشیاء کا پتہ لگانے کے لیے استعمال کرے گا۔ آپ پھر پتہ لگائی گئی اشیاء کی تصدیق کر سکتے ہیں، یا مسترد کر کے باؤنڈنگ باکسز کو دوبارہ بنا سکتے ہیں۔ یہ *بہت* وقت بچا سکتا ہے۔

1. Microsoft Docs پر [Build an object detector quickstart کے Train the detector سیکشن](https://docs.microsoft.com/azure/cognitive-services/custom-vision-service/get-started-build-detector?WT.mc_id=academic-17441-jabenn#train-the-detector) کی پیروی کریں تاکہ اپنے ٹیگ کردہ تصاویر پر آبجیکٹ ڈیٹیکٹر کو تربیت دی جا سکے۔

    آپ کو تربیت کی قسم کا انتخاب دیا جائے گا۔ **Quick Training** منتخب کریں۔

آبجیکٹ ڈیٹیکٹر تربیت حاصل کرے گا۔ تربیت مکمل ہونے میں چند منٹ لگیں گے۔

## اپنے آبجیکٹ ڈیٹیکٹر کو ٹیسٹ کریں

ایک بار جب آپ کا آبجیکٹ ڈیٹیکٹر تربیت یافتہ ہو جائے، تو آپ اسے نئی تصاویر دے کر اشیاء کا پتہ لگانے کے لیے ٹیسٹ کر سکتے ہیں۔

### کام - اپنے آبجیکٹ ڈیٹیکٹر کو ٹیسٹ کریں

1. **Quick Test** بٹن کا استعمال کرتے ہوئے ٹیسٹنگ تصاویر اپ لوڈ کریں اور تصدیق کریں کہ اشیاء کا پتہ لگایا گیا ہے۔ وہ ٹیسٹنگ تصاویر استعمال کریں جو آپ نے پہلے بنائی تھیں، تربیت کے لیے استعمال کی گئی تصاویر نہیں۔

    ![ٹماٹر پیسٹ کے 3 کین کا پتہ لگایا گیا، امکانات 38%, 35.5% اور 34.6%](../../../../../translated_images/object-detector-detected-tomato-paste.52656fe87af4c37b4ee540526d63e73ed075da2e54a9a060aa528e0c562fb1b6.ur.png)

1. آپ کے پاس موجود تمام ٹیسٹنگ تصاویر آزمائیں اور امکانات کا مشاہدہ کریں۔

## اپنے آبجیکٹ ڈیٹیکٹر کو دوبارہ تربیت دیں

جب آپ اپنے آبجیکٹ ڈیٹیکٹر کو ٹیسٹ کرتے ہیں، تو یہ ممکن ہے کہ یہ آپ کی توقع کے مطابق نتائج نہ دے، بالکل اسی طرح جیسے پچھلے پروجیکٹ میں امیج کلاسیفائرز کے ساتھ۔ آپ اپنے آبجیکٹ ڈیٹیکٹر کو ان تصاویر کے ساتھ دوبارہ تربیت دے کر بہتر بنا سکتے ہیں جن میں یہ غلطی کرتا ہے۔

جب بھی آپ Quick Test آپشن کا استعمال کرتے ہوئے پیش گوئی کرتے ہیں، تصویر اور نتائج محفوظ کیے جاتے ہیں۔ آپ ان تصاویر کو اپنے ماڈل کو دوبارہ تربیت دینے کے لیے استعمال کر سکتے ہیں۔

1. **Predictions** ٹیب کا استعمال کرتے ہوئے ان تصاویر کو تلاش کریں جو آپ نے ٹیسٹنگ
[لیکچر کے بعد کا کوئز](https://black-meadow-040d15503.1.azurestaticapps.net/quiz/38)

## جائزہ اور خود مطالعہ

* جب آپ نے اپنے آبجیکٹ ڈیٹیکٹر کو تربیت دی، تو آپ نے *Precision*، *Recall*، اور *mAP* کی قدریں دیکھی ہوں گی جو بنائے گئے ماڈل کی درجہ بندی کرتی ہیں۔ ان قدروں کے بارے میں مزید جاننے کے لیے [Microsoft Docs پر Build an object detector quickstart کے Evaluate the detector سیکشن](https://docs.microsoft.com/azure/cognitive-services/custom-vision-service/get-started-build-detector?WT.mc_id=academic-17441-jabenn#evaluate-the-detector) کو پڑھیں۔
* آبجیکٹ ڈیٹیکشن کے بارے میں مزید جاننے کے لیے [ویکیپیڈیا کے Object detection صفحے](https://wikipedia.org/wiki/Object_detection) پر جائیں۔

## اسائنمنٹ

[ڈومینز کا موازنہ کریں](assignment.md)

---

**ڈسکلیمر**:  
یہ دستاویز AI ترجمہ سروس [Co-op Translator](https://github.com/Azure/co-op-translator) کا استعمال کرتے ہوئے ترجمہ کی گئی ہے۔ ہم درستگی کے لیے کوشش کرتے ہیں، لیکن براہ کرم آگاہ رہیں کہ خودکار ترجمے میں غلطیاں یا غیر درستیاں ہو سکتی ہیں۔ اصل دستاویز کو اس کی اصل زبان میں مستند ذریعہ سمجھا جانا چاہیے۔ اہم معلومات کے لیے، پیشہ ور انسانی ترجمہ کی سفارش کی جاتی ہے۔ ہم اس ترجمے کے استعمال سے پیدا ہونے والی کسی بھی غلط فہمی یا غلط تشریح کے ذمہ دار نہیں ہیں۔