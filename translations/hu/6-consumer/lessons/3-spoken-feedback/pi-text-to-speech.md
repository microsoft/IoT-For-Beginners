<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "606f3af1c78e3741e48ce77c31cea626",
  "translation_date": "2025-08-27T21:13:08+00:00",
  "source_file": "6-consumer/lessons/3-spoken-feedback/pi-text-to-speech.md",
  "language_code": "hu"
}
-->
# Sz√∂veg besz√©dd√© alak√≠t√°sa - Raspberry Pi

Ebben a leck√©ben k√≥dot fogsz √≠rni, amely a sz√∂veget besz√©dd√© alak√≠tja a besz√©dszolg√°ltat√°s seg√≠ts√©g√©vel.

## Sz√∂veg besz√©dd√© alak√≠t√°sa a besz√©dszolg√°ltat√°s haszn√°lat√°val

A sz√∂veget a REST API seg√≠ts√©g√©vel lehet elk√ºldeni a besz√©dszolg√°ltat√°snak, hogy hangf√°jlk√©nt visszakapjuk, amelyet lej√°tszhatunk az IoT eszk√∂z√ºnk√∂n. A besz√©d k√©r√©s√©hez meg kell adni a hangot, amelyet haszn√°lni szeretn√©nk, mivel a besz√©d k√ºl√∂nb√∂z≈ë hangokkal gener√°lhat√≥.

Minden nyelvhez k√ºl√∂nb√∂z≈ë hangok √°llnak rendelkez√©sre, √©s REST k√©r√©st k√ºldhet√ºnk a besz√©dszolg√°ltat√°snak, hogy megkapjuk az adott nyelvhez t√°mogatott hangok list√°j√°t.

### Feladat - hang kiv√°laszt√°sa

1. Nyisd meg a `smart-timer` projektet a VS Code-ban.

1. Add hozz√° az al√°bbi k√≥dot a `say` f√ºggv√©ny f√∂l√©, hogy lek√©rd egy nyelv hangjainak list√°j√°t:

    ```python
    def get_voice():
        url = f'https://{location}.tts.speech.microsoft.com/cognitiveservices/voices/list'
    
        headers = {
            'Authorization': 'Bearer ' + get_access_token()
        }
    
        response = requests.get(url, headers=headers)
        voices_json = json.loads(response.text)
    
        first_voice = next(x for x in voices_json if x['Locale'].lower() == language.lower() and x['VoiceType'] == 'Neural')
        return first_voice['ShortName']
    
    voice = get_voice()
    print(f'Using voice {voice}')
    ```

    Ez a k√≥d egy `get_voice` nev≈± f√ºggv√©nyt defini√°l, amely a besz√©dszolg√°ltat√°st haszn√°lja a hangok list√°j√°nak lek√©r√©s√©re. Ezut√°n megkeresi az els≈ë hangot, amely megfelel az aktu√°lisan haszn√°lt nyelvnek.

    Ez a f√ºggv√©ny megh√≠v√°sra ker√ºl, hogy elmentse az els≈ë hangot, √©s a hang neve ki√≠r√°sra ker√ºl a konzolra. Ezt a hangot egyszer k√©rhetj√ºk le, √©s az √©rt√©ket minden sz√∂veg besz√©dd√© alak√≠t√°si h√≠v√°sn√°l haszn√°lhatjuk.

    > üíÅ A t√°mogatott hangok teljes list√°j√°t megtal√°lhatod a [Microsoft Docs nyelv- √©s hangt√°mogat√°si dokument√°ci√≥j√°ban](https://docs.microsoft.com/azure/cognitive-services/speech-service/language-support?WT.mc_id=academic-17441-jabenn#text-to-speech). Ha egy konkr√©t hangot szeretn√©l haszn√°lni, akkor elt√°vol√≠thatod ezt a f√ºggv√©nyt, √©s a dokument√°ci√≥b√≥l sz√°rmaz√≥ hangnevet hard code-olhatod. P√©ld√°ul:
    >
    > ```python
    > voice = 'hi-IN-SwaraNeural'
    > ```

### Feladat - sz√∂veg besz√©dd√© alak√≠t√°sa

1. Ezut√°n defini√°lj egy konstansot az audio form√°tumhoz, amelyet a besz√©dszolg√°ltat√°st√≥l szeretn√©l lek√©rni. Az audio k√ºl√∂nb√∂z≈ë form√°tumokban k√©rhet≈ë.

    ```python
    playback_format = 'riff-48khz-16bit-mono-pcm'
    ```

    Az alkalmazhat√≥ form√°tum a hardveredt≈ël f√ºgg. Ha `Invalid sample rate` hib√°t kapsz az audio lej√°tsz√°sakor, akkor v√°ltoztasd meg ezt egy m√°sik √©rt√©kre. A t√°mogatott √©rt√©kek list√°j√°t megtal√°lhatod a [Text to speech REST API dokument√°ci√≥j√°ban a Microsoft Docs-on](https://docs.microsoft.com/azure/cognitive-services/speech-service/rest-text-to-speech?WT.mc_id=academic-17441-jabenn#audio-outputs). `riff` form√°tum√∫ audio-t kell haszn√°lnod, √©s az √©rt√©kek, amelyeket kipr√≥b√°lhatsz: `riff-16khz-16bit-mono-pcm`, `riff-24khz-16bit-mono-pcm` √©s `riff-48khz-16bit-mono-pcm`.

1. Ezut√°n deklar√°lj egy `get_speech` nev≈± f√ºggv√©nyt, amely a sz√∂veget besz√©dd√© alak√≠tja a besz√©dszolg√°ltat√°s REST API-j√°nak haszn√°lat√°val:

    ```python
    def get_speech(text):
    ```

1. A `get_speech` f√ºggv√©nyben defini√°ld az URL-t, amelyet h√≠vni kell, √©s a fejl√©ceket, amelyeket √°t kell adni:

    ```python
        url = f'https://{location}.tts.speech.microsoft.com/cognitiveservices/v1'
    
        headers = {
            'Authorization': 'Bearer ' + get_access_token(),
            'Content-Type': 'application/ssml+xml',
            'X-Microsoft-OutputFormat': playback_format
        }
    ```

    Ez be√°ll√≠tja a fejl√©ceket egy gener√°lt hozz√°f√©r√©si token haszn√°lat√°ra, meghat√°rozza az SSML tartalmat, √©s defini√°lja a sz√ºks√©ges audio form√°tumot.

1. Ezut√°n defini√°ld az SSML-t, amelyet a REST API-nak k√ºldesz:

    ```python
    ssml =  f'<speak version=\'1.0\' xml:lang=\'{language}\'>'
    ssml += f'<voice xml:lang=\'{language}\' name=\'{voice}\'>'
    ssml += text
    ssml += '</voice>'
    ssml += '</speak>'
    ```

    Ez az SSML be√°ll√≠tja a nyelvet √©s a hangot, amelyet haszn√°lni szeretn√©l, valamint a sz√∂veget, amelyet √°t kell alak√≠tani.

1. V√©g√ºl adj hozz√° k√≥dot ebben a f√ºggv√©nyben, hogy v√©grehajtsa a REST k√©r√©st, √©s visszaadja a bin√°ris audio adatokat:

    ```python
    response = requests.post(url, headers=headers, data=ssml.encode('utf-8'))
    return io.BytesIO(response.content)
    ```

### Feladat - az audio lej√°tsz√°sa

1. A `get_speech` f√ºggv√©ny alatt defini√°lj egy √∫j f√ºggv√©nyt az audio lej√°tsz√°s√°ra, amelyet a REST API h√≠v√°s visszaadott:

    ```python
    def play_speech(speech):
    ```

1. A `speech`, amelyet ennek a f√ºggv√©nynek √°tadsz, a REST API √°ltal visszaadott bin√°ris audio adat lesz. Haszn√°ld az al√°bbi k√≥dot, hogy megnyisd ezt hull√°mf√°jlk√©nt, √©s √°tadd PyAudio-nak az audio lej√°tsz√°s√°hoz:

    ```python
    def play_speech(speech):
        with wave.open(speech, 'rb') as wave_file:
            stream = audio.open(format=audio.get_format_from_width(wave_file.getsampwidth()),
                                channels=wave_file.getnchannels(),
                                rate=wave_file.getframerate(),
                                output_device_index=speaker_card_number,
                                output=True)

            data = wave_file.readframes(4096)

            while len(data) > 0:
                stream.write(data)
                data = wave_file.readframes(4096)

            stream.stop_stream()
            stream.close()
    ```

    Ez a k√≥d PyAudio stream-et haszn√°l, ugyan√∫gy, mint az audio r√∂gz√≠t√©sn√©l. A k√ºl√∂nbs√©g itt az, hogy a stream kimeneti stream-k√©nt van be√°ll√≠tva, √©s az audio adatb√≥l olvasott adatokat tov√°bb√≠tja a stream-nek.

    Ahelyett, hogy a stream r√©szleteit, p√©ld√°ul a mintav√©teli frekvenci√°t hard code-oln√°nk, az audio adatb√≥l olvassuk ki.

1. Cser√©ld ki a `say` f√ºggv√©ny tartalm√°t az al√°bbiakra:

    ```python
    speech = get_speech(text)
    play_speech(speech)
    ```

    Ez a k√≥d a sz√∂veget bin√°ris audio adatk√©nt alak√≠tja √°t, √©s lej√°tsza az audio-t.

1. Futtasd az alkalmaz√°st, √©s gy≈ëz≈ëdj meg r√≥la, hogy a funkci√≥alkalmaz√°s is fut. √Åll√≠ts be n√©h√°ny id≈ëz√≠t≈ët, √©s hallani fogsz egy besz√©des v√°laszt, amely k√∂zli, hogy az id≈ëz√≠t≈ëd be√°ll√≠t√°sra ker√ºlt, majd egy m√°sik besz√©des v√°laszt, amikor az id≈ëz√≠t≈ë lej√°r.

    Ha `Invalid sample rate` hib√°t kapsz, v√°ltoztasd meg a `playback_format`-ot a fent le√≠rtak szerint.

> üíÅ Ezt a k√≥dot megtal√°lhatod a [code-spoken-response/pi](../../../../../6-consumer/lessons/3-spoken-feedback/code-spoken-response/pi) mapp√°ban.

üòÄ Az id≈ëz√≠t≈ë programod sikeres volt!

---

**Felel≈ëss√©g kiz√°r√°sa**:  
Ez a dokumentum az AI ford√≠t√°si szolg√°ltat√°s, a [Co-op Translator](https://github.com/Azure/co-op-translator) seg√≠ts√©g√©vel lett leford√≠tva. B√°r t√∂reksz√ºnk a pontoss√°gra, k√©rj√ºk, vegye figyelembe, hogy az automatikus ford√≠t√°sok hib√°kat vagy pontatlans√°gokat tartalmazhatnak. Az eredeti dokumentum az eredeti nyelv√©n tekintend≈ë hiteles forr√°snak. Kritikus inform√°ci√≥k eset√©n javasolt professzion√°lis emberi ford√≠t√°st ig√©nybe venni. Nem v√°llalunk felel≈ëss√©get semmilyen f√©lre√©rt√©s√©rt vagy t√©ves √©rtelmez√©s√©rt, amely a ford√≠t√°s haszn√°lat√°b√≥l eredhet.