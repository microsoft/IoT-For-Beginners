<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "7966848a1f870e4c42edb4db67b13c57",
  "translation_date": "2025-08-27T21:08:07+00:00",
  "source_file": "6-consumer/lessons/3-spoken-feedback/virtual-device-text-to-speech.md",
  "language_code": "hu"
}
-->
# Sz√∂veg besz√©dd√© alak√≠t√°sa - Virtu√°lis IoT eszk√∂z

Ebben a leck√©ben k√≥dot fogsz √≠rni, amely a sz√∂veget besz√©dd√© alak√≠tja a besz√©dszolg√°ltat√°s seg√≠ts√©g√©vel.

## Sz√∂veg besz√©dd√© alak√≠t√°sa

Az el≈ëz≈ë leck√©ben haszn√°lt besz√©dszolg√°ltat√°sok SDK, amely a besz√©det sz√∂vegg√© alak√≠totta, arra is haszn√°lhat√≥, hogy a sz√∂veget visszaalak√≠tsa besz√©dd√©. A besz√©d k√©r√©s√©hez meg kell adnod a hangot, amelyet haszn√°lni szeretn√©l, mivel a besz√©d k√ºl√∂nb√∂z≈ë hangokkal gener√°lhat√≥.

Minden nyelvhez k√ºl√∂nb√∂z≈ë hangok √°llnak rendelkez√©sre, √©s a besz√©dszolg√°ltat√°sok SDK seg√≠ts√©g√©vel lek√©rheted az adott nyelvhez t√°mogatott hangok list√°j√°t.

### Feladat - sz√∂veg besz√©dd√© alak√≠t√°sa

1. Nyisd meg a `smart-timer` projektet a VS Code-ban, √©s gy≈ëz≈ëdj meg r√≥la, hogy a virtu√°lis k√∂rnyezet bet√∂lt≈ëd√∂tt a termin√°lban.

1. Import√°ld a `SpeechSynthesizer`-t az `azure.cognitiveservices.speech` csomagb√≥l az al√°bbi m√≥don, hozz√°adva a megl√©v≈ë importokhoz:

    ```python
    from azure.cognitiveservices.speech import SpeechConfig, SpeechRecognizer, SpeechSynthesizer
    ```

1. A `say` f√ºggv√©ny f√∂l√∂tt hozz l√©tre egy besz√©dkonfigur√°ci√≥t, amelyet a besz√©dszintetiz√°tor haszn√°lni fog:

    ```python
    speech_config = SpeechConfig(subscription=speech_api_key,
                                 region=location)
    speech_config.speech_synthesis_language = language
    speech_synthesizer = SpeechSynthesizer(speech_config=speech_config)
    ```

    Ez ugyanazt az API kulcsot, helyet √©s nyelvet haszn√°lja, amelyet a felismer≈ë is haszn√°lt.

1. Ezut√°n add hozz√° az al√°bbi k√≥dot, hogy lek√©rj egy hangot, √©s be√°ll√≠tsd azt a besz√©dkonfigur√°ci√≥ban:

    ```python
    voices = speech_synthesizer.get_voices_async().get().voices
    first_voice = next(x for x in voices if x.locale.lower() == language.lower())
    speech_config.speech_synthesis_voice_name = first_voice.short_name
    ```

    Ez lek√©ri az √∂sszes el√©rhet≈ë hang list√°j√°t, majd megkeresi az els≈ë hangot, amely megfelel a haszn√°lt nyelvnek.

    > üíÅ A t√°mogatott hangok teljes list√°j√°t megtal√°lhatod a [Microsoft Docs nyelv- √©s hangt√°mogat√°si dokument√°ci√≥j√°ban](https://docs.microsoft.com/azure/cognitive-services/speech-service/language-support?WT.mc_id=academic-17441-jabenn#text-to-speech). Ha egy konkr√©t hangot szeretn√©l haszn√°lni, akkor elt√°vol√≠thatod ezt a funkci√≥t, √©s a dokument√°ci√≥ban tal√°lhat√≥ hangn√©vvel hardcode-olhatod a hangot. P√©ld√°ul:
    >
    > ```python
    > speech_config.speech_synthesis_voice_name = 'hi-IN-SwaraNeural'
    > ```

1. Friss√≠tsd a `say` f√ºggv√©ny tartalm√°t, hogy SSML-t gener√°ljon a v√°laszhoz:

    ```python
    ssml =  f'<speak version=\'1.0\' xml:lang=\'{language}\'>'
    ssml += f'<voice xml:lang=\'{language}\' name=\'{first_voice.short_name}\'>'
    ssml += text
    ssml += '</voice>'
    ssml += '</speak>'
    ```

1. Ezut√°n √°ll√≠tsd le a besz√©dfelismer√©st, mondasd el az SSML-t, majd ind√≠tsd √∫jra a felismer√©st:

    ```python
    recognizer.stop_continuous_recognition()
    speech_synthesizer.speak_ssml(ssml)
    recognizer.start_continuous_recognition()
    ```

    A felismer√©s le√°ll√≠t√°sra ker√ºl, am√≠g a sz√∂veg elhangzik, hogy elker√ºlj√ºk, hogy a visszasz√°ml√°l√≥ ind√≠t√°s√°nak bejelent√©se felismer√©sre ker√ºlj√∂n, elk√ºld√©sre ker√ºlj√∂n a LUIS-nek, √©s esetleg √∫j visszasz√°ml√°l√≥ be√°ll√≠t√°sak√©nt √©rtelmez≈ëdj√∂n.

    > üíÅ Ezt kipr√≥b√°lhatod √∫gy, hogy kikommentezed a felismer√©s le√°ll√≠t√°s√°ra √©s √∫jraind√≠t√°s√°ra vonatkoz√≥ sorokat. √Åll√≠ts be egy visszasz√°ml√°l√≥t, √©s lehet, hogy azt tapasztalod, hogy a bejelent√©s √∫j visszasz√°ml√°l√≥t √°ll√≠t be, ami √∫j bejelent√©st okoz, ami √∫j visszasz√°ml√°l√≥t eredm√©nyez, √©s √≠gy tov√°bb v√©gtelen√ºl!

1. Futtasd az alkalmaz√°st, √©s gy≈ëz≈ëdj meg r√≥la, hogy a funkci√≥alkalmaz√°s is fut. √Åll√≠ts be n√©h√°ny visszasz√°ml√°l√≥t, √©s hallani fogsz egy besz√©lt v√°laszt, amely k√∂zli, hogy a visszasz√°ml√°l√≥ be√°ll√≠t√°sra ker√ºlt, majd egy m√°sik besz√©lt v√°laszt, amikor a visszasz√°ml√°l√≥ lej√°r.

> üíÅ Ezt a k√≥dot megtal√°lhatod a [code-spoken-response/virtual-iot-device](../../../../../6-consumer/lessons/3-spoken-feedback/code-spoken-response/virtual-iot-device) mapp√°ban.

üòÄ A visszasz√°ml√°l√≥ programod sikeres volt!

---

**Felel≈ëss√©g kiz√°r√°sa**:  
Ez a dokumentum az AI ford√≠t√°si szolg√°ltat√°s, a [Co-op Translator](https://github.com/Azure/co-op-translator) seg√≠ts√©g√©vel lett leford√≠tva. B√°r t√∂reksz√ºnk a pontoss√°gra, k√©rj√ºk, vegye figyelembe, hogy az automatikus ford√≠t√°sok hib√°kat vagy pontatlans√°gokat tartalmazhatnak. Az eredeti dokumentum az eredeti nyelv√©n tekintend≈ë hiteles forr√°snak. Kritikus inform√°ci√≥k eset√©n javasolt professzion√°lis emberi ford√≠t√°st ig√©nybe venni. Nem v√°llalunk felel≈ëss√©get semmilyen f√©lre√©rt√©s√©rt vagy t√©ves √©rtelmez√©s√©rt, amely a ford√≠t√°s haszn√°lat√°b√≥l eredhet.