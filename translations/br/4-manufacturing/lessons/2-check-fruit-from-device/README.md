<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "557f4ee96b752e0651d2e6e74aa6bd14",
  "translation_date": "2025-08-28T02:46:52+00:00",
  "source_file": "4-manufacturing/lessons/2-check-fruit-from-device/README.md",
  "language_code": "br"
}
-->
# Verifique a qualidade das frutas com um dispositivo IoT

![Uma vis√£o geral ilustrada desta li√ß√£o](../../../../../translated_images/lesson-16.215daf18b00631fbdfd64c6fc2dc6044dff5d544288825d8076f9fb83d964c23.br.jpg)

> Ilustra√ß√£o por [Nitya Narasimhan](https://github.com/nitya). Clique na imagem para uma vers√£o maior.

## Quiz pr√©-aula

[Quiz pr√©-aula](https://black-meadow-040d15503.1.azurestaticapps.net/quiz/31)

## Introdu√ß√£o

Na √∫ltima li√ß√£o, voc√™ aprendeu sobre classificadores de imagens e como trein√°-los para detectar frutas boas e ruins. Para usar esse classificador de imagens em uma aplica√ß√£o IoT, voc√™ precisa ser capaz de capturar uma imagem usando algum tipo de c√¢mera e enviar essa imagem para a nuvem para ser classificada.

Nesta li√ß√£o, voc√™ aprender√° sobre sensores de c√¢mera e como us√°-los com um dispositivo IoT para capturar uma imagem. Tamb√©m aprender√° como chamar o classificador de imagens a partir do seu dispositivo IoT.

Nesta li√ß√£o, abordaremos:

* [Sensores de c√¢mera](../../../../../4-manufacturing/lessons/2-check-fruit-from-device)
* [Capturar uma imagem usando um dispositivo IoT](../../../../../4-manufacturing/lessons/2-check-fruit-from-device)
* [Publicar seu classificador de imagens](../../../../../4-manufacturing/lessons/2-check-fruit-from-device)
* [Classificar imagens a partir do seu dispositivo IoT](../../../../../4-manufacturing/lessons/2-check-fruit-from-device)
* [Melhorar o modelo](../../../../../4-manufacturing/lessons/2-check-fruit-from-device)

## Sensores de c√¢mera

Sensores de c√¢mera, como o nome sugere, s√£o c√¢meras que voc√™ pode conectar ao seu dispositivo IoT. Eles podem tirar fotos ou capturar v√≠deos em streaming. Alguns retornam dados de imagem brutos, enquanto outros comprimem os dados em arquivos de imagem, como JPEG ou PNG. Geralmente, as c√¢meras que funcionam com dispositivos IoT s√£o muito menores e t√™m resolu√ß√£o mais baixa do que aquelas que voc√™ pode estar acostumado, mas √© poss√≠vel obter c√¢meras de alta resolu√ß√£o que rivalizam com os melhores smartphones. Voc√™ pode encontrar lentes intercambi√°veis, configura√ß√µes com m√∫ltiplas c√¢meras, c√¢meras t√©rmicas infravermelhas ou c√¢meras UV.

![A luz de uma cena passa por uma lente e √© focada em um sensor CMOS](../../../../../translated_images/cmos-sensor.75f9cd74decb137149a4c9ea825251a4549497d67c0ae2776159e6102bb53aa9.br.png)

A maioria dos sensores de c√¢mera usa sensores de imagem onde cada pixel √© um fotodiodo. Uma lente foca a imagem no sensor de imagem, e milhares ou milh√µes de fotodiodos detectam a luz que incide sobre cada um, registrando isso como dados de pixel.

> üíÅ Lentes invertem imagens, e o sensor da c√¢mera ent√£o as vira para o lado correto. Isso tamb√©m acontece nos seus olhos - o que voc√™ v√™ √© detectado de cabe√ßa para baixo na parte de tr√°s do seu olho, e seu c√©rebro corrige isso.

> üéì O sensor de imagem √© conhecido como Sensor de Pixel Ativo (APS), e o tipo mais popular de APS √© um sensor de semicondutor de √≥xido met√°lico complementar, ou CMOS. Voc√™ pode ter ouvido o termo sensor CMOS usado para sensores de c√¢mera.

Sensores de c√¢mera s√£o sensores digitais, enviando dados de imagem como dados digitais, geralmente com a ajuda de uma biblioteca que fornece a comunica√ß√£o. As c√¢meras se conectam usando protocolos como SPI para permitir o envio de grandes quantidades de dados - imagens s√£o substancialmente maiores do que n√∫meros √∫nicos de sensores, como um sensor de temperatura.

‚úÖ Quais s√£o as limita√ß√µes em rela√ß√£o ao tamanho da imagem em dispositivos IoT? Pense nas restri√ß√µes, especialmente no hardware de microcontroladores.

## Capturar uma imagem usando um dispositivo IoT

Voc√™ pode usar seu dispositivo IoT para capturar uma imagem que ser√° classificada.

### Tarefa - capturar uma imagem usando um dispositivo IoT

Siga o guia relevante para capturar uma imagem usando seu dispositivo IoT:

* [Arduino - Wio Terminal](wio-terminal-camera.md)
* [Computador de placa √∫nica - Raspberry Pi](pi-camera.md)
* [Computador de placa √∫nica - Dispositivo virtual](virtual-device-camera.md)

## Publicar seu classificador de imagens

Voc√™ treinou seu classificador de imagens na √∫ltima li√ß√£o. Antes de us√°-lo a partir do seu dispositivo IoT, voc√™ precisa publicar o modelo.

### Itera√ß√µes do modelo

Quando seu modelo estava sendo treinado na √∫ltima li√ß√£o, voc√™ pode ter notado que a aba **Performance** mostra as itera√ß√µes ao lado. Quando voc√™ treinou o modelo pela primeira vez, viu *Iteration 1* em treinamento. Quando melhorou o modelo usando as imagens de previs√£o, viu *Iteration 2* em treinamento.

Cada vez que voc√™ treina o modelo, obt√©m uma nova itera√ß√£o. Isso √© uma forma de acompanhar as diferentes vers√µes do seu modelo treinadas em diferentes conjuntos de dados. Quando voc√™ faz um **Quick Test**, h√° um menu suspenso que pode ser usado para selecionar a itera√ß√£o, permitindo comparar os resultados entre v√°rias itera√ß√µes.

Quando estiver satisfeito com uma itera√ß√£o, voc√™ pode public√°-la para torn√°-la dispon√≠vel para uso em aplicativos externos. Dessa forma, voc√™ pode ter uma vers√£o publicada que √© usada pelos seus dispositivos, enquanto trabalha em uma nova vers√£o ao longo de v√°rias itera√ß√µes, publicando-a quando estiver satisfeito com ela.

### Tarefa - publicar uma itera√ß√£o

As itera√ß√µes s√£o publicadas no portal Custom Vision.

1. Acesse o portal Custom Vision em [CustomVision.ai](https://customvision.ai) e fa√ßa login, caso ainda n√£o tenha feito isso. Em seguida, abra seu projeto `fruit-quality-detector`.

1. Selecione a aba **Performance** nas op√ß√µes no topo.

1. Escolha a √∫ltima itera√ß√£o na lista *Iterations* ao lado.

1. Clique no bot√£o **Publish** para a itera√ß√£o.

    ![O bot√£o de publica√ß√£o](../../../../../translated_images/custom-vision-publish-button.b7174e1977b0c33b8b72d4e5b1326c779e0af196f3849d09985ee2d7d5493a39.br.png)

1. No di√°logo *Publish Model*, defina o *Prediction resource* como o recurso `fruit-quality-detector-prediction` que voc√™ criou na √∫ltima li√ß√£o. Mantenha o nome como `Iteration2` e clique no bot√£o **Publish**.

1. Ap√≥s publicar, clique no bot√£o **Prediction URL**. Isso mostrar√° os detalhes da API de previs√£o, que voc√™ precisar√° para chamar o modelo a partir do seu dispositivo IoT. A se√ß√£o inferior est√° rotulada como *If you have an image file*, e esses s√£o os detalhes que voc√™ deseja. Copie o URL mostrado, que ser√° algo como:

    ```output
    https://<location>.api.cognitive.microsoft.com/customvision/v3.0/Prediction/<id>/classify/iterations/Iteration2/image
    ```

    Onde `<location>` ser√° o local usado ao criar seu recurso de vis√£o personalizada, e `<id>` ser√° um longo ID composto por letras e n√∫meros.

    Tamb√©m copie o valor de *Prediction-Key*. Esta √© uma chave segura que voc√™ deve passar ao chamar o modelo. Apenas aplicativos que fornecem essa chave podem usar o modelo; qualquer outro aplicativo ser√° rejeitado.

    ![O di√°logo da API de previs√£o mostrando o URL e a chave](../../../../../translated_images/custom-vision-prediction-key-endpoint.30c569ffd0338864f319911f052d5e9b8c5066cb0800a26dd6f7ff5713130ad8.br.png)

‚úÖ Quando uma nova itera√ß√£o √© publicada, ela ter√° um nome diferente. Como voc√™ acha que poderia alterar a itera√ß√£o que um dispositivo IoT est√° usando?

## Classificar imagens a partir do seu dispositivo IoT

Agora voc√™ pode usar esses detalhes de conex√£o para chamar o classificador de imagens a partir do seu dispositivo IoT.

### Tarefa - classificar imagens a partir do seu dispositivo IoT

Siga o guia relevante para classificar imagens usando seu dispositivo IoT:

* [Arduino - Wio Terminal](wio-terminal-classify-image.md)
* [Computador de placa √∫nica - Raspberry Pi/Dispositivo IoT virtual](single-board-computer-classify-image.md)

## Melhorar o modelo

Voc√™ pode perceber que os resultados obtidos ao usar a c√¢mera conectada ao seu dispositivo IoT n√£o correspondem ao que voc√™ esperava. As previs√µes nem sempre s√£o t√£o precisas quanto ao usar imagens enviadas do seu computador. Isso ocorre porque o modelo foi treinado com dados diferentes dos usados para previs√µes.

Para obter os melhores resultados de um classificador de imagens, voc√™ deve treinar o modelo com imagens o mais semelhantes poss√≠vel √†s usadas para previs√µes. Por exemplo, se voc√™ usou a c√¢mera do seu celular para capturar imagens para treinamento, a qualidade, nitidez e cor da imagem ser√£o diferentes de uma c√¢mera conectada a um dispositivo IoT.

![2 fotos de banana, uma de baixa resolu√ß√£o com ilumina√ß√£o ruim de um dispositivo IoT, e outra de alta resolu√ß√£o com boa ilumina√ß√£o de um celular](../../../../../translated_images/banana-picture-compare.174df164dc326a42cf7fb051a7497e6113c620e91552d92ca914220305d47d9a.br.png)

Na imagem acima, a foto da banana √† esquerda foi tirada usando uma c√¢mera Raspberry Pi, enquanto a da direita foi tirada da mesma banana no mesmo local usando um iPhone. H√° uma diferen√ßa not√°vel na qualidade - a foto do iPhone √© mais n√≠tida, com cores mais vibrantes e maior contraste.

‚úÖ O que mais pode causar previs√µes incorretas nas imagens capturadas pelo seu dispositivo IoT? Pense no ambiente em que um dispositivo IoT pode ser usado e nos fatores que podem afetar a imagem capturada.

Para melhorar o modelo, voc√™ pode trein√°-lo novamente usando as imagens capturadas pelo dispositivo IoT.

### Tarefa - melhorar o modelo

1. Classifique v√°rias imagens de frutas maduras e n√£o maduras usando seu dispositivo IoT.

1. No portal Custom Vision, treine novamente o modelo usando as imagens na aba *Predictions*.

    > ‚ö†Ô∏è Voc√™ pode consultar [as instru√ß√µes para treinar novamente seu classificador na li√ß√£o 1, se necess√°rio](../1-train-fruit-detector/README.md#retrain-your-image-classifier).

1. Se suas imagens forem muito diferentes das originais usadas para treinamento, voc√™ pode excluir todas as imagens originais selecionando-as na aba *Training Images* e clicando no bot√£o **Delete**. Para selecionar uma imagem, mova o cursor sobre ela e aparecer√° um √≠cone de sele√ß√£o; clique nesse √≠cone para selecionar ou desmarcar a imagem.

1. Treine uma nova itera√ß√£o do modelo e publique-a usando os passos acima.

1. Atualize o URL do endpoint no seu c√≥digo e execute o aplicativo novamente.

1. Repita esses passos at√© estar satisfeito com os resultados das previs√µes.

---

## üöÄ Desafio

Quanto a resolu√ß√£o da imagem ou a ilumina√ß√£o afetam a previs√£o?

Tente alterar a resolu√ß√£o das imagens no c√≥digo do seu dispositivo e veja se isso faz diferen√ßa na qualidade das imagens. Tamb√©m experimente mudar a ilumina√ß√£o.

Se voc√™ fosse criar um dispositivo de produ√ß√£o para vender a fazendas ou f√°bricas, como garantiria resultados consistentes o tempo todo?

## Quiz p√≥s-aula

[Quiz p√≥s-aula](https://black-meadow-040d15503.1.azurestaticapps.net/quiz/32)

## Revis√£o e Autoestudo

Voc√™ treinou seu modelo de vis√£o personalizada usando o portal. Isso depende de ter imagens dispon√≠veis - e no mundo real, pode n√£o ser poss√≠vel obter dados de treinamento que correspondam ao que a c√¢mera do seu dispositivo captura. Voc√™ pode contornar isso treinando diretamente do seu dispositivo usando a API de treinamento, para treinar um modelo com imagens capturadas pelo seu dispositivo IoT.

* Leia sobre a API de treinamento no [guia de in√≠cio r√°pido do SDK Custom Vision](https://docs.microsoft.com/azure/cognitive-services/custom-vision-service/quickstarts/image-classification?WT.mc_id=academic-17441-jabenn&tabs=visual-studio&pivots=programming-language-python)

## Tarefa

[Responder aos resultados da classifica√ß√£o](assignment.md)

---

**Aviso Legal**:  
Este documento foi traduzido utilizando o servi√ßo de tradu√ß√£o por IA [Co-op Translator](https://github.com/Azure/co-op-translator). Embora nos esforcemos para garantir a precis√£o, esteja ciente de que tradu√ß√µes automatizadas podem conter erros ou imprecis√µes. O documento original em seu idioma nativo deve ser considerado a fonte autoritativa. Para informa√ß√µes cr√≠ticas, recomenda-se a tradu√ß√£o profissional realizada por humanos. N√£o nos responsabilizamos por quaisquer mal-entendidos ou interpreta√ß√µes equivocadas decorrentes do uso desta tradu√ß√£o.