<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "606f3af1c78e3741e48ce77c31cea626",
  "translation_date": "2025-08-28T02:58:16+00:00",
  "source_file": "6-consumer/lessons/3-spoken-feedback/pi-text-to-speech.md",
  "language_code": "br"
}
-->
# Texto para fala - Raspberry Pi

Nesta parte da li√ß√£o, voc√™ escrever√° c√≥digo para converter texto em fala usando o servi√ßo de fala.

## Converter texto em fala usando o servi√ßo de fala

O texto pode ser enviado ao servi√ßo de fala usando a API REST para obter a fala como um arquivo de √°udio que pode ser reproduzido no seu dispositivo IoT. Ao solicitar a fala, voc√™ precisa fornecer a voz a ser usada, pois a fala pode ser gerada usando uma variedade de vozes diferentes.

Cada idioma suporta uma gama de vozes diferentes, e voc√™ pode fazer uma solicita√ß√£o REST ao servi√ßo de fala para obter a lista de vozes suportadas para cada idioma.

### Tarefa - obter uma voz

1. Abra o projeto `smart-timer` no VS Code.

1. Adicione o seguinte c√≥digo acima da fun√ß√£o `say` para solicitar a lista de vozes para um idioma:

    ```python
    def get_voice():
        url = f'https://{location}.tts.speech.microsoft.com/cognitiveservices/voices/list'
    
        headers = {
            'Authorization': 'Bearer ' + get_access_token()
        }
    
        response = requests.get(url, headers=headers)
        voices_json = json.loads(response.text)
    
        first_voice = next(x for x in voices_json if x['Locale'].lower() == language.lower() and x['VoiceType'] == 'Neural')
        return first_voice['ShortName']
    
    voice = get_voice()
    print(f'Using voice {voice}')
    ```

    Este c√≥digo define uma fun√ß√£o chamada `get_voice` que usa o servi√ßo de fala para obter uma lista de vozes. Em seguida, encontra a primeira voz que corresponde ao idioma que est√° sendo usado.

    Esta fun√ß√£o √© chamada para armazenar a primeira voz, e o nome da voz √© impresso no console. Essa voz pode ser solicitada uma vez e o valor usado para cada chamada para converter texto em fala.

    > üíÅ Voc√™ pode obter a lista completa de vozes suportadas na [documenta√ß√£o de suporte de idiomas e vozes no Microsoft Docs](https://docs.microsoft.com/azure/cognitive-services/speech-service/language-support?WT.mc_id=academic-17441-jabenn#text-to-speech). Se voc√™ quiser usar uma voz espec√≠fica, pode remover esta fun√ß√£o e definir a voz diretamente com o nome da voz da documenta√ß√£o. Por exemplo:
    >
    > ```python
    > voice = 'hi-IN-SwaraNeural'
    > ```

### Tarefa - converter texto em fala

1. Abaixo disso, defina uma constante para o formato de √°udio a ser recuperado dos servi√ßos de fala. Ao solicitar √°udio, voc√™ pode faz√™-lo em uma variedade de formatos diferentes.

    ```python
    playback_format = 'riff-48khz-16bit-mono-pcm'
    ```

    O formato que voc√™ pode usar depende do seu hardware. Se voc√™ receber erros de `Invalid sample rate` ao reproduzir o √°udio, altere isso para outro valor. Voc√™ pode encontrar a lista de valores suportados na [documenta√ß√£o da API REST de texto para fala no Microsoft Docs](https://docs.microsoft.com/azure/cognitive-services/speech-service/rest-text-to-speech?WT.mc_id=academic-17441-jabenn#audio-outputs). Voc√™ precisar√° usar √°udio no formato `riff`, e os valores para tentar s√£o `riff-16khz-16bit-mono-pcm`, `riff-24khz-16bit-mono-pcm` e `riff-48khz-16bit-mono-pcm`.

1. Abaixo disso, declare uma fun√ß√£o chamada `get_speech` que converter√° o texto em fala usando a API REST do servi√ßo de fala:

    ```python
    def get_speech(text):
    ```

1. Na fun√ß√£o `get_speech`, defina a URL a ser chamada e os cabe√ßalhos a serem passados:

    ```python
        url = f'https://{location}.tts.speech.microsoft.com/cognitiveservices/v1'
    
        headers = {
            'Authorization': 'Bearer ' + get_access_token(),
            'Content-Type': 'application/ssml+xml',
            'X-Microsoft-OutputFormat': playback_format
        }
    ```

    Isso define os cabe√ßalhos para usar um token de acesso gerado, define o conte√∫do como SSML e especifica o formato de √°udio necess√°rio.

1. Abaixo disso, defina o SSML a ser enviado para a API REST:

    ```python
    ssml =  f'<speak version=\'1.0\' xml:lang=\'{language}\'>'
    ssml += f'<voice xml:lang=\'{language}\' name=\'{voice}\'>'
    ssml += text
    ssml += '</voice>'
    ssml += '</speak>'
    ```

    Este SSML define o idioma e a voz a serem usados, juntamente com o texto a ser convertido.

1. Por fim, adicione c√≥digo nesta fun√ß√£o para fazer a solicita√ß√£o REST e retornar os dados bin√°rios de √°udio:

    ```python
    response = requests.post(url, headers=headers, data=ssml.encode('utf-8'))
    return io.BytesIO(response.content)
    ```

### Tarefa - reproduzir o √°udio

1. Abaixo da fun√ß√£o `get_speech`, defina uma nova fun√ß√£o para reproduzir o √°udio retornado pela chamada da API REST:

    ```python
    def play_speech(speech):
    ```

1. O `speech` passado para esta fun√ß√£o ser√° os dados bin√°rios de √°udio retornados pela API REST. Use o seguinte c√≥digo para abrir isso como um arquivo wave e pass√°-lo para o PyAudio para reproduzir o √°udio:

    ```python
    def play_speech(speech):
        with wave.open(speech, 'rb') as wave_file:
            stream = audio.open(format=audio.get_format_from_width(wave_file.getsampwidth()),
                                channels=wave_file.getnchannels(),
                                rate=wave_file.getframerate(),
                                output_device_index=speaker_card_number,
                                output=True)

            data = wave_file.readframes(4096)

            while len(data) > 0:
                stream.write(data)
                data = wave_file.readframes(4096)

            stream.stop_stream()
            stream.close()
    ```

    Este c√≥digo usa um stream do PyAudio, o mesmo que capturar √°udio. A diferen√ßa aqui √© que o stream √© configurado como um stream de sa√≠da, e os dados s√£o lidos dos dados de √°udio e enviados para o stream.

    Em vez de definir os detalhes do stream, como a taxa de amostragem, eles s√£o lidos dos dados de √°udio.

1. Substitua o conte√∫do da fun√ß√£o `say` pelo seguinte:

    ```python
    speech = get_speech(text)
    play_speech(speech)
    ```

    Este c√≥digo converte o texto em fala como dados bin√°rios de √°udio e reproduz o √°udio.

1. Execute o aplicativo e certifique-se de que o aplicativo de fun√ß√£o tamb√©m esteja em execu√ß√£o. Configure alguns temporizadores e voc√™ ouvir√° uma resposta falada dizendo que seu temporizador foi configurado, e outra resposta falada quando o temporizador for conclu√≠do.

    Se voc√™ receber erros de `Invalid sample rate`, altere o `playback_format` conforme descrito acima.

> üíÅ Voc√™ pode encontrar este c√≥digo na pasta [code-spoken-response/pi](../../../../../6-consumer/lessons/3-spoken-feedback/code-spoken-response/pi).

üòÄ Seu programa de temporizador foi um sucesso!

---

**Aviso Legal**:  
Este documento foi traduzido utilizando o servi√ßo de tradu√ß√£o por IA [Co-op Translator](https://github.com/Azure/co-op-translator). Embora nos esforcemos para garantir a precis√£o, esteja ciente de que tradu√ß√µes autom√°ticas podem conter erros ou imprecis√µes. O documento original em seu idioma nativo deve ser considerado a fonte oficial. Para informa√ß√µes cr√≠ticas, recomenda-se a tradu√ß√£o profissional feita por humanos. N√£o nos responsabilizamos por quaisquer mal-entendidos ou interpreta√ß√µes incorretas decorrentes do uso desta tradu√ß√£o.