<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "6d6aa1be033625d201a190fc9c5cbfb4",
  "translation_date": "2025-08-28T03:00:15+00:00",
  "source_file": "6-consumer/lessons/1-speech-recognition/README.md",
  "language_code": "br"
}
-->
# Reconhe√ßa fala com um dispositivo IoT

![Uma vis√£o geral ilustrada desta li√ß√£o](../../../../../translated_images/lesson-21.e34de51354d6606fb5ee08d8c89d0222eea0a2a7aaf744a8805ae847c4f69dc4.br.jpg)

> Ilustra√ß√£o por [Nitya Narasimhan](https://github.com/nitya). Clique na imagem para uma vers√£o maior.

Este v√≠deo oferece uma vis√£o geral do servi√ßo de fala do Azure, um t√≥pico que ser√° abordado nesta li√ß√£o:

[![Como come√ßar a usar seu recurso de fala do Cognitive Services no canal do YouTube da Microsoft Azure](https://img.youtube.com/vi/iW0Fw0l3mrA/0.jpg)](https://www.youtube.com/watch?v=iW0Fw0l3mrA)

> üé• Clique na imagem acima para assistir ao v√≠deo

## Question√°rio pr√©-aula

[Question√°rio pr√©-aula](https://black-meadow-040d15503.1.azurestaticapps.net/quiz/41)

## Introdu√ß√£o

'Alexa, configure um cron√¥metro de 12 minutos'

'Alexa, qual o status do cron√¥metro?'

'Alexa, configure um cron√¥metro de 8 minutos chamado cozinhar br√≥colis no vapor'

Dispositivos inteligentes est√£o se tornando cada vez mais comuns. N√£o apenas como alto-falantes inteligentes, como HomePods, Echos e Google Homes, mas tamb√©m integrados em nossos telefones, rel√≥gios e at√© mesmo em lumin√°rias e termostatos.

> üíÅ Eu tenho pelo menos 19 dispositivos na minha casa que possuem assistentes de voz, e isso √© s√≥ o que eu sei!

O controle por voz aumenta a acessibilidade, permitindo que pessoas com mobilidade limitada interajam com dispositivos. Seja uma defici√™ncia permanente, como nascer sem bra√ßos, uma defici√™ncia tempor√°ria, como um bra√ßo quebrado, ou simplesmente ter as m√£os ocupadas com compras ou crian√ßas pequenas, poder controlar nossas casas com a voz em vez das m√£os abre um mundo de possibilidades. Gritar 'Ei Siri, feche a porta da garagem' enquanto lida com uma troca de fralda e uma crian√ßa agitada pode ser uma pequena, mas significativa, melhoria na vida.

Um dos usos mais populares para assistentes de voz √© configurar cron√¥metros, especialmente na cozinha. Poder configurar m√∫ltiplos cron√¥metros apenas com a voz √© uma grande ajuda - n√£o √© necess√°rio parar de sovar a massa, mexer a sopa ou limpar as m√£os para usar um cron√¥metro f√≠sico.

Nesta li√ß√£o, voc√™ aprender√° a incorporar reconhecimento de voz em dispositivos IoT. Voc√™ aprender√° sobre microfones como sensores, como capturar √°udio de um microfone conectado a um dispositivo IoT e como usar IA para converter o que √© ouvido em texto. Ao longo deste projeto, voc√™ construir√° um cron√¥metro de cozinha inteligente, capaz de configurar cron√¥metros usando sua voz em v√°rios idiomas.

Nesta li√ß√£o, abordaremos:

* [Microfones](../../../../../6-consumer/lessons/1-speech-recognition)
* [Capturar √°udio do seu dispositivo IoT](../../../../../6-consumer/lessons/1-speech-recognition)
* [Fala para texto](../../../../../6-consumer/lessons/1-speech-recognition)
* [Converter fala em texto](../../../../../6-consumer/lessons/1-speech-recognition)

## Microfones

Microfones s√£o sensores anal√≥gicos que convertem ondas sonoras em sinais el√©tricos. Vibra√ß√µes no ar fazem com que componentes no microfone se movam em pequenas quantidades, causando pequenas altera√ß√µes nos sinais el√©tricos. Essas altera√ß√µes s√£o ent√£o amplificadas para gerar uma sa√≠da el√©trica.

### Tipos de microfones

Microfones v√™m em uma variedade de tipos:

* Din√¢mico - Microfones din√¢micos possuem um √≠m√£ preso a um diafragma m√≥vel que se move em uma bobina de fio, criando uma corrente el√©trica. Isso √© o oposto da maioria dos alto-falantes, que usam uma corrente el√©trica para mover um √≠m√£ em uma bobina de fio, movendo um diafragma para criar som. Isso significa que alto-falantes podem ser usados como microfones din√¢micos, e microfones din√¢micos podem ser usados como alto-falantes. Em dispositivos como interfones, onde o usu√°rio est√° ouvindo ou falando, mas n√£o ambos ao mesmo tempo, um √∫nico dispositivo pode atuar como alto-falante e microfone.

    Microfones din√¢micos n√£o precisam de energia para funcionar, o sinal el√©trico √© gerado inteiramente pelo microfone.

    ![Patti Smith cantando em um microfone Shure SM58 (tipo din√¢mico cardioide)](../../../../../translated_images/dynamic-mic.8babac890a2d80dfb0874b5bf37d4b851fe2aeb9da6fd72945746176978bf3bb.br.jpg)

* Fita - Microfones de fita s√£o semelhantes aos microfones din√¢micos, exceto que possuem uma fita de metal em vez de um diafragma. Essa fita se move em um campo magn√©tico, gerando uma corrente el√©trica. Assim como os microfones din√¢micos, os microfones de fita n√£o precisam de energia para funcionar.

    ![Edmund Lowe, ator americano, em p√© ao lado de um microfone de r√°dio (etiquetado para a rede Blue da NBC), segurando um roteiro, 1942](../../../../../translated_images/ribbon-mic.eacc8e092c7441caee6d7a81e2f40e1675bf36269848964c7c09c9a9acb05127.br.jpg)

* Condensador - Microfones condensadores possuem um diafragma de metal fino e uma placa traseira de metal fixa. Eletricidade √© aplicada a ambos, e √† medida que o diafragma vibra, a carga est√°tica entre as placas muda, gerando um sinal. Microfones condensadores precisam de energia para funcionar - chamada de *Phantom power*.

    ![Microfone condensador de pequeno diafragma C451B da AKG Acoustics](../../../../../translated_images/condenser-mic.6f6ed5b76ca19e0ec3fd0c544601542d4479a6cb7565db336de49fbbf69f623e.br.jpg)

* MEMS - Microfones de sistemas microeletromec√¢nicos, ou MEMS, s√£o microfones em um chip. Eles possuem um diafragma sens√≠vel √† press√£o gravado em um chip de sil√≠cio e funcionam de maneira semelhante a um microfone condensador. Esses microfones podem ser min√∫sculos e integrados em circuitos.

    ![Um microfone MEMS em uma placa de circuito](../../../../../translated_images/mems-microphone.80574019e1f5e4d9ee72fed720ecd25a39fc2969c91355d17ebb24ba4159e4c4.br.png)

    Na imagem acima, o chip rotulado como **LEFT** √© um microfone MEMS, com um diafragma min√∫sculo de menos de um mil√≠metro de largura.

‚úÖ Fa√ßa uma pesquisa: Quais microfones voc√™ tem ao seu redor - seja no seu computador, telefone, headset ou em outros dispositivos? Que tipo de microfones s√£o eles?

### √Åudio digital

O √°udio √© um sinal anal√≥gico que carrega informa√ß√µes muito detalhadas. Para converter esse sinal em digital, o √°udio precisa ser amostrado milhares de vezes por segundo.

> üéì Amostragem √© o processo de converter o sinal de √°udio em um valor digital que representa o sinal naquele momento espec√≠fico.

![Um gr√°fico de linha mostrando um sinal, com pontos discretos em intervalos fixos](../../../../../translated_images/sampling.6f4fadb3f2d9dfe7618f9edfe75a350e6b3f74293ec84f02ab69c19d2afe3d73.br.png)

O √°udio digital √© amostrado usando Modula√ß√£o por C√≥digo de Pulso, ou PCM. PCM envolve a leitura da voltagem do sinal e a sele√ß√£o do valor discreto mais pr√≥ximo dessa voltagem usando um tamanho definido.

> üíÅ Voc√™ pode pensar no PCM como a vers√£o sensorial da modula√ß√£o por largura de pulso, ou PWM (PWM foi abordado na [li√ß√£o 3 do projeto introdut√≥rio](../../../1-getting-started/lessons/3-sensors-and-actuators/README.md#pulse-width-modulation)). PCM envolve converter um sinal anal√≥gico em digital, enquanto PWM envolve converter um sinal digital em anal√≥gico.

Por exemplo, a maioria dos servi√ßos de streaming de m√∫sica oferece √°udio de 16 bits ou 24 bits. Isso significa que eles convertem a voltagem em um valor que cabe em um n√∫mero inteiro de 16 bits ou 24 bits. O √°udio de 16 bits cabe em um n√∫mero que varia de -32.768 a 32.767, enquanto o de 24 bits varia de -8.388.608 a 8.388.607. Quanto mais bits, mais pr√≥ximo o som amostrado estar√° do que nossos ouvidos realmente ouvem.

> üíÅ Voc√™ j√° deve ter ouvido falar de √°udio de 8 bits, frequentemente chamado de LoFi. Este √© o √°udio amostrado usando apenas 8 bits, ou seja, de -128 a 127. O primeiro √°udio de computador era limitado a 8 bits devido a restri√ß√µes de hardware, por isso √© frequentemente associado a jogos retr√¥.

Essas amostras s√£o feitas milhares de vezes por segundo, usando taxas de amostragem bem definidas, medidas em KHz (milhares de leituras por segundo). Servi√ßos de streaming de m√∫sica usam 48KHz para a maioria dos √°udios, mas alguns √°udios 'sem perdas' usam at√© 96KHz ou mesmo 192KHz. Quanto maior a taxa de amostragem, mais pr√≥ximo o √°udio estar√° do original, at√© certo ponto. H√° debates sobre se os humanos conseguem perceber a diferen√ßa acima de 48KHz.

‚úÖ Fa√ßa uma pesquisa: Se voc√™ usa um servi√ßo de streaming de m√∫sica, qual √© a taxa de amostragem e o tamanho que ele utiliza? Se voc√™ usa CDs, qual √© a taxa de amostragem e o tamanho do √°udio em CD?

Existem v√°rios formatos diferentes para dados de √°udio. Voc√™ provavelmente j√° ouviu falar de arquivos mp3 - dados de √°udio comprimidos para torn√°-los menores sem perder qualidade. √Åudio n√£o comprimido geralmente √© armazenado como um arquivo WAV - este √© um arquivo com 44 bytes de informa√ß√µes de cabe√ßalho, seguido pelos dados de √°udio brutos. O cabe√ßalho cont√©m informa√ß√µes como a taxa de amostragem (por exemplo, 16000 para 16KHz), o tamanho da amostra (16 para 16 bits) e o n√∫mero de canais. Ap√≥s o cabe√ßalho, o arquivo WAV cont√©m os dados de √°udio brutos.

> üéì Canais referem-se a quantos fluxos de √°udio diferentes comp√µem o √°udio. Por exemplo, para √°udio est√©reo com canais esquerdo e direito, haveria 2 canais. Para som surround 7.1 em um sistema de home theater, seriam 8 canais.

### Tamanho dos dados de √°udio

Os dados de √°udio s√£o relativamente grandes. Por exemplo, capturar √°udio n√£o comprimido de 16 bits a 16KHz (uma taxa boa o suficiente para uso com modelos de fala para texto) consome 32KB de dados para cada segundo de √°udio:

* 16 bits significam 2 bytes por amostra (1 byte equivale a 8 bits).
* 16KHz s√£o 16.000 amostras por segundo.
* 16.000 x 2 bytes = 32.000 bytes por segundo.

Isso pode parecer uma quantidade pequena de dados, mas se voc√™ estiver usando um microcontrolador com mem√≥ria limitada, isso pode ser muito. Por exemplo, o Wio Terminal possui 192KB de mem√≥ria, e essa mem√≥ria precisa armazenar o c√≥digo do programa e as vari√°veis. Mesmo que seu c√≥digo seja pequeno, voc√™ n√£o poderia capturar mais de 5 segundos de √°udio.

Microcontroladores podem acessar armazenamento adicional, como cart√µes SD ou mem√≥ria flash. Ao construir um dispositivo IoT que captura √°udio, voc√™ precisar√° garantir n√£o apenas que possui armazenamento adicional, mas que seu c√≥digo grava o √°udio capturado do microfone diretamente nesse armazenamento. Al√©m disso, ao enviar o √°udio para a nuvem, voc√™ deve transmitir diretamente do armazenamento para a solicita√ß√£o web. Dessa forma, voc√™ evita esgotar a mem√≥ria tentando armazenar todo o bloco de dados de √°udio na mem√≥ria de uma s√≥ vez.

## Capturar √°udio do seu dispositivo IoT

Seu dispositivo IoT pode ser conectado a um microfone para capturar √°udio, pronto para convers√£o em texto. Ele tamb√©m pode ser conectado a alto-falantes para sa√≠da de √°udio. Em li√ß√µes posteriores, isso ser√° usado para fornecer feedback de √°udio, mas √© √∫til configurar os alto-falantes agora para testar o microfone.

### Tarefa - configurar seu microfone e alto-falantes

Siga o guia relevante para configurar o microfone e os alto-falantes para o seu dispositivo IoT:

* [Arduino - Wio Terminal](wio-terminal-microphone.md)
* [Computador de placa √∫nica - Raspberry Pi](pi-microphone.md)
* [Computador de placa √∫nica - Dispositivo virtual](virtual-device-microphone.md)

### Tarefa - capturar √°udio

Siga o guia relevante para capturar √°udio no seu dispositivo IoT:

* [Arduino - Wio Terminal](wio-terminal-audio.md)
* [Computador de placa √∫nica - Raspberry Pi](pi-audio.md)
* [Computador de placa √∫nica - Dispositivo virtual](virtual-device-audio.md)

## Fala para texto

Fala para texto, ou reconhecimento de fala, envolve o uso de IA para converter palavras em um sinal de √°udio em texto.

### Modelos de reconhecimento de fala

Para converter fala em texto, amostras do sinal de √°udio s√£o agrupadas e alimentadas em um modelo de aprendizado de m√°quina baseado em uma Rede Neural Recorrente (RNN). Este √© um tipo de modelo de aprendizado de m√°quina que pode usar dados anteriores para tomar decis√µes sobre os dados recebidos. Por exemplo, a RNN pode detectar um bloco de amostras de √°udio como o som 'Hel', e quando recebe outro que parece ser o som 'lo', ela pode combinar isso com o som anterior, descobrir que 'Hello' √© uma palavra v√°lida e selecionar isso como o resultado.

Modelos de aprendizado de m√°quina sempre aceitam dados do mesmo tamanho todas as vezes. O classificador de imagens que voc√™ construiu em uma li√ß√£o anterior redimensiona imagens para um tamanho fixo antes de process√°-las. O mesmo acontece com os modelos de fala, que precisam processar blocos de √°udio de tamanho fixo. Os modelos de fala precisam ser capazes de combinar as sa√≠das de v√°rias previs√µes para obter a resposta, permitindo distinguir entre 'Oi' e 'Rodovia', ou 'rebanho' e 'floccinaucinihilipilifica√ß√£o'.

Os modelos de fala tamb√©m s√£o avan√ßados o suficiente para entender o contexto e podem corrigir as palavras detectadas √† medida que mais sons s√£o processados. Por exemplo, se voc√™ disser "Fui √†s lojas para comprar duas bananas e uma ma√ß√£ tamb√©m", voc√™ usaria tr√™s palavras que soam iguais, mas s√£o escritas de forma diferente - para, duas e tamb√©m. Os modelos de fala s√£o capazes de entender o contexto e usar a grafia apropriada para a palavra.
üíÅ Alguns servi√ßos de fala permitem personaliza√ß√£o para funcionar melhor em ambientes barulhentos, como f√°bricas, ou com palavras espec√≠ficas de determinados setores, como nomes qu√≠micos. Essas personaliza√ß√µes s√£o treinadas fornecendo √°udio de exemplo e uma transcri√ß√£o, e funcionam utilizando aprendizado por transfer√™ncia, da mesma forma que voc√™ treinou um classificador de imagens usando apenas algumas imagens em uma li√ß√£o anterior.
### Privacidade

Ao utilizar reconhecimento de fala em um dispositivo IoT de consumo, a privacidade √© extremamente importante. Esses dispositivos escutam √°udio continuamente, e como consumidor, voc√™ n√£o quer que tudo o que voc√™ diz seja enviado para a nuvem e convertido em texto. Isso n√£o apenas consome muita largura de banda da Internet, mas tamb√©m tem grandes implica√ß√µes para a privacidade, especialmente quando alguns fabricantes de dispositivos inteligentes selecionam aleatoriamente √°udios para [humanos validarem em rela√ß√£o ao texto gerado para ajudar a melhorar seus modelos](https://www.theverge.com/2019/4/10/18305378/amazon-alexa-ai-voice-assistant-annotation-listen-private-recordings).

Voc√™ s√≥ quer que seu dispositivo inteligente envie √°udio para a nuvem para processamento quando voc√™ estiver usando-o, e n√£o quando ele ouvir sons em sua casa, que podem incluir reuni√µes privadas ou intera√ß√µes √≠ntimas. A forma como a maioria dos dispositivos inteligentes funciona √© com uma *palavra de ativa√ß√£o*, uma frase-chave como "Alexa", "Hey Siri" ou "OK Google", que faz com que o dispositivo 'acorde' e ou√ßa o que voc√™ est√° dizendo at√© detectar uma pausa na sua fala, indicando que voc√™ terminou de falar com o dispositivo.

> üéì A detec√ß√£o de palavras de ativa√ß√£o tamb√©m √© conhecida como *Keyword spotting* ou *Keyword recognition*.

Essas palavras de ativa√ß√£o s√£o detectadas no pr√≥prio dispositivo, n√£o na nuvem. Esses dispositivos inteligentes possuem pequenos modelos de IA que rodam no dispositivo e escutam a palavra de ativa√ß√£o. Quando ela √© detectada, o dispositivo come√ßa a transmitir o √°udio para a nuvem para reconhecimento. Esses modelos s√£o altamente especializados e s√≥ escutam a palavra de ativa√ß√£o.

> üíÅ Algumas empresas de tecnologia est√£o adicionando mais privacidade aos seus dispositivos e realizando parte da convers√£o de fala para texto no pr√≥prio dispositivo. A Apple anunciou que, como parte das atualiza√ß√µes do iOS e macOS de 2021, suportar√° a convers√£o de fala para texto no dispositivo, sendo capaz de lidar com muitas solicita√ß√µes sem precisar usar a nuvem. Isso √© poss√≠vel gra√ßas aos processadores poderosos em seus dispositivos, que podem executar modelos de ML.

‚úÖ Quais voc√™ acha que s√£o as implica√ß√µes de privacidade e √©tica de armazenar o √°udio enviado para a nuvem? Esse √°udio deveria ser armazenado e, se sim, como? Voc√™ acha que o uso de grava√ß√µes para aplica√ß√£o da lei √© uma boa troca pela perda de privacidade?

A detec√ß√£o de palavras de ativa√ß√£o geralmente utiliza uma t√©cnica conhecida como TinyML, que consiste em converter modelos de ML para que possam ser executados em microcontroladores. Esses modelos s√£o pequenos em tamanho e consomem muito pouca energia para funcionar.

Para evitar a complexidade de treinar e usar um modelo de palavra de ativa√ß√£o, o cron√¥metro inteligente que voc√™ est√° construindo nesta li√ß√£o usar√° um bot√£o para ativar o reconhecimento de fala.

> üíÅ Se voc√™ quiser tentar criar um modelo de detec√ß√£o de palavras de ativa√ß√£o para rodar no Wio Terminal ou Raspberry Pi, confira este [tutorial de resposta √† sua voz da Edge Impulse](https://docs.edgeimpulse.com/docs/responding-to-your-voice). Se quiser usar seu computador para isso, voc√™ pode experimentar o [guia r√°pido de introdu√ß√£o ao Custom Keyword na documenta√ß√£o da Microsoft](https://docs.microsoft.com/azure/cognitive-services/speech-service/keyword-recognition-overview?WT.mc_id=academic-17441-jabenn).

## Converter fala em texto

![Logotipo dos servi√ßos de fala](../../../../../translated_images/azure-speech-logo.a1f08c4befb0159f2cb5d692d3baf5b599e7b44759d316da907bda1508f46a4a.br.png)

Assim como na classifica√ß√£o de imagens em um projeto anterior, existem servi√ßos de IA pr√©-constru√≠dos que podem pegar fala como um arquivo de √°udio e convert√™-la em texto. Um desses servi√ßos √© o Speech Service, parte dos Cognitive Services, servi√ßos de IA pr√©-constru√≠dos que voc√™ pode usar em seus aplicativos.

### Tarefa - configurar um recurso de IA de fala

1. Crie um Grupo de Recursos para este projeto chamado `smart-timer`.

1. Use o seguinte comando para criar um recurso de fala gratuito:

    ```sh
    az cognitiveservices account create --name smart-timer \
                                        --resource-group smart-timer \
                                        --kind SpeechServices \
                                        --sku F0 \
                                        --yes \
                                        --location <location>
    ```

    Substitua `<location>` pela localiza√ß√£o usada ao criar o Grupo de Recursos.

1. Voc√™ precisar√° de uma chave de API para acessar o recurso de fala a partir do seu c√≥digo. Execute o seguinte comando para obter a chave:

    ```sh
    az cognitiveservices account keys list --name smart-timer \
                                           --resource-group smart-timer \
                                           --output table
    ```

    Copie uma das chaves.

### Tarefa - converter fala em texto

Siga o guia relevante para converter fala em texto no seu dispositivo IoT:

* [Arduino - Wio Terminal](wio-terminal-speech-to-text.md)
* [Computador de placa √∫nica - Raspberry Pi](pi-speech-to-text.md)
* [Computador de placa √∫nica - Dispositivo virtual](virtual-device-speech-to-text.md)

---

## üöÄ Desafio

O reconhecimento de fala existe h√° muito tempo e est√° continuamente melhorando. Pesquise as capacidades atuais e compare como elas evolu√≠ram ao longo do tempo, incluindo qu√£o precisas s√£o as transcri√ß√µes feitas por m√°quinas em compara√ß√£o com as feitas por humanos.

O que voc√™ acha que o futuro reserva para o reconhecimento de fala?

## Question√°rio p√≥s-aula

[Question√°rio p√≥s-aula](https://black-meadow-040d15503.1.azurestaticapps.net/quiz/42)

## Revis√£o e Autoestudo

* Leia sobre os diferentes tipos de microfones e como eles funcionam no [artigo sobre a diferen√ßa entre microfones din√¢micos e condensadores no Musician's HQ](https://musicianshq.com/whats-the-difference-between-dynamic-and-condenser-microphones/).
* Leia mais sobre o servi√ßo de fala dos Cognitive Services na [documenta√ß√£o do servi√ßo de fala na Microsoft Docs](https://docs.microsoft.com/azure/cognitive-services/speech-service/?WT.mc_id=academic-17441-jabenn).
* Leia sobre detec√ß√£o de palavras-chave na [documenta√ß√£o de reconhecimento de palavras-chave na Microsoft Docs](https://docs.microsoft.com/azure/cognitive-services/speech-service/keyword-recognition-overview?WT.mc_id=academic-17441-jabenn).

## Tarefa

[](assignment.md)

---

**Aviso Legal**:  
Este documento foi traduzido utilizando o servi√ßo de tradu√ß√£o por IA [Co-op Translator](https://github.com/Azure/co-op-translator). Embora nos esforcemos para garantir a precis√£o, esteja ciente de que tradu√ß√µes automatizadas podem conter erros ou imprecis√µes. O documento original em seu idioma nativo deve ser considerado a fonte autoritativa. Para informa√ß√µes cr√≠ticas, recomenda-se a tradu√ß√£o profissional realizada por humanos. N√£o nos responsabilizamos por quaisquer mal-entendidos ou interpreta√ß√µes equivocadas decorrentes do uso desta tradu√ß√£o.