<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "606f3af1c78e3741e48ce77c31cea626",
  "translation_date": "2025-08-28T09:03:13+00:00",
  "source_file": "6-consumer/lessons/3-spoken-feedback/pi-text-to-speech.md",
  "language_code": "ro"
}
-->
# Text to speech - Raspberry Pi

칉n aceast캒 parte a lec탵iei, vei scrie cod pentru a converti textul 칥n vorbire folosind serviciul de vorbire.

## Conversia textului 칥n vorbire folosind serviciul de vorbire

Textul poate fi trimis c캒tre serviciul de vorbire utiliz칙nd REST API pentru a ob탵ine vorbirea sub form캒 de fi탳ier audio, care poate fi redat pe dispozitivul t캒u IoT. C칙nd solici탵i vorbirea, trebuie s캒 specifici vocea utilizat캒, deoarece vorbirea poate fi generat캒 folosind o varietate de voci diferite.

Fiecare limb캒 suport캒 o gam캒 de voci diferite, iar tu po탵i face o cerere REST c캒tre serviciul de vorbire pentru a ob탵ine lista vocilor disponibile pentru fiecare limb캒.

### Sarcin캒 - ob탵ine o voce

1. Deschide proiectul `smart-timer` 칥n VS Code.

1. Adaug캒 urm캒torul cod deasupra func탵iei `say` pentru a solicita lista vocilor pentru o limb캒:

    ```python
    def get_voice():
        url = f'https://{location}.tts.speech.microsoft.com/cognitiveservices/voices/list'
    
        headers = {
            'Authorization': 'Bearer ' + get_access_token()
        }
    
        response = requests.get(url, headers=headers)
        voices_json = json.loads(response.text)
    
        first_voice = next(x for x in voices_json if x['Locale'].lower() == language.lower() and x['VoiceType'] == 'Neural')
        return first_voice['ShortName']
    
    voice = get_voice()
    print(f'Using voice {voice}')
    ```

    Acest cod define탳te o func탵ie numit캒 `get_voice` care utilizeaz캒 serviciul de vorbire pentru a ob탵ine o list캒 de voci. Apoi g캒se탳te prima voce care se potrive탳te cu limba utilizat캒.

    Aceast캒 func탵ie este apoi apelat캒 pentru a stoca prima voce, iar numele vocii este afi탳at 칥n consol캒. Aceast캒 voce poate fi solicitat캒 o singur캒 dat캒, iar valoarea poate fi utilizat캒 pentru fiecare apel de conversie a textului 칥n vorbire.

    > 游누 Po탵i ob탵ine lista complet캒 a vocilor disponibile din [documenta탵ia despre suportul pentru limbi 탳i voci pe Microsoft Docs](https://docs.microsoft.com/azure/cognitive-services/speech-service/language-support?WT.mc_id=academic-17441-jabenn#text-to-speech). Dac캒 dore탳ti s캒 utilizezi o voce specific캒, po탵i elimina aceast캒 func탵ie 탳i s캒 introduci manual numele vocii din aceast캒 documenta탵ie. De exemplu:
    >
    > ```python
    > voice = 'hi-IN-SwaraNeural'
    > ```

### Sarcin캒 - converte탳te textul 칥n vorbire

1. Sub acest cod, define탳te o constant캒 pentru formatul audio care va fi ob탵inut de la serviciile de vorbire. C칙nd solici탵i audio, po탵i face acest lucru 칥ntr-o gam캒 de formate diferite.

    ```python
    playback_format = 'riff-48khz-16bit-mono-pcm'
    ```

    Formatul pe care 칥l po탵i utiliza depinde de hardware-ul t캒u. Dac캒 prime탳ti erori de tipul `Invalid sample rate` atunci c칙nd redai audio, schimb캒 acest format cu o alt캒 valoare. Po탵i g캒si lista valorilor acceptate 칥n [documenta탵ia REST API pentru text-to-speech pe Microsoft Docs](https://docs.microsoft.com/azure/cognitive-services/speech-service/rest-text-to-speech?WT.mc_id=academic-17441-jabenn#audio-outputs). Va trebui s캒 utilizezi audio 칥n format `riff`, iar valorile pe care le po탵i 칥ncerca sunt `riff-16khz-16bit-mono-pcm`, `riff-24khz-16bit-mono-pcm` 탳i `riff-48khz-16bit-mono-pcm`.

1. Sub acest cod, declar캒 o func탵ie numit캒 `get_speech` care va converti textul 칥n vorbire folosind REST API-ul serviciului de vorbire:

    ```python
    def get_speech(text):
    ```

1. 칉n func탵ia `get_speech`, define탳te URL-ul care va fi apelat 탳i anteturile care vor fi transmise:

    ```python
        url = f'https://{location}.tts.speech.microsoft.com/cognitiveservices/v1'
    
        headers = {
            'Authorization': 'Bearer ' + get_access_token(),
            'Content-Type': 'application/ssml+xml',
            'X-Microsoft-OutputFormat': playback_format
        }
    ```

    Acest cod seteaz캒 anteturile pentru a utiliza un token de acces generat, define탳te con탵inutul ca SSML 탳i specific캒 formatul audio necesar.

1. Sub acest cod, define탳te SSML-ul care va fi trimis c캒tre REST API:

    ```python
    ssml =  f'<speak version=\'1.0\' xml:lang=\'{language}\'>'
    ssml += f'<voice xml:lang=\'{language}\' name=\'{voice}\'>'
    ssml += text
    ssml += '</voice>'
    ssml += '</speak>'
    ```

    Acest SSML seteaz캒 limba 탳i vocea care vor fi utilizate, 칥mpreun캒 cu textul care va fi convertit.

1. 칉n cele din urm캒, adaug캒 cod 칥n aceast캒 func탵ie pentru a face cererea REST 탳i a returna datele audio binare:

    ```python
    response = requests.post(url, headers=headers, data=ssml.encode('utf-8'))
    return io.BytesIO(response.content)
    ```

### Sarcin캒 - red캒 audio-ul

1. Sub func탵ia `get_speech`, define탳te o nou캒 func탵ie pentru a reda audio-ul returnat de apelul REST API:

    ```python
    def play_speech(speech):
    ```

1. Parametrul `speech` transmis acestei func탵ii va fi datele audio binare returnate de REST API. Utilizeaz캒 urm캒torul cod pentru a deschide acest fi탳ier ca un fi탳ier wave 탳i pentru a-l reda folosind PyAudio:

    ```python
    def play_speech(speech):
        with wave.open(speech, 'rb') as wave_file:
            stream = audio.open(format=audio.get_format_from_width(wave_file.getsampwidth()),
                                channels=wave_file.getnchannels(),
                                rate=wave_file.getframerate(),
                                output_device_index=speaker_card_number,
                                output=True)

            data = wave_file.readframes(4096)

            while len(data) > 0:
                stream.write(data)
                data = wave_file.readframes(4096)

            stream.stop_stream()
            stream.close()
    ```

    Acest cod utilizeaz캒 un flux PyAudio, la fel ca 칥n cazul captur캒rii audio. Diferen탵a aici este c캒 fluxul este setat ca flux de ie탳ire, iar datele sunt citite din datele audio 탳i transmise c캒tre flux.

    칉n loc s캒 codifici manual detaliile fluxului, cum ar fi rata de e탳antionare, acestea sunt citite din datele audio.

1. 칉nlocuie탳te con탵inutul func탵iei `say` cu urm캒torul cod:

    ```python
    speech = get_speech(text)
    play_speech(speech)
    ```

    Acest cod converte탳te textul 칥n vorbire sub form캒 de date audio binare 탳i red캒 audio-ul.

1. Ruleaz캒 aplica탵ia 탳i asigur캒-te c캒 aplica탵ia func탵ional캒 ruleaz캒 de asemenea. Seteaz캒 c칙teva cronometre 탳i vei auzi un r캒spuns vocal care 칥탵i spune c캒 cronometrul a fost setat, apoi un alt r캒spuns vocal c칙nd cronometrul se finalizeaz캒.

    Dac캒 prime탳ti erori de tipul `Invalid sample rate`, schimb캒 `playback_format` a탳a cum este descris mai sus.

> 游누 Po탵i g캒si acest cod 칥n folderul [code-spoken-response/pi](../../../../../6-consumer/lessons/3-spoken-feedback/code-spoken-response/pi).

游 Programul t캒u de cronometru a fost un succes!

---

**Declinare de responsabilitate**:  
Acest document a fost tradus folosind serviciul de traducere AI [Co-op Translator](https://github.com/Azure/co-op-translator). De탳i ne str캒duim s캒 asigur캒m acurate탵ea, v캒 rug캒m s캒 fi탵i con탳tien탵i c캒 traducerile automate pot con탵ine erori sau inexactit캒탵i. Documentul original 칥n limba sa natal캒 ar trebui considerat sursa autoritar캒. Pentru informa탵ii critice, se recomand캒 traducerea profesional캒 realizat캒 de un specialist uman. Nu ne asum캒m responsabilitatea pentru eventualele ne칥n탵elegeri sau interpret캒ri gre탳ite care pot ap캒rea din utilizarea acestei traduceri.