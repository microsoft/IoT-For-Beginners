<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "a202fa5889790a3777bfc33dd9f4b459",
  "translation_date": "2025-08-28T09:00:39+00:00",
  "source_file": "6-consumer/lessons/3-spoken-feedback/wio-terminal-text-to-speech.md",
  "language_code": "ro"
}
-->
# Text to speech - Wio Terminal

칉n aceast캒 parte a lec탵iei, vei transforma textul 칥n vorbire pentru a oferi feedback vocal.

## Text to speech

SDK-ul serviciilor de vorbire pe care l-ai folosit 칥n lec탵ia anterioar캒 pentru a transforma vorbirea 칥n text poate fi utilizat 탳i pentru a transforma textul 칥n vorbire.

## Ob탵ine o list캒 de voci

C칙nd solici탵i vorbire, trebuie s캒 specifici vocea care va fi utilizat캒, deoarece vorbirea poate fi generat캒 folosind o varietate de voci diferite. Fiecare limb캒 suport캒 o gam캒 de voci, iar lista vocilor disponibile pentru fiecare limb캒 poate fi ob탵inut캒 din SDK-ul serviciilor de vorbire. Limit캒rile microcontrolerelor intervin aici - apelul pentru a ob탵ine lista vocilor suportate de serviciile text-to-speech este un document JSON de peste 77KB, mult prea mare pentru a fi procesat de Wio Terminal. La momentul redact캒rii, lista complet캒 con탵ine 215 voci, fiecare definit캒 printr-un document JSON precum urm캒torul:

```json
{
    "Name": "Microsoft Server Speech Text to Speech Voice (en-US, AriaNeural)",
    "DisplayName": "Aria",
    "LocalName": "Aria",
    "ShortName": "en-US-AriaNeural",
    "Gender": "Female",
    "Locale": "en-US",
    "StyleList": [
        "chat",
        "customerservice",
        "narration-professional",
        "newscast-casual",
        "newscast-formal",
        "cheerful",
        "empathetic"
    ],
    "SampleRateHertz": "24000",
    "VoiceType": "Neural",
    "Status": "GA"
}
```

Acest JSON este pentru vocea **Aria**, care are mai multe stiluri vocale. Tot ce este necesar pentru a transforma textul 칥n vorbire este numele scurt, `en-US-AriaNeural`.

칉n loc s캒 descarci 탳i s캒 decodezi 칥ntreaga list캒 pe microcontroler, va trebui s캒 scrii un cod serverless suplimentar pentru a prelua lista vocilor pentru limba pe care o folose탳ti 탳i s캒 apelezi acest cod de pe Wio Terminal. Codul t캒u poate apoi s캒 aleag캒 o voce potrivit캒 din list캒, cum ar fi prima pe care o g캒se탳te.

### Sarcin캒 - creeaz캒 o func탵ie serverless pentru a ob탵ine o list캒 de voci

1. Deschide proiectul `smart-timer-trigger` 칥n VS Code 탳i deschide terminalul, asigur칙ndu-te c캒 mediul virtual este activat. Dac캒 nu, 칥nchide 탳i recreeaz캒 terminalul.

1. Deschide fi탳ierul `local.settings.json` 탳i adaug캒 set캒rile pentru cheia API a serviciului de vorbire 탳i loca탵ie:

    ```json
    "SPEECH_KEY": "<key>",
    "SPEECH_LOCATION": "<location>"
    ```

    칉nlocuie탳te `<key>` cu cheia API pentru resursa serviciului de vorbire. 칉nlocuie탳te `<location>` cu loca탵ia pe care ai utilizat-o c칙nd ai creat resursa serviciului de vorbire.

1. Adaug캒 un nou trigger HTTP 칥n aceast캒 aplica탵ie numit `get-voices` folosind urm캒toarea comand캒 din terminalul VS Code, 칥n folderul r캒d캒cin캒 al proiectului aplica탵iei de func탵ii:

    ```sh
    func new --name get-voices --template "HTTP trigger"
    ```

    Aceasta va crea un trigger HTTP numit `get-voices`.

1. 칉nlocuie탳te con탵inutul fi탳ierului `__init__.py` din folderul `get-voices` cu urm캒torul cod:

    ```python
    import json
    import os
    import requests
    
    import azure.functions as func
    
    def main(req: func.HttpRequest) -> func.HttpResponse:
        location = os.environ['SPEECH_LOCATION']
        speech_key = os.environ['SPEECH_KEY']
    
        req_body = req.get_json()
        language = req_body['language']
    
        url = f'https://{location}.tts.speech.microsoft.com/cognitiveservices/voices/list'
    
        headers = {
            'Ocp-Apim-Subscription-Key': speech_key
        }
    
        response = requests.get(url, headers=headers)
        voices_json = json.loads(response.text)
    
        voices = filter(lambda x: x['Locale'].lower() == language.lower(), voices_json)
        voices = map(lambda x: x['ShortName'], voices)
    
        return func.HttpResponse(json.dumps(list(voices)), status_code=200)
    ```

    Acest cod face o cerere HTTP c캒tre endpoint pentru a ob탵ine vocile. Lista vocilor este un bloc mare de JSON cu voci pentru toate limbile, astfel 칥nc칙t vocile pentru limba transmis캒 칥n corpul cererii sunt filtrate, iar numele scurt este extras 탳i returnat ca o list캒 JSON. Numele scurt este valoarea necesar캒 pentru a transforma textul 칥n vorbire, astfel 칥nc칙t doar aceast캒 valoare este returnat캒.

    > 游누 Po탵i modifica filtrul dup캒 cum este necesar pentru a selecta doar vocile dorite.

    Aceasta reduce dimensiunea datelor de la 77KB (la momentul redact캒rii) la un document JSON mult mai mic. De exemplu, pentru vocile din SUA, acesta are 408 bytes.

1. Ruleaz캒 aplica탵ia de func탵ii local. Po탵i apoi s캒 o apelezi folosind un instrument precum curl, la fel cum ai testat trigger-ul HTTP `text-to-timer`. Asigur캒-te c캒 transmi탵i limba ca un corp JSON:

    ```json
    {
        "language":"<language>"
    }
    ```

    칉nlocuie탳te `<language>` cu limba ta, cum ar fi `en-GB` sau `zh-CN`.

> 游누 Po탵i g캒si acest cod 칥n folderul [code-spoken-response/functions](../../../../../6-consumer/lessons/3-spoken-feedback/code-spoken-response/functions).

### Sarcin캒 - preia vocea de pe Wio Terminal

1. Deschide proiectul `smart-timer` 칥n VS Code, dac캒 nu este deja deschis.

1. Deschide fi탳ierul header `config.h` 탳i adaug캒 URL-ul pentru aplica탵ia ta de func탵ii:

    ```cpp
    const char *GET_VOICES_FUNCTION_URL = "<URL>";
    ```

    칉nlocuie탳te `<URL>` cu URL-ul pentru trigger-ul HTTP `get-voices` din aplica탵ia ta de func탵ii. Acesta va fi acela탳i cu valoarea pentru `TEXT_TO_TIMER_FUNCTION_URL`, cu excep탵ia faptului c캒 numele func탵iei va fi `get-voices` 칥n loc de `text-to-timer`.

1. Creeaz캒 un fi탳ier nou 칥n folderul `src` numit `text_to_speech.h`. Acesta va fi utilizat pentru a defini o clas캒 care transform캒 textul 칥n vorbire.

1. Adaug캒 urm캒toarele directive include 칥n partea de sus a noului fi탳ier `text_to_speech.h`:

    ```cpp
    #pragma once

    #include <Arduino.h>
    #include <ArduinoJson.h>
    #include <HTTPClient.h>
    #include <Seeed_FS.h>
    #include <SD/Seeed_SD.h>
    #include <WiFiClient.h>
    #include <WiFiClientSecure.h>
    
    #include "config.h"
    #include "speech_to_text.h"
    ```

1. Adaug캒 urm캒torul cod mai jos pentru a declara clasa `TextToSpeech`, 칥mpreun캒 cu o instan탵캒 care poate fi utilizat캒 칥n restul aplica탵iei:

    ```cpp
    class TextToSpeech
    {
    public:
    private:
    };
    
    TextToSpeech textToSpeech;
    ```

1. Pentru a apela aplica탵ia de func탵ii, trebuie s캒 declari un client WiFi. Adaug캒 urm캒torul cod 칥n sec탵iunea `private` a clasei:

    ```cpp
    WiFiClient _client;
    ```

1. 칉n sec탵iunea `private`, adaug캒 un c칙mp pentru vocea selectat캒:

    ```cpp
    String _voice;
    ```

1. 칉n sec탵iunea `public`, adaug캒 o func탵ie `init` care va ob탵ine prima voce:

    ```cpp
    void init()
    {
    }
    ```

1. Pentru a ob탵ine vocile, un document JSON trebuie trimis c캒tre aplica탵ia de func탵ii cu limba. Adaug캒 urm캒torul cod 칥n func탵ia `init` pentru a crea acest document JSON:

    ```cpp
    DynamicJsonDocument doc(1024);
    doc["language"] = LANGUAGE;

    String body;
    serializeJson(doc, body);
    ```

1. Creeaz캒 un `HTTPClient`, apoi folose탳te-l pentru a apela aplica탵ia de func탵ii pentru a ob탵ine vocile, post칙nd documentul JSON:

    ```cpp
    HTTPClient httpClient;
    httpClient.begin(_client, GET_VOICES_FUNCTION_URL);

    int httpResponseCode = httpClient.POST(body);
    ```

1. Mai jos, adaug캒 cod pentru a verifica codul de r캒spuns, iar dac캒 este 200 (succes), extrage lista de voci, prelu칙nd prima din list캒:

    ```cpp
    if (httpResponseCode == 200)
    {
        String result = httpClient.getString();
        Serial.println(result);

        DynamicJsonDocument doc(1024);
        deserializeJson(doc, result.c_str());

        JsonArray obj = doc.as<JsonArray>();
        _voice = obj[0].as<String>();

        Serial.print("Using voice ");
        Serial.println(_voice);
    }
    else
    {
        Serial.print("Failed to get voices - error ");
        Serial.println(httpResponseCode);
    }
    ```

1. Dup캒 aceasta, 칥nchide conexiunea clientului HTTP:

    ```cpp
    httpClient.end();
    ```

1. Deschide fi탳ierul `main.cpp` 탳i adaug캒 urm캒toarea directiv캒 include 칥n partea de sus pentru a include acest nou fi탳ier header:

    ```cpp
    #include "text_to_speech.h"
    ```

1. 칉n func탵ia `setup`, sub apelul c캒tre `speechToText.init();`, adaug캒 urm캒torul cod pentru a ini탵ializa clasa `TextToSpeech`:

    ```cpp
    textToSpeech.init();
    ```

1. Compileaz캒 acest cod, 칥ncarc캒-l pe Wio Terminal 탳i testeaz캒-l prin monitorul serial. Asigur캒-te c캒 aplica탵ia ta de func탵ii ruleaz캒.

    Vei vedea lista vocilor disponibile returnat캒 de aplica탵ia de func탵ii, 칥mpreun캒 cu vocea selectat캒.

    ```output
    --- Available filters and text transformations: colorize, debug, default, direct, hexlify, log2file, nocontrol, printable, send_on_enter, time
    --- More details at http://bit.ly/pio-monitor-filters
    --- Miniterm on /dev/cu.usbmodem1101  9600,8,N,1 ---
    --- Quit: Ctrl+C | Menu: Ctrl+T | Help: Ctrl+T followed by Ctrl+H ---
    Connecting to WiFi..
    Connected!
    Got access token.
    ["en-US-JennyNeural", "en-US-JennyMultilingualNeural", "en-US-GuyNeural", "en-US-AriaNeural", "en-US-AmberNeural", "en-US-AnaNeural", "en-US-AshleyNeural", "en-US-BrandonNeural", "en-US-ChristopherNeural", "en-US-CoraNeural", "en-US-ElizabethNeural", "en-US-EricNeural", "en-US-JacobNeural", "en-US-MichelleNeural", "en-US-MonicaNeural", "en-US-AriaRUS", "en-US-BenjaminRUS", "en-US-GuyRUS", "en-US-ZiraRUS"]
    Using voice en-US-JennyNeural
    Ready.
    ```

## Transform캒 textul 칥n vorbire

Odat캒 ce ai o voce de utilizat, aceasta poate fi folosit캒 pentru a transforma textul 칥n vorbire. Acelea탳i limit캒ri de memorie cu vocile se aplic캒 탳i atunci c칙nd transformi textul 칥n vorbire, astfel 칥nc칙t va trebui s캒 scrii vorbirea pe un card SD pentru a fi redat캒 prin ReSpeaker.

> 游누 칉n lec탵iile anterioare ale acestui proiect, ai folosit memoria flash pentru a stoca vorbirea captat캒 de microfon. Aceast캒 lec탵ie folose탳te un card SD, deoarece este mai u탳or s캒 redai audio de pe acesta folosind bibliotecile audio Seeed.

Exist캒 탳i o alt캒 limitare de luat 칥n considerare: datele audio disponibile de la serviciul de vorbire 탳i formatele pe care Wio Terminal le suport캒. Spre deosebire de computerele complete, bibliotecile audio pentru microcontrolere pot fi foarte limitate 칥n formatele audio pe care le suport캒. De exemplu, biblioteca Seeed Arduino Audio care poate reda sunet prin ReSpeaker suport캒 doar audio la o rat캒 de e탳antionare de 44.1KHz. Serviciile de vorbire Azure pot furniza audio 칥n mai multe formate, dar niciunul dintre ele nu folose탳te aceast캒 rat캒 de e탳antionare; ele ofer캒 doar 8KHz, 16KHz, 24KHz 탳i 48KHz. Aceasta 칥nseamn캒 c캒 audio-ul trebuie re-e탳antionat la 44.1KHz, ceva ce ar necesita mai multe resurse dec칙t are Wio Terminal, 칥n special memorie.

C칙nd este nevoie s캒 manipulezi astfel de date, este adesea mai bine s캒 folose탳ti cod serverless, mai ales dac캒 datele sunt ob탵inute printr-un apel web. Wio Terminal poate apela o func탵ie serverless, transmi탵칙nd textul de convertit, iar func탵ia serverless poate at칙t s캒 apeleze serviciul de vorbire pentru a transforma textul 칥n vorbire, c칙t 탳i s캒 re-e탳antioneze audio-ul la rata de e탳antionare necesar캒. Apoi poate returna audio-ul 칥n forma de care Wio Terminal are nevoie pentru a fi stocat pe cardul SD 탳i redat prin ReSpeaker.

### Sarcin캒 - creeaz캒 o func탵ie serverless pentru a transforma textul 칥n vorbire

1. Deschide proiectul `smart-timer-trigger` 칥n VS Code 탳i deschide terminalul, asigur칙ndu-te c캒 mediul virtual este activat. Dac캒 nu, 칥nchide 탳i recreeaz캒 terminalul.

1. Adaug캒 un nou trigger HTTP 칥n aceast캒 aplica탵ie numit `text-to-speech` folosind urm캒toarea comand캒 din terminalul VS Code, 칥n folderul r캒d캒cin캒 al proiectului aplica탵iei de func탵ii:

    ```sh
    func new --name text-to-speech --template "HTTP trigger"
    ```

    Aceasta va crea un trigger HTTP numit `text-to-speech`.

1. Pachetul Pip [librosa](https://librosa.org) are func탵ii pentru re-e탳antionarea audio-ului, a탳a c캒 adaug캒-l 칥n fi탳ierul `requirements.txt`:

    ```sh
    librosa
    ```

    Dup캒 ce l-ai ad캒ugat, instaleaz캒 pachetele Pip folosind urm캒toarea comand캒 din terminalul VS Code:

    ```sh
    pip install -r requirements.txt
    ```

    > 丘멆잺 Dac캒 folose탳ti Linux, inclusiv Raspberry Pi OS, este posibil s캒 fie nevoie s캒 instalezi `libsndfile` cu urm캒toarea comand캒:
    >
    > ```sh
    > sudo apt update
    > sudo apt install libsndfile1-dev
    > ```

1. Pentru a transforma textul 칥n vorbire, nu po탵i folosi direct cheia API a serviciului de vorbire; 칥n schimb, trebuie s캒 solici탵i un token de acces, folosind cheia API pentru a autentifica cererea de token de acces. Deschide fi탳ierul `__init__.py` din folderul `text-to-speech` 탳i 칥nlocuie탳te tot codul din el cu urm캒torul:

    ```python
    import io
    import os
    import requests
    
    import librosa
    import soundfile as sf
    import azure.functions as func
    
    location = os.environ['SPEECH_LOCATION']
    speech_key = os.environ['SPEECH_KEY']
    
    def get_access_token():
        headers = {
            'Ocp-Apim-Subscription-Key': speech_key
        }
    
        token_endpoint = f'https://{location}.api.cognitive.microsoft.com/sts/v1.0/issuetoken'
        response = requests.post(token_endpoint, headers=headers)
        return str(response.text)
    ```

    Acesta define탳te constante pentru loca탵ie 탳i cheia serviciului de vorbire, care vor fi citite din set캒ri. Apoi define탳te func탵ia `get_access_token` care va prelua un token de acces pentru serviciul de vorbire.

1. Mai jos de acest cod, adaug캒 urm캒torul:

    ```python
    playback_format = 'riff-48khz-16bit-mono-pcm'

    def main(req: func.HttpRequest) -> func.HttpResponse:
        req_body = req.get_json()
        language = req_body['language']
        voice = req_body['voice']
        text = req_body['text']
    
        url = f'https://{location}.tts.speech.microsoft.com/cognitiveservices/v1'
    
        headers = {
            'Authorization': 'Bearer ' + get_access_token(),
            'Content-Type': 'application/ssml+xml',
            'X-Microsoft-OutputFormat': playback_format
        }
    
        ssml =  f'<speak version=\'1.0\' xml:lang=\'{language}\'>'
        ssml += f'<voice xml:lang=\'{language}\' name=\'{voice}\'>'
        ssml += text
        ssml += '</voice>'
        ssml += '</speak>'
    
        response = requests.post(url, headers=headers, data=ssml.encode('utf-8'))
    
        raw_audio, sample_rate = librosa.load(io.BytesIO(response.content), sr=48000)
        resampled = librosa.resample(raw_audio, sample_rate, 44100)
        
        output_buffer = io.BytesIO()
        sf.write(output_buffer, resampled, 44100, 'PCM_16', format='wav')
        output_buffer.seek(0)
    
        return func.HttpResponse(output_buffer.read(), status_code=200)
    ```

    Acesta define탳te trigger-ul HTTP care transform캒 textul 칥n vorbire. Extrage textul de convertit, limba 탳i vocea din corpul JSON transmis cererii, construie탳te un SSML pentru a solicita vorbirea, apoi apeleaz캒 API-ul REST relevant, autentific칙ndu-se folosind token-ul de acces. Acest apel API REST returneaz캒 audio-ul codificat ca fi탳ier WAV mono de 16 bi탵i, 48KHz, definit de valoarea `playback_format`, care este transmis캒 apelului API REST.

    Acesta este apoi re-e탳antionat de `librosa` de la o rat캒 de e탳antionare de 48KHz la o rat캒 de e탳antionare de 44.1KHz, apoi acest audio este salvat 칥ntr-un buffer binar care este apoi returnat.

1. Ruleaz캒 aplica탵ia de func탵ii local sau distribuie-o 칥n cloud. Po탵i apoi s캒 o apelezi folosind un instrument precum curl, la fel cum ai testat trigger-ul HTTP `text-to-timer`. Asigur캒-te c캒 transmi탵i limba, vocea 탳i textul ca un corp JSON:

    ```json
    {
        "language": "<language>",
        "voice": "<voice>",
        "text": "<text>"
    }
    ```

    칉nlocuie탳te `<language>` cu limba ta, cum ar fi `en-GB` sau `zh-CN`. 칉nlocuie탳te `<voice>` cu vocea pe care vrei s캒 o folose탳ti. 칉nlocuie탳te `<text>` cu textul pe care vrei s캒-l transformi 칥n vorbire. Po탵i salva rezultatul 칥ntr-un fi탳ier 탳i s캒-l redai cu orice player audio care poate reda fi탳iere WAV.

    De exemplu, pentru a transforma "Hello" 칥n vorbire folosind engleza american캒 cu vocea Jenny Neural, cu aplica탵ia de func탵ii rul칙nd local, po탵i folosi urm캒toarea comand캒 curl:

    ```sh
    curl -X GET 'http://localhost:7071/api/text-to-speech' \
         -H 'Content-Type: application/json' \
         -o hello.wav \
         -d '{
           "language":"en-US",
           "voice": "en-US-JennyNeural",
           "text": "Hello"
         }'
    ```

    Aceasta va salva audio-ul 칥n `hello.wav` 칥n directorul curent.

> 游누 Po탵i g캒si acest cod 칥n folderul [code-spoken-response/functions](../../../../../6-consumer/lessons/3-spoken-feedback/code-spoken-response/functions).

### Sarcin캒 - preia vorbirea de pe Wio Terminal

1. Deschide proiectul `smart-timer` 칥n VS Code, dac캒 nu este deja deschis.

1. Deschide fi탳ierul header `config.h` 탳i adaug캒 URL-ul pentru aplica탵ia ta de func탵ii:

    ```cpp
    const char *TEXT_TO_SPEECH_FUNCTION_URL = "<URL>";
    ```

    칉nlocuie탳te `<URL>` cu URL-ul pentru trigger-ul HTTP `text-to-speech` din aplica탵ia ta de func탵ii. Acesta va fi acela탳i cu valoarea pentru `TEXT_TO_TIMER_FUNCTION_URL`, cu excep탵ia faptului c캒 numele func탵iei va fi `text-to-speech` 칥n loc de `text-to-timer`.

1. Deschide fi탳ierul header `text_to_speech.h` 탳i adaug캒 urm캒toarea metod캒 칥n sec탵iunea `public` a clasei `TextToSpeech`:

    ```cpp
    void convertTextToSpeech(String text)
    {
    }
    ```

1. 칉n metoda `convertTextToSpeech`, adaug캒 urm캒torul cod pentru a crea JSON-ul care va fi trimis c캒tre aplica탵ia de func탵ii:

    ```cpp
    DynamicJsonDocument doc(1024);
    doc["language"] = LANGUAGE;
    doc["voice"] = _voice;
    doc["text"] = text;

    String body;
    serializeJson(doc, body);
    ```

    Acesta scrie limba, vocea 탳i textul 칥n documentul JSON, apoi 칥l serializeaz캒 칥ntr-un 탳ir.

1. Mai jos, adaug캒 urm캒torul cod pentru a apela aplica탵ia de func탵ii:

    ```cpp
    HTTPClient httpClient;
    httpClient.begin(_client, TEXT_TO_SPEECH_FUNCTION_URL);

    int httpResponseCode = httpClient.POST(body);
    ```

    Acesta creeaz캒 un `HTTPClient`, apoi face o cerere POST folosind documentul JSON c캒tre trigger-ul HTTP text-to-speech.

1. Dac캒 apelul func탵ioneaz캒, datele binare brute returnate de apelul aplica탵iei de func탵ii pot fi transmise c캒tre un fi탳ier pe cardul SD. Adaug캒 urm캒torul cod pentru a face acest lucru:

    ```cpp
    if (httpResponseCode == 200)
    {            
        File wav_file = SD.open("SPEECH.WAV", FILE_WRITE);
        httpClient.writeToStream(&wav_file);
        wav_file.close();
    }
    else
    {
        Serial.print("Failed to get speech - error ");
        Serial.println(httpResponseCode);
    }
    ```

    Acest cod verific캒 r캒spunsul, iar dac캒 este 200 (succes), datele binare sunt transmise c캒tre un fi탳ier 칥n r캒d캒cina cardului SD numit `SPEECH.WAV`.

1. La sf칙r탳itul acestei metode, 칥nchide conexiunea HTTP:

    ```cpp
    httpClient.end();
    ```

1. Textul care trebuie rostit poate acum fi transformat 칥n audio. 칉n fi탳ierul `main.cpp`, adaug캒 urm캒toarea linie la sf칙r탳itul func탵iei `say` pentru a transforma textul de rostit 칥n audio:
```cpp
    textToSpeech.convertTextToSpeech(text);
    ```

### Sarcin캒 - red캒 audio pe Wio Terminal

**칉n cur칙nd**

## Implementarea aplica탵iei tale de func탵ii 칥n cloud

Motivul pentru rularea aplica탵iei de func탵ii local este c캒 pachetul Pip `librosa` pe Linux are o dependen탵캒 de o bibliotec캒 care nu este instalat캒 칥n mod implicit 탳i va trebui instalat캒 칥nainte ca aplica탵ia de func탵ii s캒 poat캒 rula. Aplica탵iile de func탵ii sunt serverless - nu exist캒 servere pe care s캒 le po탵i gestiona singur, a탳a c캒 nu exist캒 nicio modalitate de a instala aceast캒 bibliotec캒 칥n prealabil.

Modalitatea de a face acest lucru este, 칥n schimb, s캒 implementezi aplica탵ia ta de func탵ii folosind un container Docker. Acest container este implementat de cloud ori de c칙te ori este necesar s캒 se porneasc캒 o nou캒 instan탵캒 a aplica탵iei tale de func탵ii (cum ar fi atunci c칙nd cererea dep캒탳e탳te resursele disponibile sau dac캒 aplica탵ia de func탵ii nu a fost utilizat캒 de ceva timp 탳i este 칥nchis캒).

Po탵i g캒si instruc탵iunile pentru configurarea unei aplica탵ii de func탵ii 탳i implementarea prin Docker 칥n [documenta탵ia pentru crearea unei func탵ii pe Linux folosind un container personalizat pe Microsoft Docs](https://docs.microsoft.com/azure/azure-functions/functions-create-function-linux-custom-image?WT.mc_id=academic-17441-jabenn&tabs=bash%2Cazurecli&pivots=programming-language-python).

Odat캒 ce aceasta a fost implementat캒, po탵i adapta codul pentru Wio Terminal pentru a accesa aceast캒 func탵ie:

1. Adaug캒 certificatul Azure Functions 칥n `config.h`:

    ```cpp
    const char *FUNCTIONS_CERTIFICATE =
        "-----BEGIN CERTIFICATE-----\r\n"
        "MIIFWjCCBEKgAwIBAgIQDxSWXyAgaZlP1ceseIlB4jANBgkqhkiG9w0BAQsFADBa\r\n"
        "MQswCQYDVQQGEwJJRTESMBAGA1UEChMJQmFsdGltb3JlMRMwEQYDVQQLEwpDeWJl\r\n"
        "clRydXN0MSIwIAYDVQQDExlCYWx0aW1vcmUgQ3liZXJUcnVzdCBSb290MB4XDTIw\r\n"
        "MDcyMTIzMDAwMFoXDTI0MTAwODA3MDAwMFowTzELMAkGA1UEBhMCVVMxHjAcBgNV\r\n"
        "BAoTFU1pY3Jvc29mdCBDb3Jwb3JhdGlvbjEgMB4GA1UEAxMXTWljcm9zb2Z0IFJT\r\n"
        "QSBUTFMgQ0EgMDEwggIiMA0GCSqGSIb3DQEBAQUAA4ICDwAwggIKAoICAQCqYnfP\r\n"
        "mmOyBoTzkDb0mfMUUavqlQo7Rgb9EUEf/lsGWMk4bgj8T0RIzTqk970eouKVuL5R\r\n"
        "IMW/snBjXXgMQ8ApzWRJCZbar879BV8rKpHoAW4uGJssnNABf2n17j9TiFy6BWy+\r\n"
        "IhVnFILyLNK+W2M3zK9gheiWa2uACKhuvgCca5Vw/OQYErEdG7LBEzFnMzTmJcli\r\n"
        "W1iCdXby/vI/OxbfqkKD4zJtm45DJvC9Dh+hpzqvLMiK5uo/+aXSJY+SqhoIEpz+\r\n"
        "rErHw+uAlKuHFtEjSeeku8eR3+Z5ND9BSqc6JtLqb0bjOHPm5dSRrgt4nnil75bj\r\n"
        "c9j3lWXpBb9PXP9Sp/nPCK+nTQmZwHGjUnqlO9ebAVQD47ZisFonnDAmjrZNVqEX\r\n"
        "F3p7laEHrFMxttYuD81BdOzxAbL9Rb/8MeFGQjE2Qx65qgVfhH+RsYuuD9dUw/3w\r\n"
        "ZAhq05yO6nk07AM9c+AbNtRoEcdZcLCHfMDcbkXKNs5DJncCqXAN6LhXVERCw/us\r\n"
        "G2MmCMLSIx9/kwt8bwhUmitOXc6fpT7SmFvRAtvxg84wUkg4Y/Gx++0j0z6StSeN\r\n"
        "0EJz150jaHG6WV4HUqaWTb98Tm90IgXAU4AW2GBOlzFPiU5IY9jt+eXC2Q6yC/Zp\r\n"
        "TL1LAcnL3Qa/OgLrHN0wiw1KFGD51WRPQ0Sh7QIDAQABo4IBJTCCASEwHQYDVR0O\r\n"
        "BBYEFLV2DDARzseSQk1Mx1wsyKkM6AtkMB8GA1UdIwQYMBaAFOWdWTCCR1jMrPoI\r\n"
        "VDaGezq1BE3wMA4GA1UdDwEB/wQEAwIBhjAdBgNVHSUEFjAUBggrBgEFBQcDAQYI\r\n"
        "KwYBBQUHAwIwEgYDVR0TAQH/BAgwBgEB/wIBADA0BggrBgEFBQcBAQQoMCYwJAYI\r\n"
        "KwYBBQUHMAGGGGh0dHA6Ly9vY3NwLmRpZ2ljZXJ0LmNvbTA6BgNVHR8EMzAxMC+g\r\n"
        "LaArhilodHRwOi8vY3JsMy5kaWdpY2VydC5jb20vT21uaXJvb3QyMDI1LmNybDAq\r\n"
        "BgNVHSAEIzAhMAgGBmeBDAECATAIBgZngQwBAgIwCwYJKwYBBAGCNyoBMA0GCSqG\r\n"
        "SIb3DQEBCwUAA4IBAQCfK76SZ1vae4qt6P+dTQUO7bYNFUHR5hXcA2D59CJWnEj5\r\n"
        "na7aKzyowKvQupW4yMH9fGNxtsh6iJswRqOOfZYC4/giBO/gNsBvwr8uDW7t1nYo\r\n"
        "DYGHPpvnpxCM2mYfQFHq576/TmeYu1RZY29C4w8xYBlkAA8mDJfRhMCmehk7cN5F\r\n"
        "JtyWRj2cZj/hOoI45TYDBChXpOlLZKIYiG1giY16vhCRi6zmPzEwv+tk156N6cGS\r\n"
        "Vm44jTQ/rs1sa0JSYjzUaYngoFdZC4OfxnIkQvUIA4TOFmPzNPEFdjcZsgbeEz4T\r\n"
        "cGHTBPK4R28F44qIMCtHRV55VMX53ev6P3hRddJb\r\n"
        "-----END CERTIFICATE-----\r\n";
    ```

1. Schimb캒 toate includerile de `
<WiFiClient.h>` 칥n `<WiFiClientSecure.h>`.

1. Schimb캒 toate c칙mpurile `WiFiClient` 칥n `WiFiClientSecure`.

1. 칉n fiecare clas캒 care are un c칙mp `WiFiClientSecure`, adaug캒 un constructor 탳i seteaz캒 certificatul 칥n acel constructor:

    ```cpp
    _client.setCACert(FUNCTIONS_CERTIFICATE);
    ```

---

**Declinare de responsabilitate**:  
Acest document a fost tradus folosind serviciul de traducere AI [Co-op Translator](https://github.com/Azure/co-op-translator). De탳i ne str캒duim s캒 asigur캒m acurate탵ea, v캒 rug캒m s캒 re탵ine탵i c캒 traducerile automate pot con탵ine erori sau inexactit캒탵i. Documentul original 칥n limba sa natal캒 ar trebui considerat sursa autoritar캒. Pentru informa탵ii critice, se recomand캒 traducerea profesional캒 realizat캒 de un specialist. Nu ne asum캒m responsabilitatea pentru eventualele ne칥n탵elegeri sau interpret캒ri gre탳ite care pot ap캒rea din utilizarea acestei traduceri.