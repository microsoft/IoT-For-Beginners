<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "50151d9f9dce2801348a93880ef16d86",
  "translation_date": "2025-08-24T21:47:47+00:00",
  "source_file": "4-manufacturing/lessons/3-run-fruit-detector-edge/single-board-computer.md",
  "language_code": "fr"
}
-->
# Classifier une image √† l'aide d'un classificateur d'images bas√© sur IoT Edge - Mat√©riel IoT virtuel et Raspberry Pi

Dans cette partie de la le√ßon, vous allez utiliser le classificateur d'images fonctionnant sur l'appareil IoT Edge.

## Utiliser le classificateur IoT Edge

L'appareil IoT peut √™tre redirig√© pour utiliser le classificateur d'images IoT Edge. L'URL du classificateur d'images est `http://<adresse IP ou nom>/image`, en rempla√ßant `<adresse IP ou nom>` par l'adresse IP ou le nom d'h√¥te de l'ordinateur ex√©cutant IoT Edge.

La biblioth√®que Python pour Custom Vision fonctionne uniquement avec des mod√®les h√©berg√©s dans le cloud, et non avec des mod√®les h√©berg√©s sur IoT Edge. Cela signifie que vous devrez utiliser l'API REST pour appeler le classificateur.

### T√¢che - utiliser le classificateur IoT Edge

1. Ouvrez le projet `fruit-quality-detector` dans VS Code s'il n'est pas d√©j√† ouvert. Si vous utilisez un appareil IoT virtuel, assurez-vous que l'environnement virtuel est activ√©.

1. Ouvrez le fichier `app.py`, et supprimez les instructions d'importation de `azure.cognitiveservices.vision.customvision.prediction` et `msrest.authentication`.

1. Ajoutez l'importation suivante en haut du fichier :

    ```python
    import requests
    ```

1. Supprimez tout le code apr√®s que l'image soit enregistr√©e dans un fichier, √† partir de `image_file.write(image.read())` jusqu'√† la fin du fichier.

1. Ajoutez le code suivant √† la fin du fichier :

    ```python
    prediction_url = '<URL>'
    headers = {
        'Content-Type' : 'application/octet-stream'
    }
    image.seek(0)
    response = requests.post(prediction_url, headers=headers, data=image)
    results = response.json()
    
    for prediction in results['predictions']:
        print(f'{prediction["tagName"]}:\t{prediction["probability"] * 100:.2f}%')
    ```

    Remplacez `<URL>` par l'URL de votre classificateur.

    Ce code effectue une requ√™te POST REST au classificateur, en envoyant l'image comme corps de la requ√™te. Les r√©sultats reviennent sous forme de JSON, qui est d√©cod√© pour afficher les probabilit√©s.

1. Ex√©cutez votre code, en pointant votre cam√©ra vers des fruits, ou un ensemble d'images appropri√©, ou des fruits visibles sur votre webcam si vous utilisez un mat√©riel IoT virtuel. Vous verrez la sortie dans la console :

    ```output
    (.venv) ‚ûú  fruit-quality-detector python app.py
    ripe:   56.84%
    unripe: 43.16%
    ```

> üíÅ Vous pouvez trouver ce code dans le dossier [code-classify/pi](../../../../../4-manufacturing/lessons/3-run-fruit-detector-edge/code-classify/pi) ou [code-classify/virtual-iot-device](../../../../../4-manufacturing/lessons/3-run-fruit-detector-edge/code-classify/virtual-iot-device).

üòÄ Votre programme de classification de la qualit√© des fruits a √©t√© un succ√®s !

**Avertissement** :  
Ce document a √©t√© traduit √† l'aide du service de traduction automatique [Co-op Translator](https://github.com/Azure/co-op-translator). Bien que nous nous efforcions d'assurer l'exactitude, veuillez noter que les traductions automatis√©es peuvent contenir des erreurs ou des inexactitudes. Le document original dans sa langue d'origine doit √™tre consid√©r√© comme la source faisant autorit√©. Pour des informations critiques, il est recommand√© de recourir √† une traduction humaine professionnelle. Nous d√©clinons toute responsabilit√© en cas de malentendus ou d'interpr√©tations erron√©es r√©sultant de l'utilisation de cette traduction.