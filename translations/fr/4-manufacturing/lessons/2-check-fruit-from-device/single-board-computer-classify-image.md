<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "e5896207b304ce1abaf065b8acc0cc79",
  "translation_date": "2025-08-24T21:31:19+00:00",
  "source_file": "4-manufacturing/lessons/2-check-fruit-from-device/single-board-computer-classify-image.md",
  "language_code": "fr"
}
-->
# Classifier une image - Mat√©riel IoT virtuel et Raspberry Pi

Dans cette partie de la le√ßon, vous allez envoyer l'image captur√©e par la cam√©ra au service Custom Vision pour la classifier.

## Envoyer des images √† Custom Vision

Le service Custom Vision dispose d'un SDK Python que vous pouvez utiliser pour classifier des images.

### T√¢che - envoyer des images √† Custom Vision

1. Ouvrez le dossier `fruit-quality-detector` dans VS Code. Si vous utilisez un appareil IoT virtuel, assurez-vous que l'environnement virtuel est actif dans le terminal.

1. Le SDK Python pour envoyer des images √† Custom Vision est disponible sous forme de package Pip. Installez-le avec la commande suivante :

    ```sh
    pip3 install azure-cognitiveservices-vision-customvision
    ```

1. Ajoutez les instructions d'importation suivantes en haut du fichier `app.py` :

    ```python
    from msrest.authentication import ApiKeyCredentials
    from azure.cognitiveservices.vision.customvision.prediction import CustomVisionPredictionClient
    ```

    Cela importe certains modules des biblioth√®ques Custom Vision, l'un pour s'authentifier avec la cl√© de pr√©diction, et l'autre pour fournir une classe client de pr√©diction qui peut appeler Custom Vision.

1. Ajoutez le code suivant √† la fin du fichier :

    ```python
    prediction_url = '<prediction_url>'
    prediction_key = '<prediction key>'
    ```

    Remplacez `<prediction_url>` par l'URL que vous avez copi√©e depuis la bo√Æte de dialogue *Prediction URL* plus t√¥t dans cette le√ßon. Remplacez `<prediction key>` par la cl√© de pr√©diction que vous avez copi√©e depuis la m√™me bo√Æte de dialogue.

1. L'URL de pr√©diction fournie par la bo√Æte de dialogue *Prediction URL* est con√ßue pour √™tre utilis√©e lors de l'appel direct au point de terminaison REST. Le SDK Python utilise diff√©rentes parties de l'URL √† diff√©rents endroits. Ajoutez le code suivant pour diviser cette URL en parties n√©cessaires :

    ```python
    parts = prediction_url.split('/')
    endpoint = 'https://' + parts[2]
    project_id = parts[6]
    iteration_name = parts[9]
    ```

    Cela divise l'URL, en extrayant le point de terminaison `https://<location>.api.cognitive.microsoft.com`, l'ID du projet, et le nom de l'it√©ration publi√©e.

1. Cr√©ez un objet pr√©dicteur pour effectuer la pr√©diction avec le code suivant :

    ```python
    prediction_credentials = ApiKeyCredentials(in_headers={"Prediction-key": prediction_key})
    predictor = CustomVisionPredictionClient(endpoint, prediction_credentials)
    ```

    Les `prediction_credentials` encapsulent la cl√© de pr√©diction. Ces informations sont ensuite utilis√©es pour cr√©er un objet client de pr√©diction pointant vers le point de terminaison.

1. Envoyez l'image √† Custom Vision en utilisant le code suivant :

    ```python
    image.seek(0)
    results = predictor.classify_image(project_id, iteration_name, image)
    ```

    Cela remet l'image au d√©but, puis l'envoie au client de pr√©diction.

1. Enfin, affichez les r√©sultats avec le code suivant :

    ```python
    for prediction in results.predictions:
        print(f'{prediction.tag_name}:\t{prediction.probability * 100:.2f}%')
    ```

    Cela parcourra toutes les pr√©dictions retourn√©es et les affichera dans le terminal. Les probabilit√©s retourn√©es sont des nombres √† virgule flottante entre 0 et 1, o√π 0 correspond √† 0 % de chance de correspondance avec le tag, et 1 correspond √† 100 % de chance.

    > üíÅ Les classificateurs d'images retourneront les pourcentages pour tous les tags utilis√©s. Chaque tag aura une probabilit√© indiquant que l'image correspond √† ce tag.

1. Ex√©cutez votre code, avec votre cam√©ra point√©e sur un fruit, ou un ensemble d'images appropri√©, ou un fruit visible sur votre webcam si vous utilisez un mat√©riel IoT virtuel. Vous verrez la sortie dans la console :

    ```output
    (.venv) ‚ûú  fruit-quality-detector python app.py
    ripe:   56.84%
    unripe: 43.16%
    ```

    Vous pourrez voir l'image qui a √©t√© prise, ainsi que ces valeurs dans l'onglet **Predictions** de Custom Vision.

    ![Une banane dans Custom Vision pr√©dite comme m√ªre √† 56,8 % et non m√ªre √† 43,1 %](../../../../../translated_images/custom-vision-banana-prediction.30cdff4e1d72db5d9a0be0193790a47c2b387da034e12dc1314dd57ca2131b59.fr.png)

> üíÅ Vous pouvez trouver ce code dans le dossier [code-classify/pi](../../../../../4-manufacturing/lessons/2-check-fruit-from-device/code-classify/pi) ou [code-classify/virtual-iot-device](../../../../../4-manufacturing/lessons/2-check-fruit-from-device/code-classify/virtual-iot-device).

üòÄ Votre programme de classification de la qualit√© des fruits est un succ√®s !

**Avertissement** :  
Ce document a √©t√© traduit √† l'aide du service de traduction automatique [Co-op Translator](https://github.com/Azure/co-op-translator). Bien que nous nous efforcions d'assurer l'exactitude, veuillez noter que les traductions automatis√©es peuvent contenir des erreurs ou des inexactitudes. Le document original dans sa langue d'origine doit √™tre consid√©r√© comme la source faisant autorit√©. Pour des informations critiques, il est recommand√© de recourir √† une traduction humaine professionnelle. Nous d√©clinons toute responsabilit√© en cas de malentendus ou d'interpr√©tations erron√©es r√©sultant de l'utilisation de cette traduction.