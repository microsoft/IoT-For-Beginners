<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "6d6aa1be033625d201a190fc9c5cbfb4",
  "translation_date": "2025-08-25T00:19:55+00:00",
  "source_file": "6-consumer/lessons/1-speech-recognition/README.md",
  "language_code": "fr"
}
-->
# Reconna√Ætre la parole avec un appareil IoT

![Un aper√ßu illustr√© de cette le√ßon](../../../../../translated_images/lesson-21.e34de51354d6606fb5ee08d8c89d0222eea0a2a7aaf744a8805ae847c4f69dc4.fr.jpg)

> Illustration par [Nitya Narasimhan](https://github.com/nitya). Cliquez sur l'image pour une version plus grande.

Cette vid√©o donne un aper√ßu du service vocal Azure, un sujet qui sera abord√© dans cette le√ßon :

[![Comment commencer √† utiliser votre ressource Cognitive Services Speech depuis la cha√Æne YouTube Microsoft Azure](https://img.youtube.com/vi/iW0Fw0l3mrA/0.jpg)](https://www.youtube.com/watch?v=iW0Fw0l3mrA)

> üé• Cliquez sur l'image ci-dessus pour regarder une vid√©o

## Quiz avant la le√ßon

[Quiz avant la le√ßon](https://black-meadow-040d15503.1.azurestaticapps.net/quiz/41)

## Introduction

'Alexa, r√®gle un minuteur de 12 minutes'

'Alexa, statut du minuteur'

'Alexa, r√®gle un minuteur de 8 minutes appel√© cuire √† la vapeur des brocolis'

Les appareils intelligents deviennent de plus en plus omnipr√©sents. Non seulement sous forme d'enceintes connect√©es comme les HomePods, Echos et Google Homes, mais aussi int√©gr√©s dans nos t√©l√©phones, montres, et m√™me dans les luminaires et thermostats.

> üíÅ J'ai au moins 19 appareils dans ma maison qui poss√®dent des assistants vocaux, et ce ne sont que ceux dont je suis conscient !

Le contr√¥le vocal am√©liore l'accessibilit√© en permettant aux personnes ayant une mobilit√© r√©duite d'interagir avec des appareils. Que ce soit pour un handicap permanent, comme √™tre n√© sans bras, un handicap temporaire, comme un bras cass√©, ou simplement avoir les mains occup√©es par des courses ou des enfants, pouvoir contr√¥ler nos maisons avec notre voix plut√¥t qu'avec nos mains ouvre un monde d'acc√®s. Crier 'Hey Siri, ferme ma porte de garage' tout en g√©rant un b√©b√© √† langer et un enfant turbulent peut √™tre une petite mais pr√©cieuse am√©lioration de la vie quotidienne.

L'une des utilisations les plus populaires des assistants vocaux est la gestion des minuteurs, en particulier dans la cuisine. Pouvoir r√©gler plusieurs minuteurs uniquement avec sa voix est d'une grande aide - pas besoin d'arr√™ter de p√©trir une p√¢te, de remuer une soupe ou de nettoyer ses mains pleines de farce pour utiliser un minuteur physique.

Dans cette le√ßon, vous apprendrez √† int√©grer la reconnaissance vocale dans des appareils IoT. Vous d√©couvrirez les microphones en tant que capteurs, comment capturer de l'audio √† partir d'un microphone connect√© √† un appareil IoT, et comment utiliser l'IA pour convertir ce qui est entendu en texte. Tout au long de ce projet, vous construirez un minuteur de cuisine intelligent, capable de r√©gler des minuteurs en utilisant votre voix dans plusieurs langues.

Dans cette le√ßon, nous aborderons :

* [Les microphones](../../../../../6-consumer/lessons/1-speech-recognition)
* [Capturer de l'audio depuis votre appareil IoT](../../../../../6-consumer/lessons/1-speech-recognition)
* [De la parole au texte](../../../../../6-consumer/lessons/1-speech-recognition)
* [Convertir la parole en texte](../../../../../6-consumer/lessons/1-speech-recognition)

## Les microphones

Les microphones sont des capteurs analogiques qui convertissent les ondes sonores en signaux √©lectriques. Les vibrations dans l'air font bouger de minuscules composants dans le microphone, ce qui entra√Æne de l√©gers changements dans les signaux √©lectriques. Ces changements sont ensuite amplifi√©s pour g√©n√©rer une sortie √©lectrique.

### Types de microphones

Les microphones existent en plusieurs types :

* Dynamique - Les microphones dynamiques poss√®dent un aimant attach√© √† une membrane mobile qui se d√©place dans une bobine de fil, cr√©ant un courant √©lectrique. C'est l'inverse de la plupart des haut-parleurs, qui utilisent un courant √©lectrique pour d√©placer un aimant dans une bobine de fil, faisant vibrer une membrane pour produire du son. Cela signifie que les haut-parleurs peuvent √™tre utilis√©s comme microphones dynamiques, et vice versa. Dans des dispositifs comme les interphones, o√π l'utilisateur √©coute ou parle, mais pas les deux en m√™me temps, un seul appareil peut agir √† la fois comme haut-parleur et microphone.

    Les microphones dynamiques n'ont pas besoin d'alimentation pour fonctionner, le signal √©lectrique est enti√®rement g√©n√©r√© par le microphone.

    ![Patti Smith chantant dans un microphone Shure SM58 (type cardio√Øde dynamique)](../../../../../translated_images/dynamic-mic.8babac890a2d80dfb0874b5bf37d4b851fe2aeb9da6fd72945746176978bf3bb.fr.jpg)

* Ruban - Les microphones √† ruban sont similaires aux microphones dynamiques, sauf qu'ils utilisent un ruban m√©tallique au lieu d'une membrane. Ce ruban se d√©place dans un champ magn√©tique, g√©n√©rant un courant √©lectrique. Comme les microphones dynamiques, les microphones √† ruban n'ont pas besoin d'alimentation pour fonctionner.

    ![Edmund Lowe, acteur am√©ricain, debout devant un microphone radio (r√©seau NBC Blue), tenant un script, 1942](../../../../../translated_images/ribbon-mic.eacc8e092c7441caee6d7a81e2f40e1675bf36269848964c7c09c9a9acb05127.fr.jpg)

* Condensateur - Les microphones √† condensateur poss√®dent une fine membrane m√©tallique et une plaque arri√®re m√©tallique fixe. Un courant √©lectrique est appliqu√© aux deux, et lorsque la membrane vibre, la charge statique entre les plaques change, g√©n√©rant un signal. Les microphones √† condensateur n√©cessitent une alimentation pour fonctionner - appel√©e *alimentation fant√¥me*.

    ![Microphone √† condensateur √† petite membrane C451B par AKG Acoustics](../../../../../translated_images/condenser-mic.6f6ed5b76ca19e0ec3fd0c544601542d4479a6cb7565db336de49fbbf69f623e.fr.jpg)

* MEMS - Les microphones √† syst√®mes micro√©lectrom√©caniques, ou MEMS, sont des microphones sur puce. Ils poss√®dent une membrane sensible √† la pression grav√©e sur une puce de silicium, et fonctionnent de mani√®re similaire √† un microphone √† condensateur. Ces microphones peuvent √™tre minuscules et int√©gr√©s dans des circuits.

    ![Un microphone MEMS sur une carte de circuit imprim√©](../../../../../translated_images/mems-microphone.80574019e1f5e4d9ee72fed720ecd25a39fc2969c91355d17ebb24ba4159e4c4.fr.png)

    Dans l'image ci-dessus, la puce √©tiquet√©e **LEFT** est un microphone MEMS, avec une membrane minuscule de moins d'un millim√®tre de large.

‚úÖ Faites des recherches : Quels microphones avez-vous autour de vous - dans votre ordinateur, votre t√©l√©phone, votre casque ou d'autres appareils ? De quel type sont-ils ?

### Audio num√©rique

L'audio est un signal analogique contenant des informations tr√®s d√©taill√©es. Pour convertir ce signal en num√©rique, il doit √™tre √©chantillonn√© des milliers de fois par seconde.

> üéì L'√©chantillonnage consiste √† convertir le signal audio en une valeur num√©rique repr√©sentant le signal √† un moment donn√©.

![Un graphique montrant un signal, avec des points discrets √† intervalles fixes](../../../../../translated_images/sampling.6f4fadb3f2d9dfe7618f9edfe75a350e6b3f74293ec84f02ab69c19d2afe3d73.fr.png)

L'audio num√©rique est √©chantillonn√© en utilisant la modulation par impulsions cod√©es, ou PCM. La PCM consiste √† lire la tension du signal et √† s√©lectionner la valeur discr√®te la plus proche correspondant √† cette tension selon une taille d√©finie.

> üíÅ Vous pouvez consid√©rer la PCM comme la version capteur de la modulation par largeur d'impulsion, ou PWM (la PWM a √©t√© abord√©e dans [la le√ßon 3 du projet de d√©marrage](../../../1-getting-started/lessons/3-sensors-and-actuators/README.md#pulse-width-modulation)). La PCM convertit un signal analogique en num√©rique, tandis que la PWM convertit un signal num√©rique en analogique.

Par exemple, la plupart des services de musique en streaming proposent de l'audio en 16 bits ou 24 bits. Cela signifie qu'ils convertissent la tension en une valeur qui tient dans un entier de 16 bits ou de 24 bits. L'audio en 16 bits correspond √† une plage de valeurs allant de -32 768 √† 32 767, tandis que le 24 bits va de ‚àí8 388 608 √† 8 388 607. Plus il y a de bits, plus l'√©chantillon est proche de ce que nos oreilles per√ßoivent r√©ellement.

> üíÅ Vous avez peut-√™tre entendu parler de l'audio en 8 bits, souvent appel√© LoFi. Il s'agit d'un audio √©chantillonn√© en utilisant seulement 8 bits, soit une plage de -128 √† 127. Les premiers ordinateurs √©taient limit√©s √† l'audio en 8 bits en raison des contraintes mat√©rielles, ce qui est souvent associ√© aux jeux r√©tro.

Ces √©chantillons sont pris des milliers de fois par seconde, avec des taux d'√©chantillonnage bien d√©finis mesur√©s en KHz (milliers de lectures par seconde). Les services de musique en streaming utilisent 48 KHz pour la plupart des audios, mais certains audios 'sans perte' vont jusqu'√† 96 KHz ou m√™me 192 KHz. Plus le taux d'√©chantillonnage est √©lev√©, plus l'audio est proche de l'original, jusqu'√† un certain point. Il existe un d√©bat sur la capacit√© des humains √† percevoir une diff√©rence au-del√† de 48 KHz.

‚úÖ Faites des recherches : Si vous utilisez un service de musique en streaming, quel est son taux d'√©chantillonnage et sa taille ? Si vous utilisez des CD, quel est le taux d'√©chantillonnage et la taille de l'audio sur CD ?

Il existe plusieurs formats pour les donn√©es audio. Vous avez probablement entendu parler des fichiers mp3 - des donn√©es audio compress√©es pour les rendre plus petites sans perte de qualit√©. L'audio non compress√© est souvent stock√© sous forme de fichier WAV - un fichier contenant 44 octets d'informations d'en-t√™te, suivis des donn√©es audio brutes. L'en-t√™te contient des informations telles que le taux d'√©chantillonnage (par exemple 16 000 pour 16 KHz), la taille de l'√©chantillon (16 pour 16 bits) et le nombre de canaux. Apr√®s l'en-t√™te, le fichier WAV contient les donn√©es audio brutes.

> üéì Les canaux font r√©f√©rence au nombre de flux audio diff√©rents qui composent l'audio. Par exemple, pour un son st√©r√©o avec gauche et droite, il y aurait 2 canaux. Pour un son surround 7.1 dans un syst√®me home cin√©ma, il y aurait 8 canaux.

### Taille des donn√©es audio

Les donn√©es audio sont relativement volumineuses. Par exemple, capturer de l'audio non compress√© en 16 bits √† 16 KHz (un taux suffisant pour un mod√®le de reconnaissance vocale) n√©cessite 32 Ko de donn√©es par seconde d'audio :

* 16 bits signifie 2 octets par √©chantillon (1 octet = 8 bits).
* 16 KHz correspond √† 16 000 √©chantillons par seconde.
* 16 000 x 2 octets = 32 000 octets par seconde.

Cela peut sembler peu, mais si vous utilisez un microcontr√¥leur avec une m√©moire limit√©e, cela peut √™tre beaucoup. Par exemple, le Wio Terminal dispose de 192 Ko de m√©moire, qui doivent √©galement stocker le code du programme et les variables. M√™me si votre code √©tait minuscule, vous ne pourriez pas capturer plus de 5 secondes d'audio.

Les microcontr√¥leurs peuvent acc√©der √† un stockage suppl√©mentaire, comme des cartes SD ou de la m√©moire flash. Lors de la cr√©ation d'un appareil IoT capturant de l'audio, vous devrez vous assurer non seulement de disposer d'un stockage suppl√©mentaire, mais aussi que votre code √©crit l'audio captur√© directement dans ce stockage. Lorsque vous envoyez les donn√©es dans le cloud, vous devrez les diffuser depuis le stockage vers la requ√™te web. Cela permet d'√©viter de manquer de m√©moire en essayant de conserver tout le bloc de donn√©es audio en m√©moire en m√™me temps.

## Capturer de l'audio depuis votre appareil IoT

Votre appareil IoT peut √™tre connect√© √† un microphone pour capturer de l'audio, pr√™t √† √™tre converti en texte. Il peut √©galement √™tre connect√© √† des haut-parleurs pour diffuser de l'audio. Dans les le√ßons suivantes, cela sera utilis√© pour fournir des retours audio, mais il est utile de configurer les haut-parleurs d√®s maintenant pour tester le microphone.

### T√¢che - configurer votre microphone et vos haut-parleurs

Suivez le guide correspondant pour configurer le microphone et les haut-parleurs de votre appareil IoT :

* [Arduino - Wio Terminal](wio-terminal-microphone.md)
* [Ordinateur monocarte - Raspberry Pi](pi-microphone.md)
* [Ordinateur monocarte - Appareil virtuel](virtual-device-microphone.md)

### T√¢che - capturer de l'audio

Suivez le guide correspondant pour capturer de l'audio sur votre appareil IoT :

* [Arduino - Wio Terminal](wio-terminal-audio.md)
* [Ordinateur monocarte - Raspberry Pi](pi-audio.md)
* [Ordinateur monocarte - Appareil virtuel](virtual-device-audio.md)

## De la parole au texte

La conversion de la parole en texte, ou reconnaissance vocale, consiste √† utiliser l'IA pour transformer les mots d'un signal audio en texte.

### Mod√®les de reconnaissance vocale

Pour convertir la parole en texte, les √©chantillons du signal audio sont regroup√©s et transmis √† un mod√®le d'apprentissage automatique bas√© sur un r√©seau neuronal r√©current (RNN). Ce type de mod√®le peut utiliser des donn√©es pr√©c√©dentes pour prendre une d√©cision sur les donn√©es entrantes. Par exemple, le RNN pourrait d√©tecter un bloc d'√©chantillons audio comme le son 'Hel', et lorsqu'il re√ßoit un autre bloc qu'il identifie comme 'lo', il peut combiner ces sons, reconna√Ætre que 'Hello' est un mot valide et le s√©lectionner comme r√©sultat.

Les mod√®les d'apprentissage automatique acceptent toujours des donn√©es de taille fixe. Le classificateur d'images que vous avez construit dans une le√ßon pr√©c√©dente redimensionne les images √† une taille fixe avant de les traiter. Il en va de m√™me pour les mod√®les de reconnaissance vocale, qui doivent traiter des blocs audio de taille fixe. Ces mod√®les doivent √™tre capables de combiner les r√©sultats de plusieurs pr√©dictions pour obtenir une r√©ponse, afin de distinguer entre 'Hi' et 'Highway', ou 'flock' et 'floccinaucinihilipilification'.

Les mod√®les de reconnaissance vocale sont √©galement suffisamment avanc√©s pour comprendre le contexte et corriger les mots d√©tect√©s au fur et √† mesure que d'autres sons sont trait√©s. Par exemple, si vous dites "Je suis all√© au magasin pour acheter deux bananes et une pomme aussi", vous utilisez trois mots qui sonnent de la m√™me mani√®re mais s'√©crivent diff√©remment - to, two et too. Les mod√®les de reconnaissance vocale peuvent comprendre le contexte et utiliser l'orthographe appropri√©e du mot.
üíÅ Certains services de reconnaissance vocale permettent des personnalisations pour mieux fonctionner dans des environnements bruyants comme les usines, ou avec des termes sp√©cifiques √† une industrie, tels que des noms chimiques. Ces personnalisations sont entra√Æn√©es en fournissant des exemples audio et une transcription, et fonctionnent gr√¢ce √† l'apprentissage par transfert, de la m√™me mani√®re que vous avez entra√Æn√© un classificateur d'images avec seulement quelques images dans une le√ßon pr√©c√©dente.
### Confidentialit√©

Lors de l'utilisation de la reconnaissance vocale sur un appareil IoT destin√© aux consommateurs, la confidentialit√© est extr√™mement importante. Ces appareils √©coutent en continu, et en tant que consommateur, vous ne souhaitez pas que tout ce que vous dites soit envoy√© dans le cloud et converti en texte. Non seulement cela consommerait beaucoup de bande passante Internet, mais cela aurait √©galement d'√©normes implications en mati√®re de confidentialit√©, surtout lorsque certains fabricants d'appareils intelligents s√©lectionnent al√©atoirement des enregistrements audio pour [les faire valider par des humains par rapport au texte g√©n√©r√© afin d'am√©liorer leur mod√®le](https://www.theverge.com/2019/4/10/18305378/amazon-alexa-ai-voice-assistant-annotation-listen-private-recordings).

Vous souhaitez que votre appareil intelligent n'envoie de l'audio au cloud pour traitement que lorsque vous l'utilisez, et non lorsqu'il capte des sons dans votre maison, des sons qui pourraient inclure des r√©unions priv√©es ou des interactions intimes. La plupart des appareils intelligents fonctionnent avec un *mot d√©clencheur*, une phrase cl√© comme "Alexa", "Hey Siri" ou "OK Google", qui fait que l'appareil "s'active" et √©coute ce que vous dites jusqu'√† ce qu'il d√©tecte une pause dans votre discours, indiquant que vous avez termin√© de parler √† l'appareil.

> üéì La d√©tection de mot d√©clencheur est √©galement appel√©e *d√©tection de mot cl√©* ou *reconnaissance de mot cl√©*.

Ces mots d√©clencheurs sont d√©tect√©s sur l'appareil, et non dans le cloud. Ces appareils intelligents poss√®dent de petits mod√®les d'IA qui fonctionnent sur l'appareil et √©coutent le mot d√©clencheur. Lorsqu'il est d√©tect√©, ils commencent √† transmettre l'audio au cloud pour reconnaissance. Ces mod√®les sont tr√®s sp√©cialis√©s et se concentrent uniquement sur le mot d√©clencheur.

> üíÅ Certaines entreprises technologiques ajoutent davantage de confidentialit√© √† leurs appareils en r√©alisant une partie de la conversion de la parole en texte directement sur l'appareil. Apple a annonc√© qu'√† partir de ses mises √† jour iOS et macOS de 2021, ils prendront en charge la conversion de la parole en texte sur l'appareil et pourront g√©rer de nombreuses requ√™tes sans avoir besoin d'utiliser le cloud. Cela est rendu possible gr√¢ce √† des processeurs puissants dans leurs appareils capables d'ex√©cuter des mod√®les de machine learning.

‚úÖ Selon vous, quelles sont les implications en mati√®re de confidentialit√© et d'√©thique li√©es au stockage des enregistrements audio envoy√©s au cloud ? Ces enregistrements devraient-ils √™tre conserv√©s, et si oui, comment ? Pensez-vous que l'utilisation des enregistrements √† des fins d'application de la loi est un compromis acceptable pour la perte de confidentialit√© ?

La d√©tection de mot d√©clencheur utilise g√©n√©ralement une technique appel√©e TinyML, qui consiste √† convertir des mod√®les de machine learning pour qu'ils puissent fonctionner sur des microcontr√¥leurs. Ces mod√®les sont de petite taille et consomment tr√®s peu d'√©nergie.

Pour √©viter la complexit√© de l'entra√Ænement et de l'utilisation d'un mod√®le de mot d√©clencheur, le minuteur intelligent que vous construisez dans cette le√ßon utilisera un bouton pour activer la reconnaissance vocale.

> üíÅ Si vous souhaitez essayer de cr√©er un mod√®le de d√©tection de mot d√©clencheur pour fonctionner sur le Wio Terminal ou le Raspberry Pi, consultez ce [tutoriel sur la r√©ponse √† votre voix par Edge Impulse](https://docs.edgeimpulse.com/docs/responding-to-your-voice). Si vous souhaitez utiliser votre ordinateur pour cela, vous pouvez essayer le [guide rapide pour d√©marrer avec les mots cl√©s personnalis√©s sur la documentation Microsoft](https://docs.microsoft.com/azure/cognitive-services/speech-service/keyword-recognition-overview?WT.mc_id=academic-17441-jabenn).

## Convertir la parole en texte

![Logo des services vocaux](../../../../../translated_images/azure-speech-logo.a1f08c4befb0159f2cb5d692d3baf5b599e7b44759d316da907bda1508f46a4a.fr.png)

Tout comme pour la classification d'images dans un projet pr√©c√©dent, il existe des services d'IA pr√©construits qui peuvent prendre un fichier audio et le convertir en texte. L'un de ces services est le Speech Service, qui fait partie des Cognitive Services, des services d'IA pr√©construits que vous pouvez utiliser dans vos applications.

### T√¢che - configurer une ressource d'IA vocale

1. Cr√©ez un groupe de ressources pour ce projet appel√© `smart-timer`.

1. Utilisez la commande suivante pour cr√©er une ressource vocale gratuite :

    ```sh
    az cognitiveservices account create --name smart-timer \
                                        --resource-group smart-timer \
                                        --kind SpeechServices \
                                        --sku F0 \
                                        --yes \
                                        --location <location>
    ```

    Remplacez `<location>` par l'emplacement que vous avez utilis√© lors de la cr√©ation du groupe de ressources.

1. Vous aurez besoin d'une cl√© API pour acc√©der √† la ressource vocale depuis votre code. Ex√©cutez la commande suivante pour obtenir la cl√© :

    ```sh
    az cognitiveservices account keys list --name smart-timer \
                                           --resource-group smart-timer \
                                           --output table
    ```

    Copiez l'une des cl√©s.

### T√¢che - convertir la parole en texte

Suivez le guide correspondant pour convertir la parole en texte sur votre appareil IoT :

* [Arduino - Wio Terminal](wio-terminal-speech-to-text.md)
* [Ordinateur monocarte - Raspberry Pi](pi-speech-to-text.md)
* [Ordinateur monocarte - Appareil virtuel](virtual-device-speech-to-text.md)

---

## üöÄ D√©fi

La reconnaissance vocale existe depuis longtemps et ne cesse de s'am√©liorer. Faites des recherches sur les capacit√©s actuelles et comparez comment elles ont √©volu√© au fil du temps, notamment en ce qui concerne la pr√©cision des transcriptions automatiques par rapport √† celles r√©alis√©es par des humains.

Selon vous, quel avenir attend la reconnaissance vocale ?

## Quiz post-lecture

[Quiz post-lecture](https://black-meadow-040d15503.1.azurestaticapps.net/quiz/42)

## R√©vision et √©tude personnelle

* Lisez sur les diff√©rents types de microphones et leur fonctionnement dans l'article [quelle est la diff√©rence entre les microphones dynamiques et √† condensateur sur Musician's HQ](https://musicianshq.com/whats-the-difference-between-dynamic-and-condenser-microphones/).
* Lisez davantage sur le service vocal des Cognitive Services dans la [documentation sur le service vocal sur Microsoft Docs](https://docs.microsoft.com/azure/cognitive-services/speech-service/?WT.mc_id=academic-17441-jabenn).
* Lisez sur la d√©tection de mots cl√©s dans la [documentation sur la reconnaissance de mots cl√©s sur Microsoft Docs](https://docs.microsoft.com/azure/cognitive-services/speech-service/keyword-recognition-overview?WT.mc_id=academic-17441-jabenn).

## Devoir

[](assignment.md)

**Avertissement** :  
Ce document a √©t√© traduit √† l'aide du service de traduction automatique [Co-op Translator](https://github.com/Azure/co-op-translator). Bien que nous nous efforcions d'assurer l'exactitude, veuillez noter que les traductions automatis√©es peuvent contenir des erreurs ou des inexactitudes. Le document original dans sa langue d'origine doit √™tre consid√©r√© comme la source faisant autorit√©. Pour des informations critiques, il est recommand√© de faire appel √† une traduction humaine professionnelle. Nous d√©clinons toute responsabilit√© en cas de malentendus ou d'interpr√©tations erron√©es r√©sultant de l'utilisation de cette traduction.