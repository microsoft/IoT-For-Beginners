<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "1c9e5fa8b7be726c75a97232b1e41c97",
  "translation_date": "2025-08-24T21:09:20+00:00",
  "source_file": "5-retail/lessons/2-check-stock-device/README.md",
  "language_code": "ja"
}
-->
# IoTデバイスで在庫を確認する

![このレッスンの概要を示すスケッチノート](../../../../../translated_images/lesson-20.0211df9551a8abb300fc8fcf7dc2789468dea2eabe9202273ac077b0ba37f15e.ja.jpg)

> スケッチノート作成者：[Nitya Narasimhan](https://github.com/nitya)。画像をクリックすると拡大表示されます。

## 講義前のクイズ

[講義前のクイズ](https://black-meadow-040d15503.1.azurestaticapps.net/quiz/39)

## はじめに

前回のレッスンでは、小売業における物体検出のさまざまな用途について学びました。また、在庫を識別するための物体検出器のトレーニング方法も学びました。このレッスンでは、IoTデバイスから物体検出器を使用して在庫を数える方法を学びます。

このレッスンで扱う内容は以下の通りです：

* [在庫のカウント](../../../../../5-retail/lessons/2-check-stock-device)
* [IoTデバイスから物体検出器を呼び出す](../../../../../5-retail/lessons/2-check-stock-device)
* [バウンディングボックス](../../../../../5-retail/lessons/2-check-stock-device)
* [モデルの再トレーニング](../../../../../5-retail/lessons/2-check-stock-device)
* [在庫を数える](../../../../../5-retail/lessons/2-check-stock-device)

> 🗑 このプロジェクトの最後のレッスンです。このレッスンと課題を完了した後は、クラウドサービスをクリーンアップするのを忘れないでください。課題を完了するためにはサービスが必要なので、まず課題を完了してください。
>
> 必要に応じて、[プロジェクトのクリーンアップガイド](../../../clean-up.md)を参照してください。

## 在庫のカウント

物体検出器は在庫確認に使用できます。これは在庫を数える場合や、在庫があるべき場所にあるかを確認する場合です。カメラ付きのIoTデバイスを店舗内のさまざまな場所に配置し、特に重要な商品が補充されるべきホットスポットから監視を開始できます。

例えば、カメラが8缶のトマトペーストを収納できる棚を指している場合、物体検出器が7缶しか検出しない場合は、1缶が欠けており補充が必要です。

![棚にある7缶のトマトペースト。上段に4缶、下段に3缶](../../../../../translated_images/stock-7-cans-tomato-paste.f86059cc573d7becaa89a0eafb9d2cd7e2fe37405a530fe565990e2333d0e4a1.ja.png)

上記の画像では、物体検出器が8缶収納可能な棚に7缶のトマトペーストを検出しています。IoTデバイスは補充が必要であることを通知するだけでなく、欠けている商品の位置を示すこともできます。これは棚を補充するロボットを使用している場合に重要なデータとなります。

> 💁 店舗や商品の人気度によっては、1缶だけ欠けている場合は補充が行われない可能性があります。商品、顧客、その他の基準に基づいて補充のタイミングを決定するアルゴリズムを構築する必要があります。

✅ 物体検出とロボットを組み合わせて使用できる他のシナリオは何でしょうか？

時には棚に間違った商品が置かれることがあります。これは補充時の人為的なミスや、顧客が購入を取りやめて最初に見つけた空きスペースに商品を戻す場合です。缶詰などの非生鮮食品の場合、これは単なる迷惑行為ですが、冷凍食品や冷蔵食品などの生鮮食品の場合、商品が冷凍庫からどれだけの時間外に出ていたかを判断するのが難しいため、販売できなくなる可能性があります。

物体検出を使用して予期しない商品を検出し、人間やロボットに商品を元の場所に戻すよう通知することができます。

![トマトペーストの棚に置かれた迷子のベビーコーン缶](../../../../../translated_images/stock-rogue-corn.be1f3ada8c4578544641af66671c1711a4c02297f14cc7f503354dae0d30a954.ja.png)

上記の画像では、ベビーコーンの缶がトマトペーストの棚に置かれています。物体検出器がこれを検出し、IoTデバイスが人間やロボットに缶を正しい場所に戻すよう通知することができます。

## IoTデバイスから物体検出器を呼び出す

前回のレッスンでトレーニングした物体検出器は、IoTデバイスから呼び出すことができます。

### タスク - 物体検出器のイテレーションを公開する

イテレーションはCustom Visionポータルから公開されます。

1. [CustomVision.ai](https://customvision.ai)でCustom Visionポータルを開き、まだ開いていない場合はサインインします。その後、`stock-detector`プロジェクトを開きます。

1. 上部のオプションから**パフォーマンス**タブを選択します。

1. サイドの*イテレーション*リストから最新のイテレーションを選択します。

1. イテレーションの**公開**ボタンを選択します。

    ![公開ボタン](../../../../../translated_images/custom-vision-object-detector-publish-button.34ee379fc650ccb9856c3868d0003f413b9529f102fc73c37168c98d721cc293.ja.png)

1. *モデルの公開*ダイアログで、*予測リソース*を前回のレッスンで作成した`stock-detector-prediction`リソースに設定します。名前は`Iteration2`のままにして、**公開**ボタンを選択します。

1. 公開後、**予測URL**ボタンを選択します。これにより予測APIの詳細が表示され、IoTデバイスからモデルを呼び出す際に必要になります。下部のセクションは*画像ファイルがある場合*とラベル付けされており、これが必要な詳細です。以下のようなURLをコピーしてください：

    ```output
    https://<location>.api.cognitive.microsoft.com/customvision/v3.0/Prediction/<id>/detect/iterations/Iteration2/image
    ```

    `<location>`はCustom Visionリソースを作成した場所であり、`<id>`は文字と数字で構成された長いIDです。

    また、*予測キー*の値もコピーしてください。これはモデルを呼び出す際に渡す必要があるセキュアキーです。このキーを渡したアプリケーションのみがモデルを使用でき、その他のアプリケーションは拒否されます。

    ![予測APIダイアログに表示されるURLとキー](../../../../../translated_images/custom-vision-prediction-key-endpoint.30c569ffd0338864f319911f052d5e9b8c5066cb0800a26dd6f7ff5713130ad8.ja.png)

✅ 新しいイテレーションが公開されると、異なる名前が付けられます。IoTデバイスが使用するイテレーションを変更する方法は何だと思いますか？

### タスク - IoTデバイスから物体検出器を呼び出す

以下の関連ガイドに従って、IoTデバイスから物体検出器を使用してください：

* [Arduino - Wio Terminal](wio-terminal-object-detector.md)
* [シングルボードコンピュータ - Raspberry Pi/仮想デバイス](single-board-computer-object-detector.md)

## バウンディングボックス

物体検出器を使用すると、タグと確率だけでなく、検出された物体のバウンディングボックスも取得できます。これにより、物体検出器が特定の確率で物体を検出した領域が定義されます。

> 💁 バウンディングボックスとは、検出された物体を含む領域を定義するボックスであり、物体の境界を定義するボックスです。

Custom Visionの**予測**タブで予測結果を見ると、送信された画像にバウンディングボックスが描かれています。

![棚にある4缶のトマトペースト。検出結果は35.8%、33.5%、25.7%、16.6%](../../../../../translated_images/custom-vision-stock-prediction.942266ab1bcca3410ecdf23643b9f5f570cfab2345235074e24c51f285777613.ja.png)

上記の画像では、4缶のトマトペーストが検出されています。結果には、画像内で検出された各物体に赤い四角が重ねられており、画像のバウンディングボックスを示しています。

✅ Custom Visionの予測を開き、バウンディングボックスを確認してください。

バウンディングボックスは、上部、左側、高さ、幅の4つの値で定義されます。これらの値は0〜1のスケールで、画像サイズの割合として位置を表します。原点（0,0位置）は画像の左上にあり、上部の値は上からの距離、バウンディングボックスの下部は上部に高さを加えた位置です。

![トマトペースト缶の周りのバウンディングボックス](../../../../../translated_images/bounding-box.1420a7ea0d3d15f71e1ffb5cf4b2271d184fac051f990abc541975168d163684.ja.png)

上記の画像は幅600ピクセル、高さ800ピクセルです。バウンディングボックスは320ピクセル下から始まり、上部座標は0.4（800 x 0.4 = 320）です。左側は240ピクセルから始まり、左座標は0.4（600 x 0.4 = 240）です。バウンディングボックスの高さは240ピクセルで、高さ値は0.3（800 x 0.3 = 240）です。幅は120ピクセルで、幅値は0.2（600 x 0.2 = 120）です。

| 座標      | 値    |
| ---------- | ----: |
| 上部       | 0.4   |
| 左側       | 0.4   |
| 高さ       | 0.3   |
| 幅         | 0.2   |

0〜1の割合値を使用することで、画像サイズがどのようにスケールされても、バウンディングボックスは0.4の位置から始まり、0.3の高さと0.2の幅を持ちます。

バウンディングボックスと確率を組み合わせて、検出の精度を評価することができます。例えば、物体検出器が重なり合う複数の物体を検出する場合、例えば1つの缶が別の缶の中にあると検出する場合があります。コードはバウンディングボックスを確認し、それが不可能であることを理解し、他の物体と大きく重なる物体を無視することができます。

![トマトペースト缶を重ねて検出する2つのバウンディングボックス](../../../../../translated_images/overlap-object-detection.d431e03cae75072a2760430eca7f2c5fdd43045bfd72dadcbf12711f7cd6c2ae.ja.png)

上記の例では、1つのバウンディングボックスが78.3%の確率でトマトペースト缶を予測しています。2つ目のバウンディングボックスは少し小さく、最初のバウンディングボックス内にあり、確率は64.3%です。コードはバウンディングボックスを確認し、それらが完全に重なっていることを確認し、低い確率を無視します。1つの缶が別の缶の中にあることはあり得ないからです。

✅ 1つの物体が別の物体の中にあることが有効な状況を考えられますか？

## モデルの再トレーニング

画像分類器と同様に、IoTデバイスで収集したデータを使用してモデルを再トレーニングすることができます。この実際のデータを使用することで、IoTデバイスで使用する際にモデルが適切に動作することを保証できます。

画像分類器とは異なり、画像にタグを付けるだけでは済みません。代わりに、モデルが検出したすべてのバウンディングボックスを確認する必要があります。ボックスが間違ったものを囲んでいる場合は削除する必要があり、位置が間違っている場合は調整する必要があります。

### タスク - モデルの再トレーニング

1. IoTデバイスを使用してさまざまな画像を収集してください。

1. **予測**タブから画像を選択します。検出された物体のバウンディングボックスが赤で表示されます。

1. 各バウンディングボックスを確認します。まず選択すると、タグが表示されるポップアップが表示されます。必要に応じてバウンディングボックスの角のハンドルを使用してサイズを調整します。タグが間違っている場合は、**X**ボタンで削除し、正しいタグを追加します。バウンディングボックスが物体を含んでいない場合は、ゴミ箱ボタンで削除します。

1. 編集が完了したらエディタを閉じ、画像は**予測**タブから**トレーニング画像**タブに移動します。このプロセスをすべての予測に対して繰り返します。

1. **トレーニング**ボタンを使用してモデルを再トレーニングします。トレーニングが完了したら、イテレーションを公開し、IoTデバイスを新しいイテレーションのURLを使用するように更新します。

1. コードを再デプロイし、IoTデバイスをテストします。

## 在庫を数える

検出された物体の数とバウンディングボックスを組み合わせて、棚の在庫を数えることができます。

### タスク - 在庫を数える

以下の関連ガイドに従って、IoTデバイスの物体検出器の結果を使用して在庫を数えてください：

* [Arduino - Wio Terminal](wio-terminal-count-stock.md)
* [シングルボードコンピュータ - Raspberry Pi/仮想デバイス](single-board-computer-count-stock.md)

---

## 🚀 チャレンジ

間違った在庫を検出できますか？複数の物体でモデルをトレーニングし、間違った在庫が検出された場合にアプリが通知するように更新してください。

さらに進めて、同じ棚に並んだ在庫を検出し、バウンディングボックスの制限を定義して、何かが間違った場所に置かれているかを確認してみてください。

## 講義後のクイズ

[講義後のクイズ](https://black-meadow-040d15503.1.azurestaticapps.net/quiz/40)

## 復習と自己学習

* [Microsoft Docsのエッジパターンガイド](https://docs.microsoft.com/hybrid/app-solutions/pattern-out-of-stock-at-edge?WT.mc_id=academic-17441-jabenn)で、エンドツーエンドの在庫検出システムを設計する方法について学びましょう。
* [YouTubeの「Behind the scenes of a retail solution - Hands On!」動画](https://www.youtube.com/watch?v=m3Pc300x2Mw)を視聴して、IoTとクラウドサービスを組み合わせたエンドツーエンドの小売ソリューションを構築する他の方法を学びましょう。

## 課題

[エッジで物体検出器を使用する](assignment.md)

**免責事項**:  
この文書は、AI翻訳サービス [Co-op Translator](https://github.com/Azure/co-op-translator) を使用して翻訳されています。正確性を追求しておりますが、自動翻訳には誤りや不正確な表現が含まれる可能性があることをご承知おきください。原文（元の言語で記載された文書）が公式な情報源として優先されるべきです。重要な情報については、専門の人間による翻訳を推奨します。本翻訳の使用に起因する誤解や誤認について、当方は一切の責任を負いません。