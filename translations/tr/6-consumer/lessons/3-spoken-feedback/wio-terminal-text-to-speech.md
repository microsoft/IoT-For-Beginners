<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "a202fa5889790a3777bfc33dd9f4b459",
  "translation_date": "2025-08-28T02:57:23+00:00",
  "source_file": "6-consumer/lessons/3-spoken-feedback/wio-terminal-text-to-speech.md",
  "language_code": "tr"
}
-->
# Metinden Sese - Wio Terminal

Bu dersin bu b칬l칲m칲nde, metni sese d칬n칲릆칲rerek sesli geri bildirim sa륿ayacaks캼n캼z.

## Metinden Sese

Bir 칬nceki derste konu릀ay캼 metne d칬n칲릆칲rmek i칞in kulland캼캼n캼z konu릀a hizmetleri SDK's캼, metni tekrar sese d칬n칲릆칲rmek i칞in de kullan캼labilir.

## Ses Listesi Almak

Konu릀a talep ederken, kullan캼lacak sesi belirtmeniz gerekir 칞칲nk칲 konu릀a, 칞e를tli farkl캼 sesler kullan캼larak olu릆urulabilir. Her dil, farkl캼 seslerden olu르n bir yelpazeyi destekler ve her dil i칞in desteklenen seslerin listesini konu릀a hizmetleri SDK's캼ndan alabilirsiniz. Ancak, mikrodenetleyicilerin s캼n캼rlamalar캼 burada devreye giriyor - metinden sese hizmetleri taraf캼ndan desteklenen seslerin listesini almak i칞in yap캼lan 칞ar캼, 77KB'den b칲y칲k bir JSON belgesidir ve bu, Wio Terminal taraf캼ndan i륿enemeyecek kadar b칲y칲kt칲r. Yaz캼m s캼ras캼nda, tam liste 215 ses i칞eriyor ve her biri a르캼daki gibi bir JSON belgesiyle tan캼mlan캼yor:

```json
{
    "Name": "Microsoft Server Speech Text to Speech Voice (en-US, AriaNeural)",
    "DisplayName": "Aria",
    "LocalName": "Aria",
    "ShortName": "en-US-AriaNeural",
    "Gender": "Female",
    "Locale": "en-US",
    "StyleList": [
        "chat",
        "customerservice",
        "narration-professional",
        "newscast-casual",
        "newscast-formal",
        "cheerful",
        "empathetic"
    ],
    "SampleRateHertz": "24000",
    "VoiceType": "Neural",
    "Status": "GA"
}
```

Bu JSON, birden fazla ses stiline sahip olan **Aria** sesi i칞indir. Metni sese d칬n칲릆칲r칲rken gereken tek 른y, `en-US-AriaNeural` gibi k캼sa isimdir.

Bu listenin tamam캼n캼 mikrodenetleyicinize indirip 칞칬z칲mlemek yerine, kulland캼캼n캼z dil i칞in ses listesini almak ve bunu Wio Terminal'den 칞a캼rmak i칞in biraz daha sunucusuz kod yazman캼z gerekecek. Kodunuz daha sonra listedeki uygun bir sesi, 칬rne를n buldu릇 ilk sesi se칞ebilir.

### G칬rev - Ses Listesi Almak i칞in Sunucusuz Bir Fonksiyon Olu릆urun

1. VS Code'da `smart-timer-trigger` projenizi a칞캼n ve sanal ortam캼n etkinle릆irildi를nden emin olarak terminali a칞캼n. De를lse, terminali kapat캼p yeniden olu릆urun.

1. `local.settings.json` dosyas캼n캼 a칞캼n ve konu릀a API anahtar캼 ve konumu i칞in ayarlar캼 ekleyin:

    ```json
    "SPEECH_KEY": "<key>",
    "SPEECH_LOCATION": "<location>"
    ```

    `<key>` k캼sm캼n캼 konu릀a hizmeti kayna캼n캼z캼n API anahtar캼yla de를릆irin. `<location>` k캼sm캼n캼 ise konu릀a hizmeti kayna캼n캼 olu릆urdu릇nuz konumla de를릆irin.

1. Bu uygulamaya `get-voices` ad캼nda yeni bir HTTP tetikleyici eklemek i칞in, VS Code terminalinde fonksiyon uygulamas캼 projesinin k칬k klas칬r칲nden a르캼daki komutu 칞al캼릆캼r캼n:

    ```sh
    func new --name get-voices --template "HTTP trigger"
    ```

    Bu, `get-voices` ad캼nda bir HTTP tetikleyici olu릆uracakt캼r.

1. `get-voices` klas칬r칲ndeki `__init__.py` dosyas캼n캼n i칞eri를ni a르캼dakiyle de를릆irin:

    ```python
    import json
    import os
    import requests
    
    import azure.functions as func
    
    def main(req: func.HttpRequest) -> func.HttpResponse:
        location = os.environ['SPEECH_LOCATION']
        speech_key = os.environ['SPEECH_KEY']
    
        req_body = req.get_json()
        language = req_body['language']
    
        url = f'https://{location}.tts.speech.microsoft.com/cognitiveservices/voices/list'
    
        headers = {
            'Ocp-Apim-Subscription-Key': speech_key
        }
    
        response = requests.get(url, headers=headers)
        voices_json = json.loads(response.text)
    
        voices = filter(lambda x: x['Locale'].lower() == language.lower(), voices_json)
        voices = map(lambda x: x['ShortName'], voices)
    
        return func.HttpResponse(json.dumps(list(voices)), status_code=200)
    ```

    Bu kod, sesleri almak i칞in bir HTTP iste를 yapar. Bu ses listesi, t칲m diller i칞in sesleri i칞eren b칲y칲k bir JSON blo릇dur, bu nedenle istek g칬vdesinde iletilen dil i칞in sesler filtrelenir, ard캼ndan k캼sa isim 칞캼kar캼l캼r ve bir JSON listesi olarak d칬nd칲r칲l칲r. Metni sese d칬n칲릆칲rmek i칞in gereken de른r k캼sa isimdir, bu nedenle yaln캼zca bu de른r d칬nd칲r칲l칲r.

    > 游누 Gerekirse, yaln캼zca istedi를niz sesleri se칞mek i칞in filtreyi de를릆irebilirsiniz.

    Bu, verilerin boyutunu yaz캼m s캼ras캼nda 77KB'den, 칞ok daha k칲칞칲k bir JSON belgesine indirir. 칐rne를n, ABD sesleri i칞in bu 408 baytt캼r.

1. Fonksiyon uygulaman캼z캼 yerel olarak 칞al캼릆캼r캼n. Daha sonra bunu, `text-to-timer` HTTP tetikleyicinizi test etti를niz gibi bir ara칞 (칬rne를n curl) kullanarak 칞a캼rabilirsiniz. Dilinizi bir JSON g칬vdesi olarak iletti를nizden emin olun:

    ```json
    {
        "language":"<language>"
    }
    ```

    `<language>` k캼sm캼n캼 dilinizle de를릆irin, 칬rne를n `en-GB` veya `zh-CN`.

> 游누 Bu kodu [code-spoken-response/functions](../../../../../6-consumer/lessons/3-spoken-feedback/code-spoken-response/functions) klas칬r칲nde bulabilirsiniz.

### G칬rev - Wio Terminal'inizden Sesi Al캼n

1. `smart-timer` projenizi VS Code'da a칞캼n (hen칲z a칞캼k de를lse).

1. `config.h` ba륿캼k dosyas캼n캼 a칞캼n ve fonksiyon uygulaman캼z캼n URL'sini ekleyin:

    ```cpp
    const char *GET_VOICES_FUNCTION_URL = "<URL>";
    ```

    `<URL>` k캼sm캼n캼, fonksiyon uygulaman캼zdaki `get-voices` HTTP tetikleyicisinin URL'siyle de를릆irin. Bu, `TEXT_TO_TIMER_FUNCTION_URL` de른riyle ayn캼 olacakt캼r, ancak `text-to-timer` yerine `get-voices` fonksiyon ad캼n캼 i칞erecektir.

1. `src` klas칬r칲nde `text_to_speech.h` ad캼nda yeni bir dosya olu릆urun. Bu, metni sese d칬n칲릆칲rmek i칞in bir s캼n캼f tan캼mlamak i칞in kullan캼lacakt캼r.

1. Yeni `text_to_speech.h` dosyas캼n캼n en 칲st칲ne a르캼daki include y칬nergelerini ekleyin:

    ```cpp
    #pragma once

    #include <Arduino.h>
    #include <ArduinoJson.h>
    #include <HTTPClient.h>
    #include <Seeed_FS.h>
    #include <SD/Seeed_SD.h>
    #include <WiFiClient.h>
    #include <WiFiClientSecure.h>
    
    #include "config.h"
    #include "speech_to_text.h"
    ```

1. Bu y칬nergelerin alt캼na, uygulaman캼n geri kalan캼nda kullan캼labilecek bir 칬rnekle birlikte `TextToSpeech` s캼n캼f캼n캼 bildiren a르캼daki kodu ekleyin:

    ```cpp
    class TextToSpeech
    {
    public:
    private:
    };
    
    TextToSpeech textToSpeech;
    ```

1. Fonksiyon uygulaman캼z캼 칞a캼rmak i칞in bir WiFi istemcisi bildirmeniz gerekir. S캼n캼f캼n `private` b칬l칲m칲ne a르캼dakileri ekleyin:

    ```cpp
    WiFiClient _client;
    ```

1. `private` b칬l칲m칲ne, se칞ilen ses i칞in bir alan ekleyin:

    ```cpp
    String _voice;
    ```

1. `public` b칬l칲m칲ne, ilk sesi alacak bir `init` fonksiyonu ekleyin:

    ```cpp
    void init()
    {
    }
    ```

1. Sesleri almak i칞in, dile sahip bir JSON belgesinin fonksiyon uygulamas캼na g칬nderilmesi gerekir. Bu JSON belgesini olu릆urmak i칞in `init` fonksiyonuna a르캼daki kodu ekleyin:

    ```cpp
    DynamicJsonDocument doc(1024);
    doc["language"] = LANGUAGE;

    String body;
    serializeJson(doc, body);
    ```

1. Ard캼ndan bir `HTTPClient` olu릆urun ve JSON belgesini g칬ndererek fonksiyon uygulamas캼n캼 칞a캼r캼n:

    ```cpp
    HTTPClient httpClient;
    httpClient.begin(_client, GET_VOICES_FUNCTION_URL);

    int httpResponseCode = httpClient.POST(body);
    ```

1. Bunun alt캼na, yan캼t kodunu kontrol eden ve e른r 200 (ba르r캼l캼) ise ses listesini 칞캼karan, listeden ilk sesi alan kodu ekleyin:

    ```cpp
    if (httpResponseCode == 200)
    {
        String result = httpClient.getString();
        Serial.println(result);

        DynamicJsonDocument doc(1024);
        deserializeJson(doc, result.c_str());

        JsonArray obj = doc.as<JsonArray>();
        _voice = obj[0].as<String>();

        Serial.print("Using voice ");
        Serial.println(_voice);
    }
    else
    {
        Serial.print("Failed to get voices - error ");
        Serial.println(httpResponseCode);
    }
    ```

1. Bunun ard캼ndan, HTTP istemci ba륿ant캼s캼n캼 sonland캼r캼n:

    ```cpp
    httpClient.end();
    ```

1. `main.cpp` dosyas캼n캼 a칞캼n ve bu yeni ba륿캼k dosyas캼n캼 dahil etmek i칞in en 칲ste a르캼daki include y칬nergesini ekleyin:

    ```cpp
    #include "text_to_speech.h"
    ```

1. `setup` fonksiyonunda, `speechToText.init();` 칞ar캼s캼n캼n alt캼na, `TextToSpeech` s캼n캼f캼n캼 ba륿atmak i칞in a르캼dakileri ekleyin:

    ```cpp
    textToSpeech.init();
    ```

1. Bu kodu derleyin, Wio Terminal'inize y칲kleyin ve seri monit칬r 칲zerinden test edin. Fonksiyon uygulaman캼z캼n 칞al캼릆캼캼ndan emin olun.

    Fonksiyon uygulamas캼ndan d칬nd칲r칲len mevcut seslerin listesini ve se칞ilen sesi g칬receksiniz.

    ```output
    --- Available filters and text transformations: colorize, debug, default, direct, hexlify, log2file, nocontrol, printable, send_on_enter, time
    --- More details at http://bit.ly/pio-monitor-filters
    --- Miniterm on /dev/cu.usbmodem1101  9600,8,N,1 ---
    --- Quit: Ctrl+C | Menu: Ctrl+T | Help: Ctrl+T followed by Ctrl+H ---
    Connecting to WiFi..
    Connected!
    Got access token.
    ["en-US-JennyNeural", "en-US-JennyMultilingualNeural", "en-US-GuyNeural", "en-US-AriaNeural", "en-US-AmberNeural", "en-US-AnaNeural", "en-US-AshleyNeural", "en-US-BrandonNeural", "en-US-ChristopherNeural", "en-US-CoraNeural", "en-US-ElizabethNeural", "en-US-EricNeural", "en-US-JacobNeural", "en-US-MichelleNeural", "en-US-MonicaNeural", "en-US-AriaRUS", "en-US-BenjaminRUS", "en-US-GuyRUS", "en-US-ZiraRUS"]
    Using voice en-US-JennyNeural
    Ready.
    ```

## Metni Sese D칬n칲릆칲rmek

Kullan캼lacak bir ses elde ettikten sonra, bu ses metni sese d칬n칲릆칲rmek i칞in kullan캼labilir. Sesleri d칬n칲릆칲r칲rken ayn캼 bellek s캼n캼rlamalar캼 ge칞erlidir, bu nedenle ses, ReSpeaker 칲zerinden 칞al캼nmak 칲zere SD karta yaz캼lmal캼d캼r.

> 游누 Bu projedeki 칬nceki derslerde, mikrofondan al캼nan konu릀ay캼 depolamak i칞in flash bellek kulland캼n캼z. Bu ders, Seeed ses k칲t칲phanelerini kullanarak SD karttan ses 칞alman캼n daha kolay olmas캼 nedeniyle bir SD kart kullan캼r.

Dikkate al캼nmas캼 gereken ba륾a bir s캼n캼rlama daha vard캼r: konu릀a hizmetinden al캼nan mevcut ses verileri ve Wio Terminal'in destekledi를 formatlar. Tam bilgisayarlar캼n aksine, mikrodenetleyiciler i칞in ses k칲t칲phaneleri destekledikleri ses formatlar캼nda 칞ok s캼n캼rl캼 olabilir. 칐rne를n, ReSpeaker 칲zerinden ses 칞alabilen Seeed Arduino Audio k칲t칲phanesi yaln캼zca 44.1KHz 칬rnekleme h캼z캼nda sesi destekler. Azure konu릀a hizmetleri bir dizi formatta ses sa륿ayabilir, ancak bunlar캼n hi칞biri bu 칬rnekleme h캼z캼n캼 kullanmaz; yaln캼zca 8KHz, 16KHz, 24KHz ve 48KHz sa륿ar. Bu, sesin 44.1KHz'ye yeniden 칬rneklenmesi gerekti를 anlam캼na gelir; bu, 칬zellikle bellek a칞캼s캼ndan Wio Terminal'in sahip oldu릇ndan daha fazla kayna르 ihtiya칞 duyar.

Bu t칲r verileri manip칲le etmeniz gerekti를nde, 칬zellikle veri bir web 칞ar캼s캼 yoluyla al캼n캼yorsa, sunucusuz kod kullanmak genellikle daha iyidir. Wio Terminal, d칬n칲릆칲r칲lecek metni ileten bir sunucusuz fonksiyonu 칞a캼rabilir ve sunucusuz fonksiyon hem konu릀a hizmetini 칞a캼rarak metni sese d칬n칲릆칲rebilir hem de sesi gerekli 칬rnekleme h캼z캼na yeniden 칬rnekleyebilir. Daha sonra sesi, Wio Terminal'in SD karta kaydetmesi ve ReSpeaker 칲zerinden 칞almas캼 i칞in gereken formatta d칬nd칲rebilir.

### G칬rev - Metni Sese D칬n칲릆칲rmek i칞in Sunucusuz Bir Fonksiyon Olu릆urun

1. VS Code'da `smart-timer-trigger` projenizi a칞캼n ve sanal ortam캼n etkinle릆irildi를nden emin olarak terminali a칞캼n. De를lse, terminali kapat캼p yeniden olu릆urun.

1. Bu uygulamaya `text-to-speech` ad캼nda yeni bir HTTP tetikleyici eklemek i칞in, VS Code terminalinde fonksiyon uygulamas캼 projesinin k칬k klas칬r칲nden a르캼daki komutu 칞al캼릆캼r캼n:

    ```sh
    func new --name text-to-speech --template "HTTP trigger"
    ```

    Bu, `text-to-speech` ad캼nda bir HTTP tetikleyici olu릆uracakt캼r.

1. [librosa](https://librosa.org) Pip paketi, sesi yeniden 칬rneklemek i칞in i륿evlere sahiptir, bu nedenle bunu `requirements.txt` dosyas캼na ekleyin:

    ```sh
    librosa
    ```

    Eklendikten sonra, VS Code terminalinden a르캼daki komutu kullanarak Pip paketlerini y칲kleyin:

    ```sh
    pip install -r requirements.txt
    ```

    > 丘멆잺 Linux, Raspberry Pi OS dahil, kullan캼yorsan캼z, a르캼daki komutla `libsndfile` y칲klemeniz gerekebilir:
    >
    > ```sh
    > sudo apt update
    > sudo apt install libsndfile1-dev
    > ```

1. Metni sese d칬n칲릆칲rmek i칞in, konu릀a API anahtar캼n캼 dorudan kullanamazs캼n캼z; bunun yerine, bir eri를m jetonu talep etmeniz gerekir. Bu talep, API anahtar캼n캼 kullanarak kimlik dorulamas캼 yapar. `text-to-speech` klas칬r칲ndeki `__init__.py` dosyas캼n캼 a칞캼n ve i칞indeki t칲m kodu a르캼dakiyle de를릆irin:

    ```python
    import io
    import os
    import requests
    
    import librosa
    import soundfile as sf
    import azure.functions as func
    
    location = os.environ['SPEECH_LOCATION']
    speech_key = os.environ['SPEECH_KEY']
    
    def get_access_token():
        headers = {
            'Ocp-Apim-Subscription-Key': speech_key
        }
    
        token_endpoint = f'https://{location}.api.cognitive.microsoft.com/sts/v1.0/issuetoken'
        response = requests.post(token_endpoint, headers=headers)
        return str(response.text)
    ```

    Bu, ayarlardan okunacak konum ve konu릀a anahtar캼 i칞in sabitler tan캼mlar. Daha sonra, konu릀a hizmeti i칞in bir eri를m jetonu alacak `get_access_token` fonksiyonunu tan캼mlar.

1. Bu kodun alt캼na a르캼dakileri ekleyin:

    ```python
    playback_format = 'riff-48khz-16bit-mono-pcm'

    def main(req: func.HttpRequest) -> func.HttpResponse:
        req_body = req.get_json()
        language = req_body['language']
        voice = req_body['voice']
        text = req_body['text']
    
        url = f'https://{location}.tts.speech.microsoft.com/cognitiveservices/v1'
    
        headers = {
            'Authorization': 'Bearer ' + get_access_token(),
            'Content-Type': 'application/ssml+xml',
            'X-Microsoft-OutputFormat': playback_format
        }
    
        ssml =  f'<speak version=\'1.0\' xml:lang=\'{language}\'>'
        ssml += f'<voice xml:lang=\'{language}\' name=\'{voice}\'>'
        ssml += text
        ssml += '</voice>'
        ssml += '</speak>'
    
        response = requests.post(url, headers=headers, data=ssml.encode('utf-8'))
    
        raw_audio, sample_rate = librosa.load(io.BytesIO(response.content), sr=48000)
        resampled = librosa.resample(raw_audio, sample_rate, 44100)
        
        output_buffer = io.BytesIO()
        sf.write(output_buffer, resampled, 44100, 'PCM_16', format='wav')
        output_buffer.seek(0)
    
        return func.HttpResponse(output_buffer.read(), status_code=200)
    ```

    Bu, metni sese d칬n칲릆칲ren HTTP tetikleyiciyi tan캼mlar. D칬n칲릆칲r칲lecek metni, dili ve sesi istekle g칬nderilen JSON g칬vdesinden 칞캼kar캼r, konu릀ay캼 talep etmek i칞in biraz SSML olu릆urur ve ard캼ndan eri를m jetonunu kullanarak ilgili REST API'yi 칞a캼r캼r. Bu REST API 칞ar캼s캼, 16-bit, 48KHz mono WAV dosyas캼 olarak kodlanm캼 sesi d칬nd칲r칲r; bu, `playback_format` de른rine g칬re REST API 칞ar캼s캼na g칬nderilir.

    Daha sonra bu ses, `librosa` taraf캼ndan 48KHz 칬rnekleme h캼z캼ndan 44.1KHz 칬rnekleme h캼z캼na yeniden 칬rneklenir ve ard캼ndan bu ses, d칬nd칲r칲len bir ikili tamponda saklan캼r.

1. Fonksiyon uygulaman캼z캼 yerel olarak 칞al캼릆캼r캼n veya buluta da캼t캼n. Daha sonra bunu, `text-to-timer` HTTP tetikleyicinizi test etti를niz gibi bir ara칞 (칬rne를n curl) kullanarak 칞a캼rabilirsiniz. Dil, ses ve metni JSON g칬vdesi olarak iletti를nizden emin olun:

    ```json
    {
        "language": "<language>",
        "voice": "<voice>",
        "text": "<text>"
    }
    ```

    `<language>` k캼sm캼n캼 dilinizle de를릆irin, 칬rne를n `en-GB` veya `zh-CN`. `<voice>` k캼sm캼n캼 kullanmak istedi를niz sesle de를릆irin. `<text>` k캼sm캼n캼 ise sese d칬n칲릆칲rmek istedi를niz metinle de를릆irin. 칂캼kt캼y캼 bir dosyaya kaydedebilir ve WAV dosyalar캼n캼 칞alabilen herhangi bir ses oynat캼c캼yla 칞alabilirsiniz.

    칐rne를n, "Hello" kelimesini ABD 캻ngilizcesi ile Jenny Neural sesi kullanarak sese d칬n칲릆칲rmek i칞in, fonksiyon uygulamas캼 yerel olarak 칞al캼캼rken a르캼daki curl komutunu kullanabilirsiniz:

    ```sh
    curl -X GET 'http://localhost:7071/api/text-to-speech' \
         -H 'Content-Type: application/json' \
         -o hello.wav \
         -d '{
           "language":"en-US",
           "voice": "en-US-JennyNeural",
           "text": "Hello"
         }'
    ```

    Bu, sesi `hello.wav` olarak ge칞erli dizine kaydedecektir.

> 游누 Bu kodu [code-spoken-response/functions](../../../../../6-consumer/lessons/3-spoken-feedback/code-spoken-response/functions) klas칬r칲nde bulabilirsiniz.

### G칬rev - Wio Terminal'inizden Konu릀ay캼 Al캼n

1. `smart-timer` projenizi VS Code'da a칞캼n (hen칲z a칞캼k de를lse).

1. `config.h` ba륿캼k dosyas캼n캼 a칞캼n ve fonksiyon uygulaman캼z캼n URL'sini ekleyin:

    ```cpp
    const char *TEXT_TO_SPEECH_FUNCTION_URL = "<URL>";
    ```

    `<URL>` k캼sm캼n캼, fonksiyon uygulaman캼zdaki `text-to-speech` HTTP tetikleyicisinin URL'siyle de를릆irin. Bu, `TEXT_TO_TIMER_FUNCTION_URL` de른riyle ayn캼 olacakt캼r, ancak `text-to-timer` yerine `text-to-speech` fonksiyon ad캼n캼 i칞erecektir.

1. `text_to_speech.h` ba륿캼k dosyas캼n캼 a칞캼n ve `TextToSpeech` s캼n캼f캼n캼n `public` b칬l칲m칲ne a르캼daki y칬ntemi ekleyin:

    ```cpp
    void convertTextToSpeech(String text)
    {
    }
    ```

1. `convertTextToSpeech` y칬ntemine, fonksiyon uygulamas캼na g칬nderilecek JSON'u olu릆urmak i칞in a르캼daki kodu ekleyin:

    ```cpp
    DynamicJsonDocument doc(1024);
    doc["language"] = LANGUAGE;
    doc["voice"] = _voice;
    doc["text"] = text;

    String body;
    serializeJson(doc, body);
    ```

    Bu, dili, sesi ve metni JSON belgesine yazar, ard캼ndan bunu bir dizeye serile릆irir.

1. Bunun alt캼na, fonksiyon uygulamas캼n캼 칞a캼rmak i칞in a르캼daki kodu ekleyin:

    ```cpp
    HTTPClient httpClient;
    httpClient.begin(_client, TEXT_TO_SPEECH_FUNCTION_URL);

    int httpResponseCode = httpClient.POST(body);
    ```

    Bu, bir HTTPClient olu릆urur ve JSON belgesini kullanarak metni sese d칬n칲릆칲rmek i칞in POST iste를 yapar.

1. 칂ar캼 ba르r캼l캼 olursa, fonksiyon uygulamas캼ndan d칬nd칲r칲len ham ikili veri, SD kartta bir dosyaya aktar캼labilir. Bunu yapmak i칞in a르캼daki kodu ekleyin:

    ```cpp
    if (httpResponseCode == 200)
    {            
        File wav_file = SD.open("SPEECH.WAV", FILE_WRITE);
        httpClient.writeToStream(&wav_file);
        wav_file.close();
    }
    else
    {
        Serial.print("Failed to get speech - error ");
        Serial.println(httpResponseCode);
    }
    ```

    Bu kod, yan캼t캼 kontrol eder ve e른r 200 (ba르r캼l캼) ise, ikili veriyi SD Kart캼n k칬k칲nde `SPEECH.WAV` adl캼 bir dosyaya aktar캼r.

1. Bu y칬ntemin sonunda, HTTP ba륿ant캼s캼n캼 kapat캼n:

    ```cpp
    httpClient.end();
    ```

1. Art캼k konu릇lacak metin sese d칬n칲릆칲r칲lebilir. `main.cpp` dosyas캼nda, `say` fonksiyonunun sonuna a르캼daki sat캼r캼 ekleyerek s칬ylenecek metni sese d칬n칲릆칲r칲n:
```cpp
    textToSpeech.convertTextToSpeech(text);
    ```

### G칬rev - Wio Terminal cihaz캼n캼zdan ses 칞al캼n

**Yak캼nda geliyor**

## Fonksiyon uygulaman캼z캼 buluta da캼tma

Fonksiyon uygulamas캼n캼 yerel olarak 칞al캼릆캼rman캼n sebebi, Linux'taki `librosa` Pip paketinin varsay캼lan olarak y칲kl칲 olmayan bir k칲t칲phaneye ba캼ml캼 olmas캼d캼r ve bu k칲t칲phane, fonksiyon uygulamas캼 칞al캼릀adan 칬nce y칲klenmelidir. Fonksiyon uygulamalar캼 sunucusuzdur - y칬netebilece를niz sunucular yoktur, dolay캼s캼yla bu k칲t칲phaneyi 칬nceden y칲klemenin bir yolu yoktur.

Bunun yerine, fonksiyon uygulaman캼z캼 bir Docker konteyneri kullanarak da캼tman캼z gerekir. Bu konteyner, bulut taraf캼ndan, fonksiyon uygulaman캼z캼n yeni bir 칬rne를ni ba륿atmas캼 gerekti를nde (칬rne를n, talep mevcut kaynaklar캼 a릆캼캼nda veya fonksiyon uygulamas캼 bir s칲redir kullan캼lmad캼캼 i칞in kapat캼ld캼캼nda) da캼t캼l캼r.

Bir fonksiyon uygulamas캼 olu릆urma ve Docker 칲zerinden da캼tma talimatlar캼n캼 [Microsoft Docs'taki 칬zel bir konteyner kullanarak Linux'ta bir fonksiyon olu릆urma dok칲man캼nda](https://docs.microsoft.com/azure/azure-functions/functions-create-function-linux-custom-image?WT.mc_id=academic-17441-jabenn&tabs=bash%2Cazurecli&pivots=programming-language-python) bulabilirsiniz.

Bu i륿em tamamland캼ktan sonra, Wio Terminal kodunuzu bu fonksiyona eri른cek 른kilde uyarlayabilirsiniz:

1. Azure Functions sertifikas캼n캼 `config.h` dosyas캼na ekleyin:

    ```cpp
    const char *FUNCTIONS_CERTIFICATE =
        "-----BEGIN CERTIFICATE-----\r\n"
        "MIIFWjCCBEKgAwIBAgIQDxSWXyAgaZlP1ceseIlB4jANBgkqhkiG9w0BAQsFADBa\r\n"
        "MQswCQYDVQQGEwJJRTESMBAGA1UEChMJQmFsdGltb3JlMRMwEQYDVQQLEwpDeWJl\r\n"
        "clRydXN0MSIwIAYDVQQDExlCYWx0aW1vcmUgQ3liZXJUcnVzdCBSb290MB4XDTIw\r\n"
        "MDcyMTIzMDAwMFoXDTI0MTAwODA3MDAwMFowTzELMAkGA1UEBhMCVVMxHjAcBgNV\r\n"
        "BAoTFU1pY3Jvc29mdCBDb3Jwb3JhdGlvbjEgMB4GA1UEAxMXTWljcm9zb2Z0IFJT\r\n"
        "QSBUTFMgQ0EgMDEwggIiMA0GCSqGSIb3DQEBAQUAA4ICDwAwggIKAoICAQCqYnfP\r\n"
        "mmOyBoTzkDb0mfMUUavqlQo7Rgb9EUEf/lsGWMk4bgj8T0RIzTqk970eouKVuL5R\r\n"
        "IMW/snBjXXgMQ8ApzWRJCZbar879BV8rKpHoAW4uGJssnNABf2n17j9TiFy6BWy+\r\n"
        "IhVnFILyLNK+W2M3zK9gheiWa2uACKhuvgCca5Vw/OQYErEdG7LBEzFnMzTmJcli\r\n"
        "W1iCdXby/vI/OxbfqkKD4zJtm45DJvC9Dh+hpzqvLMiK5uo/+aXSJY+SqhoIEpz+\r\n"
        "rErHw+uAlKuHFtEjSeeku8eR3+Z5ND9BSqc6JtLqb0bjOHPm5dSRrgt4nnil75bj\r\n"
        "c9j3lWXpBb9PXP9Sp/nPCK+nTQmZwHGjUnqlO9ebAVQD47ZisFonnDAmjrZNVqEX\r\n"
        "F3p7laEHrFMxttYuD81BdOzxAbL9Rb/8MeFGQjE2Qx65qgVfhH+RsYuuD9dUw/3w\r\n"
        "ZAhq05yO6nk07AM9c+AbNtRoEcdZcLCHfMDcbkXKNs5DJncCqXAN6LhXVERCw/us\r\n"
        "G2MmCMLSIx9/kwt8bwhUmitOXc6fpT7SmFvRAtvxg84wUkg4Y/Gx++0j0z6StSeN\r\n"
        "0EJz150jaHG6WV4HUqaWTb98Tm90IgXAU4AW2GBOlzFPiU5IY9jt+eXC2Q6yC/Zp\r\n"
        "TL1LAcnL3Qa/OgLrHN0wiw1KFGD51WRPQ0Sh7QIDAQABo4IBJTCCASEwHQYDVR0O\r\n"
        "BBYEFLV2DDARzseSQk1Mx1wsyKkM6AtkMB8GA1UdIwQYMBaAFOWdWTCCR1jMrPoI\r\n"
        "VDaGezq1BE3wMA4GA1UdDwEB/wQEAwIBhjAdBgNVHSUEFjAUBggrBgEFBQcDAQYI\r\n"
        "KwYBBQUHAwIwEgYDVR0TAQH/BAgwBgEB/wIBADA0BggrBgEFBQcBAQQoMCYwJAYI\r\n"
        "KwYBBQUHMAGGGGh0dHA6Ly9vY3NwLmRpZ2ljZXJ0LmNvbTA6BgNVHR8EMzAxMC+g\r\n"
        "LaArhilodHRwOi8vY3JsMy5kaWdpY2VydC5jb20vT21uaXJvb3QyMDI1LmNybDAq\r\n"
        "BgNVHSAEIzAhMAgGBmeBDAECATAIBgZngQwBAgIwCwYJKwYBBAGCNyoBMA0GCSqG\r\n"
        "SIb3DQEBCwUAA4IBAQCfK76SZ1vae4qt6P+dTQUO7bYNFUHR5hXcA2D59CJWnEj5\r\n"
        "na7aKzyowKvQupW4yMH9fGNxtsh6iJswRqOOfZYC4/giBO/gNsBvwr8uDW7t1nYo\r\n"
        "DYGHPpvnpxCM2mYfQFHq576/TmeYu1RZY29C4w8xYBlkAA8mDJfRhMCmehk7cN5F\r\n"
        "JtyWRj2cZj/hOoI45TYDBChXpOlLZKIYiG1giY16vhCRi6zmPzEwv+tk156N6cGS\r\n"
        "Vm44jTQ/rs1sa0JSYjzUaYngoFdZC4OfxnIkQvUIA4TOFmPzNPEFdjcZsgbeEz4T\r\n"
        "cGHTBPK4R28F44qIMCtHRV55VMX53ev6P3hRddJb\r\n"
        "-----END CERTIFICATE-----\r\n";
    ```

1. T칲m `<WiFiClient.h>` dahil etmelerini `<WiFiClientSecure.h>` ile de를릆irin.

1. T칲m `WiFiClient` alanlar캼n캼 `WiFiClientSecure` ile de를릆irin.

1. `WiFiClientSecure` alan캼na sahip her s캼n캼fta bir kurucu (constructor) ekleyin ve bu kurucuda sertifikay캼 ayarlay캼n:

    ```cpp
    _client.setCACert(FUNCTIONS_CERTIFICATE);
    ```

---

**Feragatname**:  
Bu belge, AI 칞eviri hizmeti [Co-op Translator](https://github.com/Azure/co-op-translator) kullan캼larak 칞evrilmi릆ir. Doruluk i칞in 칞aba g칬stersek de, otomatik 칞evirilerin hata veya yanl캼륿캼k i칞erebilece를ni l칲tfen unutmay캼n. Belgenin orijinal dili, yetkili kaynak olarak kabul edilmelidir. Kritik bilgiler i칞in profesyonel insan 칞evirisi 칬nerilir. Bu 칞evirinin kullan캼m캼ndan kaynaklanan yanl캼 anlamalar veya yanl캼 yorumlamalardan sorumlu de를liz.