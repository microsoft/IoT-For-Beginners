<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "606f3af1c78e3741e48ce77c31cea626",
  "translation_date": "2025-08-28T02:58:31+00:00",
  "source_file": "6-consumer/lessons/3-spoken-feedback/pi-text-to-speech.md",
  "language_code": "tr"
}
-->
# Metinden KonuÅŸmaya - Raspberry Pi

Bu dersin bu bÃ¶lÃ¼mÃ¼nde, konuÅŸma hizmetini kullanarak metni konuÅŸmaya dÃ¶nÃ¼ÅŸtÃ¼ren bir kod yazacaksÄ±nÄ±z.

## KonuÅŸma Hizmetini Kullanarak Metni KonuÅŸmaya DÃ¶nÃ¼ÅŸtÃ¼rme

Metin, IoT cihazÄ±nÄ±zda Ã§alÄ±nabilecek bir ses dosyasÄ± olarak konuÅŸma hizmetine REST API kullanÄ±larak gÃ¶nderilebilir. KonuÅŸma talep ederken, kullanÄ±lacak sesi belirtmeniz gerekir Ã§Ã¼nkÃ¼ konuÅŸma, farklÄ± sesler kullanÄ±larak oluÅŸturulabilir.

Her dil, Ã§eÅŸitli sesleri destekler ve her dil iÃ§in desteklenen seslerin listesini almak iÃ§in konuÅŸma hizmetine bir REST isteÄŸi gÃ¶nderebilirsiniz.

### GÃ¶rev - Bir Ses AlÄ±n

1. VS Code'da `smart-timer` projesini aÃ§Ä±n.

1. Bir dil iÃ§in ses listesini talep etmek Ã¼zere `say` fonksiyonunun Ã¼stÃ¼ne aÅŸaÄŸÄ±daki kodu ekleyin:

    ```python
    def get_voice():
        url = f'https://{location}.tts.speech.microsoft.com/cognitiveservices/voices/list'
    
        headers = {
            'Authorization': 'Bearer ' + get_access_token()
        }
    
        response = requests.get(url, headers=headers)
        voices_json = json.loads(response.text)
    
        first_voice = next(x for x in voices_json if x['Locale'].lower() == language.lower() and x['VoiceType'] == 'Neural')
        return first_voice['ShortName']
    
    voice = get_voice()
    print(f'Using voice {voice}')
    ```

    Bu kod, konuÅŸma hizmetini kullanarak bir ses listesi alan `get_voice` adlÄ± bir fonksiyon tanÄ±mlar. Daha sonra kullanÄ±lan dile uyan ilk sesi bulur.

    Bu fonksiyon, ilk sesi saklamak ve ses adÄ±nÄ± konsola yazdÄ±rmak iÃ§in Ã§aÄŸrÄ±lÄ±r. Bu ses bir kez talep edilebilir ve metni konuÅŸmaya dÃ¶nÃ¼ÅŸtÃ¼rmek iÃ§in yapÄ±lan her Ã§aÄŸrÄ±da kullanÄ±labilir.

    > ğŸ’ Desteklenen seslerin tam listesini [Microsoft Docs'taki Dil ve Ses DesteÄŸi dokÃ¼manÄ±ndan](https://docs.microsoft.com/azure/cognitive-services/speech-service/language-support?WT.mc_id=academic-17441-jabenn#text-to-speech) alabilirsiniz. Belirli bir sesi kullanmak istiyorsanÄ±z, bu fonksiyonu kaldÄ±rabilir ve bu dokÃ¼mandan ses adÄ±nÄ± sabit kodlayabilirsiniz. Ã–rneÄŸin:
    >
    > ```python
    > voice = 'hi-IN-SwaraNeural'
    > ```

### GÃ¶rev - Metni KonuÅŸmaya DÃ¶nÃ¼ÅŸtÃ¼rme

1. Bunun altÄ±na, konuÅŸma hizmetlerinden alÄ±nacak ses formatÄ± iÃ§in bir sabit tanÄ±mlayÄ±n. Ses talep ettiÄŸinizde, bunu farklÄ± formatlarda yapabilirsiniz.

    ```python
    playback_format = 'riff-48khz-16bit-mono-pcm'
    ```

    KullanabileceÄŸiniz format, donanÄ±mÄ±nÄ±za baÄŸlÄ±dÄ±r. EÄŸer sesi Ã§alarken `Invalid sample rate` (GeÃ§ersiz Ã¶rnekleme oranÄ±) hatalarÄ± alÄ±rsanÄ±z, bunu baÅŸka bir deÄŸere deÄŸiÅŸtirin. Desteklenen deÄŸerlerin listesini [Microsoft Docs'taki Metinden KonuÅŸmaya REST API dokÃ¼manÄ±nda](https://docs.microsoft.com/azure/cognitive-services/speech-service/rest-text-to-speech?WT.mc_id=academic-17441-jabenn#audio-outputs) bulabilirsiniz. `riff` formatÄ±nda ses kullanmanÄ±z gerekecek ve denemeniz gereken deÄŸerler `riff-16khz-16bit-mono-pcm`, `riff-24khz-16bit-mono-pcm` ve `riff-48khz-16bit-mono-pcm` olacaktÄ±r.

1. Bunun altÄ±na, konuÅŸma hizmeti REST API'sini kullanarak metni konuÅŸmaya dÃ¶nÃ¼ÅŸtÃ¼recek `get_speech` adlÄ± bir fonksiyon tanÄ±mlayÄ±n:

    ```python
    def get_speech(text):
    ```

1. `get_speech` fonksiyonunda, Ã§aÄŸrÄ±lacak URL'yi ve gÃ¶nderilecek baÅŸlÄ±klarÄ± tanÄ±mlayÄ±n:

    ```python
        url = f'https://{location}.tts.speech.microsoft.com/cognitiveservices/v1'
    
        headers = {
            'Authorization': 'Bearer ' + get_access_token(),
            'Content-Type': 'application/ssml+xml',
            'X-Microsoft-OutputFormat': playback_format
        }
    ```

    Bu, bir eriÅŸim jetonu oluÅŸturmak, iÃ§eriÄŸi SSML olarak ayarlamak ve gerekli ses formatÄ±nÄ± tanÄ±mlamak iÃ§in baÅŸlÄ±klarÄ± ayarlar.

1. Bunun altÄ±na, REST API'ye gÃ¶nderilecek SSML'yi tanÄ±mlayÄ±n:

    ```python
    ssml =  f'<speak version=\'1.0\' xml:lang=\'{language}\'>'
    ssml += f'<voice xml:lang=\'{language}\' name=\'{voice}\'>'
    ssml += text
    ssml += '</voice>'
    ssml += '</speak>'
    ```

    Bu SSML, kullanÄ±lacak dili ve sesi, ayrÄ±ca dÃ¶nÃ¼ÅŸtÃ¼rÃ¼lecek metni ayarlar.

1. Son olarak, bu fonksiyona REST isteÄŸi yapacak ve ikili ses verilerini dÃ¶ndÃ¼recek kodu ekleyin:

    ```python
    response = requests.post(url, headers=headers, data=ssml.encode('utf-8'))
    return io.BytesIO(response.content)
    ```

### GÃ¶rev - Sesi Ã‡alma

1. `get_speech` fonksiyonunun altÄ±na, REST API Ã§aÄŸrÄ±sÄ±ndan dÃ¶nen sesi Ã§almak iÃ§in yeni bir fonksiyon tanÄ±mlayÄ±n:

    ```python
    def play_speech(speech):
    ```

1. Bu fonksiyona geÃ§irilen `speech`, REST API'den dÃ¶nen ikili ses verisi olacaktÄ±r. Bu veriyi bir dalga dosyasÄ± olarak aÃ§mak ve PyAudio kullanarak Ã§almak iÃ§in aÅŸaÄŸÄ±daki kodu kullanÄ±n:

    ```python
    def play_speech(speech):
        with wave.open(speech, 'rb') as wave_file:
            stream = audio.open(format=audio.get_format_from_width(wave_file.getsampwidth()),
                                channels=wave_file.getnchannels(),
                                rate=wave_file.getframerate(),
                                output_device_index=speaker_card_number,
                                output=True)

            data = wave_file.readframes(4096)

            while len(data) > 0:
                stream.write(data)
                data = wave_file.readframes(4096)

            stream.stop_stream()
            stream.close()
    ```

    Bu kod, bir PyAudio akÄ±ÅŸÄ± kullanÄ±r; ses kaydetme iÅŸlemine benzer. Buradaki fark, akÄ±ÅŸÄ±n bir Ã§Ä±kÄ±ÅŸ akÄ±ÅŸÄ± olarak ayarlanmasÄ± ve ses verilerinden okunan verilerin akÄ±ÅŸa aktarÄ±lmasÄ±dÄ±r.

    AkÄ±ÅŸ detaylarÄ±nÄ± sabit kodlamak yerine, bunlar ses verilerinden okunur.

1. `say` fonksiyonunun iÃ§eriÄŸini aÅŸaÄŸÄ±dakiyle deÄŸiÅŸtirin:

    ```python
    speech = get_speech(text)
    play_speech(speech)
    ```

    Bu kod, metni ikili ses verisi olarak konuÅŸmaya dÃ¶nÃ¼ÅŸtÃ¼rÃ¼r ve sesi Ã§alar.

1. UygulamayÄ± Ã§alÄ±ÅŸtÄ±rÄ±n ve iÅŸlev uygulamasÄ±nÄ±n da Ã§alÄ±ÅŸtÄ±ÄŸÄ±ndan emin olun. BazÄ± zamanlayÄ±cÄ±lar ayarlayÄ±n; zamanlayÄ±cÄ±nÄ±zÄ±n ayarlandÄ±ÄŸÄ±nÄ± sÃ¶yleyen bir sesli yanÄ±t ve zamanlayÄ±cÄ± tamamlandÄ±ÄŸÄ±nda baÅŸka bir sesli yanÄ±t duyacaksÄ±nÄ±z.

    EÄŸer `Invalid sample rate` hatalarÄ± alÄ±rsanÄ±z, yukarÄ±da aÃ§Ä±klandÄ±ÄŸÄ± gibi `playback_format` deÄŸerini deÄŸiÅŸtirin.

> ğŸ’ Bu kodu [code-spoken-response/pi](../../../../../6-consumer/lessons/3-spoken-feedback/code-spoken-response/pi) klasÃ¶rÃ¼nde bulabilirsiniz.

ğŸ˜€ ZamanlayÄ±cÄ± programÄ±nÄ±z baÅŸarÄ±lÄ± oldu!

---

**Feragatname**:  
Bu belge, AI Ã§eviri hizmeti [Co-op Translator](https://github.com/Azure/co-op-translator) kullanÄ±larak Ã§evrilmiÅŸtir. DoÄŸruluk iÃ§in Ã§aba gÃ¶stersek de, otomatik Ã§evirilerin hata veya yanlÄ±ÅŸlÄ±klar iÃ§erebileceÄŸini lÃ¼tfen unutmayÄ±n. Belgenin orijinal dili, yetkili kaynak olarak kabul edilmelidir. Kritik bilgiler iÃ§in profesyonel insan Ã§evirisi Ã¶nerilir. Bu Ã§evirinin kullanÄ±mÄ±ndan kaynaklanan yanlÄ±ÅŸ anlamalar veya yanlÄ±ÅŸ yorumlamalardan sorumlu deÄŸiliz.